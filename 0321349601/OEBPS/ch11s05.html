<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Example: Comparing Map Performance</title><link rel="stylesheet" href="styles/convert.css" type="text/css"/></head><body><div class="section" title="Example: Comparing Map Performance"><div class="titlepage"><div><div><h2 class="title"><a id="ch11lev1sec5"/>Example: Comparing Map Performance</h2></div></div></div>

<p>The single-threaded performance of <code class="literal">ConcurrentHashMap</code> is slightly better than that of a synchronized <code class="literal">HashMap</code>, but it is in concurrent use that it really shines. The implementation of <code class="literal">ConcurrentHashMap</code> assumes the most common operation is retrieving a value that already exists, and is therefore optimized to provide highest performance and concurrency for successful <code class="literal">get</code> operations.</p>
<p>The major scalability impediment for the synchronized <code class="literal">Map</code> implementations is that there is a single lock for the entire map, so only one thread can access the map at a time. On the other hand, <code class="literal">ConcurrentHashMap</code> does no locking for most successful read operations, and uses lock striping for write operations and those few read operations that do require locking. As a result, multiple threads can access the <code class="literal">Map</code> concurrently without blocking.</p>
<p><a class="link" href="ch11s05.html#ch11fig03" title="Figure 11.3. Comparing Scalability of Map Implementations.">Figure 11.3</a> illustrates the differences in scalability between several <code class="literal">Map</code> implementations: <code class="literal">ConcurrentHashMap</code>, <code class="literal">ConcurrentSkipListMap</code>, and <code class="literal">HashMap</code> and <code class="literal">TreeMap</code> wrapped with <code class="literal">synchronizedMap</code>. The first two are thread-safe by design; the latter two are made thread-safe by the synchronized wrapper. In each run, <span class="emphasis"><em>N</em></span> threads concurrently execute a tight loop that selects a random key and attempts to retrieve the value corresponding to that key. If the value is not present, it is added to the <code class="literal">Map</code> with probability <span class="emphasis"><em>p</em></span> = .6, and if it is present, is removed with probability <span class="emphasis"><em>p</em></span> = .02. The tests were run under a pre-release build of Java 6 on an 8-way Sparc V880, and the graph displays throughput normalized to the onethread case for <code class="literal">ConcurrentHashMap</code>. (The scalability gap between the concurrent and synchronized collections is even larger on Java 5.0.)</p>
<p>The data for <code class="literal">ConcurrentHashMap</code> and <code class="literal">ConcurrentSkipListMap</code> shows that they scale well to large numbers of threads; throughput continues to improve as threads are added. While the numbers of threads in <a class="link" href="ch11s05.html#ch11fig03" title="Figure 11.3. Comparing Scalability of Map Implementations.">Figure 11.3</a> may not seem large, this test program generates more contention per thread than a typical application because it does little other than pound on the <code class="literal">Map</code>; a real program would do additional thread-local work in each iteration.</p>
<div class="figure-float"><div class="figure"><a id="ch11fig03"/><p class="title"><b>Figure 11.3. Comparing Scalability of <code class="literal">Map</code> Implementations.</b></p><div class="figure-contents">


<div class="mediaobject"><img src="graphics/11fig03.gif" height="229" alt="Comparing Scalability of Map Implementations."/></div>
</div></div><br class="figure-break"/></div>
<p>The numbers for the synchronized collections are not as encouraging. Performance for the one-thread case is comparable to <code class="literal">ConcurrentHashMap</code>, but once the load transitions from mostly uncontended to mostly contended—which happens here at two threads—the synchronized collections suffer badly. This is common behavior for code whose scalability is limited by lock contention. So long as contention is low, time per operation is dominated by the time to actually do the work and throughput may improve as threads are added. Once contention becomes significant, time per operation is dominated by context switch and scheduling delays, and adding more threads has little effect on throughput.</p>
</div></body></html>
