<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Fairness</title><link rel="stylesheet" href="styles/convert.css" type="text/css"/></head><body><div class="section" title="Fairness"><div class="titlepage"><div><div><h2 class="title"><a id="ch13lev1sec3"/>Fairness</h2></div></div></div>

<p>The <code class="literal">ReentrantLock</code> constructor offers a choice of two <span class="emphasis"><em>fairness</em></span> options: create a <span class="emphasis"><em>nonfair</em></span> lock (the default) or a <span class="emphasis"><em>fair</em></span> lock. Threads acquire a fair lock in the order in which they requested it, whereas a nonfair lock permits <span class="emphasis"><em>barging</em></span>: threads requesting a lock can jump ahead of the queue of waiting threads if the lock happens to be available when it is requested. (<code class="literal">Semaphore</code> also offers the choice of fair or nonfair acquisition ordering.) Nonfair <code class="literal">ReentrantLock</code>s do not go out of their way to promote barging—they simply don’t prevent a thread from barging if it shows up at the right time. With a fair lock, a newly requesting thread is queued if the lock is held by another thread or if threads are queued waiting for the lock; with a nonfair lock, the thread is queued only if the lock is currently held.<sup>[<a id="ch13fn04" href="#ftn.ch13fn04" class="footnote">4</a>]</sup></p>
<p>Wouldn’t we want all locks to be fair? After all, fairness is good and unfairness is bad, right? (Just ask your kids.) When it comes to locking, though, fairness has a significant performance cost because of the overhead of suspending and resuming threads. In practice, a statistical fairness guarantee—promising that a blocked thread will <span class="emphasis"><em>eventually</em></span> acquire the lock—is often good enough, and is far less expensive to deliver. Some algorithms rely on fair queueing to ensure their <a id="iddle1188" class="indexterm"/><a id="iddle3493" class="indexterm"/>correctness, but these are unusual. In most cases, the performance benefits of nonfair locks outweigh the benefits of fair queueing.</p>
<p><a class="link" href="ch13s03.html#ch13fig02" title="Figure 13.2. Fair Versus Nonfair Lock Performance.">Figure 13.2</a> shows another run of the <code class="literal">Map</code> performance test, this time comparing <code class="literal">HashMap</code> wrapped with fair and nonfair <code class="literal">ReentrantLock</code>s on a four-way Opteron system running Solaris, plotted on a log scale.<sup>[<a id="ch13fn05" href="#ftn.ch13fn05" class="footnote">5</a>]</sup> The fairness penalty is nearly two orders of magnitude. <span class="emphasis"><em>Don’t pay for fairness if you don’t need it.</em></span></p>
<div class="figure-float"><div class="figure"><a id="ch13fig02"/><p class="title"><b>Figure 13.2. Fair Versus Nonfair Lock Performance.</b></p><div class="figure-contents">


<div class="mediaobject"><img src="graphics/13fig02.gif" height="261" alt="Fair Versus Nonfair Lock Performance."/></div>
</div></div><br class="figure-break"/></div>
<p>One reason barging locks perform so much better than fair locks under heavy contention is that there can be a significant delay between when a suspended thread is resumed and when it actually runs. Let’s say thread <span class="emphasis"><em>A</em></span> holds a lock and thread <span class="emphasis"><em>B</em></span> asks for that lock. Since the lock is busy, <span class="emphasis"><em>B</em></span> is suspended. When <span class="emphasis"><em>A</em></span> releases the lock, <span class="emphasis"><em>B</em></span> is resumed so it can try again. In the meantime, though, if thread <span class="emphasis"><em>C</em></span> requests the lock, there is a good chance that <span class="emphasis"><em>C</em></span> can acquire the lock, use it, and release it before <span class="emphasis"><em>B</em></span> even finishes waking up. In this case, everyone wins: <span class="emphasis"><em>B</em></span> gets the lock no later than it otherwise would have, <span class="emphasis"><em>C</em></span> gets it much earlier, and throughput is improved.</p>
<p>Fair locks tend to work best when they are held for a relatively long time or when the mean time between lock requests is relatively long. In these cases, the condition under which barging provides a throughput advantage—when the lock is unheld but a thread is currently waking up to claim it—is less likely to hold.</p>
<p><a id="iddle1834" class="indexterm"/><a id="iddle1835" class="indexterm"/><a id="iddle2543" class="indexterm"/><a id="iddle2833" class="indexterm"/><a id="iddle3109" class="indexterm"/><a id="iddle4769" class="indexterm"/>Like the default <code class="literal">ReentrantLock</code>, intrinsic locking offers no deterministic fairness guarantees, but the statistical fairness guarantees of most locking implementations are good enough for almost all situations. The language specification does not require the JVM to implement intrinsic locks fairly, and no production JVMs do. <code class="literal">ReentrantLock</code> does not depress lock fairness to new lows—it only makes explicit something that was present all along.</p>
<div class="footnotes"><br/><hr/><div class="footnote"><p><sup>[<a id="ftn.ch13fn04" href="#ch13fn04" class="para">4</a>] </sup>The polled <code class="literal">tryLock</code> always barges, even for fair locks.</p></div><div class="footnote"><p><sup>[<a id="ftn.ch13fn05" href="#ch13fn05" class="para">5</a>] </sup>The graph for <code class="literal">ConcurrentHashMap</code> is fairly wiggly in the region between four and eight threads. These variations almost certainly come from measurement noise, which could be introduced by coincidental interactions with the hash codes of the elements, thread scheduling, map resizing, garbage collection or other memory-system effects, or by the OS deciding to run some periodic housekeeping task around the time that test case ran. The reality is that there are all sorts of variations in performance tests that usually aren’t worth bothering to control. We made no attempt to clean up our graphs artificially, because real-world performance measurements are also full of noise.</p></div></div></div></body></html>
