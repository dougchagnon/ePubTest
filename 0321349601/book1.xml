<?xml version="1.0" encoding="utf-8"?><?variable name="target" value="default"?>
<book fpi="0321349601">
<title>Java Concurrency in Practice</title>


<preface condition="vi" id="copyrightp1g" role="copyrightpg"><title>Copyright</title>

<para><?docpage num="vi"?>Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this book, and the publisher was aware of a trademark claim, the designations have been printed with initial capital letters or in all capitals.</para>
<para>The authors and publisher have taken care in the preparation of this book, but make no expressed or implied warranty of any kind and assume no responsibility for errors or omissions. No liability is assumed for incidental or consequential damages in connection with or arising out of the use of the information or programs contained herein.</para>
<para>The publisher offers excellent discounts on this book when ordered in quantity for bulk purchases or special sales, which may include electronic versions and/or custom covers and content particular to your business, training goals, marketing focus, and branding interests. For more information, please contact:</para>
<blockquote>
<para>U.S. Corporate and Government Sales<?lb?>(800) 382-3419<?lb?>corpsales@pearsontechgroup.com</para>
</blockquote>
<para>For sales outside the United States, please contact:</para>
<blockquote>
<para>International Sales<?lb?>international@pearsoned.com</para>
</blockquote>
<para>Visit us on the Web: <ulink url="http://www.awprofessional.com">www.awprofessional.com</ulink></para>
<literallayout class="normal" format="linespecific"><?lb?><emphasis>Library of Congress Cataloging-in-Publication Data</emphasis><?lb?><?lb?>Goetz, Brian.<?lb?> Java Concurrency in Practice / Brian Goetz, with Tim Peierls. . . [et al.]<?lb?>      p. cm.<?lb?> Includes bibliographical references and index.<?lb?> ISBN 0-321-34960-1 (pbk. : alk. paper)<?lb?>1. Java (Computer program language) 2. Parallel programming (Computer science) 3. Threads (Computer<?lb?>programs) I. Title.<?lb?>  QA76.73.J38G588 2006<?lb?>  005.13'3--dc22                                                        2006012205<?lb?></literallayout>
<para>Copyright © 2006 Pearson Education, Inc.</para>
<para>Text printed in the United States on recycled paper at Courier in Stoughton, Massachusetts.</para>
<para>9th Printing March 2010</para>
<section id="ded01" condition="vii"><?docpage num="vii"?>
<?docpage num="vii"?>
<title id="ded01__title">Dedication</title>
<para><emphasis>To Jessica</emphasis></para>
</section>
</preface>

<preface id="pref01" condition="i"><title id="pref01__title">Advance Praise for <emphasis>Java Concurrency in Practice</emphasis></title>
<?docpage num="i"?>

<blockquote>
<attribution><emphasis>Martin Buchholz<?lb?>JDK Concurrency Czar, Sun Microsystems</emphasis></attribution>
<para>I was fortunate indeed to have worked with a fantastic team on the design and implementation of the concurrency features added to the Java platform in Java 5.0 and Java 6. Now this same team provides the best explanation yet of these new features, and of concurrency in general. Concurrency is no longer a subject for advanced users only. Every Java developer should read this book.</para>
</blockquote>
<blockquote>
<attribution><emphasis>Doron Rajwan<?lb?>Research Scientist, Intel Corp</emphasis></attribution>
<para>For the past 30 years, computer performance has been driven by Moore’s Law; from now on, it will be driven by Amdahl’s Law. Writing code that effectively exploits multiple processors can be very challenging. <emphasis>Java Concurrency in Practice</emphasis> provides you with the concepts and techniques needed to write safe and scalable Java programs for today’s—and tomorrow’s—systems.</para>
</blockquote>
<blockquote>
<attribution><emphasis>Ted Neward<?lb?>Author of</emphasis> Effective Enterprise Java</attribution>
<para>This is the book you need if you’re writing—or designing, or debugging, or maintaining, or contemplating—multithreaded Java programs. If you’ve ever had to synchronize a method and you weren’t sure why, you owe it to yourself and your users to read this book, cover to cover.</para>
</blockquote>
<blockquote>
<attribution><emphasis>Kirk Pepperdine<?lb?>CTO, JavaPerformanceTuning.com</emphasis></attribution>
<para>Brian addresses the fundamental issues and complexities of concurrency with uncommon clarity. This book is a must-read for anyone who uses threads and cares about performance.</para>
</blockquote>
<blockquote>
<attribution><emphasis>Dr. Cliff Click<?lb?>Senior Software Engineer, Azul Systems</emphasis></attribution>
<para>This book covers a very deep and subtle topic in a very clear and concise way, making it the perfect Java Concurrency reference manual. Each page is filled with the problems (and solutions!) that programmers struggle with every day. Effectively exploiting concurrency is becoming more and more important now that Moore’s Law is delivering more cores but not faster cores, and this book will show you how to do it.</para>
</blockquote>
<blockquote>
<attribution><emphasis>Dr. Heinz Kabutz<?lb?>The Java Specialists’ Newsletter</emphasis></attribution>
<para><?docpage num="ii"?>I have a strong interest in concurrency, and have probably written more thread deadlocks and made more synchronization mistakes than most programmers. Brian’s book is the most readable on the topic of threading and concurrency in Java, and deals with this difficult subject with a wonderful hands-on approach. This is a book I am recommending to all my readers of The Java Specialists’ Newsletter, because it is interesting, useful, and relevant to the problems facing Java developers today.</para>
</blockquote>
<blockquote>
<attribution><emphasis>Bruce Tate<?lb?>Author of</emphasis> Beyond Java</attribution>
<para>I’ve focused a career on simplifying simple problems, but this book ambitiously and effectively works to simplify a complex but critical subject: concurrency. <emphasis>Java Concurrency in Practice</emphasis> is revolutionary in its approach, smooth and easy in style, and timely in its delivery—it’s destined to be a very important book.</para>
</blockquote>
<blockquote>
<attribution><emphasis>Bill Venners<?lb?>Author of</emphasis> Inside the Java Virtual Machine</attribution>
<para><emphasis>Java Concurrency in Practice</emphasis> is an invaluable compilation of threading know-how for Java developers. I found reading this book intellectually exciting, in part because it is an excellent introduction to Java’s concurrency API, but mostly because it captures in a thorough and accessible way expert knowledge on threading not easily found elsewhere.</para>
</blockquote>
</preface>
<preface id="pref02" condition="xii"><title id="pref02__title">Listings</title>
<?docpage num="xii"?>

<informaltable float="0" frame="none">
<?docpage num="xiii"?><?docpagerange xiii - xvi?><tgroup align="left" cols="3" colsep="0" rowsep="0">
<colspec colname="c1" colnum="1" colwidth="50"/>
<colspec colname="c2" colnum="2" colwidth="400"/>
<colspec colname="c3" colnum="3" colwidth="50"/>
<tbody>
<row>
<entry valign="top"><para>1</para></entry>
<entry valign="top"><para><link linkend="pref03list01" preference="0">Bad way to sort a list. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>xix</para></entry>
</row>
<row>
<entry valign="top"><para>2</para></entry>
<entry valign="top"><para><link linkend="pref03list01" preference="0">Less than optimal way to sort a list</link></para></entry>
<entry valign="top"><para>xx</para></entry>
</row>
<row>
<entry valign="top"><para>1.1</para></entry>
<entry valign="top"><para><link linkend="ch01list01" preference="0">Non-thread-safe sequence generator</link></para></entry>
<entry valign="top"><para>6</para></entry>
</row>
<row>
<entry valign="top"><para>1.2</para></entry>
<entry valign="top"><para><link linkend="ch01list02" preference="0">Thread-safe sequence generator</link></para></entry>
<entry valign="top"><para>7</para></entry>
</row>
<row>
<entry valign="top"><para>2.1</para></entry>
<entry valign="top"><para><link linkend="ch02list01" preference="0">A stateless servlet</link></para></entry>
<entry valign="top"><para>18</para></entry>
</row>
<row>
<entry valign="top"><para>2.2</para></entry>
<entry valign="top"><para><link linkend="ch02list02" preference="0">Servlet that counts requests without the necessary synchronization. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>19</para></entry>
</row>
<row>
<entry valign="top"><para>2.3</para></entry>
<entry valign="top"><para><link linkend="ch02list03" preference="0">Race condition in lazy initialization. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>21</para></entry>
</row>
<row>
<entry valign="top"><para>2.4</para></entry>
<entry valign="top"><para><link linkend="ch02list04" preference="0">Servlet that counts requests using <literal>AtomicLong</literal></link></para></entry>
<entry valign="top"><para>23</para></entry>
</row>
<row>
<entry valign="top"><para>2.5</para></entry>
<entry valign="top"><para><link linkend="ch02list05" preference="0">Servlet that attempts to cache its last result without adequate atomicity. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>24</para></entry>
</row>
<row>
<entry valign="top"><para>2.6</para></entry>
<entry valign="top"><para><link linkend="ch02list06" preference="0">Servlet that caches last result, but with unnacceptably poor concurrency. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>26</para></entry>
</row>
<row>
<entry valign="top"><para>2.7</para></entry>
<entry valign="top"><para><link linkend="ch02list07" preference="0">Code that would deadlock if intrinsic locks were not reentrant</link></para></entry>
<entry valign="top"><para>27</para></entry>
</row>
<row>
<entry valign="top"><para>2.8</para></entry>
<entry valign="top"><para><link linkend="ch02list08" preference="0">Servlet that caches its last request and result</link></para></entry>
<entry valign="top"><para>31</para></entry>
</row>
<row>
<entry valign="top"><para>3.1</para></entry>
<entry valign="top"><para><link linkend="ch03list01" preference="0">Sharing variables without synchronization. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>34</para></entry>
</row>
<row>
<entry valign="top"><para>3.2</para></entry>
<entry valign="top"><para><link linkend="ch03list02" preference="0">Non-thread-safe mutable integer holder</link></para></entry>
<entry valign="top"><para>36</para></entry>
</row>
<row>
<entry valign="top"><para>3.3</para></entry>
<entry valign="top"><para><link linkend="ch03list03" preference="0">Thread-safe mutable integer holder</link></para></entry>
<entry valign="top"><para>36</para></entry>
</row>
<row>
<entry valign="top"><para>3.4</para></entry>
<entry valign="top"><para><link linkend="ch03list04" preference="0">Counting sheep</link></para></entry>
<entry valign="top"><para>39</para></entry>
</row>
<row>
<entry valign="top"><para>3.5</para></entry>
<entry valign="top"><para><link linkend="ch03list05" preference="0">Publishing an object</link></para></entry>
<entry valign="top"><para>40</para></entry>
</row>
<row>
<entry valign="top"><para>3.6</para></entry>
<entry valign="top"><para><link linkend="ch03list06" preference="0">Allowing internal mutable state to escape. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>40</para></entry>
</row>
<row>
<entry valign="top"><para>3.7</para></entry>
<entry valign="top"><para><link linkend="ch03list07" preference="0">Implicitly allowing the <literal>this</literal> reference to escape. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>41</para></entry>
</row>
<row>
<entry valign="top"><para>3.8</para></entry>
<entry valign="top"><para><link linkend="ch03list08" preference="0">Using a factory method to prevent the <literal>this</literal> reference from escaping during construction</link></para></entry>
<entry valign="top"><para>42</para></entry>
</row>
<row>
<entry valign="top"><para>3.9</para></entry>
<entry valign="top"><para><link linkend="ch03list09" preference="0">Thread confinement of local primitive and reference variables</link></para></entry>
<entry valign="top"><para>44</para></entry>
</row>
<row>
<entry valign="top"><para>3.10</para></entry>
<entry valign="top"><para><link linkend="ch03list10" preference="0">Using <literal>ThreadLocal</literal> to ensure thread confinement</link></para></entry>
<entry valign="top"><para>45</para></entry>
</row>
<row>
<entry valign="top"><para>3.11</para></entry>
<entry valign="top"><para><link linkend="ch03list11" preference="0">Immutable class built out of mutable underlying objects</link></para></entry>
<entry valign="top"><para>47</para></entry>
</row>
<row>
<entry valign="top"><para>3.12</para></entry>
<entry valign="top"><para><link linkend="ch03list12" preference="0">Immutable holder for caching a number and its factors</link></para></entry>
<entry valign="top"><para>49</para></entry>
</row>
<row>
<entry valign="top"><para>3.13</para></entry>
<entry valign="top"><para><link linkend="ch03list13" preference="0">Caching the last result using a volatile reference to an immutable holder object</link></para></entry>
<entry valign="top"><para>50</para></entry>
</row>
<row>
<entry valign="top"><para>3.14</para></entry>
<entry valign="top"><para><link linkend="ch03list14" preference="0">Publishing an object without adequate synchronization. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>50</para></entry>
</row>
<row>
<entry valign="top"><para>3.15</para></entry>
<entry valign="top"><para><link linkend="ch03list15" preference="0">Class at risk of failure if not properly published</link></para></entry>
<entry valign="top"><para>51</para></entry>
</row>
<row>
<entry valign="top"><para>4.1</para></entry>
<entry valign="top"><para><link linkend="ch04list01" preference="0">Simple thread-safe counter using the Java monitor pattern</link></para></entry>
<entry valign="top"><para>56</para></entry>
</row>
<row>
<entry valign="top"><para>4.2</para></entry>
<entry valign="top"><para><link linkend="ch04list02" preference="0">Using confinement to ensure thread safety</link></para></entry>
<entry valign="top"><para>59</para></entry>
</row>
<row>
<entry valign="top"><para>4.3</para></entry>
<entry valign="top"><para><link linkend="ch04list03" preference="0">Guarding state with a private lock</link></para></entry>
<entry valign="top"><para>61</para></entry>
</row>
<row>
<entry valign="top"><para><?docpage num="xiii"?>4.4</para></entry>
<entry valign="top"><para><link linkend="ch04list04" preference="0">Monitor-based vehicle tracker implementation</link></para></entry>
<entry valign="top"><para>63</para></entry>
</row>
<row>
<entry valign="top"><para>4.5</para></entry>
<entry valign="top"><para><link linkend="ch04list05" preference="0">Mutable point class similar to <literal>java.awt.Point</literal></link></para></entry>
<entry valign="top"><para>64</para></entry>
</row>
<row>
<entry valign="top"><para>4.6</para></entry>
<entry valign="top"><para><link linkend="ch04list06" preference="0">Immutable <literal>Point</literal> class used by <literal>DelegatingVehicleTracker</literal></link></para></entry>
<entry valign="top"><para>64</para></entry>
</row>
<row>
<entry valign="top"><para>4.7</para></entry>
<entry valign="top"><para><link linkend="ch04list07" preference="0">Delegating thread safety to a <literal>ConcurrentHashMap</literal></link></para></entry>
<entry valign="top"><para>65</para></entry>
</row>
<row>
<entry valign="top"><para>4.8</para></entry>
<entry valign="top"><para><link linkend="ch04list08" preference="0">Returning a static copy of the location set instead of a “live” one</link></para></entry>
<entry valign="top"><para>66</para></entry>
</row>
<row>
<entry valign="top"><para>4.9</para></entry>
<entry valign="top"><para><link linkend="ch04list09" preference="0">Delegating thread safety to multiple underlying state variables</link></para></entry>
<entry valign="top"><para>66</para></entry>
</row>
<row>
<entry valign="top"><para>4.10</para></entry>
<entry valign="top"><para><link linkend="ch04list10" preference="0">Number range class that does not sufficiently protect its invariants. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>67</para></entry>
</row>
<row>
<entry valign="top"><para>4.11</para></entry>
<entry valign="top"><para><link linkend="ch04list11" preference="0">Thread-safe mutable point class</link></para></entry>
<entry valign="top"><para>69</para></entry>
</row>
<row>
<entry valign="top"><para>4.12</para></entry>
<entry valign="top"><para><link linkend="ch04list12" preference="0">Vehicle tracker that safely publishes underlying state</link></para></entry>
<entry valign="top"><para>70</para></entry>
</row>
<row>
<entry valign="top"><para>4.13</para></entry>
<entry valign="top"><para><link linkend="ch04list13" preference="0">Extending <literal>Vector</literal> to have a put-if-absent method</link></para></entry>
<entry valign="top"><para>72</para></entry>
</row>
<row>
<entry valign="top"><para>4.14</para></entry>
<entry valign="top"><para><link linkend="ch04list14" preference="0">Non-thread-safe attempt to implement put-if-absent. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>72</para></entry>
</row>
<row>
<entry valign="top"><para>4.15</para></entry>
<entry valign="top"><para><link linkend="ch04list15" preference="0">Implementing put-if-absent with client-side locking</link></para></entry>
<entry valign="top"><para>73</para></entry>
</row>
<row>
<entry valign="top"><para>4.16</para></entry>
<entry valign="top"><para><link linkend="ch04list16" preference="0">Implementing put-if-absent using composition</link></para></entry>
<entry valign="top"><para>74</para></entry>
</row>
<row>
<entry valign="top"><para>5.1</para></entry>
<entry valign="top"><para><link linkend="ch05list01" preference="0">Compound actions on a <literal>Vector</literal> that may produce confusing results</link></para></entry>
<entry valign="top"><para>80</para></entry>
</row>
<row>
<entry valign="top"><para>5.2</para></entry>
<entry valign="top"><para><link linkend="ch05list02" preference="0">Compound actions on <literal>Vector</literal> using client-side locking</link></para></entry>
<entry valign="top"><para>81</para></entry>
</row>
<row>
<entry valign="top"><para>5.3</para></entry>
<entry valign="top"><para><link linkend="ch05list03" preference="0">Iteration that may throw <literal>ArrayIndexOutOfBoundsException</literal></link></para></entry>
<entry valign="top"><para>81</para></entry>
</row>
<row>
<entry valign="top"><para>5.4</para></entry>
<entry valign="top"><para><link linkend="ch05list04" preference="0">Iteration with client-side locking</link></para></entry>
<entry valign="top"><para>82</para></entry>
</row>
<row>
<entry valign="top"><para>5.5</para></entry>
<entry valign="top"><para><link linkend="ch05list05" preference="0">Iterating a <literal>List</literal> with an <literal>Iterator</literal></link></para></entry>
<entry valign="top"><para>82</para></entry>
</row>
<row>
<entry valign="top"><para>5.6</para></entry>
<entry valign="top"><para><link linkend="ch05list06" preference="0">Iteration hidden within string concatenation. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>84</para></entry>
</row>
<row>
<entry valign="top"><para>5.7</para></entry>
<entry valign="top"><para><link linkend="ch05list07" preference="0"><literal>ConcurrentMap</literal> interface</link></para></entry>
<entry valign="top"><para>87</para></entry>
</row>
<row>
<entry valign="top"><para>5.8</para></entry>
<entry valign="top"><para><link linkend="ch05list08" preference="0">Producer and consumer tasks in a desktop search application</link></para></entry>
<entry valign="top"><para>91</para></entry>
</row>
<row>
<entry valign="top"><para>5.9</para></entry>
<entry valign="top"><para><link linkend="ch05list09" preference="0">Starting the desktop search</link></para></entry>
<entry valign="top"><para>92</para></entry>
</row>
<row>
<entry valign="top"><para>5.10</para></entry>
<entry valign="top"><para><link linkend="ch05list10" preference="0">Restoring the interrupted status so as not to swallow the interrupt</link></para></entry>
<entry valign="top"><para>94</para></entry>
</row>
<row>
<entry valign="top"><para>5.11</para></entry>
<entry valign="top"><para><link linkend="ch05list11" preference="0">Using <literal>CountDownLatch</literal> for starting and stopping threads in timing tests</link></para></entry>
<entry valign="top"><para>96</para></entry>
</row>
<row>
<entry valign="top"><para>5.12</para></entry>
<entry valign="top"><para><link linkend="ch05list12" preference="0">Using <literal>FutureTask</literal> to preload data that is needed later</link></para></entry>
<entry valign="top"><para>97</para></entry>
</row>
<row>
<entry valign="top"><para>5.13</para></entry>
<entry valign="top"><para><link linkend="ch05list13" preference="0">Coercing an unchecked <literal>Throwable</literal> to a <literal>RuntimeException</literal></link></para></entry>
<entry valign="top"><para>98</para></entry>
</row>
<row>
<entry valign="top"><para>5.14</para></entry>
<entry valign="top"><para><link linkend="ch05list14" preference="0">Using <literal>Semaphore</literal> to bound a collection</link></para></entry>
<entry valign="top"><para>100</para></entry>
</row>
<row>
<entry valign="top"><para>5.15</para></entry>
<entry valign="top"><para><link linkend="ch05list15" preference="0">Coordinating computation in a cellular automaton with <literal>Cyclic-Barrier</literal></link></para></entry>
<entry valign="top"><para>102</para></entry>
</row>
<row>
<entry valign="top"><para>5.16</para></entry>
<entry valign="top"><para><link linkend="ch05list16" preference="0">Initial cache attempt using <literal>HashMap</literal> and synchronization</link></para></entry>
<entry valign="top"><para>103</para></entry>
</row>
<row>
<entry valign="top"><para>5.17</para></entry>
<entry valign="top"><para><link linkend="ch05list17" preference="0">Replacing <literal>HashMap</literal> with <literal>ConcurrentHashMap</literal></link></para></entry>
<entry valign="top"><para>105</para></entry>
</row>
<row>
<entry valign="top"><para>5.18</para></entry>
<entry valign="top"><para><link linkend="ch05list18" preference="0">Memoizing wrapper using <literal>FutureTask</literal></link></para></entry>
<entry valign="top"><para>106</para></entry>
</row>
<row>
<entry valign="top"><para>5.19</para></entry>
<entry valign="top"><para><link linkend="ch05list19" preference="0">Final implementation of <literal>Memoizer</literal></link></para></entry>
<entry valign="top"><para>108</para></entry>
</row>
<row>
<entry valign="top"><para>5.20</para></entry>
<entry valign="top"><para><link linkend="ch05list20" preference="0">Factorizing servlet that caches results using <literal>Memoizer</literal></link></para></entry>
<entry valign="top"><para>109</para></entry>
</row>
<row>
<entry valign="top"><para>6.1</para></entry>
<entry valign="top"><para><link linkend="ch06list01" preference="0">Sequential web server</link></para></entry>
<entry valign="top"><para>114</para></entry>
</row>
<row>
<entry valign="top"><para>6.2</para></entry>
<entry valign="top"><para><link linkend="ch06list02" preference="0">Web server that starts a new thread for each request</link></para></entry>
<entry valign="top"><para>115</para></entry>
</row>
<row>
<entry valign="top"><para>6.3</para></entry>
<entry valign="top"><para><link linkend="ch06list03" preference="0"><literal>Executor</literal> interface</link></para></entry>
<entry valign="top"><para>117</para></entry>
</row>
<row>
<entry valign="top"><para>6.4</para></entry>
<entry valign="top"><para><link linkend="ch06list04" preference="0">Web server using a thread pool</link></para></entry>
<entry valign="top"><para>118</para></entry>
</row>
<row>
<entry valign="top"><para>6.5</para></entry>
<entry valign="top"><para><link linkend="ch06list05" preference="0"><literal>Executor</literal> that starts a new thread for each task</link></para></entry>
<entry valign="top"><para>118</para></entry>
</row>
<row>
<entry valign="top"><para>6.6</para></entry>
<entry valign="top"><para><link linkend="ch06list06" preference="0"><literal>Executor</literal> that executes tasks synchronously in the calling thread</link></para></entry>
<entry valign="top"><para>119</para></entry>
</row>
<row>
<entry valign="top"><para>6.7</para></entry>
<entry valign="top"><para><link linkend="ch06list07" preference="0">Lifecycle methods in <literal>ExecutorService</literal></link></para></entry>
<entry valign="top"><para>121</para></entry>
</row>
<row>
<entry valign="top"><para>6.8</para></entry>
<entry valign="top"><para><link linkend="ch06list08" preference="0">Web server with shutdown support</link></para></entry>
<entry valign="top"><para>122</para></entry>
</row>
<row>
<entry valign="top"><para>6.9</para></entry>
<entry valign="top"><para><link linkend="ch06list09" preference="0">Class illustrating confusing <literal>Timer</literal> behavior</link></para></entry>
<entry valign="top"><para>124</para></entry>
</row>
<row>
<entry valign="top"><para>6.10</para></entry>
<entry valign="top"><para><link linkend="ch06list10" preference="0">Rendering page elements sequentially</link></para></entry>
<entry valign="top"><para>125</para></entry>
</row>
<row>
<entry valign="top"><para>6.11</para></entry>
<entry valign="top"><para><link linkend="ch06list11" preference="0"><literal>Callable</literal> and <literal>Future</literal> interfaces</link></para></entry>
<entry valign="top"><para>126</para></entry>
</row>
<row>
<entry valign="top"><para><?docpage num="xiv"?>6.12</para></entry>
<entry valign="top"><para><link linkend="ch06list12" preference="0">Default implementation of <literal>newTaskFor</literal> in <literal>ThreadPoolExecutor</literal></link></para></entry>
<entry valign="top"><para>126</para></entry>
</row>
<row>
<entry valign="top"><para>6.13</para></entry>
<entry valign="top"><para><link linkend="ch06list13" preference="0">Waiting for image download with <literal>Future</literal></link></para></entry>
<entry valign="top"><para>128</para></entry>
</row>
<row>
<entry valign="top"><para>6.14</para></entry>
<entry valign="top"><para><link linkend="ch06list14" preference="0"><literal>QueueingFuture</literal> class used by <literal>ExecutorCompletionService</literal></link></para></entry>
<entry valign="top"><para>129</para></entry>
</row>
<row>
<entry valign="top"><para>6.15</para></entry>
<entry valign="top"><para><link linkend="ch06list15" preference="0">Using <literal>CompletionService</literal> to render page elements as they become available</link></para></entry>
<entry valign="top"><para>130</para></entry>
</row>
<row>
<entry valign="top"><para>6.16</para></entry>
<entry valign="top"><para><link linkend="ch06list16" preference="0">Fetching an advertisement with a time budget</link></para></entry>
<entry valign="top"><para>132</para></entry>
</row>
<row>
<entry valign="top"><para>6.17</para></entry>
<entry valign="top"><para><link linkend="ch06list17" preference="0">Requesting travel quotes under a time budget</link></para></entry>
<entry valign="top"><para>134</para></entry>
</row>
<row>
<entry valign="top"><para>7.1</para></entry>
<entry valign="top"><para><link linkend="ch07list01" preference="0">Using a <literal>volatile</literal> field to hold cancellation state</link></para></entry>
<entry valign="top"><para>137</para></entry>
</row>
<row>
<entry valign="top"><para>7.2</para></entry>
<entry valign="top"><para><link linkend="ch07list02" preference="0">Generating a second’ sworth of prime numbers</link></para></entry>
<entry valign="top"><para>137</para></entry>
</row>
<row>
<entry valign="top"><para>7.3</para></entry>
<entry valign="top"><para><link linkend="ch07list03" preference="0">Unreliable cancellation that can leave producers stuck in a blocking operation. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>139</para></entry>
</row>
<row>
<entry valign="top"><para>7.4</para></entry>
<entry valign="top"><para><link linkend="ch07list04" preference="0">Interruption methods in <literal>Thread</literal></link></para></entry>
<entry valign="top"><para>139</para></entry>
</row>
<row>
<entry valign="top"><para>7.5</para></entry>
<entry valign="top"><para><link linkend="ch07list05" preference="0">Using interruption for cancellation</link></para></entry>
<entry valign="top"><para>141</para></entry>
</row>
<row>
<entry valign="top"><para>7.6</para></entry>
<entry valign="top"><para><link linkend="ch07list06" preference="0">Propagating <literal>InterruptedException</literal> to callers</link></para></entry>
<entry valign="top"><para>143</para></entry>
</row>
<row>
<entry valign="top"><para>7.7</para></entry>
<entry valign="top"><para><link linkend="ch07list07" preference="0">Noncancelable task that restores interruption before exit</link></para></entry>
<entry valign="top"><para>144</para></entry>
</row>
<row>
<entry valign="top"><para>7.8</para></entry>
<entry valign="top"><para><link linkend="ch07list08" preference="0">Scheduling an interrupt on a borrowed thread. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>145</para></entry>
</row>
<row>
<entry valign="top"><para>7.9</para></entry>
<entry valign="top"><para><link linkend="ch07list09" preference="0">Interrupting a task in a dedicated thread</link></para></entry>
<entry valign="top"><para>146</para></entry>
</row>
<row>
<entry valign="top"><para>7.10</para></entry>
<entry valign="top"><para><link linkend="ch07list10" preference="0">Cancelling a task using <literal>Future</literal></link></para></entry>
<entry valign="top"><para>147</para></entry>
</row>
<row>
<entry valign="top"><para>7.11</para></entry>
<entry valign="top"><para><link linkend="ch07list11" preference="0">Encapsulating nonstandard cancellation in a <literal>Thread</literal> by overriding <literal>interrupt</literal></link></para></entry>
<entry valign="top"><para>149</para></entry>
</row>
<row>
<entry valign="top"><para>7.12</para></entry>
<entry valign="top"><para><link linkend="ch07list12" preference="0">Encapsulating nonstandard cancellation in a task with <literal>newTaskFor</literal></link></para></entry>
<entry valign="top"><para>151</para></entry>
</row>
<row>
<entry valign="top"><para>7.13</para></entry>
<entry valign="top"><para><link linkend="ch07list13" preference="0">Producer-consumer logging service with no shutdown support</link></para></entry>
<entry valign="top"><para>152</para></entry>
</row>
<row>
<entry valign="top"><para>7.14</para></entry>
<entry valign="top"><para><link linkend="ch07list14" preference="0">Unreliable way to add shutdown support to the logging service</link></para></entry>
<entry valign="top"><para>153</para></entry>
</row>
<row>
<entry valign="top"><para>7.15</para></entry>
<entry valign="top"><para><link linkend="ch07list15" preference="0">Adding reliable cancellation to <literal>LogWriter</literal></link></para></entry>
<entry valign="top"><para>154</para></entry>
</row>
<row>
<entry valign="top"><para>7.16</para></entry>
<entry valign="top"><para><link linkend="ch07list16" preference="0">Logging service that uses an <literal>ExecutorService</literal></link></para></entry>
<entry valign="top"><para>155</para></entry>
</row>
<row>
<entry valign="top"><para>7.17</para></entry>
<entry valign="top"><para><link linkend="ch07list17" preference="0">Shutdown with poison pill</link></para></entry>
<entry valign="top"><para>156</para></entry>
</row>
<row>
<entry valign="top"><para>7.18</para></entry>
<entry valign="top"><para><link linkend="ch07list18" preference="0">Producer thread for <literal>IndexingService</literal></link></para></entry>
<entry valign="top"><para>157</para></entry>
</row>
<row>
<entry valign="top"><para>7.19</para></entry>
<entry valign="top"><para><link linkend="ch07list19" preference="0">Consumer thread for <literal>IndexingService</literal></link></para></entry>
<entry valign="top"><para>157</para></entry>
</row>
<row>
<entry valign="top"><para>7.20</para></entry>
<entry valign="top"><para><link linkend="ch07list20" preference="0">Using a private <literal>Executor</literal> whose lifetime is bounded by a method call</link></para></entry>
<entry valign="top"><para>158</para></entry>
</row>
<row>
<entry valign="top"><para>7.21</para></entry>
<entry valign="top"><para><link linkend="ch07list21" preference="0"><literal>ExecutorService</literal> that keeps track of cancelled tasks after shutdown</link></para></entry>
<entry valign="top"><para>159</para></entry>
</row>
<row>
<entry valign="top"><para>7.22</para></entry>
<entry valign="top"><para><link linkend="ch07list22" preference="0">Using <literal>TrackingExecutorService</literal> to save unfinished tasks for later execution</link></para></entry>
<entry valign="top"><para>160</para></entry>
</row>
<row>
<entry valign="top"><para>7.23</para></entry>
<entry valign="top"><para><link linkend="ch07list23" preference="0">Typical thread-pool worker thread structure</link></para></entry>
<entry valign="top"><para>162</para></entry>
</row>
<row>
<entry valign="top"><para>7.24</para></entry>
<entry valign="top"><para><link linkend="ch07list24" preference="0"><literal>UncaughtExceptionHandler</literal> interface</link></para></entry>
<entry valign="top"><para>163</para></entry>
</row>
<row>
<entry valign="top"><para>7.25</para></entry>
<entry valign="top"><para><link linkend="ch07list25" preference="0"><literal>UncaughtExceptionHandler</literal> that logs the exception</link></para></entry>
<entry valign="top"><para>163</para></entry>
</row>
<row>
<entry valign="top"><para>7.26</para></entry>
<entry valign="top"><para><link linkend="ch07list26" preference="0">Registering a shutdown hook to stop the logging service</link></para></entry>
<entry valign="top"><para>165</para></entry>
</row>
<row>
<entry valign="top"><para>8.1</para></entry>
<entry valign="top"><para><link linkend="ch08list01" preference="0">Task that deadlocks in a single-threaded <literal>Executor</literal>. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>169</para></entry>
</row>
<row>
<entry valign="top"><para>8.2</para></entry>
<entry valign="top"><para><link linkend="ch08list02" preference="0">General constructor for <literal>ThreadPoolExecutor</literal></link></para></entry>
<entry valign="top"><para>172</para></entry>
</row>
<row>
<entry valign="top"><para>8.3</para></entry>
<entry valign="top"><para><link linkend="ch08list03" preference="0">Creating a fixed-sized thread pool with a bounded queue and the caller-runs saturation policy</link></para></entry>
<entry valign="top"><para>175</para></entry>
</row>
<row>
<entry valign="top"><para>8.4</para></entry>
<entry valign="top"><para><link linkend="ch08list04" preference="0">Using a <literal>Semaphore</literal> to throttle task submission</link></para></entry>
<entry valign="top"><para>176</para></entry>
</row>
<row>
<entry valign="top"><para>8.5</para></entry>
<entry valign="top"><para><link linkend="ch08list05" preference="0"><literal>ThreadFactory</literal> interface</link></para></entry>
<entry valign="top"><para>176</para></entry>
</row>
<row>
<entry valign="top"><para>8.6</para></entry>
<entry valign="top"><para><link linkend="ch08list06" preference="0">Custom thread factory</link></para></entry>
<entry valign="top"><para>177</para></entry>
</row>
<row>
<entry valign="top"><para>8.7</para></entry>
<entry valign="top"><para><link linkend="ch08list07" preference="0">Custom thread base class</link></para></entry>
<entry valign="top"><para>178</para></entry>
</row>
<row>
<entry valign="top"><para>8.8</para></entry>
<entry valign="top"><para><link linkend="ch08list08" preference="0">Modifying an <literal>Executor</literal> created with the standard factories</link></para></entry>
<entry valign="top"><para>179</para></entry>
</row>
<row>
<entry valign="top"><para>8.9</para></entry>
<entry valign="top"><para><link linkend="ch08list09" preference="0">Thread pool extended with logging and timing</link></para></entry>
<entry valign="top"><para>180</para></entry>
</row>
<row>
<entry valign="top"><para><?docpage num="xv"?>8.10</para></entry>
<entry valign="top"><para><link linkend="ch08list10" preference="0">Transforming sequential execution into parallel execution</link></para></entry>
<entry valign="top"><para>181</para></entry>
</row>
<row>
<entry valign="top"><para>8.11</para></entry>
<entry valign="top"><para><link linkend="ch08list11" preference="0">Transforming sequential tail-recursion into parallelized recursion</link></para></entry>
<entry valign="top"><para>182</para></entry>
</row>
<row>
<entry valign="top"><para>8.12</para></entry>
<entry valign="top"><para><link linkend="ch08list12" preference="0">Waiting for results to be calculated in parallel</link></para></entry>
<entry valign="top"><para>182</para></entry>
</row>
<row>
<entry valign="top"><para>8.13</para></entry>
<entry valign="top"><para><link linkend="ch08list13" preference="0">Abstraction for puzzles like the “sliding blocks puzzle”</link></para></entry>
<entry valign="top"><para>183</para></entry>
</row>
<row>
<entry valign="top"><para>8.14</para></entry>
<entry valign="top"><para><link linkend="ch08list14" preference="0">Link node for the puzzle solver framework</link></para></entry>
<entry valign="top"><para>184</para></entry>
</row>
<row>
<entry valign="top"><para>8.15</para></entry>
<entry valign="top"><para><link linkend="ch08list15" preference="0">Sequential puzzle solver</link></para></entry>
<entry valign="top"><para>185</para></entry>
</row>
<row>
<entry valign="top"><para>8.16</para></entry>
<entry valign="top"><para><link linkend="ch08list16" preference="0">Concurrent version of puzzle solver</link></para></entry>
<entry valign="top"><para>186</para></entry>
</row>
<row>
<entry valign="top"><para>8.17</para></entry>
<entry valign="top"><para><link linkend="ch08list17" preference="0">Result-bearing latch used by <literal>ConcurrentPuzzleSolver</literal></link></para></entry>
<entry valign="top"><para>187</para></entry>
</row>
<row>
<entry valign="top"><para>8.18</para></entry>
<entry valign="top"><para><link linkend="ch08list18" preference="0">Solver that recognizes when no solution exists</link></para></entry>
<entry valign="top"><para>188</para></entry>
</row>
<row>
<entry valign="top"><para>9.1</para></entry>
<entry valign="top"><para><link linkend="ch09list01" preference="0">Implementing <literal>SwingUtilities</literal> using an <literal>Executor</literal></link></para></entry>
<entry valign="top"><para>193</para></entry>
</row>
<row>
<entry valign="top"><para>9.2</para></entry>
<entry valign="top"><para><link linkend="ch09list02" preference="0"><literal>Executor</literal> built atop <literal>SwingUtilities</literal></link></para></entry>
<entry valign="top"><para>194</para></entry>
</row>
<row>
<entry valign="top"><para>9.3</para></entry>
<entry valign="top"><para><link linkend="ch09list03" preference="0">Simple event listener</link></para></entry>
<entry valign="top"><para>194</para></entry>
</row>
<row>
<entry valign="top"><para>9.4</para></entry>
<entry valign="top"><para><link linkend="ch09list04" preference="0">Binding a long-running task to a visual component</link></para></entry>
<entry valign="top"><para>196</para></entry>
</row>
<row>
<entry valign="top"><para>9.5</para></entry>
<entry valign="top"><para><link linkend="ch09list05" preference="0">Long-running task with user feedback</link></para></entry>
<entry valign="top"><para>196</para></entry>
</row>
<row>
<entry valign="top"><para>9.6</para></entry>
<entry valign="top"><para><link linkend="ch09list06" preference="0">Cancelling a long-running task</link></para></entry>
<entry valign="top"><para>197</para></entry>
</row>
<row>
<entry valign="top"><para>9.7</para></entry>
<entry valign="top"><para><link linkend="ch09list07" preference="0">Background task class supporting cancellation, completion notification, and progress notification</link></para></entry>
<entry valign="top"><para>199</para></entry>
</row>
<row>
<entry valign="top"><para>9.8</para></entry>
<entry valign="top"><para><link linkend="ch09list08" preference="0">Initiating a long-running, cancellable task with <literal>BackgroundTask</literal>. .</link></para></entry>
<entry valign="top"><para>200</para></entry>
</row>
<row>
<entry valign="top"><para>10.1</para></entry>
<entry valign="top"><para><link linkend="ch10list01" preference="0">Simple lock-ordering deadlock. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>207</para></entry>
</row>
<row>
<entry valign="top"><para>10.2</para></entry>
<entry valign="top"><para><link linkend="ch10list02" preference="0">Dynamic lock-ordering deadlock. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>208</para></entry>
</row>
<row>
<entry valign="top"><para>10.3</para></entry>
<entry valign="top"><para><link linkend="ch10list03" preference="0">Inducing a lock ordering to avoid deadlock</link></para></entry>
<entry valign="top"><para>209</para></entry>
</row>
<row>
<entry valign="top"><para>10.4</para></entry>
<entry valign="top"><para><link linkend="ch10list04" preference="0">Driver loop that induces deadlock under typical conditions</link></para></entry>
<entry valign="top"><para>210</para></entry>
</row>
<row>
<entry valign="top"><para>10.5</para></entry>
<entry valign="top"><para><link linkend="ch10list05" preference="0">Lock-ordering deadlock between cooperating objects. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>212</para></entry>
</row>
<row>
<entry valign="top"><para>10.6</para></entry>
<entry valign="top"><para><link linkend="ch10list06" preference="0">Using open calls to avoiding deadlock between cooperating objects</link></para></entry>
<entry valign="top"><para>214</para></entry>
</row>
<row>
<entry valign="top"><para>10.7</para></entry>
<entry valign="top"><para><link linkend="ch10list07" preference="0">Portion of thread dump after deadlock</link></para></entry>
<entry valign="top"><para>217</para></entry>
</row>
<row>
<entry valign="top"><para>11.1</para></entry>
<entry valign="top"><para><link linkend="ch11list01" preference="0">Serialized access to a task queue</link></para></entry>
<entry valign="top"><para>227</para></entry>
</row>
<row>
<entry valign="top"><para>11.2</para></entry>
<entry valign="top"><para><link linkend="ch11list02" preference="0">Synchronization that has no effect. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>230</para></entry>
</row>
<row>
<entry valign="top"><para>11.3</para></entry>
<entry valign="top"><para><link linkend="ch11list03" preference="0">Candidate for lock elision</link></para></entry>
<entry valign="top"><para>231</para></entry>
</row>
<row>
<entry valign="top"><para>11.4</para></entry>
<entry valign="top"><para><link linkend="ch11list04" preference="0">Holding a lock longer than necessary</link></para></entry>
<entry valign="top"><para>233</para></entry>
</row>
<row>
<entry valign="top"><para>11.5</para></entry>
<entry valign="top"><para><link linkend="ch11list05" preference="0">Reducing lock duration</link></para></entry>
<entry valign="top"><para>234</para></entry>
</row>
<row>
<entry valign="top"><para>11.6</para></entry>
<entry valign="top"><para><link linkend="ch11list06" preference="0">Candidate for lock splitting</link></para></entry>
<entry valign="top"><para>236</para></entry>
</row>
<row>
<entry valign="top"><para>11.7</para></entry>
<entry valign="top"><para><link linkend="ch11list07" preference="0"><literal>ServerStatus</literal> refactored to use split locks</link></para></entry>
<entry valign="top"><para>236</para></entry>
</row>
<row>
<entry valign="top"><para>11.8</para></entry>
<entry valign="top"><para><link linkend="ch11list08" preference="0">Hash-based map using lock striping</link></para></entry>
<entry valign="top"><para>238</para></entry>
</row>
<row>
<entry valign="top"><para>12.1</para></entry>
<entry valign="top"><para><link linkend="ch12list01" preference="0">Bounded buffer using <literal>Semaphore</literal></link></para></entry>
<entry valign="top"><para>249</para></entry>
</row>
<row>
<entry valign="top"><para>12.2</para></entry>
<entry valign="top"><para><link linkend="ch12list02" preference="0">Basic unit tests for <literal>BoundedBuffer</literal></link></para></entry>
<entry valign="top"><para>250</para></entry>
</row>
<row>
<entry valign="top"><para>12.3</para></entry>
<entry valign="top"><para><link linkend="ch12list03" preference="0">Testing blocking and responsiveness to interruption</link></para></entry>
<entry valign="top"><para>252</para></entry>
</row>
<row>
<entry valign="top"><para>12.4</para></entry>
<entry valign="top"><para><link linkend="ch12list04" preference="0">Medium-quality random number generator suitable for testing</link></para></entry>
<entry valign="top"><para>253</para></entry>
</row>
<row>
<entry valign="top"><para>12.5</para></entry>
<entry valign="top"><para><link linkend="ch12list05" preference="0">Producer-consumer test program for <literal>BoundedBuffer</literal></link></para></entry>
<entry valign="top"><para>255</para></entry>
</row>
<row>
<entry valign="top"><para>12.6</para></entry>
<entry valign="top"><para><link linkend="ch12list06" preference="0">Producer and consumer classes used in <literal>PutTakeTest</literal></link></para></entry>
<entry valign="top"><para>256</para></entry>
</row>
<row>
<entry valign="top"><para>12.7</para></entry>
<entry valign="top"><para><link linkend="ch12list07" preference="0">Testing for resource leaks</link></para></entry>
<entry valign="top"><para>258</para></entry>
</row>
<row>
<entry valign="top"><para>12.8</para></entry>
<entry valign="top"><para><link linkend="ch12list08" preference="0">Thread factory for testing <literal>ThreadPoolExecutor</literal></link></para></entry>
<entry valign="top"><para>258</para></entry>
</row>
<row>
<entry valign="top"><para>12.9</para></entry>
<entry valign="top"><para><link linkend="ch12list09" preference="0">Test method to verify thread pool expansion</link></para></entry>
<entry valign="top"><para>259</para></entry>
</row>
<row>
<entry valign="top"><para>12.10</para></entry>
<entry valign="top"><para><link linkend="ch12list10" preference="0">Using <literal>Thread.yield</literal> to generate more interleavings</link></para></entry>
<entry valign="top"><para>260</para></entry>
</row>
<row>
<entry valign="top"><para>12.11</para></entry>
<entry valign="top"><para><link linkend="ch12list11" preference="0">Barrier-based timer</link></para></entry>
<entry valign="top"><para>261</para></entry>
</row>
<row>
<entry valign="top"><para>12.12</para></entry>
<entry valign="top"><para><link linkend="ch12list12" preference="0">Testing with a barrier-based timer</link></para></entry>
<entry valign="top"><para>262</para></entry>
</row>
<row>
<entry valign="top"><para>12.13</para></entry>
<entry valign="top"><para><link linkend="ch12list13" preference="0">Driver program for <literal>TimedPutTakeTest</literal></link></para></entry>
<entry valign="top"><para>262</para></entry>
</row>
<row>
<entry valign="top"><para>13.1</para></entry>
<entry valign="top"><para><link linkend="ch13list01" preference="0"><literal>Lock</literal> interface</link></para></entry>
<entry valign="top"><para>277</para></entry>
</row>
<row>
<entry valign="top"><para><?docpage num="xvi"?>13.2</para></entry>
<entry valign="top"><para><link linkend="ch13list02" preference="0">Guarding object state using <literal>ReentrantLock</literal></link></para></entry>
<entry valign="top"><para>278</para></entry>
</row>
<row>
<entry valign="top"><para>13.3</para></entry>
<entry valign="top"><para><link linkend="ch13list03" preference="0">Avoiding lock-ordering deadlock using <literal>tryLock</literal></link></para></entry>
<entry valign="top"><para>280</para></entry>
</row>
<row>
<entry valign="top"><para>13.4</para></entry>
<entry valign="top"><para><link linkend="ch13list04" preference="0">Locking with a time budget</link></para></entry>
<entry valign="top"><para>281</para></entry>
</row>
<row>
<entry valign="top"><para>13.5</para></entry>
<entry valign="top"><para><link linkend="ch13list05" preference="0">Interruptible lock acquisition</link></para></entry>
<entry valign="top"><para>281</para></entry>
</row>
<row>
<entry valign="top"><para>13.6</para></entry>
<entry valign="top"><para><link linkend="ch13list06" preference="0"><literal>ReadWriteLock</literal> interface</link></para></entry>
<entry valign="top"><para>286</para></entry>
</row>
<row>
<entry valign="top"><para>13.7</para></entry>
<entry valign="top"><para><link linkend="ch13list07" preference="0">Wrapping a <literal>Map</literal> with a read-write lock</link></para></entry>
<entry valign="top"><para>288</para></entry>
</row>
<row>
<entry valign="top"><para>14.1</para></entry>
<entry valign="top"><para><link linkend="ch14list01" preference="0">Structure of blocking state-dependent actions</link></para></entry>
<entry valign="top"><para>292</para></entry>
</row>
<row>
<entry valign="top"><para>14.2</para></entry>
<entry valign="top"><para><link linkend="ch14list02" preference="0">Base class for bounded buffer implementations</link></para></entry>
<entry valign="top"><para>293</para></entry>
</row>
<row>
<entry valign="top"><para>14.3</para></entry>
<entry valign="top"><para><link linkend="ch14list03" preference="0">Bounded buffer that balks when preconditions are not met</link></para></entry>
<entry valign="top"><para>294</para></entry>
</row>
<row>
<entry valign="top"><para>14.4</para></entry>
<entry valign="top"><para><link linkend="ch14list04" preference="0">Client logic for calling <literal>GrumpyBoundedBuffer</literal></link></para></entry>
<entry valign="top"><para>294</para></entry>
</row>
<row>
<entry valign="top"><para>14.5</para></entry>
<entry valign="top"><para><link linkend="ch14list05" preference="0">Bounded buffer using crude blocking</link></para></entry>
<entry valign="top"><para>296</para></entry>
</row>
<row>
<entry valign="top"><para>14.6</para></entry>
<entry valign="top"><para><link linkend="ch14list06" preference="0">Bounded buffer using condition queues</link></para></entry>
<entry valign="top"><para>298</para></entry>
</row>
<row>
<entry valign="top"><para>14.7</para></entry>
<entry valign="top"><para><link linkend="ch14list07" preference="0">Canonical form for state-dependent methods</link></para></entry>
<entry valign="top"><para>301</para></entry>
</row>
<row>
<entry valign="top"><para>14.8</para></entry>
<entry valign="top"><para><link linkend="ch14list08" preference="0">Using conditional notification in <literal>BoundedBuffer.put</literal></link></para></entry>
<entry valign="top"><para>304</para></entry>
</row>
<row>
<entry valign="top"><para>14.9</para></entry>
<entry valign="top"><para><link linkend="ch14list09" preference="0">Recloseable gate using <literal>wait</literal> and <literal>notifyAll</literal></link></para></entry>
<entry valign="top"><para>305</para></entry>
</row>
<row>
<entry valign="top"><para>14.10</para></entry>
<entry valign="top"><para><link linkend="ch14list10" preference="0"><literal>Condition</literal> interface</link></para></entry>
<entry valign="top"><para>307</para></entry>
</row>
<row>
<entry valign="top"><para>14.11</para></entry>
<entry valign="top"><para><link linkend="ch14list11" preference="0">Bounded buffer using explicit condition variables</link></para></entry>
<entry valign="top"><para>309</para></entry>
</row>
<row>
<entry valign="top"><para>14.12</para></entry>
<entry valign="top"><para><link linkend="ch14list12" preference="0">Counting semaphore implemented using <literal>Lock</literal></link></para></entry>
<entry valign="top"><para>310</para></entry>
</row>
<row>
<entry valign="top"><para>14.13</para></entry>
<entry valign="top"><para><link linkend="ch14list13" preference="0">Canonical forms for acquisition and release in AQS</link></para></entry>
<entry valign="top"><para>312</para></entry>
</row>
<row>
<entry valign="top"><para>14.14</para></entry>
<entry valign="top"><para><link linkend="ch14list14" preference="0">Binary latch using <literal>AbstractQueuedSynchronizer</literal></link></para></entry>
<entry valign="top"><para>313</para></entry>
</row>
<row>
<entry valign="top"><para>14.15</para></entry>
<entry valign="top"><para><link linkend="ch14list15" preference="0"><literal>tryAcquire</literal> implementation from nonfair <literal>ReentrantLock</literal></link></para></entry>
<entry valign="top"><para>315</para></entry>
</row>
<row>
<entry valign="top"><para>14.16</para></entry>
<entry valign="top"><para><link linkend="ch14list16" preference="0"><literal>tryAcquireShared</literal> and <literal>tryReleaseShared</literal> from <literal>Semaphore</literal></link></para></entry>
<entry valign="top"><para>316</para></entry>
</row>
<row>
<entry valign="top"><para>15.1</para></entry>
<entry valign="top"><para><link linkend="ch15list01" preference="0">Simulated CAS operation</link></para></entry>
<entry valign="top"><para>322</para></entry>
</row>
<row>
<entry valign="top"><para>15.2</para></entry>
<entry valign="top"><para><link linkend="ch15list02" preference="0">Nonblocking counter using CAS</link></para></entry>
<entry valign="top"><para>323</para></entry>
</row>
<row>
<entry valign="top"><para>15.3</para></entry>
<entry valign="top"><para><link linkend="ch15list03" preference="0">Preserving multivariable invariants using CAS</link></para></entry>
<entry valign="top"><para>326</para></entry>
</row>
<row>
<entry valign="top"><para>15.4</para></entry>
<entry valign="top"><para><link linkend="ch15list04" preference="0">Random number generator using <literal>ReentrantLock</literal></link></para></entry>
<entry valign="top"><para>327</para></entry>
</row>
<row>
<entry valign="top"><para>15.5</para></entry>
<entry valign="top"><para><link linkend="ch15list05" preference="0">Random number generator using <literal>AtomicInteger</literal></link></para></entry>
<entry valign="top"><para>327</para></entry>
</row>
<row>
<entry valign="top"><para>15.6</para></entry>
<entry valign="top"><para><link linkend="ch15list06" preference="0">Nonblocking stack using Treiber’s algorithm (Treiber, 1986)</link></para></entry>
<entry valign="top"><para>331</para></entry>
</row>
<row>
<entry valign="top"><para>15.7</para></entry>
<entry valign="top"><para><link linkend="ch15list07" preference="0">Insertion in the Michael-Scott nonblocking queue algorithm (Michael and Scott, 1996)</link></para></entry>
<entry valign="top"><para>334</para></entry>
</row>
<row>
<entry valign="top"><para>15.8</para></entry>
<entry valign="top"><para><link linkend="ch15list08" preference="0">Using atomic field updaters in <literal>ConcurrentLinkedQueue</literal></link></para></entry>
<entry valign="top"><para>335</para></entry>
</row>
<row>
<entry valign="top"><para>16.1</para></entry>
<entry valign="top"><para><link linkend="ch16list01" preference="0">Insufficiently synchronized program that can have surprising results. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>340</para></entry>
</row>
<row>
<entry valign="top"><para>16.2</para></entry>
<entry valign="top"><para><link linkend="ch16list02" preference="0">Inner class of <literal>FutureTask</literal> illustrating synchronization piggybacking</link></para></entry>
<entry valign="top"><para>343</para></entry>
</row>
<row>
<entry valign="top"><para>16.3</para></entry>
<entry valign="top"><para><link linkend="ch16list03" preference="0">Unsafe lazy initialization. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>345</para></entry>
</row>
<row>
<entry valign="top"><para>16.4</para></entry>
<entry valign="top"><para><link linkend="ch16list04" preference="0">Thread-safe lazy initialization</link></para></entry>
<entry valign="top"><para>347</para></entry>
</row>
<row>
<entry valign="top"><para>16.5</para></entry>
<entry valign="top"><para><link linkend="ch16list05" preference="0">Eager initialization</link></para></entry>
<entry valign="top"><para>347</para></entry>
</row>
<row>
<entry valign="top"><para>16.6</para></entry>
<entry valign="top"><para><link linkend="ch16list06" preference="0">Lazy initialization holder class idiom</link></para></entry>
<entry valign="top"><para>348</para></entry>
</row>
<row>
<entry valign="top"><para>16.7</para></entry>
<entry valign="top"><para><link linkend="ch16list07" preference="0">Double-checked-locking antipattern. <emphasis>Don’t do this.</emphasis></link></para></entry>
<entry valign="top"><para>349</para></entry>
</row>
<row>
<entry valign="top"><para>16.8</para></entry>
<entry valign="top"><para><link linkend="ch16list08" preference="0">Initialization safety for immutable objects</link></para></entry>
<entry valign="top"><para>350</para></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</preface>
<preface id="pref03" condition="xvii"><title id="pref03__title">Preface</title>
<?docpage num="xvii"?>

<para>At this writing, multicore processors are just now becoming inexpensive enough for midrange desktop systems. Not coincidentally, many development teams are noticing more and more threading-related bug reports in their projects. In a recent post on the NetBeans developer site, one of the core maintainers observed that a single class had been patched over 14 times to fix threading-related problems. Dion Almaer, former editor of TheServerSide, recently blogged (after a painful debugging session that ultimately revealed a threading bug) that most Java programs are so rife with concurrency bugs that they work only “by accident”.</para>
<para>Indeed, developing, testing and debugging multithreaded programs can be extremely difficult because concurrency bugs do not manifest themselves predictably. And when they do surface, it is often at the worst possible time—in production, under heavy load.</para>
<para>One of the challenges of developing concurrent programs in Java is the mismatch between the concurrency features offered by the platform and how developers need to think about concurrency in their programs. The language provides low-level <emphasis>mechanisms</emphasis> such as synchronization and condition waits, but these mechanisms must be used consistently to implement application-level protocols or <emphasis>policies</emphasis>. Without such policies, it is all too easy to create programs that compile and appear to work but are nevertheless broken. Many otherwise excellent books on concurrency fall short of their goal by focusing excessively on low-level mechanisms and APIs rather than design-level policies and patterns.</para>
<para>Java 5.0 is a huge step forward for the development of concurrent applications in Java, providing new higher-level components and additional low-level mechanisms that make it easier for novices and experts alike to build concurrent applications. The authors are the primary members of the JCP Expert Group that created these facilities; in addition to describing their behavior and features, we present the underlying design patterns and anticipated usage scenarios that motivated their inclusion in the platform libraries.</para>
<para>Our goal is to give readers a set of design rules and mental models that make it easier—and more fun—to build correct, performant concurrent classes and applications in Java.</para>
<para>We hope you enjoy <emphasis>Java Concurrency in Practice</emphasis>.</para>
<para>Brian Goetz<?lb?>Williston, VT<?lb?><emphasis>March 2006</emphasis></para>
<section id="pref03lev1sec1" condition="xviii" label="" xreflabel="">
<?docpage num="xviii"?>
<title id="pref03lev1sec1__title">How to Use this Book</title>
<para>To address the abstraction mismatch between Java’s low-level mechanisms and the necessary design-level policies, we present a <emphasis>simplified</emphasis> set of rules for writing concurrent programs. Experts may look at these rules and say “Hmm, that’s not entirely true: class <emphasis>C</emphasis> is thread-safe even though it violates rule <emphasis>R</emphasis>.” While it is possible to write correct programs that break our rules, doing so requires a deep understanding of the low-level details of the Java Memory Model, and we want developers to be able to write correct concurrent programs <emphasis>without</emphasis> having to master these details. Consistently following our simplified rules will produce correct and maintainable concurrent programs.</para>
<para>We assume the reader already has some familiarity with the basic mechanisms for concurrency in Java. <emphasis>Java Concurrency in Practice</emphasis> is not an introduction to concurrency—for that, see the threading chapter of any decent introductory volume, such as <emphasis>The Java Programming Language</emphasis> (<link linkend="biblio01_001" preference="0">Arnold et al., 2005</link>). Nor is it an encyclopedic reference for All Things Concurrency—for that, see <emphasis>Concurrent Programming in Java</emphasis> (<link linkend="biblio01_021" preference="0">Lea, 2000</link>). Rather, it offers practical design rules to assist developers in the difficult process of creating safe and performant concurrent classes. Where appropriate, we cross-reference relevant sections of <emphasis>The Java Programming Language</emphasis>, <emphasis>Concurrent Programming in Java</emphasis>, <emphasis>The Java Language Specification</emphasis> (<link linkend="biblio01_001" preference="0">Gosling et al., 2005</link>), and <emphasis>Effective Java</emphasis> (<link linkend="biblio01_003" preference="0">Bloch, 2001</link>) using the conventions [JPL n.m], [CPJ n.m], [JLS n.m], and [EJ Item n].</para>
<para>After the introduction (<link linkend="ch01" preference="0">Chapter 1</link>), the book is divided into four parts:</para>
<formalpara><title><emphasis role="strong"><?design?>Fundamentals.</emphasis></title><para><link linkend="part01" preference="0">Part I</link> (<link linkend="ch02" preference="0">Chapters 2</link>-<link linkend="ch05" preference="0">5</link>) focuses on the basic concepts of concurrency and thread safety, and how to compose thread-safe classes out of the concurrent building blocks provided by the class library. A “cheat sheet” summarizing the most important of the rules presented in <link linkend="part01" preference="0">Part I</link> appears on page 110.</para></formalpara>
<para><link linkend="ch02" preference="0">Chapters 2</link> (Thread Safety) and <link linkend="ch03" preference="0">3</link> (Sharing Objects) form the foundation for the book. Nearly all of the rules on avoiding concurrency hazards, constructing thread-safe classes, and verifying thread safety are here. Readers who prefer “practice” to “theory” may be tempted to skip ahead to <link linkend="part02" preference="0">Part II</link>, but make sure to come back and read <link linkend="ch02" preference="0">Chapters 2</link> and <link linkend="ch03" preference="0">3</link> before writing any concurrent code!</para>
<para><link linkend="ch04" preference="0">Chapter 4</link> (Composing Objects) covers techniques for composing thread-safe classes into larger thread-safe classes. <link linkend="ch05" preference="0">Chapter 5</link> (Building Blocks) covers the concurrent building blocks—thread-safe collections and synchronizers—provided by the platform libraries.</para>
<formalpara><title><emphasis role="strong"><?design?>Structuring Concurrent Applications.</emphasis></title><para><link linkend="part02" preference="0">Part II</link> (<link linkend="ch06" preference="0">Chapters 6</link>-<link linkend="ch09" preference="0">9</link>) describes how to exploit threads to improve the throughput or responsiveness of concurrent applications. <link linkend="ch06" preference="0">Chapter 6</link> (Task Execution) covers identifying parallelizable tasks and executing them within the task-execution framework. <link linkend="ch07" preference="0">Chapter 7</link> (Cancellation and Shutdown) deals with techniques for convincing tasks and threads to terminate before they would normally do so; how programs deal with cancellation and shutdown is often one of the factors that separates truly robust concurrent applications from those that merely work. <link linkend="ch08" preference="0">Chapter 8</link> (Applying Thread Pools) addresses some of the more advanced features of the task-execution framework.</para></formalpara>
<para><?docpage num="xix"?><link linkend="ch09" preference="0">Chapter 9</link> (GUI Applications) focuses on techniques for improving responsiveness in single-threaded subsystems.</para>
<formalpara><title><emphasis role="strong"><?design?>Liveness, Performance, and Testing.</emphasis></title><para><link linkend="part03" preference="0">Part III</link> (<link linkend="ch10" preference="0">Chapters 10</link>-<link linkend="ch12" preference="0">12</link>) concerns itself with ensuring that concurrent programs actually do what you want them to do and do so with acceptable performance. <link linkend="ch10" preference="0">Chapter 10</link> (Avoiding Liveness Hazards) describes how to avoid liveness failures that can prevent programs from making forward progress. <link linkend="ch11" preference="0">Chapter 11</link> (Performance and Scalability) covers techniques for improving the performance and scalability of concurrent code. <link linkend="ch12" preference="0">Chapter 12</link> (Testing Concurrent Programs) covers techniques for testing concurrent code for both correctness and performance.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Advanced Topics.</emphasis></title><para><link linkend="part04" preference="0">Part IV</link> (<link linkend="ch13" preference="0">Chapters 13</link>-<link linkend="ch16" preference="0">16</link>) covers topics that are likely to be of interest only to experienced developers: explicit locks, atomic variables, nonblocking algorithms, and developing custom synchronizers.</para></formalpara>
</section>
<section id="pref03lev1sec2" condition="xix" label="" xreflabel=""><?docpage cont page="xix"?>
<title id="pref03lev1sec2__title">Code Examples</title>
<para>While many of the general concepts in this book are applicable to versions of Java prior to Java 5.0 and even to non-Java environments, most of the code examples (and all the statements about the Java Memory Model) assume Java 5.0 or later. Some of the code examples may use library features added in Java 6.</para>
<para>The code examples have been compressed to reduce their size and to highlight the relevant portions. The full versions of the code examples, as well as supplementary examples and errata, are available from the book’s website, <literal><ulink url="http://www.javaconcurrencyinpractice.com">http://www.javaconcurrencyinpractice.com</ulink></literal>.</para>
<para>The code examples are of three sorts: “good” examples, “not so good” examples, and “bad” examples. Good examples illustrate techniques that should be emulated. Bad examples illustrate techniques that should definitely <emphasis>not</emphasis> be emulated, and are identified with a “Mr. Yuk” icon<footnote id="pref03fn01" label="1"><para>Mr. Yuk is a registered trademark of the Children’s Hospital of Pittsburgh and appears by permission.</para></footnote> to make it clear that this is “toxic” code (see <link linkend="pref03list01" preference="0">Listing 1</link>). Not-so-good examples illustrate techniques that are not <emphasis>necessarily</emphasis> wrong but are fragile, risky, or perform poorly, and are decorated with a “Mr. Could BeHappier” icon as in <link linkend="pref03list02" preference="0">Listing 2</link>.</para>
<example id="pref03list01" label="1" role="Listing" xreflabel="1" condition="xix">
<title id="pref03list01__title">Bad Way to Sort a List. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public &lt;T extends Comparable&lt;? super T&gt;&gt; void sort(List&lt;T&gt; list) {
    // <emphasis>Never returns the wrong answer!</emphasis>
    System.exit(0);
}
</programlisting>
</example>
<para>Some readers may question the role of the “bad” examples in this book; after all, a book should show how to do things right, not wrong. The bad examples have two purposes. They illustrate common pitfalls, but more importantly they demonstrate how to analyze a program for thread safety—and the best way to do that is to see the ways in which thread safety is compromised.</para>

<para><?docpage num="xx"?></para><example id="pref03list02" label="2" role="Listing" xreflabel="2" condition="xx">

<title id="pref03list02__title">Less than Optimal Way to Sort a List.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public &lt;T extends Comparable&lt;? super T&gt;&gt; void sort(List&lt;T&gt; list) {
    for (int i=0; i&lt;1000000; i++)
        doNothing();
    Collections.sort(list);
}
</programlisting>
</example>
</section>
<section id="pref03lev1sec3" condition="xx" label="" xreflabel=""><?docpage cont page="xx"?>
<title id="pref03lev1sec3__title">Acknowledgments</title>
<para>This book grew out of the development process for the <literal>java.util.concurrent</literal> package that was created by the Java Community Process JSR 166 for inclusion in Java 5.0. Many others contributed to JSR 166; in particular we thank Martin Buchholz for doing all the work related to getting the code into the JDK, and all the readers of the <literal>concurrency-interest</literal> mailing list who offered their suggestions and feedback on the draft APIs.</para>
<para>This book has been tremendously improved by the suggestions and assistance of a small army of reviewers, advisors, cheerleaders, and armchair critics. We would like to thank Dion Almaer, Tracy Bialik, Cindy Bloch, Martin Buchholz, Paul Christmann, Cliff Click, Stuart Halloway, David Hovemeyer, Jason Hunter, Michael Hunter, Jeremy Hylton, Heinz Kabutz, Robert Kuhar, Ramnivas Laddad, Jared Levy, Nicole Lewis, Victor Luchangco, Jeremy Manson, Paul Martin, Berna Massingill, Michael Maurer, Ted Neward, Kirk Pepperdine, Bill Pugh, Sam Pullara, Russ Rufer, Bill Scherer, Jeffrey Siegal, Bruce Tate, Gil Tene, Paul Tyma, and members of the Silicon Valley Patterns Group who, through many interesting technical conversations, offered guidance and made suggestions that helped make this book better.</para>
<para>We are especially grateful to Cliff Biffle, Barry Hayes, Dawid Kurzyniec, Angelika Langer, Doron Rajwan, and Bill Venners, who reviewed the entire manuscript in excruciating detail, found bugs in the code examples, and suggested numerous improvements.</para>
<para>We thank Katrina Avery for a great copy-editing job and Rosemary Simpson for producing the index under unreasonable time pressure. We thank Ami Dewar for doing the illustrations.</para>
<para>Thanks to the whole team at Addison-Wesley who helped make this book a reality. Ann Sellers got the project launched and Greg Doench shepherded it to a smooth completion; Elizabeth Ryan guided it through the production process.</para>
<para>We would also like to thank the thousands of software engineers who contributed indirectly by creating the software used to create this book, including TEX, LATEX, Adobe Acrobat, <literal>pic</literal>, <literal>grap</literal>, Adobe Illustrator, Perl, Apache Ant, IntelliJ IDEA, GNU emacs, Subversion, TortoiseSVN, and of course, the Java platform and class libraries.</para>
</section>
</preface>

<chapter id="ch01" label="1" xreflabel="1" condition="1">
<?docpage num="1"?>
<title id="ch01__title">Introduction</title>


<para><indexterm id="iddle1387" significance="normal"><?indexkey C?><?primarykey communication?><primary><emphasis role="strong">communication</emphasis></primary></indexterm><indexterm id="iddle1388" significance="normal"><?indexkey C?><?primarykey communication?><?secondarykey MECHANISMS FOR?><primary><emphasis role="strong">communication</emphasis></primary><secondary>mechanisms for</secondary></indexterm><indexterm id="iddle1457" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey BRIEF HISTORY?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>brief history</secondary></indexterm><indexterm id="iddle2321" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey AS CONCURRENCY MOTIVATION?><primary><emphasis role="strong">fairness</emphasis></primary><secondary>as concurrency motivation</secondary></indexterm><indexterm id="iddle2349" significance="normal"><?indexkey F?><?primarykey files?><?secondarykey AS COMMUNICATION MECHANISM?><primary><emphasis role="strong">files</emphasis></primary><secondary>as communication mechanism</secondary></indexterm><indexterm id="iddle3371" significance="normal"><?indexkey O?><?primarykey operating systems?><primary><emphasis role="strong">operating systems</emphasis></primary></indexterm><indexterm id="iddle3372" significance="normal"><?indexkey O?><?primarykey operating systems?><?secondarykey CONCURRENCY USE?><primary><emphasis role="strong">operating systems</emphasis></primary><secondary>concurrency use</secondary></indexterm><indexterm id="iddle3373" significance="normal"><?indexkey O?><?primarykey operating systems?><?secondarykey CONCURRENCY USE?><?tertiarykey HISTORICAL ROLE?><primary><emphasis role="strong">operating systems</emphasis></primary><secondary>concurrency use</secondary><tertiary>historical role</tertiary></indexterm><indexterm id="iddle3674" significance="normal"><?indexkey P?><?primarykey process(es)?><primary><emphasis role="strong">process(es)</emphasis></primary></indexterm><indexterm id="iddle3675" significance="normal"><?indexkey P?><?primarykey process(es)?><?secondarykey COMMUNICATION MECHANISMS?><primary><emphasis role="strong">process(es)</emphasis></primary><secondary>communication mechanisms</secondary></indexterm><indexterm id="iddle3941" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey UTILIZATION?><?tertiarykey AS CONCURRENCY MOTIVATION?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>utilization</secondary><tertiary>as concurrency motivation</tertiary></indexterm><indexterm id="iddle4147" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey AS COORDINATION MECHANISM?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>as coordination mechanism</secondary></indexterm><indexterm id="iddle4231" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey MEMORY?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>memory</secondary></indexterm><indexterm id="iddle4232" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey MEMORY?><?tertiarykey AS COORDINATION MECHANISM?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>memory</secondary><tertiary>as coordination mechanism</tertiary></indexterm><indexterm id="iddle4280" significance="normal"><?indexkey S?><?primarykey signal handlers?><primary><emphasis role="strong">signal handlers</emphasis></primary></indexterm><indexterm id="iddle4281" significance="normal"><?indexkey S?><?primarykey signal handlers?><?secondarykey AS COORDINATION MECHANISM?><primary><emphasis role="strong">signal handlers</emphasis></primary><secondary>as coordination mechanism</secondary></indexterm><indexterm id="iddle4323" significance="normal"><?indexkey S?><?primarykey sockets?><primary><emphasis role="strong">sockets</emphasis></primary></indexterm><indexterm id="iddle4324" significance="normal"><?indexkey S?><?primarykey sockets?><?secondarykey AS COORDINATION MECHANISM?><primary><emphasis role="strong">sockets</emphasis></primary><secondary>as coordination mechanism</secondary></indexterm>Writing correct programs is hard; writing correct concurrent programs is harder. There are simply more things that can go wrong in a concurrent program than in a sequential one. So, why do we bother with concurrency? Threads are an inescapable feature of the Java language, and they can simplify the development of complex systems by turning complicated asynchronous code into simpler straight-line code. In addition, threads are the easiest way to tap the computing power of multiprocessor systems. And, as processor counts increase, exploiting concurrency effectively will only become more important.</para>



<section id="ch01lev1sec1" condition="1" label="1.1" xreflabel="1.1"><?docpage num="1"?>
<title id="ch01lev1sec1__title">A (Very) Brief History of Concurrency</title>
<para>In the ancient past, computers didn’t have operating systems; they executed a single program from beginning to end, and that program had direct access to all the resources of the machine. Not only was it difficult to write programs that ran on the bare metal, but running only a single program at a time was an inefficient use of expensive and scarce computer resources.</para>
<para>Operating systems evolved to allow more than one program to run at once, running individual programs in <emphasis>processes</emphasis>: isolated, independently executing programs to which the operating system allocates resources such as memory, file handles, and security credentials. If they needed to, processes could communicate with one another through a variety of coarse-grained communication mechanisms: sockets, signal handlers, shared memory, semaphores, and files.</para>
<para>Several motivating factors led to the development of operating systems that allowed multiple programs to execute simultaneously:</para>
<formalpara><title><emphasis role="strong"><?design?>Resource utilization.</emphasis></title><para>Programs sometimes have to wait for external operations such as input or output, and while waiting can do no useful work. It is more efficient to use that wait time to let another program run.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Fairness.</emphasis></title><para>Multiple users and programs may have equal claims on the machine’s resources. It is preferable to let them share the computer via finer-grained time slicing than to let one program run to completion and then start another.</para></formalpara>
<formalpara><?docpage num="2"?><title><emphasis role="strong"><?design?>Convenience.</emphasis></title><para><indexterm id="iddle1133" significance="normal"><?indexkey A?><?primarykey asynchrony/asynchronous?><?secondarykey SEQUENTIALITY VS?><primary><emphasis role="strong">asynchrony/asynchronous</emphasis></primary><secondary>sequentiality vs</secondary></indexterm><indexterm id="iddle1634" significance="normal"><?indexkey C?><?primarykey convenience?><?secondarykey AS CONCURRENCY MOTIVATION?><primary><emphasis role="strong">convenience</emphasis></primary><secondary>as concurrency motivation</secondary></indexterm><indexterm id="iddle1756" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey SHARING?><?tertiarykey ADVANTAGES OF THREADS?><primary><emphasis role="strong">data</emphasis></primary><secondary>sharing</secondary><tertiary>advantages of threads</tertiary></indexterm><indexterm id="iddle2033" significance="normal"><?indexkey E?><?primarykey end-of-lifecycle?><primary><emphasis role="strong">end-of-lifecycle</emphasis></primary><seealso> <link linkend="iddle2603" preference="0"><emphasis role="strong">guidelines</emphasis>, threads</link>.</seealso></indexterm><indexterm id="iddle2984" significance="normal"><?indexkey L?><?primarykey lightweight processes?><primary><emphasis role="strong">lightweight processes</emphasis></primary><see> <link linkend="iddle2603" preference="0"><emphasis role="strong">guidelines</emphasis>, threads</link>.</see></indexterm><indexterm id="iddle3228" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey PROGRAMMING?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>programming</secondary></indexterm><indexterm id="iddle3229" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey PROGRAMMING?><?tertiarykey SEQUENTIAL?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>programming</secondary><tertiary>sequential</tertiary></indexterm><indexterm id="iddle3676" significance="normal"><?indexkey P?><?primarykey process(es)?><?secondarykey LIGHTWEIGHT?><primary><emphasis role="strong">process(es)</emphasis></primary><secondary>lightweight</secondary><see> <link linkend="iddle2603" preference="0"><emphasis role="strong">guidelines</emphasis>, threads</link>.</see></indexterm><indexterm id="iddle3677" significance="normal"><?indexkey P?><?primarykey process(es)?><?secondarykey THREADS VS?><primary><emphasis role="strong">process(es)</emphasis></primary><secondary>threads vs</secondary></indexterm><indexterm id="iddle3696" significance="normal"><?indexkey P?><?primarykey programming?><primary><emphasis role="strong">programming</emphasis></primary></indexterm><indexterm id="iddle3697" significance="normal"><?indexkey P?><?primarykey programming?><?secondarykey MODELS?><primary><emphasis role="strong">programming</emphasis></primary><secondary>models</secondary></indexterm><indexterm id="iddle3698" significance="normal"><?indexkey P?><?primarykey programming?><?secondarykey MODELS?><?tertiarykey SEQUENTIAL?><primary><emphasis role="strong">programming</emphasis></primary><secondary>models</secondary><tertiary>sequential</tertiary></indexterm><indexterm id="iddle4159" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey ASYNCHRONY VS?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>asynchrony vs</secondary></indexterm><indexterm id="iddle4168" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey PROGRAMMING MODEL?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>programming model</secondary></indexterm><indexterm id="iddle4228" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey DATA?><?tertiarykey THREADS ADVANTAGES VS. PROCESSES?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>data</secondary><tertiary>threads advantages vs. processes</tertiary></indexterm><indexterm id="iddle4294" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><seealso> <link linkend="iddle2603" preference="0"><emphasis role="strong">guidelines</emphasis>, threads</link>.</seealso></indexterm><indexterm id="iddle4295" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><seealso> <link linkend="iddle4720" preference="0"><emphasis role="strong">Thread</emphasis></link>.</seealso></indexterm><indexterm id="iddle4741" significance="normal"><?indexkey T?><?primarykey thread(s)?><primary><emphasis role="strong">thread(s)</emphasis></primary><seealso> <link linkend="iddle1451" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis></link>.</seealso></indexterm><indexterm id="iddle4742" significance="normal"><?indexkey T?><?primarykey thread(s)?><primary><emphasis role="strong">thread(s)</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle4743" significance="normal"><?indexkey T?><?primarykey thread(s)?><primary><emphasis role="strong">thread(s)</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle4810" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey PROCESSES VS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>processes vs</secondary></indexterm><indexterm id="iddle4935" significance="normal"><?indexkey T?><?primarykey timesharing systems?><primary><emphasis role="strong">timesharing systems</emphasis></primary></indexterm><indexterm id="iddle4936" significance="normal"><?indexkey T?><?primarykey timesharing systems?><?secondarykey AS CONCURRENCY MECHANISM?><primary><emphasis role="strong">timesharing systems</emphasis></primary><secondary>as concurrency mechanism</secondary></indexterm>It is often easier or more desirable to write several programs that each perform a single task and have them coordinate with each other as necessary than to write a single program that performs all the tasks.</para></formalpara>
<para role="continued">In early timesharing systems, each process was a virtual von Neumann computer; it had a memory space storing both instructions and data, executing instructions sequentially according to the semantics of the machine language, and interacting with the outside world via the operating system through a set of I/O primitives. For each instruction executed there was a clearly defined “next instruction”, and control flowed through the program according to the rules of the instruction set. Nearly all widely used programming languages today follow this sequential programming model, where the language specification clearly defines “what comes next” after a given action is executed.</para>
<para>The sequential programming model is intuitive and natural, as it models the way humans work: do one thing at a time, in sequence—mostly. Get out of bed, put on your bathrobe, go downstairs and start the tea. As in programming languages, each of these real-world actions is an abstraction for a sequence of finer-grained actions—open the cupboard, select a flavor of tea, measure some tea into the pot, see if there’s enough water in the teakettle, if not put some more water in, set it on the stove, turn the stove on, wait for the water to boil, and so on. This last step—waiting for the water to boil—also involves a degree of <emphasis>asynchrony</emphasis>. While the water is heating, you have a choice of what to do—just wait, or do other tasks in that time such as starting the toast (another asynchronous task) or fetching the newspaper, while remaining aware that your attention will soon be needed by the teakettle. The manufacturers of teakettles and toasters know their products are often used in an asynchronous manner, so they raise an audible signal when they complete their task. Finding the right balance of sequentiality and asynchrony is often a characteristic of efficient people—and the same is true of programs.</para>
<para>The same concerns (resource utilization, fairness, and convenience) that motivated the development of processes also motivated the development of <emphasis>threads</emphasis>. Threads allow multiple streams of program control flow to coexist within a process. They share process-wide resources such as memory and file handles, but each thread has its own program counter, stack, and local variables. Threads also provide a natural decomposition for exploiting hardware parallelism on multiprocessor systems; multiple threads within the same program can be scheduled simultaneously on multiple CPUs.</para>
<para>Threads are sometimes called <emphasis>lightweight processes</emphasis>, and most modern operating systems treat threads, not processes, as the basic units of scheduling. In the absence of explicit coordination, threads execute simultaneously and asynchronously with respect to one another. Since threads share the memory address space of their owning process, all threads within a process have access to the same variables and allocate objects from the same heap, which allows finer-grained data sharing than inter-process mechanisms. But without explicit synchronization to coordinate access to shared data, a thread may modify variables that another thread is in the middle of using, with unpredictable results.</para>
</section>
<section id="ch01lev1sec2" condition="3" label="1.2" xreflabel="1.2">
<?docpage num="3"?>
<title id="ch01lev1sec2__title">Benefits of Threads</title>
<para><indexterm id="iddle3232" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey SIMPLICITY?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>simplicity</secondary></indexterm><indexterm id="iddle3233" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey SIMPLICITY?><?tertiarykey THREADS BENEFIT FOR?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>simplicity</secondary><tertiary>threads benefit for</tertiary></indexterm><indexterm id="iddle3265" significance="normal"><?indexkey M?><?primarykey multiprocessor systems?><?secondarykey THREADS USE OF?><primary><emphasis role="strong">multiprocessor systems</emphasis></primary><secondary>threads use of</secondary></indexterm><indexterm id="iddle4099" significance="normal"><?indexkey S?><?primarykey scheduling?><?secondarykey THREADS AS BASIC UNIT OF?><primary><emphasis role="strong">scheduling</emphasis></primary><secondary>threads as basic unit of</secondary></indexterm><indexterm id="iddle4284" significance="normal"><?indexkey S?><?primarykey simplicity?><?secondarykey OF MODELING?><primary><emphasis role="strong">simplicity</emphasis></primary><secondary>of modeling</secondary></indexterm><indexterm id="iddle4285" significance="normal"><?indexkey S?><?primarykey simplicity?><?secondarykey OF MODELING?><?tertiarykey THREADS BENEFIT FOR?><primary><emphasis role="strong">simplicity</emphasis></primary><secondary>of modeling</secondary><tertiary>threads benefit for</tertiary></indexterm><indexterm id="iddle4746" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey BENEFITS OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>benefits of</secondary></indexterm><indexterm id="iddle4879" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey THREADS BENEFIT FOR?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>threads benefit for</secondary></indexterm>When used properly, threads can reduce development and maintenance costs and improve the performance of complex applications. Threads make it easier to model how humans work and interact, by turning asynchronous workflows into mostly sequential ones. They can also turn otherwise convoluted code into straight-line code that is easier to write, read, and maintain.</para>
<para>Threads are useful in GUI applications for improving the responsiveness of the user interface, and in server applications for improving resource utilization and throughput. They also simplify the implementation of the JVM—the garbage collector usually runs in one or more dedicated threads. Most nontrivial Java applications rely to some degree on threads for their organization.</para>
<section id="ch01lev2sec1" label="1.2.1" xreflabel="1.2.1">
<title id="ch01lev2sec1__title">Exploiting Multiple Processors</title>
<para>Multiprocessor systems used to be expensive and rare, found only in large data centers and scientific computing facilities. Today they are cheap and plentiful; even low-end server and midrange desktop systems often have multiple processors. This trend will only accelerate; as it gets harder to scale up clock rates, processor manufacturers will instead put more processor cores on a single chip. All the major chip manufacturers have begun this transition, and we are already seeing machines with dramatically higher processor counts.</para>
<para>Since the basic unit of scheduling is the thread, a program with only one thread can run on at most one processor at a time. On a two-processor system, a single-threaded program is giving up access to half the available CPU resources; on a 100-processor system, it is giving up access to 99%. On the other hand, programs with multiple active threads can execute simultaneously on multiple processors. When properly designed, multithreaded programs can improve throughput by utilizing available processor resources more effectively.</para>
<para>Using multiple threads can also help achieve better throughput on singleprocessor systems. If a program is single-threaded, the processor remains idle while it waits for a synchronous I/O operation to complete. In a multithreaded program, another thread can still run while the first thread is waiting for the I/O to complete, allowing the application to still make progress during the blocking I/O. (This is like reading the newspaper while waiting for the water to boil, rather than waiting for the water to boil before starting to read.)</para>
</section>
<section id="ch01lev2sec2" label="1.2.2" xreflabel="1.2.2">
<title id="ch01lev2sec2__title">Simplicity of Modeling</title>
<para>It is often easier to manage your time when you have only one type of task to perform (fix these twelve bugs) than when you have several (fix the bugs, interview replacement candidates for the system administrator, complete your team’s performance evaluations, and create the slides for your presentation next week). When you have only one type of task to do, you can start at the top of the pile and keep working until the pile is exhausted (or you are); you don’t have to spend any mental energy figuring out what to work on next. On the other hand, managing <?docpage num="4"?><indexterm id="iddle1130" significance="normal"><?indexkey A?><?primarykey asynchrony/asynchronous?><primary><emphasis role="strong">asynchrony/asynchronous</emphasis></primary></indexterm><indexterm id="iddle1131" significance="normal"><?indexkey A?><?primarykey asynchrony/asynchronous?><?secondarykey EVENTS, HANDLING?><primary><emphasis role="strong">asynchrony/asynchronous</emphasis></primary><secondary>events, handling</secondary></indexterm><indexterm id="iddle2066" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey HANDLING?><?tertiarykey THREADS BENEFITS FOR?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>handling</secondary><tertiary>threads benefits for</tertiary></indexterm><indexterm id="iddle2413" significance="normal"><?indexkey F?><?primarykey frameworks?><?secondarykey THREADS BENEFITS FOR?><primary><emphasis role="strong">frameworks</emphasis></primary><secondary>threads benefits for</secondary></indexterm><indexterm id="iddle2683" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey SYNCHRONOUS?><?tertiarykey THREADS USE TO SIMULATE?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>synchronous</secondary><tertiary>threads use to simulate</tertiary></indexterm><indexterm id="iddle3340" significance="normal"><?indexkey N?><?primarykey NPTL threads package?><primary><emphasis role="strong">NPTL threads package</emphasis></primary></indexterm><indexterm id="iddle3341" significance="normal"><?indexkey N?><?primarykey NPTL threads package?><?secondarykey LINUX USE?><primary><emphasis role="strong">NPTL threads package</emphasis></primary><secondary>Linux use</secondary></indexterm><indexterm id="iddle4004" significance="normal"><?indexkey R?><?primarykey RMI (Remote Method Invocation)?><?secondarykey THREADS BENEFITS FOR?><primary><emphasis role="strong">RMI (Remote Method Invocation)</emphasis></primary><secondary>threads benefits for</secondary></indexterm><indexterm id="iddle4171" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey THREADS SIMULATION OF?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>threads simulation of</secondary></indexterm><indexterm id="iddle4203" significance="normal"><?indexkey S?><?primarykey servlets?><?secondarykey FRAMEWORK?><?tertiarykey THREADS BENEFITS FOR?><primary><emphasis role="strong">servlets</emphasis></primary><secondary>framework</secondary><tertiary>threads benefits for</tertiary></indexterm>multiple priorities and deadlines and switching from task to task usually carries some overhead.</para>
<para>The same is true for software: a program that processes one type of task sequentially is simpler to write, less error-prone, and easier to test than one managing multiple different types of tasks at once. Assigning a thread to each type of task or to each element in a simulation affords the illusion of sequentiality and insulates domain logic from the details of scheduling, interleaved operations, asynchronous I/O, and resource waits. A complicated, asynchronous workflow can be decomposed into a number of simpler, synchronous workflows each running in a separate thread, interacting only with each other at specific synchronization points.</para>
<para>This benefit is often exploited by frameworks such as servlets or RMI (Remote Method Invocation). The framework handles the details of request management, thread creation, and load balancing, dispatching portions of the request handling to the appropriate application component at the appropriate point in the work-flow. Servlet writers do not need to worry about how many other requests are being processed at the same time or whether the socket input and output streams block; when a servlet’s <literal>service</literal> method is called in response to a web request, it can process the request synchronously as if it were a single-threaded program. This can simplify component development and reduce the learning curve for using such frameworks.</para>
</section>
<section id="ch01lev2sec3" label="1.2.3" xreflabel="1.2.3">
<title id="ch01lev2sec3__title">Simplified Handling of Asynchronous Events</title>
<para>A server application that accepts socket connections from multiple remote clients may be easier to develop when each connection is allocated its own thread and allowed to use synchronous I/O.</para>
<para>If an application goes to read from a socket when no data is available, <literal>read</literal> blocks until some data is available. In a single-threaded application, this means that not only does processing the corresponding request stall, but processing of <emphasis>all</emphasis> requests stalls while the single thread is blocked. To avoid this problem, singlethreaded server applications are forced to use nonblocking I/O, which is far more complicated and error-prone than synchronous I/O. However, if each request has its own thread, then blocking does not affect the processing of other requests.</para>
<para>Historically, operating systems placed relatively low limits on the number of threads that a process could create, as few as several hundred (or even less). As a result, operating systems developed efficient facilities for multiplexed I/O, such as the Unix <literal>select</literal> and <literal>poll</literal> system calls, and to access these facilities, the Java class libraries acquired a set of packages (<literal>java.nio</literal>) for nonblocking I/O. However, operating system support for larger numbers of threads has improved significantly, making the thread-per-client model practical even for large numbers of clients on some platforms.<footnote id="ch01fn01" label="1"><para>The NPTL threads package, now part of most Linux distributions, was designed to support hundreds of thousands of threads. Nonblocking I/O has its own benefits, but better OS support for threads means that there are fewer situations for which it is <emphasis>essential</emphasis>.</para></footnote></para>
</section>
<section id="ch01lev2sec4" condition="5" label="1.2.4" xreflabel="1.2.4">
<?docpage num="5"?>
<title id="ch01lev2sec4__title">More Responsive User Interfaces</title>
<para><indexterm id="iddle1979" significance="normal"><?indexkey E?><?primarykey EDT (event dispatch thread)?><primary><emphasis role="strong">EDT (event dispatch thread)</emphasis></primary></indexterm><indexterm id="iddle1980" significance="normal"><?indexkey E?><?primarykey EDT (event dispatch thread)?><?secondarykey GUI FRAMEWORKS USE?><primary><emphasis role="strong">EDT (event dispatch thread)</emphasis></primary><secondary>GUI frameworks use</secondary></indexterm><indexterm id="iddle2061" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey DISPATCH THREAD?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>dispatch thread</secondary></indexterm><indexterm id="iddle2062" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey DISPATCH THREAD?><?tertiarykey GUI FRAMEWORKS USE?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>dispatch thread</secondary><tertiary>GUI frameworks use</tertiary></indexterm><indexterm id="iddle2068" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey MAIN EVENT LOOP?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>main event loop</secondary></indexterm><indexterm id="iddle2069" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey MAIN EVENT LOOP?><?tertiarykey VS. EVENT DISPATCH THREAD?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>main event loop</secondary><tertiary>vs. event dispatch thread</tertiary></indexterm><indexterm id="iddle2497" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey THREADS BENEFITS FOR?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>threads benefits for</secondary></indexterm><indexterm id="iddle2765" significance="normal"><?indexkey I?><?primarykey interfaces?><primary><emphasis role="strong">interfaces</emphasis></primary></indexterm><indexterm id="iddle2766" significance="normal"><?indexkey I?><?primarykey interfaces?><?secondarykey USER?><primary><emphasis role="strong">interfaces</emphasis></primary><secondary>user</secondary></indexterm><indexterm id="iddle2767" significance="normal"><?indexkey I?><?primarykey interfaces?><?secondarykey USER?><?tertiarykey THREADS BENEFITS FOR?><primary><emphasis role="strong">interfaces</emphasis></primary><secondary>user</secondary><tertiary>threads benefits for</tertiary></indexterm><indexterm id="iddle2776" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey THREAD?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle2777" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey THREAD?><?tertiarykey DANGERS OF?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>thread</secondary><tertiary>dangers of</tertiary></indexterm><indexterm id="iddle3176" significance="normal"><?indexkey M?><?primarykey main event loop?><primary><emphasis role="strong">main event loop</emphasis></primary></indexterm><indexterm id="iddle3177" significance="normal"><?indexkey M?><?primarykey main event loop?><?secondarykey VS. EVENT DISPATCH THREAD?><primary><emphasis role="strong">main event loop</emphasis></primary><secondary>vs. event dispatch thread</secondary></indexterm><indexterm id="iddle4573" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey THREAD SAFETY NEED FOR?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>thread safety need for</secondary></indexterm><indexterm id="iddle4740" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey RISKS?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>risks</secondary></indexterm><indexterm id="iddle4777" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey INTERLEAVING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>interleaving</secondary></indexterm><indexterm id="iddle4778" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey INTERLEAVING?><?tertiarykey DANGERS OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>interleaving</secondary><tertiary>dangers of</tertiary></indexterm><indexterm id="iddle4813" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey RISKS OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>risks of</secondary></indexterm><indexterm id="iddle5028" significance="normal"><?indexkey U?><?primarykey user?><?secondarykey INTERFACES?><primary><emphasis role="strong">user</emphasis></primary><secondary>interfaces</secondary></indexterm><indexterm id="iddle5029" significance="normal"><?indexkey U?><?primarykey user?><?secondarykey INTERFACES?><?tertiarykey THREADS BENEFITS FOR?><primary><emphasis role="strong">user</emphasis></primary><secondary>interfaces</secondary><tertiary>threads benefits for</tertiary></indexterm>GUI applications used to be single-threaded, which meant that you had to either frequently poll throughout the code for input events (which is messy and intrusive) or execute all application code indirectly through a “main event loop”. If code called from the main event loop takes too long to execute, the user interface appears to “freeze” until that code finishes, because subsequent user interface events cannot be processed until control is returned to the main event loop.</para>
<para>Modern GUI frameworks, such as the AWT and Swing toolkits, replace the main event loop with an <emphasis>event dispatch thread</emphasis> (EDT). When a user interface event such as a button press occurs, application-defined event handlers are called in the event thread. Most GUI frameworks are single-threaded subsystems, so the main event loop is effectively still present, but it runs in its own thread under the control of the GUI toolkit rather than the application.</para>
<para>If only short-lived tasks execute in the event thread, the interface remains responsive since the event thread is always able to process user actions reasonably quickly. However, processing a long-running task in the event thread, such as spell-checking a large document or fetching a resource over the network, impairs responsiveness. If the user performs an action while this task is running, there is a long delay before the event thread can process or even acknowledge it. To add insult to injury, not only does the UI become unresponsive, but it is impossible to cancel the offending task even if the UI provides a cancel button because the event thread is busy and cannot handle the cancel button-press event until the lengthy task completes! If, however, the long-running task is instead executed in a separate thread, the event thread remains free to process UI events, making the UI more responsive.</para>
</section>
</section>
<section id="ch01lev1sec3" condition="5" label="1.3" xreflabel="1.3"><?docpage num="5"?>
<title id="ch01lev1sec3__title">Risks of Threads</title>
<para>Java’s built-in support for threads is a double-edged sword. While it simplifies the development of concurrent applications by providing language and library support and a formal cross-platform memory model (it is this formal cross-platform memory model thatmakes possible the development of write-once, run-anywhere <emphasis>concurrent</emphasis> applications in Java), it also raises the bar for developers because more programs will use threads. When threads were more esoteric, concurrency was an “advanced” topic; now, mainstream developers must be aware of thread-safety issues.</para>
<section id="ch01lev2sec5" label="1.3.1" xreflabel="1.3.1">
<title id="ch01lev2sec5__title">Safety Hazards</title>
<para>Thread safety can be unexpectedly subtle because, in the absence of sufficient synchronization, the ordering of operations in multiple threads is unpredictable and sometimes surprising. <literal>UnsafeSequence</literal> in <link linkend="ch01list01" preference="0">Listing 1.1</link>, which is supposed to generate a sequence of unique integer values, offers a simple illustration of how the interleaving of actions in multiple threads can lead to undesirable results. It behaves correctly in a single-threaded environment, but in a multithreaded environment does not.</para>

<para><?docpage num="6"?></para><example id="ch01list01" label="1.1" role="Listing" xreflabel="1.1" condition="6">

<title id="ch01list01__title">Non-thread-safe Sequence Generator.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@NotThreadSafe
public class UnsafeSequence {
    private int value;

    <emphasis>/** Returns a unique value. */</emphasis>
    public int getNext() {
        return value++;
    }
}
</programlisting>
</example>
<para><indexterm id="iddle1094" significance="normal"><?indexkey A?><?primarykey annotations?><?secondarykey FOR CONCURRENCY DOCUMENTATION?><primary><emphasis role="strong">annotations</emphasis></primary><secondary>for concurrency documentation</secondary></indexterm><indexterm id="iddle1635" significance="normal"><?indexkey C?><?primarykey conventions?><primary><emphasis role="strong">conventions</emphasis></primary></indexterm><indexterm id="iddle1636" significance="normal"><?indexkey C?><?primarykey conventions?><?secondarykey ANNOTATIONS?><primary><emphasis role="strong">conventions</emphasis></primary><secondary>annotations</secondary></indexterm><indexterm id="iddle1637" significance="normal"><?indexkey C?><?primarykey conventions?><?secondarykey ANNOTATIONS?><?tertiarykey CONCURRENCY DOCUMENTATION?><primary><emphasis role="strong">conventions</emphasis></primary><secondary>annotations</secondary><tertiary>concurrency documentation</tertiary></indexterm><indexterm id="iddle1959" significance="normal"><?indexkey D?><?primarykey documentation?><?secondarykey ANNOTATION USE?><primary><emphasis role="strong">documentation</emphasis></primary><secondary>annotation use</secondary></indexterm><indexterm id="iddle2537" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INTERLEAVING DIAGRAMS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>interleaving diagrams</secondary></indexterm><indexterm id="iddle2768" significance="normal"><?indexkey I?><?primarykey interleaving?><primary><emphasis role="strong">interleaving</emphasis></primary></indexterm><indexterm id="iddle2769" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey DIAGRAM INTERPRETATIONS?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>diagram interpretations</secondary></indexterm><indexterm id="iddle3338" significance="normal"><?indexkey N?><?primarykey NotThreadSafe?><primary sortas="NotThreadSafe"><emphasis role="strong">@NotThreadSafe</emphasis></primary></indexterm><indexterm id="iddle4465" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey DOCUMENTATION USE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>documentation use</secondary></indexterm><indexterm id="iddle4466" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey DOCUMENTATION USE?><?tertiarykey ANNOTATIONS VALUE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>documentation use</secondary><tertiary>annotations value</tertiary></indexterm>The problem with <literal>UnsafeSequence</literal> is that with some unlucky timing, two threads could call <literal>getNext</literal> and receive <emphasis>the same value</emphasis>. <link linkend="ch01fig01" preference="1">Figure 1.1</link> shows how this can happen. The increment notation, <literal>someVariable++</literal>, may <emphasis>appear</emphasis> to be a single operation, but is in fact three separate operations: read the value, add one to it, and write out the new value. Since operations in multiple threads may be arbitrarily interleaved by the runtime, it is possible for two threads to read the value at the same time, both see the same value, and then both add one to it. The result is that the same sequence number is returned from multiple calls in different threads.</para>
<figure float="1" id="ch01fig01" label="1.1" xreflabel="1.1" condition="6">

<title id="ch01fig01__title">Unlucky Execution of <literal>UnsafeSequence.getNext</literal>.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="134" fileref="graphics/01fig01.gif" format="GIF" width="500"/></imageobject>

</mediaobject>
</figure>
<sidebar float="1" id="ch01sb01" condition="6"><title/>
<para>Diagrams like <link linkend="ch01fig01" preference="1">Figure 1.1</link> depict possible interleavings of operations in different threads. In these diagrams, time runs from left to right, and each line represents the activities of a different thread. These interleaving diagrams usually depict the worst case<footnote id="ch01fn02" label="2"><para>Actually, as we’ll see in <link linkend="ch03" preference="0">Chapter 3</link>, the worst case can be even worse than these diagrams usually show because of the possibility of reordering.</para></footnote> and are intended to show the danger of incorrectly assuming things will happen in a particular order.</para>
</sidebar>
<para><literal>UnsafeSequence</literal> uses a nonstandard annotation: <literal>@NotThreadSafe</literal>. This is one of several custom annotations used throughout this book to document concurrency properties of classes and class members. (Other class-level annotations used <?docpage num="7"?><indexterm id="iddle1395" significance="normal"><?indexkey C?><?primarykey compilation?><?secondarykey TIMING AND ORDERING ALTERATIONS?><primary><emphasis role="strong">compilation</emphasis></primary><secondary>timing and ordering alterations</secondary></indexterm><indexterm id="iddle1396" significance="normal"><?indexkey C?><?primarykey compilation?><?secondarykey TIMING AND ORDERING ALTERATIONS?><?tertiarykey THREAD SAFETY RISKS?><primary><emphasis role="strong">compilation</emphasis></primary><secondary>timing and ordering alterations</secondary><tertiary>thread safety risks</tertiary></indexterm><indexterm id="iddle2175" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SEQUENCE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Sequence</literal></secondary></indexterm><indexterm id="iddle2481" significance="normal"><?indexkey G?><?primarykey GuardedBy?><?secondarykey AND DOCUMENTING SYNCHRONIZATION POLICY?><primary sortas="GuardedBy"><emphasis role="strong">@GuardedBy</emphasis></primary><secondary>and documenting synchronization policy</secondary></indexterm><indexterm id="iddle2621" significance="normal"><?indexkey H?><?primarykey hardware?><?secondarykey TIMING AND ORDERING ALTERATIONS BY?><primary><emphasis role="strong">hardware</emphasis></primary><secondary>timing and ordering alterations by</secondary></indexterm><indexterm id="iddle2622" significance="normal"><?indexkey H?><?primarykey hardware?><?secondarykey TIMING AND ORDERING ALTERATIONS BY?><?tertiarykey THREAD SAFETY RISKS?><primary><emphasis role="strong">hardware</emphasis></primary><secondary>timing and ordering alterations by</secondary><tertiary>thread safety risks</tertiary></indexterm><indexterm id="iddle2703" significance="normal"><?indexkey I?><?primarykey Immutable?><primary sortas="Immutable"><emphasis role="strong">@Immutable</emphasis></primary></indexterm><indexterm id="iddle3415" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey PERFORMANCE-BASED ALTERATIONS IN?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>performance-based alterations in</secondary></indexterm><indexterm id="iddle3416" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey PERFORMANCE-BASED ALTERATIONS IN?><?tertiarykey THREAD SAFETY RISKS?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>performance-based alterations in</secondary><tertiary>thread safety risks</tertiary></indexterm><indexterm id="iddle3544" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TIMING AND ORDERING ALTERATIONS FOR?><primary><emphasis role="strong">performance</emphasis></primary><secondary>timing and ordering alterations for</secondary></indexterm><indexterm id="iddle3545" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TIMING AND ORDERING ALTERATIONS FOR?><?tertiarykey THREAD SAFETY RISKS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>timing and ordering alterations for</secondary><tertiary>thread safety risks</tertiary></indexterm><indexterm id="iddle3776" significance="normal"><?indexkey R?><?primarykey race conditions?><primary><emphasis role="strong">race conditions</emphasis></primary><seealso> <link linkend="iddle1451" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis></link>.</seealso></indexterm><indexterm id="iddle3777" significance="normal"><?indexkey R?><?primarykey race conditions?><primary><emphasis role="strong">race conditions</emphasis></primary><seealso> <link linkend="iddle17641" preference="0"><emphasis role="strong">data race</emphasis></link>.</seealso></indexterm><indexterm id="iddle3778" significance="normal"><?indexkey R?><?primarykey race conditions?><primary><emphasis role="strong">race conditions</emphasis></primary><seealso> <link linkend="iddle48911" preference="0"><emphasis role="strong">time/timing</emphasis></link>.</seealso></indexterm><indexterm id="iddle4020" significance="normal"><?indexkey R?><?primarykey runtime?><primary><emphasis role="strong">runtime</emphasis></primary></indexterm><indexterm id="iddle4021" significance="normal"><?indexkey R?><?primarykey runtime?><?secondarykey TIMING AND ORDERING ALTERATIONS BY?><primary><emphasis role="strong">runtime</emphasis></primary><secondary>timing and ordering alterations by</secondary></indexterm><indexterm id="iddle4022" significance="normal"><?indexkey R?><?primarykey runtime?><?secondarykey TIMING AND ORDERING ALTERATIONS BY?><?tertiarykey THREAD SAFETY RISKS?><primary><emphasis role="strong">runtime</emphasis></primary><secondary>timing and ordering alterations by</secondary><tertiary>thread safety risks</tertiary></indexterm><indexterm id="iddle4566" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey POLICY?><?tertiarykey RACE CONDITION PREVENTION WITH?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>policy</secondary><tertiary>race condition prevention with</tertiary></indexterm><indexterm id="iddle4860" significance="normal"><?indexkey T?><?primarykey ThreadSafe?><primary sortas="ThreadSafe"><emphasis role="strong">@ThreadSafe</emphasis></primary></indexterm><indexterm id="iddle48911" significance="normal"><?indexkey T?><?primarykey time/timing?><primary><emphasis role="strong">time/timing</emphasis></primary></indexterm><indexterm id="iddle4915" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey PERFORMANCE-BASED ALTERATIONS IN THREAD SAFETY RISKS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>performance-based alterations in thread safety risks</secondary></indexterm>in this way are <literal>@ThreadSafe</literal> and <literal>@Immutable</literal>; see <link linkend="app01" preference="0">Appendix A</link> for details.) Annotations documenting thread safety are useful to multiple audiences. If a class is annotated with <literal>@ThreadSafe</literal>, users can use it with confidence in a multithreaded environment, maintainers are put on notice that it makes thread safety guarantees that must be preserved, and software analysis tools can identify possible coding errors.</para>
<para><literal>UnsafeSequence</literal> illustrates a common concurrency hazard called a <emphasis>race condition</emphasis>. Whether or not <literal>getNext</literal> returns a unique value when called from multiple threads, as required by its specification, depends on how the runtime interleaves the operations—which is not a desirable state of affairs.</para>
<para>Because threads share the same memory address space and run concurrently, they can access or modify variables that other threads might be using. This is a tremendous convenience, because it makes data sharing much easier than would other inter-thread communications mechanisms. But it is also a significant risk: threads can be confused by having data change unexpectedly. Allowing multiple threads to access and modify the same variables introduces an element of nonsequentiality into an otherwise sequential programming model, which can be confusing and difficult to reason about. For a multithreaded program’s behavior to be predictable, access to shared variables must be properly coordinated so that threads do not interfere with one another. Fortunately, Java provides synchronization mechanisms to coordinate such access.</para>
<para><literal>UnsafeSequence</literal> can be fixed by making <literal>getNext</literal> a <literal>synchronized</literal> method, as shown in <literal>Sequence</literal> in <link linkend="ch01list02" preference="0">Listing 1.2</link>,<footnote id="ch01fn03" label="3"><para><literal>@GuardedBy</literal> is described in <link linkend="ch02lev1sec4" preference="0">Section 2.4</link>; it documents the <emphasis>synchronization policy</emphasis> for <literal>Sequence</literal>.</para></footnote> thus preventing the unfortunate interaction in <link linkend="ch01fig01" preference="1">Figure 1.1</link>. (Exactly why this works is the subject of <link linkend="ch02" preference="0">Chapters 2</link> and <link linkend="ch03" preference="0">3</link>.)</para>
<example id="ch01list02" label="1.2" role="Listing" xreflabel="1.2" condition="7">
<title id="ch01list02__title">Thread-safe Sequence Generator.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class Sequence {
    <emphasis role="strong">@GuardedBy("this")</emphasis> private int Value;

    public <emphasis role="strong">synchronized</emphasis> int getNext() {
        return Value++;
    }
}
</programlisting>
</example>
<para>In the absence of synchronization, the compiler, hardware, and runtime are allowed to take substantial liberties with the timing and ordering of actions, such as caching variables in registers or processor-local caches where they are temporarily (or even permanently) invisible to other threads. These tricks are in aid of better performance and are generally desirable, but they place a burden on the developer to clearly identify where data is being shared across threads so that these optimizations do not undermine safety. (<link linkend="ch16" preference="0">Chapter 16</link> gives the gory details on exactly what ordering guarantees the JVM makes and how synchronization <?docpage num="8"?><indexterm id="iddle1261" significance="normal"><?indexkey B?><?primarykey buffer(s)?><primary><emphasis role="strong">buffer(s)</emphasis></primary><seealso> <link linkend="iddle1279" preference="0"><emphasis role="strong">cache/caching</emphasis></link>.</seealso></indexterm><indexterm id="iddle1279" significance="normal"><?indexkey C?><?primarykey cache/caching?><primary><emphasis role="strong">cache/caching</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle1614" significance="normal"><?indexkey C?><?primarykey context switching?><?secondarykey COST(S)?><primary><emphasis role="strong">context switching</emphasis></primary><secondary>cost(s)</secondary></indexterm><indexterm id="iddle1693" significance="normal"><?indexkey C?><?primarykey cost(s)?><?secondarykey THREAD?><?tertiarykey CONTEXT SWITCHING?><primary><emphasis role="strong">cost(s)</emphasis></primary><secondary>thread</secondary><tertiary>context switching</tertiary></indexterm><indexterm id="iddle1694" significance="normal"><?indexkey C?><?primarykey cost(s)?><?secondarykey THREAD?><?tertiarykey LOCALITY LOSS?><primary><emphasis role="strong">cost(s)</emphasis></primary><secondary>thread</secondary><tertiary>locality loss</tertiary></indexterm><indexterm id="iddle1709" significance="normal"><?indexkey C?><?primarykey CPU utilization?><primary><emphasis role="strong">CPU utilization</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle1758" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey SHARING?><?tertiarykey SYNCHRONIZATION COSTS?><primary><emphasis role="strong">data</emphasis></primary><secondary>sharing</secondary><tertiary>synchronization costs</tertiary></indexterm><indexterm id="iddle1797" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey AS LIVENESS FAILURE?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>as liveness failure</secondary></indexterm><indexterm id="iddle1991" significance="normal"><?indexkey E?><?primarykey efficiency?><primary><emphasis role="strong">efficiency</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle2074" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey TIMING?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>timing</secondary></indexterm><indexterm id="iddle2075" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey TIMING?><?tertiarykey AND LIVENESS FAILURES?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>timing</secondary><tertiary>and liveness failures</tertiary></indexterm><indexterm id="iddle2616" significance="normal"><?indexkey H?><?primarykey hardware?><primary><emphasis role="strong">hardware</emphasis></primary><seealso> <link linkend="iddle3251" preference="0"><emphasis role="strong">monitoring</emphasis>, CPU utilization</link>.</seealso></indexterm><indexterm id="iddle2950" significance="normal"><?indexkey L?><?primarykey leakage?><primary><emphasis role="strong">leakage</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle3014" significance="normal"><?indexkey L?><?primarykey livelock?><?secondarykey AS LIVENESS FAILURE?><primary><emphasis role="strong">livelock</emphasis></primary><secondary>as liveness failure</secondary></indexterm><indexterm id="iddle3015" significance="normal"><?indexkey L?><?primarykey liveness?><primary><emphasis role="strong">liveness</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle3016" significance="normal"><?indexkey L?><?primarykey liveness?><primary><emphasis role="strong">liveness</emphasis></primary><seealso> <link linkend="iddle3944" preference="0"><emphasis role="strong">responsiveness</emphasis></link>.</seealso></indexterm><indexterm id="iddle3028" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey TERM DEFINITION?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>term definition</secondary></indexterm><indexterm id="iddle3031" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey THREAD SAFETY HAZARDS FOR?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>thread safety hazards for</secondary></indexterm><indexterm id="iddle3037" significance="normal"><?indexkey L?><?primarykey locality, loss of?><primary><emphasis role="strong">locality, loss of</emphasis></primary></indexterm><indexterm id="iddle3038" significance="normal"><?indexkey L?><?primarykey locality, loss of?><?secondarykey AS COST OF THREAD USE?><primary><emphasis role="strong">locality, loss of</emphasis></primary><secondary>as cost of thread use</secondary></indexterm><indexterm id="iddle3422" significance="normal"><?indexkey O?><?primarykey overhead?><primary><emphasis role="strong">overhead</emphasis></primary><seealso> <link linkend="iddle3251" preference="0"><emphasis role="strong">monitoring</emphasis>, CPU utilization</link>.</seealso></indexterm><indexterm id="iddle3423" significance="normal"><?indexkey O?><?primarykey overhead?><primary><emphasis role="strong">overhead</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle3424" significance="normal"><?indexkey O?><?primarykey overhead?><primary><emphasis role="strong">overhead</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle3425" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey IMPACT OF?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>impact of</secondary><see> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</see></indexterm><indexterm id="iddle3426" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey IMPACT OF?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>impact of</secondary><see> <link linkend="iddle4867" preference="0"><emphasis role="strong">throughput</emphasis></link>.</see></indexterm><indexterm id="iddle3477" significance="normal"><?indexkey P?><?primarykey performance?><primary><emphasis role="strong">performance</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle3478" significance="normal"><?indexkey P?><?primarykey performance?><primary><emphasis role="strong">performance</emphasis></primary><seealso> <link linkend="iddle3497" preference="0"><emphasis role="strong">performance</emphasis>, liveness</link>.</seealso></indexterm><indexterm id="iddle3479" significance="normal"><?indexkey P?><?primarykey performance?><primary><emphasis role="strong">performance</emphasis></primary><seealso> <link linkend="iddle2574" preference="0"><emphasis role="strong">guidelines</emphasis>, scalability</link>.</seealso></indexterm><indexterm id="iddle3480" significance="normal"><?indexkey P?><?primarykey performance?><primary><emphasis role="strong">performance</emphasis></primary><seealso> <link linkend="iddle4867" preference="0"><emphasis role="strong">throughput</emphasis></link>.</seealso></indexterm><indexterm id="iddle3481" significance="normal"><?indexkey P?><?primarykey performance?><primary><emphasis role="strong">performance</emphasis></primary><seealso> <link linkend="iddle3939" preference="0"><emphasis role="strong">resource(s)</emphasis>, utilization</link>.</seealso></indexterm><indexterm id="iddle3494" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey HAZARDS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>hazards</secondary><seealso> <link linkend="iddle4093" preference="0"><emphasis role="strong">scheduling</emphasis>, overhead</link>.</seealso></indexterm><indexterm id="iddle3495" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey HAZARDS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>hazards</secondary><seealso> <link linkend="iddle3657" preference="0"><emphasis role="strong">priority(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle3511" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey OPTIMIZATION?><primary><emphasis role="strong">performance</emphasis></primary><secondary>optimization</secondary><seealso> <link linkend="iddle3251" preference="0"><emphasis role="strong">monitoring</emphasis>, CPU utilization</link>.</seealso></indexterm><indexterm id="iddle3512" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey OPTIMIZATION?><primary><emphasis role="strong">performance</emphasis></primary><secondary>optimization</secondary><seealso> <link linkend="iddle2614" preference="0"><emphasis role="strong">happens-before</emphasis>, piggybacking</link>.</seealso></indexterm><indexterm id="iddle3543" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey THREAD SAFETY HAZARDS FOR?><primary><emphasis role="strong">performance</emphasis></primary><secondary>thread safety hazards for</secondary></indexterm><indexterm id="iddle3907" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey CONSUMPTION?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>consumption</secondary></indexterm><indexterm id="iddle3908" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey CONSUMPTION?><?tertiarykey THREAD SAFETY HAZARDS FOR?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>consumption</secondary><tertiary>thread safety hazards for</tertiary></indexterm><indexterm id="iddle3974" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey THREAD?><?tertiarykey SAFETY HAZARDS FOR?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>thread</secondary><tertiary>safety hazards for</tertiary></indexterm><indexterm id="iddle4087" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey THREAD SAFETY HAZARDS FOR?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>thread safety hazards for</secondary></indexterm><indexterm id="iddle4227" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey DATA?><?tertiarykey SYNCHRONIZATION COSTS?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>data</secondary><tertiary>synchronization costs</tertiary></indexterm><indexterm id="iddle4372" significance="normal"><?indexkey S?><?primarykey starvation?><?secondarykey AS LIVENESS FAILURE?><primary><emphasis role="strong">starvation</emphasis></primary><secondary>as liveness failure</secondary></indexterm><indexterm id="iddle4759" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey COST?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>cost</secondary></indexterm><indexterm id="iddle4760" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey COST?><?tertiarykey CONTEXT LOCALITY LOSS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>cost</secondary><tertiary>context locality loss</tertiary></indexterm><indexterm id="iddle4761" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey COST?><?tertiarykey CONTEXT SWITCHING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>cost</secondary><tertiary>context switching</tertiary></indexterm><indexterm id="iddle4867" significance="normal"><?indexkey T?><?primarykey throughput?><primary><emphasis role="strong">throughput</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle4878" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey THREAD SAFETY HAZARDS FOR?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>thread safety hazards for</secondary></indexterm>affects those guarantees, but if you follow the rules in <link linkend="ch02" preference="0">Chapters 2</link> and <link linkend="ch03" preference="0">3</link>, you can safely avoid these low-level details.)</para>
</section>
<section id="ch01lev2sec6" label="1.3.2" xreflabel="1.3.2">
<title id="ch01lev2sec6__title">Liveness Hazards</title>
<para>It is critically important to pay attention to thread safety issues when developing concurrent code: safety cannot be compromised. The importance of safety is not unique to multithreaded programs—single-threaded programs also must take care to preserve safety and correctness—but the use of threads introduces additional safety hazards not present in single-threaded programs. Similarly, the use of threads introduces additional forms of <emphasis>liveness failure</emphasis> that do not occur in single-threaded programs.</para>
<para>While <emphasis>safety</emphasis> means “nothing bad ever happens”, liveness concerns the complementary goal that “something good eventually happens”. A liveness failure occurs when an activity gets into a state such that it is permanently unable to make forward progress. One form of liveness failure that can occur in sequential programs is an inadvertent infinite loop, where the code that follows the loop never gets executed. The use of threads introduces additional liveness risks. For example, if thread <emphasis>A</emphasis> is waiting for a resource that thread <emphasis>B</emphasis> holds exclusively, and <emphasis>B</emphasis> never releases it, <emphasis>A</emphasis> will wait forever. <link linkend="ch10" preference="0">Chapter 10</link> describes various forms of liveness failures and how to avoid them, including deadlock (<link linkend="ch10lev1sec1" preference="0">Section 10.1</link>), starvation (<link linkend="ch10lev2sec8" preference="0">Section 10.3.1</link>), and livelock (<link linkend="ch10lev2sec10" preference="0">Section 10.3.3</link>). Like most concurrency bugs, bugs that cause liveness failures can be elusive because they depend on the relative timing of events in different threads, and therefore do not always manifest themselves in development or testing.</para>
</section>
<section id="ch01lev2sec7" label="1.3.3" xreflabel="1.3.3">
<title id="ch01lev2sec7__title">Performance Hazards</title>
<para>Related to liveness is <emphasis>performance</emphasis>. While liveness means that something good <emphasis>eventually</emphasis> happens, eventually may not be good enough—we often want good things to happen quickly. Performance issues subsume a broad range of problems, including poor service time, responsiveness, throughput, resource consumption, or scalability. Just as with safety and liveness, multithreaded programs are subject to all the performance hazards of single-threaded programs, and to others as well that are introduced by the use of threads.</para>
<para>In well designed concurrent applications the use of threads is a net performance gain, but threads nevertheless carry some degree of runtime overhead. <emphasis>Context switches</emphasis>—when the scheduler suspends the active thread temporarily so another thread can run—are more frequent in applications with many threads, and have significant costs: saving and restoring execution context, loss of locality, and CPU time spent scheduling threads instead of running them. When threads share data, they must use synchronization mechanisms that can inhibit compiler optimizations, flush or invalidate memory caches, and create synchronization traffic on the shared memory bus. All these factors introduce additional performance costs; <link linkend="ch11" preference="0">Chapter 11</link> covers techniques for analyzing and reducing these costs.</para>
</section>
</section>
<section id="ch01lev1sec4" condition="9" label="1.4" xreflabel="1.4">
<?docpage num="9"?>
<title id="ch01lev1sec4__title">Threads are Everywhere</title>
<para><indexterm id="iddle1180" significance="normal"><?indexkey A?><?primarykey AWT (Abstract Window Toolkit)?><?secondarykey THREAD USE?><primary><emphasis role="strong">AWT (Abstract Window Toolkit)</emphasis></primary><secondary>thread use</secondary></indexterm><indexterm id="iddle2411" significance="normal"><?indexkey F?><?primarykey frameworks?><?secondarykey THREAD USE?><primary><emphasis role="strong">frameworks</emphasis></primary><secondary>thread use</secondary></indexterm><indexterm id="iddle2412" significance="normal"><?indexkey F?><?primarykey frameworks?><?secondarykey THREAD USE IMPACT ON APPLICATIONS?><primary><emphasis role="strong">frameworks</emphasis></primary><secondary>thread use impact on applications</secondary></indexterm><indexterm id="iddle2928" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey THREAD USE?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>thread use</secondary></indexterm><indexterm id="iddle4000" significance="normal"><?indexkey R?><?primarykey RMI (Remote Method Invocation)?><primary><emphasis role="strong">RMI (Remote Method Invocation)</emphasis></primary></indexterm><indexterm id="iddle4001" significance="normal"><?indexkey R?><?primarykey RMI (Remote Method Invocation)?><?secondarykey THREAD USE?><primary><emphasis role="strong">RMI (Remote Method Invocation)</emphasis></primary><secondary>thread use</secondary></indexterm><indexterm id="iddle4383" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey APPLICATION?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>application</secondary></indexterm><indexterm id="iddle4384" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey APPLICATION?><?tertiarykey FRAMEWORK THREADS IMPACT ON?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>application</secondary><tertiary>framework threads impact on</tertiary></indexterm><indexterm id="iddle4527" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey THREAD?><?tertiarykey USE?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>thread</secondary><tertiary>use</tertiary></indexterm><indexterm id="iddle4822" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SOURCES OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>sources of</secondary></indexterm><indexterm id="iddle4934" significance="normal"><?indexkey T?><?primarykey Timer?><?secondarykey THREAD USE?><primary><emphasis role="strong">Timer</emphasis></primary><secondary>thread use</secondary></indexterm>Even if your program never explicitly creates a thread, frameworks may create threads on your behalf, and code called from these threads must be thread-safe. This can place a significant design and implementation burden on developers, since developing thread-safe classes requires more care and analysis than developing non-thread-safe classes.</para>
<para>Every Java application uses threads. When the JVM starts, it creates threads for JVM housekeeping tasks (garbage collection, finalization) and a main thread for running the <literal>main</literal> method. The AWT (Abstract Window Toolkit) and Swing user interface frameworks create threads for managing user interface events. <literal>Timer</literal> creates threads for executing deferred tasks. Component frameworks, such as servlets and RMI create pools of threads and invoke component methods in these threads.</para>
<para>If you use these facilities—as many developers do—you have to be familiar with concurrency and thread safety, because these frameworks create threads and call your components from them. It would be nice to believe that concurrency is an “optional” or “advanced” language feature, but the reality is that nearly all Java applications are multithreaded and these frameworks do not insulate you from the need to properly coordinate access to application state.</para>
<para>When concurrency is introduced into an application by a framework, it is usually impossible to restrict the concurrency-awareness to the framework code, because frameworks by their nature make callbacks to application components that in turn access application state. Similarly, the need for thread safety does not end with the components called by the framework—it extends to all code paths that access the program state accessed by those components. Thus, the need for thread safety is contagious.</para>
<sidebar float="1" id="ch01sb02" condition="9"><title/>
<para>Frameworks introduce concurrency into applications by calling application components from framework threads. Components invariably access application state, thus requiring that <emphasis>all</emphasis> code paths accessing that state be thread-safe.</para>
</sidebar>
<para>The facilities described below all cause application code to be called from threads not managed by the application. While the need for thread safety may start with these facilities, it rarely ends there; instead, it ripples through the application.</para>
<itemizedlist mark="none" spacing="normal">
<listitem><formalpara><title><emphasis role="strong"><?design?>Timer.</emphasis></title><para><literal>Timer</literal> is a convenience mechanism for scheduling tasks to run at a later time, either once or periodically. The introduction of a <literal>Timer</literal> can complicate an otherwise sequential program, because <literal>TimerTask</literal>s are executed in a thread managed by the <literal>Timer</literal>, not the application. If a <literal>TimerTask</literal> accesses data that is also accessed by other application threads, then not only must the <literal>TimerTask</literal> do so in a thread-safe manner, but <emphasis>so must any other classes that access that data</emphasis>. Often <?docpage num="10"?><indexterm id="iddle1107" significance="normal"><?indexkey A?><?primarykey application(s)?><?secondarykey %?><primary><emphasis role="strong">application(s)</emphasis></primary><secondary>-scoped objects</secondary></indexterm><indexterm id="iddle1108" significance="normal"><?indexkey A?><?primarykey application(s)?><?secondarykey %?><?tertiarykey THREAD SAFETY CONCERNS?><primary><emphasis role="strong">application(s)</emphasis></primary><secondary>-scoped objects</secondary><tertiary>thread safety concerns</tertiary></indexterm><indexterm id="iddle1111" significance="normal"><?indexkey A?><?primarykey application(s)?><?secondarykey GUI?><?tertiarykey THREAD SAFETY CONCERNS?><primary><emphasis role="strong">application(s)</emphasis></primary><secondary>GUI</secondary><tertiary>thread safety concerns</tertiary></indexterm><indexterm id="iddle1181" significance="normal"><?indexkey A?><?primarykey AWT (Abstract Window Toolkit)?><?secondarykey THREAD USE?><?tertiarykey SAFETY CONCERNS AND?><primary><emphasis role="strong">AWT (Abstract Window Toolkit)</emphasis></primary><secondary>thread use</secondary><tertiary>safety concerns and</tertiary></indexterm><indexterm id="iddle1583" significance="normal"><?indexkey C?><?primarykey containers?><?secondarykey SCOPED?><primary><emphasis role="strong">containers</emphasis></primary><secondary>scoped</secondary></indexterm><indexterm id="iddle1584" significance="normal"><?indexkey C?><?primarykey containers?><?secondarykey SCOPED?><?tertiarykey THREAD SAFETY CONCERNS?><primary><emphasis role="strong">containers</emphasis></primary><secondary>scoped</secondary><tertiary>thread safety concerns</tertiary></indexterm><indexterm id="iddle2487" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey APPLICATIONS?><?tertiarykey THREAD SAFETY CONCERNS?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>applications</secondary><tertiary>thread safety concerns</tertiary></indexterm><indexterm id="iddle2912" significance="normal"><?indexkey J?><?primarykey JSPs (JavaServer Pages)?><primary><emphasis role="strong">JSPs (JavaServer Pages)</emphasis></primary></indexterm><indexterm id="iddle2913" significance="normal"><?indexkey J?><?primarykey JSPs (JavaServer Pages)?><?secondarykey THREAD SAFETY REQUIREMENTS?><primary><emphasis role="strong">JSPs (JavaServer Pages)</emphasis></primary><secondary>thread safety requirements</secondary></indexterm><indexterm id="iddle3843" significance="normal"><?indexkey R?><?primarykey remote objects?><primary><emphasis role="strong">remote objects</emphasis></primary></indexterm><indexterm id="iddle3844" significance="normal"><?indexkey R?><?primarykey remote objects?><?secondarykey THREAD SAFETY CONCERNS?><primary><emphasis role="strong">remote objects</emphasis></primary><secondary>thread safety concerns</secondary></indexterm><indexterm id="iddle4002" significance="normal"><?indexkey R?><?primarykey RMI (Remote Method Invocation)?><?secondarykey THREAD USE?><primary><emphasis role="strong">RMI (Remote Method Invocation)</emphasis></primary><secondary>thread use</secondary></indexterm><indexterm id="iddle4003" significance="normal"><?indexkey R?><?primarykey RMI (Remote Method Invocation)?><?secondarykey THREAD USE?><?tertiarykey SAFETY CONCERNS AND?><primary><emphasis role="strong">RMI (Remote Method Invocation)</emphasis></primary><secondary>thread use</secondary><tertiary>safety concerns and</tertiary></indexterm><indexterm id="iddle4103" significance="normal"><?indexkey S?><?primarykey scope/scoped?><?secondarykey CONTAINERS?><primary><emphasis role="strong">scope/scoped</emphasis></primary><secondary>containers</secondary></indexterm><indexterm id="iddle4104" significance="normal"><?indexkey S?><?primarykey scope/scoped?><?secondarykey CONTAINERS?><?tertiarykey THREAD SAFETY CONCERNS?><primary><emphasis role="strong">scope/scoped</emphasis></primary><secondary>containers</secondary><tertiary>thread safety concerns</tertiary></indexterm><indexterm id="iddle4200" significance="normal"><?indexkey S?><?primarykey servlets?><primary><emphasis role="strong">servlets</emphasis></primary></indexterm><indexterm id="iddle4201" significance="normal"><?indexkey S?><?primarykey servlets?><?secondarykey FRAMEWORK?><primary><emphasis role="strong">servlets</emphasis></primary><secondary>framework</secondary></indexterm><indexterm id="iddle4202" significance="normal"><?indexkey S?><?primarykey servlets?><?secondarykey FRAMEWORK?><?tertiarykey THREAD SAFETY REQUIREMENTS?><primary><emphasis role="strong">servlets</emphasis></primary><secondary>framework</secondary><tertiary>thread safety requirements</tertiary></indexterm><indexterm id="iddle4210" significance="normal"><?indexkey S?><?primarykey session-scoped objects?><primary><emphasis role="strong">session-scoped objects</emphasis></primary></indexterm><indexterm id="iddle4211" significance="normal"><?indexkey S?><?primarykey session-scoped objects?><?secondarykey STATELESS?><?tertiarykey THREAD SAFETY CONCERNS?><primary><emphasis role="strong">session-scoped objects</emphasis></primary><secondary>stateless</secondary><tertiary>thread safety concerns</tertiary></indexterm><indexterm id="iddle4414" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey OBJECT?><?tertiarykey REMOTE AND THREAD SAFETY?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>object</secondary><tertiary>remote and thread safety</tertiary></indexterm><indexterm id="iddle4528" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey THREAD?><?tertiarykey USE, SAFETY CONCERNS AND?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>thread</secondary><tertiary>use, safety concerns and</tertiary></indexterm> the easiest way to achieve this is to ensure that objects accessed by the <literal>TimerTask</literal> are themselves thread-safe, thus encapsulating the thread safety within the shared objects.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Servlets and JavaServer Pages (JSPs).</emphasis></title><para>The servlets framework is designed to handle all the infrastructure of deploying a web application and dispatching requests from remote HTTP clients. A request arriving at the server is dispatched, perhaps through a chain of filters, to the appropriate servlet or JSP. Each servlet represents a component of application logic, and in high-volume web sites, multiple clients may require the services of the same servlet at once. The servlets specification requires that a servlet be prepared to be called simultaneously from multiple threads. In other words, servlets need to be thread-safe.</para></formalpara></listitem>
</itemizedlist>
<para>Even if you could guarantee that a servlet was only called from one thread at a time, you would still have to pay attention to thread safety when building a web application. Servlets often access state information shared with other servlets, such as application-scoped objects (those stored in the <literal>ServletContext</literal>) or session-scoped objects (those stored in the per-client <literal>HttpSession</literal>). When a servlet accesses objects shared across servlets or requests, it must coordinate access to these objects properly, since multiple requests could be accessing them simultaneously from separate threads. Servlets and JSPs, as well as servlet filters and objects stored in scoped containers like <literal>ServletContext</literal> and <literal>HttpSession</literal>, simply have to be thread-safe.</para>
<formalpara><title><emphasis role="strong"><?design?>Remote Method Invocation.</emphasis></title><para>RMI lets you invoke methods on objects running in another JVM. When you call a remote method with RMI, the method arguments are packaged (marshaled) into a byte stream and shipped over the network to the remote JVM, where they are unpacked (unmarshaled) and passed to the remote method.</para></formalpara>
<para>When the RMI code calls your remote object, in what thread does that call happen? You don’t know, but it’s definitely not in a thread you created—your object gets called in a thread managed by RMI. How many threads does RMI create? Could the same remote method on the same remote object be called simultaneously in multiple RMI threads?<footnote id="ch01fn04" label="4"><para>Answer: yes, but it’s not all that clear from the Javadoc—you have to read the RMI spec.</para></footnote></para>
<para>A remote object must guard against two thread safety hazards: properly coordinating access to state that may be shared with other objects, and properly coordinating access to the state of the remote object itself (since the same object may be called in multiple threads simultaneously). Like servlets, RMI objects should be prepared for multiple simultaneous calls and must provide their own thread safety.</para>
<formalpara><title><emphasis role="strong"><?design?>Swing and AWT.</emphasis></title><para>GUI applications are inherently asynchronous. Users may select a menu item or press a button at any time, and they expect that the application will respond promptly even if it is in the middle of doing something else. Swing and AWT address this problem by creating a separate thread for handling user-initiated events and updating the graphical view presented to the user.</para></formalpara>
<para><?docpage num="11"?><?docpage num="12"?>Swing components, such as <literal>JTable</literal>, are not thread-safe. Instead, Swing programs achieve their thread safety by confining all access to GUI components to the event thread. If an application wants to manipulate the GUI from outside the event thread, it must cause the code that will manipulate the GUI to run in the event thread instead.</para>
<para>When the user performs a UI action, an event handler is called in the event thread to perform whatever operation the user requested. If the handler needs to access application state that is also accessed from other threads (such as a document being edited), then the event handler, along with any other code that accesses that state, must do so in a thread-safe manner.</para>
</section>

</chapter>

<part id="part01" label="I" xreflabel="I" condition="13">
<?docpage num="13"?><?docpage num="14"?>
<title id="part01__title">Fundamentals</title>
<chapter id="ch02" label="2" xreflabel="2" condition="15">
<?docpage num="15"?><?docpage num="16"?>
<title id="ch02__title">Thread Safety</title>


<para><indexterm id="iddle1017" significance="normal"><?indexkey A?><?primarykey access?><primary><emphasis role="strong">access</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle1018" significance="normal"><?indexkey A?><?primarykey access?><primary><emphasis role="strong">access</emphasis></primary><seealso> <link linkend="iddle1754" preference="0"><emphasis role="strong">data</emphasis>, sharing, access coordination</link>.</seealso></indexterm><indexterm id="iddle1019" significance="normal"><?indexkey A?><?primarykey access?><primary><emphasis role="strong">access</emphasis></primary><seealso> <link linkend="iddle3209" preference="0"><emphasis role="strong">memory</emphasis>, visibility</link>.</seealso></indexterm><indexterm id="iddle1254" significance="normal"><?indexkey B?><?primarykey boundaries?><primary><emphasis role="strong">boundaries</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle1451" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><seealso> <link linkend="iddle3448" preference="0"><emphasis role="strong">parallelizing/parallelism</emphasis></link>.</seealso></indexterm><indexterm id="iddle1452" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle1453" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><seealso> <link linkend="iddle4532" preference="0"><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></link>.</seealso></indexterm><indexterm id="iddle1531" significance="normal"><?indexkey C?><?primarykey confinement?><primary><emphasis role="strong">confinement</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle1532" significance="normal"><?indexkey C?><?primarykey confinement?><primary><emphasis role="strong">confinement</emphasis></primary><seealso> <link linkend="iddle4294" preference="0"><emphasis role="strong">single-thread(ed)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1639" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle1640" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle1652" significance="normal"><?indexkey C?><?primarykey coordination?><primary><emphasis role="strong">coordination</emphasis></primary><seealso> <link linkend="iddle4532" preference="0"><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></link>.</seealso></indexterm><indexterm id="iddle1746" significance="normal"><?indexkey D?><?primarykey data?><primary><emphasis role="strong">data</emphasis></primary><seealso> <link linkend="iddle1338" preference="0"><emphasis role="strong">checkpoint</emphasis>, state</link>.</seealso></indexterm><indexterm id="iddle1998" significance="normal"><?indexkey E?><?primarykey encapsulation?><primary><emphasis role="strong">encapsulation</emphasis></primary><seealso> <link linkend="iddle4173" preference="0"><emphasis role="strong">serialized/serialization</emphasis>, access</link>.</seealso></indexterm><indexterm id="iddle1999" significance="normal"><?indexkey E?><?primarykey encapsulation?><primary><emphasis role="strong">encapsulation</emphasis></primary><seealso> <link linkend="iddle1284" preference="0"><emphasis role="strong">cache/caching</emphasis>, implementation issues, atomic/atomicity</link>.</seealso></indexterm><indexterm id="iddle2000" significance="normal"><?indexkey E?><?primarykey encapsulation?><primary><emphasis role="strong">encapsulation</emphasis></primary><seealso> <link linkend="iddle2512" preference="0"><emphasis role="strong">guidelines</emphasis>, confinement</link>.</seealso></indexterm><indexterm id="iddle2001" significance="normal"><?indexkey E?><?primarykey encapsulation?><primary><emphasis role="strong">encapsulation</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle2002" significance="normal"><?indexkey E?><?primarykey encapsulation?><primary><emphasis role="strong">encapsulation</emphasis></primary><seealso> <link linkend="iddle1338" preference="0"><emphasis role="strong">checkpoint</emphasis>, state</link>.</seealso></indexterm><indexterm id="iddle2003" significance="normal"><?indexkey E?><?primarykey encapsulation?><primary><emphasis role="strong">encapsulation</emphasis></primary><seealso> <link linkend="iddle3209" preference="0"><emphasis role="strong">memory</emphasis>, visibility</link>.</seealso></indexterm><indexterm id="iddle2347" significance="normal"><?indexkey F?><?primarykey files?><primary><emphasis role="strong">files</emphasis></primary><seealso> <link linkend="iddle1662" preference="0"><emphasis role="strong">copying</emphasis>, data</link>.</seealso></indexterm><indexterm id="iddle2348" significance="normal"><?indexkey F?><?primarykey files?><primary><emphasis role="strong">files</emphasis></primary><seealso> <link linkend="iddle1780" preference="0"><emphasis role="strong">database(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2870" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle2871" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><seealso> <link linkend="iddle1653" preference="0"><emphasis role="strong">coordination</emphasis>, control flow</link>.</seealso></indexterm><indexterm id="iddle2872" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><seealso> <link linkend="iddle3801" preference="0"><emphasis role="strong">recursion</emphasis></link>.</seealso></indexterm><indexterm id="iddle3027" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey SAFETY VS?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>safety vs</secondary><see> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</see></indexterm><indexterm id="iddle3032" significance="normal"><?indexkey L?><?primarykey local variables?><primary><emphasis role="strong">local variables</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle3033" significance="normal"><?indexkey L?><?primarykey local variables?><primary><emphasis role="strong">local variables</emphasis></primary><seealso> <link linkend="iddle1338" preference="0"><emphasis role="strong">checkpoint</emphasis>, state</link>.</seealso></indexterm><indexterm id="iddle3034" significance="normal"><?indexkey L?><?primarykey local variables?><primary><emphasis role="strong">local variables</emphasis></primary><seealso> <link linkend="iddle1510" preference="0"><emphasis role="strong">condition</emphasis>, variables</link>.</seealso></indexterm><indexterm id="iddle3262" significance="normal"><?indexkey M?><?primarykey multiprocessor systems?><primary><emphasis role="strong">multiprocessor systems</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle3266" significance="normal"><?indexkey M?><?primarykey multithreaded?><primary><emphasis role="strong">multithreaded</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle3267" significance="normal"><?indexkey M?><?primarykey multithreaded?><primary><emphasis role="strong">multithreaded</emphasis></primary><seealso> <link linkend="iddle2263" preference="0"><emphasis role="strong">Executor framework</emphasis>, single-threaded</link>.</seealso></indexterm><indexterm id="iddle3268" significance="normal"><?indexkey M?><?primarykey multithreaded?><primary><emphasis role="strong">multithreaded</emphasis></primary><seealso> <link linkend="iddle2603" preference="0"><emphasis role="strong">guidelines</emphasis>, threads</link>.</seealso></indexterm><indexterm id="iddle3278" significance="normal"><?indexkey M?><?primarykey mutable?><primary><emphasis role="strong">mutable</emphasis></primary></indexterm><indexterm id="iddle3281" significance="normal"><?indexkey M?><?primarykey mutable?><?secondarykey STATE?><primary><emphasis role="strong">mutable</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle3282" significance="normal"><?indexkey M?><?primarykey mutable?><?secondarykey STATE?><?tertiarykey MANAGING ACCESS TO, AS THREAD SAFETY GOAL?><primary><emphasis role="strong">mutable</emphasis></primary><secondary>state</secondary><tertiary>managing access to, as thread safety goal</tertiary></indexterm><indexterm id="iddle3448" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle3449" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><seealso> <link linkend="iddle5168" preference="0"><emphasis role="strong">wrapper(s)</emphasis>, factories, Decorator pattern</link>.</seealso></indexterm><indexterm id="iddle4028" significance="normal"><?indexkey S?><?primarykey safety?><primary><emphasis role="strong">safety</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle4029" significance="normal"><?indexkey S?><?primarykey safety?><primary><emphasis role="strong">safety</emphasis></primary><seealso> <link linkend="iddle5016" preference="0"><emphasis role="strong">updating</emphasis>, immutable objects</link>.</seealso></indexterm><indexterm id="iddle4030" significance="normal"><?indexkey S?><?primarykey safety?><primary><emphasis role="strong">safety</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle4031" significance="normal"><?indexkey S?><?primarykey safety?><primary><emphasis role="strong">safety</emphasis></primary><seealso> <link linkend="iddle4742" preference="0"><emphasis role="strong">thread(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle4158" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle4222" significance="normal"><?indexkey S?><?primarykey shared/sharing?><primary><emphasis role="strong">shared/sharing</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle4223" significance="normal"><?indexkey S?><?primarykey shared/sharing?><primary><emphasis role="strong">shared/sharing</emphasis></primary><seealso> <link linkend="iddle2569" preference="0"><emphasis role="strong">guidelines</emphasis>, publication</link>.</seealso></indexterm><indexterm id="iddle4239" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey STATE?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle4240" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey STATE?><?tertiarykey MANAGING ACCESS TO, AS THREAD SAFETY GOAL?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>state</secondary><tertiary>managing access to, as thread safety goal</tertiary></indexterm><indexterm id="iddle4377" significance="normal"><?indexkey S?><?primarykey state(s)?><primary><emphasis role="strong">state(s)</emphasis></primary><seealso> <link linkend="iddle1284" preference="0"><emphasis role="strong">cache/caching</emphasis>, implementation issues, atomic/atomicity</link>.</seealso></indexterm><indexterm id="iddle4378" significance="normal"><?indexkey S?><?primarykey state(s)?><primary><emphasis role="strong">state(s)</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle4379" significance="normal"><?indexkey S?><?primarykey state(s)?><primary><emphasis role="strong">state(s)</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle4380" significance="normal"><?indexkey S?><?primarykey state(s)?><primary><emphasis role="strong">state(s)</emphasis></primary><seealso> <link linkend="iddle4645" preference="0"><emphasis role="strong">task(s)</emphasis>, representation</link>.</seealso></indexterm><indexterm id="iddle4381" significance="normal"><?indexkey S?><?primarykey state(s)?><primary><emphasis role="strong">state(s)</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle4382" significance="normal"><?indexkey S?><?primarykey state(s)?><primary><emphasis role="strong">state(s)</emphasis></primary><seealso> <link linkend="iddle3209" preference="0"><emphasis role="strong">memory</emphasis>, visibility</link>.</seealso></indexterm><indexterm id="iddle4406" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey MANAGING ACCESS TO?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>managing access to</secondary></indexterm><indexterm id="iddle4407" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey MANAGING ACCESS TO?><?tertiarykey AS THREAD SAFETY GOAL?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>managing access to</secondary><tertiary>as thread safety goal</tertiary></indexterm><indexterm id="iddle4532" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><seealso> <link linkend="iddle4173" preference="0"><emphasis role="strong">serialized/serialization</emphasis>, access</link>.</seealso></indexterm><indexterm id="iddle4533" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle4534" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><seealso> <link linkend="iddle2879" preference="0"><emphasis role="strong">iterators/iteration</emphasis>, locking</link>.</seealso></indexterm><indexterm id="iddle4535" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle4729" significance="normal"><?indexkey T?><?primarykey thread safety?><primary><emphasis role="strong">thread safety</emphasis></primary></indexterm><indexterm id="iddle4959" significance="normal"><?indexkey T?><?primarykey transition?><primary><emphasis role="strong">transition</emphasis></primary><seealso> <link linkend="iddle1338" preference="0"><emphasis role="strong">checkpoint</emphasis>, state</link>.</seealso></indexterm><indexterm id="iddle5011" significance="normal"><?indexkey U?><?primarykey untrusted code behavior?><primary><emphasis role="strong">untrusted code behavior</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle5040" significance="normal"><?indexkey V?><?primarykey variables?><primary><emphasis role="strong">variables</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle5041" significance="normal"><?indexkey V?><?primarykey variables?><primary><emphasis role="strong">variables</emphasis></primary><seealso> <link linkend="iddle1338" preference="0"><emphasis role="strong">checkpoint</emphasis>, state</link>.</seealso></indexterm><indexterm id="iddle5060" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey STATE?><?tertiarykey OBJECT DATA STORED IN?><primary><emphasis role="strong">variables</emphasis></primary><secondary>state</secondary><tertiary>object data stored in</tertiary></indexterm><indexterm id="iddle5097" significance="normal"><?indexkey V?><?primarykey visibility?><primary><emphasis role="strong">visibility</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle5098" significance="normal"><?indexkey V?><?primarykey visibility?><primary><emphasis role="strong">visibility</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle5099" significance="normal"><?indexkey V?><?primarykey visibility?><primary><emphasis role="strong">visibility</emphasis></primary><seealso> <link linkend="iddle1602" preference="0"><emphasis role="strong">contention/contended</emphasis>, scope</link>.</seealso></indexterm>Perhaps surprisingly, concurrent programming isn’t so much about threads or locks, any more than civil engineering is about rivets and I-beams. Of course, building bridges that don’t fall down requires the correct use of a lot of rivets and I-beams, just as building concurrent programs require the correct use of threads and locks. But these are just <emphasis>mechanisms</emphasis>—means to an end. Writing thread-safe code is, at its core, about managing access to <emphasis>state</emphasis>, and in particular to <emphasis>shared, mutable state</emphasis>.</para>
<para>Informally, an object’s <emphasis>state</emphasis> is its data, stored in <emphasis>state variables</emphasis> such as instance or static fields. An object’s state may include fields from other, dependent objects; a <literal>HashMap</literal>’s state is partially stored in the <literal>HashMap</literal> object itself, but also in many <literal>Map.Entry</literal> objects. An object’s state encompasses any data that can affect its externally visible behavior.</para>
<para>By <emphasis>shared</emphasis>, we mean that a variable could be accessed by multiple threads; by <emphasis>mutable</emphasis>, we mean that its value could change during its lifetime. We may talk about thread safety as if it were about <emphasis>code</emphasis>, but what we are really trying to do is protect <emphasis>data</emphasis> from uncontrolled concurrent access.</para>
<para>Whether an object needs to be thread-safe depends on whether it will be accessed from multiple threads. This is a property of how the object is <emphasis>used</emphasis> in a program, not what it <emphasis>does</emphasis>. Making an object thread-safe requires using synchronization to coordinate access to its mutable state; failing to do so could result in data corruption and other undesirable consequences.</para>
<para><emphasis>Whenever more than one thread accesses a given state variable, and one of them might write to it, they all must coordinate their access to it using synchronization.</emphasis> The primary mechanism for synchronization in Java is the <literal>synchronized</literal> keyword, which provides exclusive locking, but the term “synchronization” also includes the use of <literal>volatile</literal> variables, explicit locks, and atomic variables.</para>
<para>You should avoid the temptation to think that there are “special” situations in which this rule does not apply. A program that omits needed synchronization might appear to work, passing its tests and performing well for years, but it is still broken and may fail at any moment.</para>
<sidebar float="1" id="ch02sb01" condition="15"><title/>
<para><?docpage num="16"?>If multiple threads access the same mutable state variable without appropriate synchronization, <emphasis>your program is broken</emphasis>. There are three ways to fix it:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para><emphasis>Don’t share</emphasis> the state variable across threads;</para></listitem>
<listitem><para>Make the state variable <emphasis>immutable</emphasis>; or</para></listitem>
<listitem><para>Use <emphasis>synchronization</emphasis> whenever accessing the state variable.</para></listitem>
</itemizedlist>
</sidebar>
<para role="continued">If you haven’t considered concurrent access in your class design, some of these approaches can require significant design modifications, so fixing the problem might not be as trivial as this advice makes it sound. <emphasis>It is far easier to design a class to be thread-safe than to retrofit it for thread safety later.</emphasis></para>
<para>In a large program, identifying whether multiple threads might access a given variable can be complicated. Fortunately, the same object-oriented techniques that help you write well-organized, maintainable classes—such as encapsulation and data hiding—can also help you create thread-safe classes. The less code that has access to a particular variable, the easier it is to ensure that all of it uses the proper synchronization, and the easier it is to reason about the conditions under which a given variable might be accessed. The Java language doesn’t force you to encapsulate state—it is perfectly allowable to store state in public fields (even public static fields) or publish a reference to an otherwise internal object—but the better encapsulated your program state, the easier it is to make your program thread-safe and to help maintainers keep it that way.</para>
<sidebar float="1" id="ch02sb02" condition="15"><title/>
<para>When designing thread-safe classes, good object-oriented techniques—encapsulation, immutability, and clear specification of invariants—are your best friends.</para>
</sidebar>
<para>There will be times when good object-oriented design techniques are at odds with real-world requirements; it may be necessary in these cases to compromise the rules of good design for the sake of performance or for the sake of backward compatibility with legacy code. Sometimes abstraction and encapsulation are at odds with performance—although not nearly as often as many developers believe—but it is always a good practice first to make your code right, and <emphasis>then</emphasis> make it fast. Even then, pursue optimization only if your performance measurements and requirements tell you that you must, and if those same measurements tell you that your optimizations actually made a difference under realistic conditions. <footnote id="ch02fn01" label="1"><para>In concurrent code, this practice should be adhered to even more than usual. Because concurrency bugs are so difficult to reproduce and debug, the benefit of a small performance gain on some infrequently used code path may well be dwarfed by the risk that the program will fail in the field.</para></footnote></para>
<para>If you decide that you simply must break encapsulation, all is not lost. It is still possible to make your program thread-safe, it is just a lot harder. Moreover, the <?docpage num="17"?><indexterm id="iddle1257" significance="normal"><?indexkey B?><?primarykey broken multi-threaded programs?><primary><emphasis role="strong">broken multi-threaded programs</emphasis></primary></indexterm><indexterm id="iddle1258" significance="normal"><?indexkey B?><?primarykey broken multi-threaded programs?><?secondarykey STRATEGIES FOR FIXING?><primary><emphasis role="strong">broken multi-threaded programs</emphasis></primary><secondary>strategies for fixing</secondary></indexterm><indexterm id="iddle1749" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey HIDING?><primary><emphasis role="strong">data</emphasis></primary><secondary>hiding</secondary></indexterm><indexterm id="iddle1750" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey HIDING?><?tertiarykey THREAD-SAFETY USE?><primary><emphasis role="strong">data</emphasis></primary><secondary>hiding</secondary><tertiary>thread-safety use</tertiary></indexterm><indexterm id="iddle1909" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey IMPORTANCE?><primary><emphasis role="strong">design</emphasis></primary><secondary>importance</secondary></indexterm><indexterm id="iddle1910" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey IMPORTANCE?><?tertiarykey IN THREAD-SAFE PROGRAMS?><primary><emphasis role="strong">design</emphasis></primary><secondary>importance</secondary><tertiary>in thread-safe programs</tertiary></indexterm><indexterm id="iddle2004" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey BREAKING?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>breaking</secondary></indexterm><indexterm id="iddle2005" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey BREAKING?><?tertiarykey COSTS OF?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>breaking</secondary><tertiary>costs of</tertiary></indexterm><indexterm id="iddle2022" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey STATE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle2023" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey STATE?><?tertiarykey BREAKING, COSTS OF?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>state</secondary><tertiary>breaking, costs of</tertiary></indexterm><indexterm id="iddle2032" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey THREAD-SAFETY USE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>thread-safety use</secondary></indexterm><indexterm id="iddle2518" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey DOCUMENTATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>documentation</secondary></indexterm><indexterm id="iddle2519" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey DOCUMENTATION?><?tertiarykey VALUE FOR SAFETY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>documentation</secondary><tertiary>value for safety</tertiary></indexterm><indexterm id="iddle2522" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey ENCAPSULATION?><?tertiarykey VALUE FOR SAFETY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>encapsulation</secondary><tertiary>value for safety</tertiary></indexterm><indexterm id="iddle2534" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey IMMUTABILITY?><?tertiarykey VALUE FOR SAFETY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>immutability</secondary><tertiary>value for safety</tertiary></indexterm><indexterm id="iddle2547" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INVARIANTS?><?tertiarykey VALUE FOR SAFETY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>invariants</secondary><tertiary>value for safety</tertiary></indexterm><indexterm id="iddle2580" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SHARING?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>sharing</secondary></indexterm><indexterm id="iddle2581" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SHARING?><?tertiarykey SAFETY STRATEGIES?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>sharing</secondary><tertiary>safety strategies</tertiary></indexterm><indexterm id="iddle2715" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><?secondarykey THREAD-SAFETY USE?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><secondary>thread-safety use</secondary></indexterm><indexterm id="iddle2864" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey SPECIFICATION OF?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>specification of</secondary></indexterm><indexterm id="iddle2865" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey SPECIFICATION OF?><?tertiarykey THREAD-SAFETY USE?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>specification of</secondary><tertiary>thread-safety use</tertiary></indexterm><indexterm id="iddle3522" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey REQUIREMENTS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>requirements</secondary></indexterm><indexterm id="iddle3523" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey REQUIREMENTS?><?tertiarykey THREAD-SAFETY IMPACT?><primary><emphasis role="strong">performance</emphasis></primary><secondary>requirements</secondary><tertiary>thread-safety impact</tertiary></indexterm><indexterm id="iddle3889" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey PERFORMANCE?><?tertiarykey THREAD-SAFETY IMPACT?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>performance</secondary><tertiary>thread-safety impact</tertiary></indexterm><indexterm id="iddle4395" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey ENCAPSULATION?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>encapsulation</secondary></indexterm><indexterm id="iddle4396" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey ENCAPSULATION?><?tertiarykey BREAKING, COSTS OF?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>encapsulation</secondary><tertiary>breaking, costs of</tertiary></indexterm><indexterm id="iddle4481" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey PROGRAM DESIGN ORDER?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>program design order</secondary></indexterm><indexterm id="iddle4482" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey PROGRAM DESIGN ORDER?><?tertiarykey CORRECTNESS THEN PERFORMANCE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>program design order</secondary><tertiary>correctness then performance</tertiary></indexterm><indexterm id="iddle1676" significance="normal"><?indexkey C?><?primarykey correctness?><primary><emphasis role="strong">correctness</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle1679" significance="normal"><?indexkey C?><?primarykey correctness?><?secondarykey THREAD SAFETY DEFINED IN TERMS OF?><primary><emphasis role="strong">correctness</emphasis></primary><secondary>thread safety defined in terms of</secondary></indexterm><indexterm id="iddle2401" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey SOLUTIONS?><?tertiarykey ENCAPSULATION?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>solutions</secondary><tertiary>encapsulation</tertiary></indexterm><indexterm id="iddle2866" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey THREAD SAFETY ROLE?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>thread safety role</secondary></indexterm><indexterm id="iddle3638" significance="normal"><?indexkey P?><?primarykey postconditions?><?secondarykey THREAD SAFETY ROLE?><primary><emphasis role="strong">postconditions</emphasis></primary><secondary>thread safety role</secondary></indexterm><indexterm id="iddle4338" significance="normal"><?indexkey S?><?primarykey specification?><?secondarykey CORRECTNESS DEFINED IN TERMS OF?><primary><emphasis role="strong">specification</emphasis></primary><secondary>correctness defined in terms of</secondary></indexterm><indexterm id="iddle4385" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey CODE VS?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>code vs</secondary></indexterm><indexterm id="iddle4386" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey CODE VS?><?tertiarykey THREAD-SAFETY FOCUS?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>code vs</secondary><tertiary>thread-safety focus</tertiary></indexterm><indexterm id="iddle4732" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey CHARACTERISTICS OF?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>characteristics of</secondary></indexterm>thread safety of your program will be more fragile, increasing not only development cost and risk but maintenance cost and risk as well. <link linkend="ch04" preference="0">Chapter 4</link> characterizes the conditions under which it is safe to relax encapsulation of state variables.</para>
<para>We’ve used the terms “thread-safe class” and “thread-safe program” nearly interchangeably thus far. Is a thread-safe program one that is constructed entirely of thread-safe classes? Not necessarily—a program that consists entirely of thread-safe classes may not be thread-safe, and a thread-safe program may contain classes that are not thread-safe. The issues surrounding the composition of thread-safe classes are also taken up in <link linkend="ch04" preference="0">Chapter 4</link>. In any case, the concept of a thread-safe class makes sense only if the class encapsulates its own state. Thread safety may be a term that is applied to <emphasis>code</emphasis>, but it is about <emphasis>state</emphasis>, and it can only be applied to the entire body of code that encapsulates its state, which may be an object or an entire program.</para>



<section id="ch02lev1sec1" condition="17" label="2.1" xreflabel="2.1"><?docpage num="17"?><?docpage num="18"?>
<title id="ch02lev1sec1__title">What is Thread Safety?</title>
<para>Defining thread safety is surprisingly tricky. The more formal attempts are so complicated as to offer little practical guidance or intuitive understanding, and the rest are informal descriptions that can seem downright circular. A quick Google search turns up numerous “definitions” like these:</para>
<blockquote>
<para>. . . can be called from multiple program threads without unwanted interactions between the threads.</para>
<para>. . .may be called by more than one thread at a time without requiring any other action on the caller’s part.</para>
</blockquote>
<para role="continued">Given definitions like these, it’s no wonder we find thread safety confusing! They sound suspiciously like “a class is thread-safe if it can be used safely from multiple threads.” You can’t really argue with such a statement, but it doesn’t offer much practical help either. How do we tell a thread-safe class from an unsafe one? What do we even mean by “safe”?</para>
<para>At the heart of any reasonable definition of thread safety is the concept of <emphasis>correctness</emphasis>. If our definition of thread safety is fuzzy, it is because we lack a clear definition of correctness.</para>
<para>Correctness means that a class <emphasis>conforms to its specification</emphasis>. A good specification defines <emphasis>invariants</emphasis> constraining an object’s state and <emphasis>postconditions</emphasis> describing the effects of its operations. Since we often don’t write adequate specifications for our classes, how can we possibly know they are correct? We can’t, but that doesn’t stop us from using them anyway once we’ve convinced ourselves that “the code works”. This “code confidence” is about as close as many of us get to correctness, so let’s just assume that single-threaded correctness is something that “we know it when we see it”. Having optimistically defined “correctness” as something that can be recognized, we can now define thread safety in a somewhat less circular way: a class is thread-safe when it continues to behave correctly when accessed from multiple threads.</para>
<sidebar float="1" id="ch02sb03" condition="17"><title/>
<para><?docpage num="18"?>A class is <emphasis>thread-safe</emphasis> if it behaves correctly when accessed from multiple threads, regardless of the scheduling or interleaving of the execution of those threads by the runtime environment, and with no additional synchronization or other coordination on the part of the calling code.</para>
</sidebar>
<para>Since any single-threaded program is also a valid multithreaded program, it cannot be thread-safe if it is not even correct in a single-threaded environment. <footnote id="ch02fn02" label="2"><para>If the loose use of “correctness” here bothers you, you may prefer to think of a thread-safe class as one that is no more broken in a concurrent environment than in a single-threaded environment.</para></footnote> If an object is correctly implemented, no sequence of operations—calls to public methods and reads or writes of public fields—should be able to violate any of its invariants or postconditions. <emphasis>No set of operations performed sequentially or concurrently on instances of a thread-safe class can cause an instance to be in an invalid state.</emphasis></para>
<sidebar float="1" id="ch02sb04" condition="17"><title/>
<para>Thread-safe classes encapsulate any needed synchronization so that clients need not provide their own.</para>
</sidebar>
<section id="ch02lev2sec1" label="2.1.1" xreflabel="2.1.1">
<title id="ch02lev2sec1__title">Example: A Stateless Servlet</title>
<para>In <link linkend="ch01" preference="0">Chapter 1</link>, we listed a number of frameworks that create threads and call your components from those threads, leaving you with the responsibility of making your components thread-safe. Very often, thread-safety requirements stem not from a decision to use threads directly but from a decision to use a facility like the Servlets framework. We’re going to develop a simple example—a servlet-based factorization service—and slowly extend it to add features while preserving its thread safety.</para>
<para><link linkend="ch02list01" preference="0">Listing 2.1</link> shows our simple factorization servlet. It unpacks the number to be factored from the servlet request, factors it, and packages the results into the servlet response.</para>
<example id="ch02list01" label="2.1" role="Listing" xreflabel="2.1" condition="17">
<title id="ch02list01__title">A Stateless Servlet.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class StatelessFactorizer implements Servlet {
    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        encodeIntoResponse(resp, factors);
    }
}
</programlisting>
</example>
<para><?docpage num="19"?><indexterm id="iddle2185" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey STATELESSFACTORIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>StatelessFactorizer</literal></secondary></indexterm><indexterm id="iddle2571" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SAFETY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>safety</secondary></indexterm><indexterm id="iddle2572" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SAFETY?><?tertiarykey DEFINITION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>safety</secondary><tertiary>definition</tertiary></indexterm><indexterm id="iddle2608" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey THREADS?><?tertiarykey SAFETY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>threads</secondary><tertiary>safety</tertiary></indexterm><indexterm id="iddle2779" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey THREAD EXECUTION?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>thread execution</secondary></indexterm><indexterm id="iddle2780" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey THREAD EXECUTION?><?tertiarykey IN THREAD SAFETY DEFINITION?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>thread execution</secondary><tertiary>in thread safety definition</tertiary></indexterm><indexterm id="iddle4208" significance="normal"><?indexkey S?><?primarykey servlets?><?secondarykey STATELESS?><primary><emphasis role="strong">servlets</emphasis></primary><secondary>stateless</secondary></indexterm><indexterm id="iddle4209" significance="normal"><?indexkey S?><?primarykey servlets?><?secondarykey STATELESS?><?tertiarykey AS THREAD-SAFETY EXAMPLE?><primary><emphasis role="strong">servlets</emphasis></primary><secondary>stateless</secondary><tertiary>as thread-safety example</tertiary></indexterm><indexterm id="iddle4422" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey STATELESS SERVLET?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>stateless servlet</secondary></indexterm><indexterm id="iddle4423" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey STATELESS SERVLET?><?tertiarykey AS THREAD-SAFETY EXAMPLE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>stateless servlet</secondary><tertiary>as thread-safety example</tertiary></indexterm><indexterm id="iddle4551" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey ENCAPSULATION?><?tertiarykey REQUIREMENT FOR THREAD-SAFE CLASSES?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>encapsulation</secondary><tertiary>requirement for thread-safe classes</tertiary></indexterm><indexterm id="iddle4728" significance="normal"><?indexkey T?><?primarykey thread safety?><primary><emphasis role="strong">thread safety</emphasis></primary></indexterm><indexterm id="iddle1166" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey THREAD-SAFETY ISSUES?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>thread-safety issues</secondary></indexterm><indexterm id="iddle1167" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey THREAD-SAFETY ISSUES?><?tertiarykey IN SERVLETS WITH STATE?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>thread-safety issues</secondary><tertiary>in servlets with state</tertiary></indexterm><indexterm id="iddle2210" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey UNSAFECOUNTINGFACTORIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>UnsafeCountingFactorizer</literal></secondary></indexterm><indexterm id="iddle2556" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey OBJECTS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>objects</secondary></indexterm><indexterm id="iddle2557" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey OBJECTS?><?tertiarykey STATELESS, THREAD-SAFETY OF?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>objects</secondary><tertiary>stateless, thread-safety of</tertiary></indexterm><indexterm id="iddle2591" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey STATELESS OBJECTS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>stateless objects</secondary></indexterm><indexterm id="iddle2592" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey STATELESS OBJECTS?><?tertiarykey THREAD-SAFETY OF?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>stateless objects</secondary><tertiary>thread-safety of</tertiary></indexterm><indexterm id="iddle2719" significance="normal"><?indexkey I?><?primarykey increment operation (++)?><primary><emphasis role="strong">increment operation (++)</emphasis></primary></indexterm><indexterm id="iddle2720" significance="normal"><?indexkey I?><?primarykey increment operation (++)?><?secondarykey AS NON-ATOMIC OPERATION?><primary><emphasis role="strong">increment operation (++)</emphasis></primary><secondary>as non-atomic operation</secondary></indexterm><indexterm id="iddle4204" significance="normal"><?indexkey S?><?primarykey servlets?><?secondarykey STATEFUL, THREAD-SAFETY ISSUES?><primary><emphasis role="strong">servlets</emphasis></primary><secondary>stateful, thread-safety issues</secondary></indexterm><indexterm id="iddle4205" significance="normal"><?indexkey S?><?primarykey servlets?><?secondarykey STATEFUL, THREAD-SAFETY ISSUES?><?tertiarykey ATOMICITY?><primary><emphasis role="strong">servlets</emphasis></primary><secondary>stateful, thread-safety issues</secondary><tertiary>atomicity</tertiary></indexterm><indexterm id="iddle4417" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey SERVLETS WITH?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>servlets with</secondary></indexterm><indexterm id="iddle4418" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey SERVLETS WITH?><?tertiarykey THREAD-SAFETY ISSUES, ATOMICITY?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>servlets with</secondary><tertiary>thread-safety issues, atomicity</tertiary></indexterm><indexterm id="iddle4737" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey ISSUES, ATOMICITY?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>issues, atomicity</secondary></indexterm><literal>StatelessFactorizer</literal> is, like most servlets, stateless: it has no fields and references no fields from other classes. The transient state for a particular computation exists solely in local variables that are stored on the thread’s stack and are accessible only to the executing thread. One thread accessing a <literal>StatelessFactorizer</literal> cannot influence the result of another thread accessing the same <literal>StatelessFactorizer</literal>; because the two threads do not share state, it is as if they were accessing different instances. Since the actions of a thread accessing a stateless object cannot affect the correctness of operations in other threads, stateless objects are thread-safe.</para>
<sidebar float="1" id="ch02sb05" condition="19"><title/>
<para>Stateless objects are always thread-safe.</para>
</sidebar>
<para>The fact that most servlets can be implemented with no state greatly reduces the burden of making servlets thread-safe. It is only when servlets want to remember things from one request to another that the thread safety requirement becomes an issue.</para>
</section>
</section>
<section id="ch02lev1sec2" condition="19" label="2.2" xreflabel="2.2"><?docpage num="19"?>
<title id="ch02lev1sec2__title">Atomicity</title>
<para>What happens when we add one element of state to what was a stateless object? Suppose we want to add a “hit counter” that measures the number of requests processed. The obvious approach is to add a <literal>long</literal> field to the servlet and increment it on each request, as shown in <literal>UnsafeCountingFactorizer</literal> in <link linkend="ch02list02" preference="0">Listing 2.2</link>.</para>
<example id="ch02list02" label="2.2" role="Listing" xreflabel="2.2" condition="19">
<title id="ch02list02__title">Servlet that Counts Requests without the Necessary Synchronization. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@NotThreadSafe
public class UnsafeCountingFactorizer implements Servlet {
    private long count = 0;

    public long getCount() { return count; }

    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        <emphasis role="strong">++count;</emphasis>
        encodeIntoResponse(resp, factors);
    }

}
</programlisting>
</example>
<para>Unfortunately, <literal>UnsafeCountingFactorizer</literal> is not thread-safe, even though it would work just fine in a single-threaded environment. Just like <literal>UnsafeSequence</literal> on page <link linkend="ch01list01" preference="0" role="pageref">6</link>, it is susceptible to <emphasis>lost updates</emphasis>. While the increment operation, <literal>++count</literal>, <?docpage num="20"?><indexterm id="iddle17641" significance="normal"><?indexkey D?><?primarykey data race?><primary><emphasis role="strong">data race</emphasis></primary></indexterm><indexterm id="iddle1764" significance="normal"><?indexkey D?><?primarykey data race?><?secondarykey RACE CONDITION VS?><primary><emphasis role="strong">data race</emphasis></primary><secondary>race condition vs</secondary></indexterm><indexterm id="iddle2778" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey THREAD?><?tertiarykey TIMING DEPENDENCIES IMPACT ON RACE CONDITIONS?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>thread</secondary><tertiary>timing dependencies impact on race conditions</tertiary></indexterm><indexterm id="iddle3779" significance="normal"><?indexkey R?><?primarykey race conditions?><primary><emphasis role="strong">race conditions</emphasis></primary></indexterm><indexterm id="iddle3794" significance="normal"><?indexkey R?><?primarykey read-modify-write operation?><?secondarykey AS NON-ATOMIC OPERATION?><primary><emphasis role="strong">read-modify-write operation</emphasis></primary><secondary>as non-atomic operation</secondary></indexterm><indexterm id="iddle4366" significance="normal"><?indexkey S?><?primarykey stale data?><?secondarykey RACE CONDITION CAUSE?><primary><emphasis role="strong">stale data</emphasis></primary><secondary>race condition cause</secondary></indexterm>may look like a single action because of its compact syntax, it is not <emphasis>atomic</emphasis>, which means that it does not execute as a single, indivisible operation. Instead, it is a shorthand for a sequence of three discrete operations: fetch the current value, add one to it, and write the new value back. This is an example of a <emphasis>read-modify-write</emphasis> operation, in which the resulting state is derived from the previous state.</para>
<para><link linkend="ch01fig01" preference="1">Figure 1.1</link> on page <link linkend="ch01list01" preference="0" role="pageref">6</link> shows what can happen if two threads try to increment a counter simultaneously without synchronization. If the counter is initially 9, with some unlucky timing each thread could read the value, see that it is 9, add one to it, and each set the counter to 10. This is clearly not what is supposed to happen; an increment got lost along the way, and the hit counter is now permanently off by one.</para>
<para>You might think that having a slightly inaccurate count of hits in a web-based service is an acceptable loss of accuracy, and sometimes it is. But if the counter is being used to generate sequences or unique object identifiers, returning the same value from multiple invocations could cause serious data integrity problems.<footnote id="ch02fn03" label="3"><para>The approach taken by <literal>UnsafeSequence</literal> and <literal>UnsafeCountingFactorizer</literal> has other serious problems, including the possibility of stale data (<link linkend="ch03lev2sec1" preference="0">Section 3.1.1</link>).</para></footnote> The possibility of incorrect results in the presence of unlucky timing is so important in concurrent programming that it has a name: a <emphasis>race condition</emphasis>.</para>
<section id="ch02lev2sec2" label="2.2.1" xreflabel="2.2.1">
<title id="ch02lev2sec2__title">Race Conditions</title>
<para><literal>UnsafeCountingFactorizer</literal> has several <emphasis>race conditions</emphasis> that make its results unreliable. A race condition occurs when the correctness of a computation depends on the relative timing or interleaving of multiple threads by the runtime; in other words, when getting the right answer relies on lucky timing. <footnote id="ch02fn04" label="4"><para>The term <emphasis>race condition</emphasis> is often confused with the related term <emphasis>data race</emphasis>, which arises when synchronization is not used to coordinate all access to a shared nonfinal field. You risk a data race whenever a thread writes a variable that might next be read by another thread or reads a variable that might have last been written by another thread if both threads do not use synchronization; code with data races has no useful defined semantics under the Java Memory Model. Not all race conditions are data races, and not all data races are race conditions, but they both can cause concurrent programs to fail in unpredictable ways. <literal>UnsafeCountingFactorizer</literal> has both race conditions and data races. See <link linkend="ch16" preference="0">Chapter 16</link> for more on data races.</para></footnote> The most common type of race condition is <emphasis>check-then-act</emphasis>, where a potentially stale observation is used to make a decision on what to do next.</para>
<para>We often encounter race conditions in real life. Let’s say you planned to meet a friend at noon at the Starbucks on University Avenue. But when you get there, you realize there are <emphasis>two</emphasis> Starbucks on University Avenue, and you’re not sure which one you agreed to meet at. At 12:10, you don’t see your friend at Starbucks <emphasis>A</emphasis>, so you walk over to Starbucks <emphasis>B</emphasis> to see if he’s there, but he isn’t there either. There are a few possibilities: your friend is late and not at either Starbucks; your friend arrived at Starbucks <emphasis>A</emphasis> after you left; or your friend <emphasis>was</emphasis> at Starbucks <emphasis>B</emphasis>, but went to look for you, and is now en route to Starbucks <emphasis>A</emphasis>. Let’s assume the worst and say it was the last possibility. Now it’s 12:15, you’ve both been to both Starbucks, and you’re both wondering if you’ve been stood up. What do you do now? Go back to the other Starbucks? How many times are you going to go back <?docpage num="21"?><indexterm id="iddle1331" significance="normal"><?indexkey C?><?primarykey check-then-act operation?><?secondarykey AS RACE CONDITION CAUSE?><primary><emphasis role="strong">check-then-act operation</emphasis></primary><secondary>as race condition cause</secondary></indexterm><indexterm id="iddle2126" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey LAZYINITRACE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>LazyInitRace</literal></secondary></indexterm><indexterm id="iddle2736" significance="normal"><?indexkey I?><?primarykey initialization?><?secondarykey LAZY?><primary><emphasis role="strong">initialization</emphasis></primary><secondary>lazy</secondary></indexterm><indexterm id="iddle2737" significance="normal"><?indexkey I?><?primarykey initialization?><?secondarykey LAZY?><?tertiarykey AS RACE CONDITION CAUSE?><primary><emphasis role="strong">initialization</emphasis></primary><secondary>lazy</secondary><tertiary>as race condition cause</tertiary></indexterm><indexterm id="iddle2946" significance="normal"><?indexkey L?><?primarykey lazy initialization?><primary><emphasis role="strong">lazy initialization</emphasis></primary></indexterm><indexterm id="iddle2947" significance="normal"><?indexkey L?><?primarykey lazy initialization?><?secondarykey AS RACE CONDITION CAUSE?><primary><emphasis role="strong">lazy initialization</emphasis></primary><secondary>as race condition cause</secondary></indexterm><indexterm id="iddle3712" significance="normal"><?indexkey P?><?primarykey protocol(s)?><?secondarykey RACE CONDITION HANDLING?><primary><emphasis role="strong">protocol(s)</emphasis></primary><secondary>race condition handling</secondary></indexterm>and forth? Unless you have agreed on a protocol, you could both spend the day walking up and down University Avenue, frustrated and undercaffeinated.</para>
<para>The problem with the “I’ll just nip up the street and see if he’s at the other one” approach is that while you’re walking up the street, your friend might have moved. You look around Starbucks <emphasis>A</emphasis>, observe “he’s not here”, and go looking for him. And you can do the same for Starbucks <emphasis>B</emphasis>, but <emphasis>not at the same time</emphasis>. It takes a few minutes to walk up the street, and during those few minutes, <emphasis>the state of the system may have changed</emphasis>.</para>
<para>The Starbucks example illustrates a race condition because reaching the desired outcome (meeting your friend) depends on the relative timing of events (when each of you arrives at one Starbucks or the other, how long you wait there before switching, etc). The observation that he is not at Starbucks <emphasis>A</emphasis> becomes potentially invalid as soon as you walk out the front door; he could have come in through the back door and you wouldn’t know. It is this invalidation of observations that characterizes most race conditions—using a potentially stale observation to make a decision or perform a computation. This type of race condition is called <emphasis>check-then-act</emphasis>: you observe something to be true (file <emphasis>X</emphasis> doesn’t exist) and then take action based on that observation (create <emphasis>X</emphasis>); but in fact the observation could have become invalid between the time you observed it and the time you acted on it (someone else created <emphasis>X</emphasis> in the meantime), causing a problem (unexpected exception, overwritten data, file corruption).</para>
</section>
<section id="ch02lev2sec3" label="2.2.2" xreflabel="2.2.2">
<title id="ch02lev2sec3__title">Example: Race Conditions in Lazy Initialization</title>
<para>A common idiom that uses check-then-act is <emphasis>lazy initialization</emphasis>. The goal of lazy initialization is to defer initializing an object until it is actually needed while at the same time ensuring that it is initialized only once. <literal>LazyInitRace</literal> in <link linkend="ch02list03" preference="0">Listing 2.3</link> illustrates the lazy initialization idiom. The <literal>getInstance</literal> method first checks whether the <literal>ExpensiveObject</literal> has already been initialized, in which case it returns the existing instance; otherwise it creates a new instance and returns it after retaining a reference to it so that future invocations can avoid the more expensive code path.</para>
<example id="ch02list03" label="2.3" role="Listing" xreflabel="2.3" condition="21">
<title id="ch02list03__title">Race Condition in Lazy Initialization. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@NotThreadSafe
public class LazyInitRace {
    private ExpensiveObject instance = null;

    public ExpensiveObject getInstance() {
        if (instance == null)
            instance = new ExpensiveObject();
        return instance;
    }
}
</programlisting>
</example>
<para><?docpage num="22"?><indexterm id="iddle1035" significance="normal"><?indexkey A?><?primarykey action(s)?><primary><emphasis role="strong">action(s)</emphasis></primary><seealso> <link linkend="iddle1411" preference="0"><emphasis role="strong">compound actions</emphasis></link>.</seealso></indexterm><indexterm id="iddle1036" significance="normal"><?indexkey A?><?primarykey action(s)?><primary><emphasis role="strong">action(s)</emphasis></primary><seealso> <link linkend="iddle15001" preference="0"><emphasis role="strong">condition</emphasis></link>.</seealso></indexterm><indexterm id="iddle1037" significance="normal"><?indexkey A?><?primarykey action(s)?><primary><emphasis role="strong">action(s)</emphasis></primary><seealso> <link linkend="iddle1653" preference="0"><emphasis role="strong">coordination</emphasis>, control flow</link>.</seealso></indexterm><indexterm id="iddle1038" significance="normal"><?indexkey A?><?primarykey action(s)?><primary><emphasis role="strong">action(s)</emphasis></primary><seealso> <link linkend="iddle1134" preference="0"><emphasis role="strong">asynchrony/asynchronous</emphasis>, tasks</link>.</seealso></indexterm><indexterm id="iddle1144" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><seealso> <link linkend="iddle2544" preference="0"><emphasis role="strong">guidelines</emphasis>, invariants</link>.</seealso></indexterm><indexterm id="iddle1145" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle1146" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><seealso> <link linkend="iddle3209" preference="0"><emphasis role="strong">memory</emphasis>, visibility</link>.</seealso></indexterm><indexterm id="iddle1149" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey AND COMPOUND ACTIONS?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>and compound actions</secondary></indexterm><indexterm id="iddle1240" significance="normal"><?indexkey B?><?primarykey bound(ed)?><primary><emphasis role="strong">bound(ed)</emphasis></primary><seealso> <link linkend="iddle4891" preference="0"><emphasis role="strong">time/timing</emphasis>, constraints</link>.</seealso></indexterm><indexterm id="iddle1241" significance="normal"><?indexkey B?><?primarykey bound(ed)?><primary><emphasis role="strong">bound(ed)</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle1330" significance="normal"><?indexkey C?><?primarykey check-then-act operation?><primary><emphasis role="strong">check-then-act operation</emphasis></primary><seealso> <link linkend="iddle1411" preference="0"><emphasis role="strong">compound actions</emphasis></link>.</seealso></indexterm><indexterm id="iddle1411" significance="normal"><?indexkey C?><?primarykey compound actions?><primary><emphasis role="strong">compound actions</emphasis></primary><seealso> <link linkend="iddle1284" preference="0"><emphasis role="strong">cache/caching</emphasis>, implementation issues, atomic/atomicity</link>.</seealso></indexterm><indexterm id="iddle1412" significance="normal"><?indexkey C?><?primarykey compound actions?><primary><emphasis role="strong">compound actions</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle1413" significance="normal"><?indexkey C?><?primarykey compound actions?><primary><emphasis role="strong">compound actions</emphasis></primary><seealso> <link linkend="iddle3776" preference="0"><emphasis role="strong">race conditions</emphasis></link>.</seealso></indexterm><indexterm id="iddle1414" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey ATOMICITY HANDLING OF?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>atomicity handling of</secondary></indexterm><indexterm id="iddle1417" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey EXAMPLES OF?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>examples of</secondary><see> <link linkend="iddle1330" preference="0"><emphasis role="strong">check-then-act operation</emphasis></link>.</see></indexterm><indexterm id="iddle1418" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey EXAMPLES OF?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>examples of</secondary><see> <link linkend="iddle3116" preference="0"><emphasis role="strong">lock(ing)</emphasis>, iteration</link>.</see></indexterm><indexterm id="iddle1419" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey EXAMPLES OF?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>examples of</secondary><see> <link linkend="iddle3295" preference="0"><emphasis role="strong">navigation</emphasis></link>.</see></indexterm><indexterm id="iddle1420" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey EXAMPLES OF?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>examples of</secondary><see> <link linkend="iddle3736" preference="0"><emphasis role="strong">put-if-absent operation</emphasis></link>.</see></indexterm><indexterm id="iddle1421" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey EXAMPLES OF?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>examples of</secondary><see> <link linkend="iddle3793" preference="0"><emphasis role="strong">read-modify-write operation</emphasis></link>.</see></indexterm><indexterm id="iddle1422" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey EXAMPLES OF?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>examples of</secondary><see> <link linkend="iddle3845" preference="0"><emphasis role="strong">remove-if-equal operation</emphasis></link>.</see></indexterm><indexterm id="iddle1423" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey EXAMPLES OF?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>examples of</secondary><see> <link linkend="iddle3858" preference="0"><emphasis role="strong">replace-if-equal operation</emphasis></link>.</see></indexterm><indexterm id="iddle1559" significance="normal"><?indexkey C?><?primarykey constraints?><primary><emphasis role="strong">constraints</emphasis></primary><seealso> <link linkend="iddle2544" preference="0"><emphasis role="strong">guidelines</emphasis>, invariants</link>.</seealso></indexterm><indexterm id="iddle1560" significance="normal"><?indexkey C?><?primarykey constraints?><primary><emphasis role="strong">constraints</emphasis></primary><seealso> <link linkend="iddle3635" preference="0"><emphasis role="strong">postconditions</emphasis></link>.</seealso></indexterm><indexterm id="iddle1561" significance="normal"><?indexkey C?><?primarykey constraints?><primary><emphasis role="strong">constraints</emphasis></primary><seealso> <link linkend="iddle3635" preference="0"><emphasis role="strong">postconditions</emphasis></link>.</seealso></indexterm><indexterm id="iddle1680" significance="normal"><?indexkey C?><?primarykey corruption?><primary><emphasis role="strong">corruption</emphasis></primary><seealso> <link linkend="iddle1284" preference="0"><emphasis role="strong">cache/caching</emphasis>, implementation issues, atomic/atomicity</link>.</seealso></indexterm><indexterm id="iddle1681" significance="normal"><?indexkey C?><?primarykey corruption?><primary><emphasis role="strong">corruption</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle1682" significance="normal"><?indexkey C?><?primarykey corruption?><primary><emphasis role="strong">corruption</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle1683" significance="normal"><?indexkey C?><?primarykey corruption?><primary><emphasis role="strong">corruption</emphasis></primary><seealso> <link linkend="iddle1338" preference="0"><emphasis role="strong">checkpoint</emphasis>, state</link>.</seealso></indexterm><indexterm id="iddle1704" significance="normal"><?indexkey C?><?primarykey coupling?><primary><emphasis role="strong">coupling</emphasis></primary><seealso> <link linkend="iddle3983" preference="0"><emphasis role="strong">result(s)</emphasis>, dependencies</link>.</seealso></indexterm><indexterm id="iddle1770" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey HANDLING?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>handling</secondary><see> <link linkend="iddle1284" preference="0"><emphasis role="strong">cache/caching</emphasis>, implementation issues, atomic/atomicity</link>.</see></indexterm><indexterm id="iddle1771" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey HANDLING?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>handling</secondary><see> <link linkend="iddle2512" preference="0"><emphasis role="strong">guidelines</emphasis>, confinement</link>.</see></indexterm><indexterm id="iddle1772" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey HANDLING?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>handling</secondary><see> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</see></indexterm><indexterm id="iddle1773" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey HANDLING?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>handling</secondary><see> <link linkend="iddle2870" preference="0"><emphasis role="strong">iterators/iteration</emphasis></link>.</see></indexterm><indexterm id="iddle1774" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey HANDLING?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>handling</secondary><see> <link linkend="iddle3801" preference="0"><emphasis role="strong">recursion</emphasis></link>.</see></indexterm><indexterm id="iddle1864" significance="normal"><?indexkey D?><?primarykey dependencies?><primary><emphasis role="strong">dependencies</emphasis></primary><seealso> <link linkend="iddle1284" preference="0"><emphasis role="strong">cache/caching</emphasis>, implementation issues, atomic/atomicity</link>.</seealso></indexterm><indexterm id="iddle1865" significance="normal"><?indexkey D?><?primarykey dependencies?><primary><emphasis role="strong">dependencies</emphasis></primary><seealso> <link linkend="iddle2544" preference="0"><emphasis role="strong">guidelines</emphasis>, invariants</link>.</seealso></indexterm><indexterm id="iddle1866" significance="normal"><?indexkey D?><?primarykey dependencies?><primary><emphasis role="strong">dependencies</emphasis></primary><seealso> <link linkend="iddle2567" preference="0"><emphasis role="strong">guidelines</emphasis>, postconditions</link>.</seealso></indexterm><indexterm id="iddle1867" significance="normal"><?indexkey D?><?primarykey dependencies?><primary><emphasis role="strong">dependencies</emphasis></primary><seealso> <link linkend="iddle3639" preference="0"><emphasis role="strong">precondition(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1868" significance="normal"><?indexkey D?><?primarykey dependencies?><primary><emphasis role="strong">dependencies</emphasis></primary><seealso> <link linkend="iddle1338" preference="0"><emphasis role="strong">checkpoint</emphasis>, state</link>.</seealso></indexterm><indexterm id="iddle2464" significance="normal"><?indexkey G?><?primarykey granularity?><primary><emphasis role="strong">granularity</emphasis></primary><seealso> <link linkend="iddle1284" preference="0"><emphasis role="strong">cache/caching</emphasis>, implementation issues, atomic/atomicity</link>.</seealso></indexterm><indexterm id="iddle2465" significance="normal"><?indexkey G?><?primarykey granularity?><primary><emphasis role="strong">granularity</emphasis></primary><seealso> <link linkend="iddle1602" preference="0"><emphasis role="strong">contention/contended</emphasis>, scope</link>.</seealso></indexterm><indexterm id="iddle2503" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey ATOMICITY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>atomicity</secondary></indexterm><indexterm id="iddle2504" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey ATOMICITY?><?tertiarykey DEFINITIONS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>atomicity</secondary><tertiary>definitions</tertiary></indexterm><indexterm id="iddle2716" significance="normal"><?indexkey I?><?primarykey implicit coupling?><primary><emphasis role="strong">implicit coupling</emphasis></primary><seealso> <link linkend="iddle3983" preference="0"><emphasis role="strong">result(s)</emphasis>, dependencies</link>.</seealso></indexterm><indexterm id="iddle2840" significance="normal"><?indexkey I?><?primarykey invariant(s)?><primary><emphasis role="strong">invariant(s)</emphasis></primary><seealso> <link linkend="iddle1284" preference="0"><emphasis role="strong">cache/caching</emphasis>, implementation issues, atomic/atomicity</link>.</seealso></indexterm><indexterm id="iddle2841" significance="normal"><?indexkey I?><?primarykey invariant(s)?><primary><emphasis role="strong">invariant(s)</emphasis></primary><seealso> <link linkend="iddle2567" preference="0"><emphasis role="strong">guidelines</emphasis>, postconditions</link>.</seealso></indexterm><indexterm id="iddle2842" significance="normal"><?indexkey I?><?primarykey invariant(s)?><primary><emphasis role="strong">invariant(s)</emphasis></primary><seealso> <link linkend="iddle3635" preference="0"><emphasis role="strong">postconditions</emphasis></link>.</seealso></indexterm><indexterm id="iddle2843" significance="normal"><?indexkey I?><?primarykey invariant(s)?><primary><emphasis role="strong">invariant(s)</emphasis></primary><seealso> <link linkend="iddle1338" preference="0"><emphasis role="strong">checkpoint</emphasis>, state</link>.</seealso></indexterm><indexterm id="iddle3635" significance="normal"><?indexkey P?><?primarykey postconditions?><primary><emphasis role="strong">postconditions</emphasis></primary><seealso> <link linkend="iddle2544" preference="0"><emphasis role="strong">guidelines</emphasis>, invariants</link>.</seealso></indexterm><indexterm id="iddle3639" significance="normal"><?indexkey P?><?primarykey precondition(s)?><primary><emphasis role="strong">precondition(s)</emphasis></primary><seealso> <link linkend="iddle18731" preference="0"><emphasis role="strong">dependencies</emphasis></link>.</seealso></indexterm><indexterm id="iddle3640" significance="normal"><?indexkey P?><?primarykey precondition(s)?><primary><emphasis role="strong">precondition(s)</emphasis></primary><seealso> <link linkend="iddle2544" preference="0"><emphasis role="strong">guidelines</emphasis>, invariants</link>.</seealso></indexterm><indexterm id="iddle3736" significance="normal"><?indexkey P?><?primarykey put-if-absent operation?><primary><emphasis role="strong">put-if-absent operation</emphasis></primary><seealso> <link linkend="iddle1411" preference="0"><emphasis role="strong">compound actions</emphasis></link>.</seealso></indexterm><indexterm id="iddle3793" significance="normal"><?indexkey R?><?primarykey read-modify-write operation?><primary><emphasis role="strong">read-modify-write operation</emphasis></primary><seealso> <link linkend="iddle1411" preference="0"><emphasis role="strong">compound actions</emphasis></link>.</seealso></indexterm><indexterm id="iddle3876" significance="normal"><?indexkey R?><?primarykey requirements?><primary><emphasis role="strong">requirements</emphasis></primary><seealso> <link linkend="iddle4891" preference="0"><emphasis role="strong">time/timing</emphasis>, constraints</link>.</seealso></indexterm><indexterm id="iddle3877" significance="normal"><?indexkey R?><?primarykey requirements?><primary><emphasis role="strong">requirements</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle3878" significance="normal"><?indexkey R?><?primarykey requirements?><primary><emphasis role="strong">requirements</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle3879" significance="normal"><?indexkey R?><?primarykey requirements?><primary><emphasis role="strong">requirements</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle4102" significance="normal"><?indexkey S?><?primarykey scope/scoped?><primary><emphasis role="strong">scope/scoped</emphasis></primary><seealso> <link linkend="iddle3101" preference="0"><emphasis role="strong">lock(ing)</emphasis>, granularity</link>.</seealso></indexterm><indexterm id="iddle4988" significance="normal"><?indexkey U?><?primarykey unbounded?><primary><emphasis role="strong">unbounded</emphasis></primary><seealso> <link linkend="iddle1262" preference="0"><emphasis role="strong">buffer(s)</emphasis>, bounded</link>.</seealso></indexterm><indexterm id="iddle4989" significance="normal"><?indexkey U?><?primarykey unbounded?><primary><emphasis role="strong">unbounded</emphasis></primary><seealso> <link linkend="iddle4891" preference="0"><emphasis role="strong">time/timing</emphasis>, constraints</link>.</seealso></indexterm><indexterm id="iddle4990" significance="normal"><?indexkey U?><?primarykey unbounded?><primary><emphasis role="strong">unbounded</emphasis></primary><seealso> <link linkend="iddle1222" preference="0"><emphasis role="strong">block(ing)</emphasis>, queues, and thread pool management</link>.</seealso></indexterm><literal>LazyInitRace</literal> has race conditions that can undermine its correctness. Say that threads <emphasis>A</emphasis> and <emphasis>B</emphasis> execute <literal>getInstance</literal> at the same time. <emphasis>A</emphasis> sees that <literal>instance</literal> is <literal>null</literal>, and instantiates a new <literal>ExpensiveObject</literal>. <emphasis>B</emphasis> also checks if <literal>instance</literal> is <literal>null</literal>. Whether <literal>instance</literal> is <literal>null</literal> at this point depends unpredictably on timing, including the vagaries of scheduling and how long <emphasis>A</emphasis> takes to instantiate the <literal>ExpensiveObject</literal> and set the <literal>instance</literal> field. If <literal>instance</literal> is <literal>null</literal> when <emphasis>B</emphasis> examines it, the two callers to <literal>getInstance</literal> may receive two different results, even though <literal>getInstance</literal> is always supposed to return the same instance.</para>
<para>The hit-counting operation in <literal>UnsafeCountingFactorizer</literal> has another sort of race condition. Read-modify-write operations, like incrementing a counter, define a transformation of an object’s state in terms of its previous state. To increment a counter, you have to know its previous value <emphasis>and</emphasis> make sure no one else changes or uses that value while you are in mid-update.</para>
<para>Like most concurrency errors, race conditions don’t <emphasis>always</emphasis> result in failure: some unlucky timing is also required. But race conditions can cause serious problems. If <literal>LazyInitRace</literal> is used to instantiate an application-wide registry, having it return different instances from multiple invocations could cause registrations to be lost or multiple activities to have inconsistent views of the set of registered objects. If <literal>UnsafeSequence</literal> is used to generate entity identifiers in a persistence framework, two distinct objects could end up with the same ID, violating identity integrity constraints.</para>
</section>
<section id="ch02lev2sec4" label="2.2.3" xreflabel="2.2.3">
<title id="ch02lev2sec4__title">Compound Actions</title>
<para>Both <literal>LazyInitRace</literal> and <literal>UnsafeCountingFactorizer</literal> contained a sequence of operations that needed to be <emphasis>atomic</emphasis>, or indivisible, relative to other operations on the same state. To avoid race conditions, there must be a way to prevent other threads from using a variable while we’re in the middle of modifying it, so we can ensure that other threads can observe or modify the state only before we start or after we finish, but not in the middle.</para>
<sidebar float="1" id="ch02sb06" condition="22"><title/>
<para>Operations <emphasis>A</emphasis> and <emphasis>B</emphasis> are <emphasis>atomic</emphasis> with respect to each other if, from the perspective of a thread executing <emphasis>A</emphasis>, when another thread executes <emphasis>B</emphasis>, either all of <emphasis>B</emphasis> has executed or none of it has. An <emphasis>atomic operation</emphasis> is one that is atomic with respect to all operations, including itself, that operate on the same state.</para>
</sidebar>
<para>If the increment operation in <literal>UnsafeSequence</literal> were atomic, the race condition illustrated in <link linkend="ch01fig01" preference="1">Figure 1.1</link> on page <link linkend="ch01list01" preference="0" role="pageref">6</link> could not occur, and each execution of the increment operation would have the desired effect of incrementing the counter by exactly one. To ensure thread safety, check-then-act operations (like lazy initialization) and read-modify-write operations (like increment) must always be atomic. We refer collectively to check-then-act and read-modify-write sequences as <emphasis>compound actions</emphasis>: sequences of operations that must be executed atomically in order to remain thread-safe. In the next section, we’ll consider <emphasis>locking</emphasis>, Java’s builtin mechanism for ensuring atomicity. For now, we’re going to fix the problem <?docpage num="23"?><indexterm id="iddle2027" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey STATE?><?tertiarykey THREAD-SAFE CLASS USE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>state</secondary><tertiary>thread-safe class use</tertiary></indexterm><indexterm id="iddle2105" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey COUNTINGFACTORIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>CountingFactorizer</literal></secondary></indexterm><indexterm id="iddle2589" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey STATE?><?tertiarykey MANAGING?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>state</secondary><tertiary>managing</tertiary></indexterm><indexterm id="iddle3156" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey THREAD-SAFETY ISSUES?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>thread-safety issues</secondary></indexterm><indexterm id="iddle3157" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey THREAD-SAFETY ISSUES?><?tertiarykey IN SERVLETS WITH STATE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>thread-safety issues</secondary><tertiary>in servlets with state</tertiary></indexterm><indexterm id="iddle4207" significance="normal"><?indexkey S?><?primarykey servlets?><?secondarykey STATEFUL, THREAD-SAFETY ISSUES?><?tertiarykey LOCKING?><primary><emphasis role="strong">servlets</emphasis></primary><secondary>stateful, thread-safety issues</secondary><tertiary>locking</tertiary></indexterm><indexterm id="iddle4399" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey ENCAPSULATION?><?tertiarykey THREAD-SAFE CLASS USE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>encapsulation</secondary><tertiary>thread-safe class use</tertiary></indexterm><indexterm id="iddle4420" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey SERVLETS WITH?><?tertiarykey THREAD-SAFETY ISSUES, LOCKING?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>servlets with</secondary><tertiary>thread-safety issues, locking</tertiary></indexterm><indexterm id="iddle4739" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey MECHANISMS, LOCKING?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>mechanisms, locking</secondary></indexterm>another way, by using an existing thread-safe class, as shown in <literal>CountingFactorizer</literal> in <link linkend="ch02list04" preference="0">Listing 2.4</link>.</para>
<example id="ch02list04" label="2.4" role="Listing" xreflabel="2.4" condition="23">
<title id="ch02list04__title">Servlet that Counts Requests Using <literal>AtomicLong</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class CountingFactorizer implements Servlet {
    private final <emphasis role="strong">AtomicLong count = new AtomicLong(0);</emphasis>

    public long getCount() { return <emphasis role="strong">count.get();</emphasis> }

    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = factor(i);
        <emphasis role="strong">count.incrementAndGet();</emphasis>
        encodeIntoResponse(resp, factors);
    }
}
</programlisting>
</example>
<para>The <literal>java.util.concurrent.atomic</literal> package contains <emphasis>atomic variable</emphasis> classes for effecting atomic state transitions on numbers and object references. By replacing the <literal>long</literal> counter with an <literal>AtomicLong</literal>, we ensure that all actions that access the counter state are atomic. <footnote id="ch02fn05" label="5"><para><literal>CountingFactorizer</literal> calls <literal>incrementAndGet</literal> to increment the counter, which also returns the incremented value; in this case the return value is ignored.</para></footnote> Because the state of the servlet <emphasis>is</emphasis> the state of the counter and the counter is thread-safe, our servlet is once again thread-safe.</para>
<para>We were able to add a counter to our factoring servlet and maintain thread safety by using an existing thread-safe class to manage the counter state, <literal>AtomicLong</literal>. When a <emphasis>single</emphasis> element of state is added to a stateless class, the resulting class will be thread-safe if the state is entirely managed by a thread-safe object. But, as we’ll see in the next section, going from one state variable to more than one is not necessarily as simple as going from zero to one.</para>
<sidebar float="1" id="ch02sb07" condition="23"><title/>
<para>Where practical, use existing thread-safe objects, like <literal>AtomicLong</literal>, to manage your class’s state. It is simpler to reason about the possible states and state transitions for existing thread-safe objects than it is for arbitrary state variables, and this makes it easier to maintain and verify thread safety.</para>
</sidebar>
</section>
</section>
<section id="ch02lev1sec3" condition="23" label="2.3" xreflabel="2.3"><?docpage num="23"?>
<title id="ch02lev1sec3__title">Locking</title>
<para>We were able to add one state variable to our servlet while maintaining thread safety by using a thread-safe object to manage the entire state of the servlet. But if <?docpage num="24"?><indexterm id="iddle1155" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey CACHING ISSUES?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>caching issues</secondary></indexterm><indexterm id="iddle1280" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey ATOMICITY ISSUES?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>atomicity issues</secondary></indexterm><indexterm id="iddle1871" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey IN MULTIPLE-VARIABLE INVARIANTS?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>in multiple-variable invariants</secondary></indexterm><indexterm id="iddle1872" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey IN MULTIPLE-VARIABLE INVARIANTS?><?tertiarykey THREAD SAFETY ISSUES?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>in multiple-variable invariants</secondary><tertiary>thread safety issues</tertiary></indexterm><indexterm id="iddle2209" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey UNSAFECACHINGFACTORIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>UnsafeCachingFactorizer</literal></secondary></indexterm><indexterm id="iddle2725" significance="normal"><?indexkey I?><?primarykey independent/independence?><?secondarykey MULTIPLE-VARIABLE INVARIANT LACK OF?><primary><emphasis role="strong">independent/independence</emphasis></primary><secondary>multiple-variable invariant lack of</secondary></indexterm><indexterm id="iddle2726" significance="normal"><?indexkey I?><?primarykey independent/independence?><?secondarykey MULTIPLE-VARIABLE INVARIANT LACK OF?><?tertiarykey THREAD SAFETY ISSUES?><primary><emphasis role="strong">independent/independence</emphasis></primary><secondary>multiple-variable invariant lack of</secondary><tertiary>thread safety issues</tertiary></indexterm><indexterm id="iddle2858" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey MULTIVARIABLE?><?tertiarykey PRESERVATION OF, AS THREAD SAFETY REQUIREMENT?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>multivariable</secondary><tertiary>preservation of, as thread safety requirement</tertiary></indexterm><indexterm id="iddle2859" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey MULTIVARIABLE?><?tertiarykey THREAD SAFETY ISSUES?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>multivariable</secondary><tertiary>thread safety issues</tertiary></indexterm><indexterm id="iddle3275" significance="normal"><?indexkey M?><?primarykey multivariable invariants?><?secondarykey DEPENDENCIES, THREAD SAFETY ISSUES?><primary><emphasis role="strong">multivariable invariants</emphasis></primary><secondary>dependencies, thread safety issues</secondary></indexterm><indexterm id="iddle3277" significance="normal"><?indexkey M?><?primarykey multivariable invariants?><?secondarykey PRESERVATION OF, AS THREAD SAFETY REQUIREMENT?><primary><emphasis role="strong">multivariable invariants</emphasis></primary><secondary>preservation of, as thread safety requirement</secondary></indexterm>we want to add more state to our servlet, can we just add more thread-safe state variables?</para>
<para>Imagine that we want to improve the performance of our servlet by caching the most recently computed result, just in case two consecutive clients request factorization of the same number. (This is unlikely to be an effective caching strategy; we offer a better one in <link linkend="ch05lev1sec6" preference="0">Section 5.6</link>.) To implement this strategy, we need to remember two things: the last number factored, and its factors.</para>
<para>We used <literal>AtomicLong</literal> to manage the counter state in a thread-safe manner; could we perhaps use its cousin, <literal>AtomicReference</literal>, <footnote id="ch02fn06" label="6"><para>Just as <literal>AtomicLong</literal> is a thread-safe holder class for a <literal>long</literal> integer, <literal>AtomicReference</literal> is a threadsafe holder class for an object reference. Atomic variables and their benefits are covered in <link linkend="ch15" preference="0">Chapter 15</link>.</para></footnote> to manage the last number and its factors? An attempt at this is shown in <literal>UnsafeCachingFactorizer</literal> in <link linkend="ch02list05" preference="0">Listing 2.5</link>.</para>
<example id="ch02list05" label="2.5" role="Listing" xreflabel="2.5" condition="24">
<title id="ch02list05__title">Servlet that Attempts to Cache its Last Result without Adequate Atomicity. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@NotThreadSafe
public class UnsafeCachingFactorizer implements Servlet {
     private final AtomicReference&lt;BigInteger&gt; <emphasis role="strong">lastNumber</emphasis>
         = new AtomicReference&lt;BigInteger&gt;();
     private final AtomicReference&lt;BigInteger[]&gt;  <emphasis role="strong">lastFactors</emphasis>
         = new AtomicReference&lt;BigInteger[]&gt;();

     public void service(ServletRequest req, ServletResponse resp) {
         BigInteger i = extractFromRequest(req);
         if (i.equals(<emphasis role="strong">lastNumber.get()</emphasis>))
             encodeIntoResponse(resp,  <emphasis role="strong">lastFactors.get()</emphasis> )<emphasis role="strong">;</emphasis>
         else {
             BigInteger[] factors = factor(i);
             <emphasis role="strong">lastNumber.set(i);</emphasis>
             <emphasis role="strong">lastFactors.set(factors);</emphasis>
             encodeIntoResponse(resp, factors);
         }
     }
}
</programlisting>
</example>
<para>Unfortunately, this approach does not work. Even though the atomic references are individually thread-safe, <literal>UnsafeCachingFactorizer</literal> has race conditions that could make it produce the wrong answer.</para>
<para>The definition of thread safety requires that invariants be preserved regardless of timing or interleaving of operations in multiple threads. One invariant of <literal>UnsafeCachingFactorizer</literal> is that the product of the factors cached in <literal>lastFactors</literal> equal the value cached in <literal>lastNumber</literal>; our servlet is correct only if this invariant always holds. When multiple variables participate in an invariant, they are not <?docpage num="25"?><indexterm id="iddle1160" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey INTRINSIC LOCK ENFORCEMENT OF?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>intrinsic lock enforcement of</secondary></indexterm><indexterm id="iddle2368" significance="normal"><?indexkey F?><?primarykey flag(s)?><primary><emphasis role="strong">flag(s)</emphasis></primary><see> <link linkend="iddle3283" preference="0"><emphasis role="strong">mutexes (mutual exclusion locks)</emphasis></link>.</see></indexterm><indexterm id="iddle2587" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey STATE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle2588" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey STATE?><?tertiarykey CONSISTENCY PRESERVATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>state</secondary><tertiary>consistency preservation</tertiary></indexterm><indexterm id="iddle2721" significance="normal"><?indexkey I?><?primarykey independent/independence?><primary><emphasis role="strong">independent/independence</emphasis></primary><seealso> <link linkend="iddle3983" preference="0"><emphasis role="strong">result(s)</emphasis>, dependencies</link>.</seealso></indexterm><indexterm id="iddle2722" significance="normal"><?indexkey I?><?primarykey independent/independence?><primary><emphasis role="strong">independent/independence</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle2723" significance="normal"><?indexkey I?><?primarykey independent/independence?><primary><emphasis role="strong">independent/independence</emphasis></primary><seealso> <link linkend="iddle2544" preference="0"><emphasis role="strong">guidelines</emphasis>, invariants</link>.</seealso></indexterm><indexterm id="iddle2724" significance="normal"><?indexkey I?><?primarykey independent/independence?><primary><emphasis role="strong">independent/independence</emphasis></primary><seealso> <link linkend="iddle1338" preference="0"><emphasis role="strong">checkpoint</emphasis>, state</link>.</seealso></indexterm><indexterm id="iddle2826" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle2827" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><seealso> <link linkend="iddle2879" preference="0"><emphasis role="strong">iterators/iteration</emphasis>, locking</link>.</seealso></indexterm><indexterm id="iddle2828" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle2829" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle2830" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><seealso> <link linkend="iddle2603" preference="0"><emphasis role="strong">guidelines</emphasis>, threads</link>.</seealso></indexterm><indexterm id="iddle2831" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><primary><emphasis role="strong">intrinsic locks</emphasis></primary></indexterm><indexterm id="iddle3106" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary></indexterm><indexterm id="iddle3107" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary></indexterm><indexterm id="iddle3119" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey MONITOR?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>monitor</secondary><see> <link linkend="iddle2831" preference="0"><emphasis role="strong">intrinsic locks</emphasis></link>.</see></indexterm><indexterm id="iddle3245" significance="normal"><?indexkey M?><?primarykey monitor(s)?><?secondarykey LOCKS?><primary><emphasis role="strong">monitor(s)</emphasis></primary><secondary>locks</secondary><see> <link linkend="iddle2831" preference="0"><emphasis role="strong">intrinsic locks</emphasis></link>.</see></indexterm><indexterm id="iddle3283" significance="normal"><?indexkey M?><?primarykey mutexes (mutual exclusion locks)?><primary><emphasis role="strong">mutexes (mutual exclusion locks)</emphasis></primary></indexterm><indexterm id="iddle3285" significance="normal"><?indexkey M?><?primarykey mutexes (mutual exclusion locks)?><?secondarykey INTRINSIC LOCKS AS?><primary><emphasis role="strong">mutexes (mutual exclusion locks)</emphasis></primary><secondary>intrinsic locks as</secondary></indexterm><indexterm id="iddle4539" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey BLOCKS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>blocks</secondary></indexterm><indexterm id="iddle4540" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey BLOCKS?><?tertiarykey JAVA OBJECTS AS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>blocks</secondary><tertiary>Java objects as</tertiary></indexterm><indexterm id="iddle4955" significance="normal"><?indexkey T?><?primarykey transactions?><?secondarykey CONCURRENT ATOMICITY SIMILAR TO?><primary><emphasis role="strong">transactions</emphasis></primary><secondary>concurrent atomicity similar to</secondary></indexterm><emphasis>independent</emphasis>: the value of one constrains the allowed value(s) of the others. Thus when updating one, you must update the others <emphasis>in the same atomic operation</emphasis>.</para>
<para>With some unlucky timing, <literal>UnsafeCachingFactorizer</literal> can violate this invariant. Using atomic references, we cannot update both <literal>lastNumber</literal> and <literal>lastFactors</literal> simultaneously, even though each call to <literal>set</literal> is atomic; there is still a window of vulnerability when one has been modified and the other has not, and during that time other threads could see that the invariant does not hold. Similarly, the two values cannot be fetched simultaneously: between the time when thread <emphasis>A</emphasis> fetches the two values, thread <emphasis>B</emphasis> could have changed them, and again <emphasis>A</emphasis> may observe that the invariant does not hold.</para>
<sidebar float="1" id="ch02sb08" condition="25"><title/>
<para>To preserve state consistency, update related state variables in a single atomic operation.</para>
</sidebar>
<section id="ch02lev2sec5" label="2.3.1" xreflabel="2.3.1">
<title id="ch02lev2sec5__title">Intrinsic Locks</title>
<para>Java provides a built-in locking mechanism for enforcing atomicity: the <literal>synchronized</literal> block. (There is also another critical aspect to locking and other synchronization mechanisms—visibility—which is covered in <link linkend="ch03" preference="0">Chapter 3</link>.) A <literal>synchronized</literal> block has two parts: a reference to an object that will serve as the <emphasis>lock</emphasis>, and a block of code to be guarded by that lock. A <literal>synchronized</literal> method is a shorthand for a <literal>synchronized</literal> block that spans an entire method body, and whose lock is the object on which the method is being invoked. (Static <literal>synchronized</literal> methods use the <literal>Class</literal> object for the lock.)</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">synchronized (lock) {
    <emphasis>// Access or modify shared state guarded by lock</emphasis>
}
</programlisting>
</informalexample>
<para>Every Java object can implicitly act as a lock for purposes of synchronization; these built-in locks are called <emphasis>intrinsic locks</emphasis> or <emphasis>monitor locks</emphasis>. The lock is automatically acquired by the executing thread before entering a <literal>synchronized</literal> block and automatically released when control exits the <literal>synchronized</literal> block, whether by the normal control path or by throwing an exception out of the block. The only way to acquire an intrinsic lock is to enter a <literal>synchronized</literal> block or method guarded by that lock.</para>
<para>Intrinsic locks in Java act as <emphasis>mutexes</emphasis> (or <emphasis>mutual exclusion locks</emphasis>), which means that at most one thread may own the lock. When thread <emphasis>A</emphasis> attempts to acquire a lock held by thread <emphasis>B</emphasis>, <emphasis>A</emphasis> must wait, or <emphasis>block</emphasis>, until <emphasis>B</emphasis> releases it. If <emphasis>B</emphasis> never releases the lock, <emphasis>A</emphasis> waits forever.</para>
<para>Since only one thread at a time can execute a block of code guarded by a given lock, the <literal>synchronized</literal> blocks guarded by the same lock execute atomically with respect to one another. In the context of concurrency, atomicity means the same thing as it does in transactional applications—that a group of statements appear to execute as a single, indivisible unit. No thread executing a <literal>synchronized</literal> block <?docpage num="26"?><indexterm id="iddle2191" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SYNCHRONIZEDFACTORIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SynchronizedFactorizer</literal></secondary></indexterm><indexterm id="iddle3057" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><?tertiarykey REENTRANT LOCK COUNT?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary><tertiary>reentrant lock count</tertiary></indexterm><indexterm id="iddle3134" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey REENTRANT?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>reentrant</secondary></indexterm><indexterm id="iddle3135" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey REENTRANT?><?tertiarykey SEMANTICS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>reentrant</secondary><tertiary>semantics</tertiary></indexterm><indexterm id="iddle3715" significance="normal"><?indexkey P?><?primarykey pthreads (POSIX threads)?><primary><emphasis role="strong">pthreads (POSIX threads)</emphasis></primary></indexterm><indexterm id="iddle3716" significance="normal"><?indexkey P?><?primarykey pthreads (POSIX threads)?><?secondarykey DEFAULT LOCKING BEHAVIOR?><primary><emphasis role="strong">pthreads (POSIX threads)</emphasis></primary><secondary>default locking behavior</secondary></indexterm><indexterm id="iddle3805" significance="normal"><?indexkey R?><?primarykey reentrant/reentrancy?><primary><emphasis role="strong">reentrant/reentrancy</emphasis></primary></indexterm><indexterm id="iddle3807" significance="normal"><?indexkey R?><?primarykey reentrant/reentrancy?><?secondarykey LOCKING SEMANTICS?><primary><emphasis role="strong">reentrant/reentrancy</emphasis></primary><secondary>locking semantics</secondary></indexterm><indexterm id="iddle3809" significance="normal"><?indexkey R?><?primarykey reentrant/reentrancy?><?secondarykey PER-THREAD LOCK ACQUISITION?><primary><emphasis role="strong">reentrant/reentrancy</emphasis></primary><secondary>per-thread lock acquisition</secondary></indexterm><indexterm id="iddle4128" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey REENTRANT LOCKING?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>reentrant locking</secondary></indexterm>can observe another thread to be in the middle of a <literal>synchronized</literal> block guarded by the same lock.</para>
<para>The machinery of synchronization makes it easy to restore thread safety to the factoring servlet. <link linkend="ch02list06" preference="0">Listing 2.6</link> makes the <literal>service</literal> method <literal>synchronized</literal>, so only one thread may enter <literal>service</literal> at a time. <literal>SynchronizedFactorizer</literal> is now thread-safe; however, this approach is fairly extreme, since it inhibits multiple clients from using the factoring servlet simultaneously at all—resulting in unacceptably poor responsiveness. This problem—which is a performance problem, not a thread safety problem—is addressed in <link linkend="ch02lev1sec5" preference="0">Section 2.5</link>.</para>
<example id="ch02list06" label="2.6" role="Listing" xreflabel="2.6" condition="26">
<title id="ch02list06__title">Servlet that Caches Last Result, But with Unnacceptably Poor Concurrency. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class SynchronizedFactorizer implements Servlet {
    @GuardedBy("this") private BigInteger lastNumber;
    @GuardedBy("this") private BigInteger[] lastFactors;

    public <emphasis role="strong">synchronized</emphasis> void service(ServletRequest req,
                                     ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        if (i.equals(lastNumber))
            encodeIntoResponse(resp, lastFactors);
        else {
            BigInteger[] factors = factor(i);
            lastNumber = i;
            lastFactors = factors;
            encodeIntoResponse(resp, factors);
        }
    }
}
</programlisting>
</example>
</section>
<section id="ch02lev2sec6" label="2.3.2" xreflabel="2.3.2">
<title id="ch02lev2sec6__title">Reentrancy</title>
<para>When a thread requests a lock that is already held by another thread, the requesting thread blocks. But because intrinsic locks are <emphasis>reentrant</emphasis>, if a thread tries to acquire a lock that <emphasis>it</emphasis> already holds, the request succeeds. Reentrancy means that locks are acquired on a per-thread rather than per-invocation basis. <footnote id="ch02fn07" label="7"><para>This differs from the default locking behavior for pthreads (POSIX threads) mutexes, which are granted on a per-invocation basis.</para></footnote> Reentrancy is implemented by associating with each lock an acquisition count and an owning thread. When the count is zero, the lock is considered unheld. When a thread acquires a previously unheld lock, the JVM records the owner and sets the acquisition count to one. If that same thread acquires the lock again, the count <?docpage num="27"?><indexterm id="iddle1030" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey SERIALIZED?><?tertiarykey VS. OBJECT SERIALIZATION?><primary><emphasis role="strong">access</emphasis></primary><secondary>serialized</secondary><tertiary>vs. object serialization</tertiary></indexterm><indexterm id="iddle1815" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey REENTRANCY AVOIDANCE OF?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>reentrancy avoidance of</secondary></indexterm><indexterm id="iddle2014" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey LOCKING BEHAVIOR?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>locking behavior</secondary></indexterm><indexterm id="iddle2015" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey LOCKING BEHAVIOR?><?tertiarykey REENTRANCY FACILITATION OF?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>locking behavior</secondary><tertiary>reentrancy facilitation of</tertiary></indexterm><indexterm id="iddle2218" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey WIDGET?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Widget</literal></secondary></indexterm><indexterm id="iddle2478" significance="normal"><?indexkey G?><?primarykey guarded?><?secondarykey STATE?><primary><emphasis role="strong">guarded</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle2479" significance="normal"><?indexkey G?><?primarykey guarded?><?secondarykey STATE?><?tertiarykey LOCKS USE FOR?><primary><emphasis role="strong">guarded</emphasis></primary><secondary>state</secondary><tertiary>locks use for</tertiary></indexterm><indexterm id="iddle3092" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ENCAPSULATION OF?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>encapsulation of</secondary></indexterm><indexterm id="iddle3093" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ENCAPSULATION OF?><?tertiarykey REENTRANCY FACILITATION?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>encapsulation of</secondary><tertiary>reentrancy facilitation</tertiary></indexterm><indexterm id="iddle3150" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey STATE GUARDING WITH?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>state guarding with</secondary></indexterm><indexterm id="iddle4172" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><primary><emphasis role="strong">serialized/serialization</emphasis></primary></indexterm><indexterm id="iddle4173" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey ACCESS?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>access</secondary></indexterm><indexterm id="iddle4174" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey ACCESS?><?tertiarykey OBJECT SERIALIZATION VS?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>access</secondary><tertiary>object serialization vs</tertiary></indexterm><indexterm id="iddle4402" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey LOCKS CONTROL OF?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>locks control of</secondary></indexterm>is incremented, and when the owning thread exits the <literal>synchronized</literal> block, the count is decremented. When the count reaches zero, the lock is released.</para>
<para>Reentrancy facilitates encapsulation of locking behavior, and thus simplifies the development of object-oriented concurrent code. Without reentrant locks, the very natural-looking code in <link linkend="ch02list07" preference="0">Listing 2.7</link>, in which a subclass overrides a <literal>synchronized</literal> method and then calls the superclass method, would deadlock. Because the <literal>doSomething</literal> methods in <literal>Widget</literal> and <literal>LoggingWidget</literal> are both <literal>synchronized</literal>, each tries to acquire the lock on the <literal>Widget</literal> before proceeding. But if intrinsic locks were not reentrant, the call to <literal>super.doSomething</literal> would never be able to acquire the lock because it would be considered already held, and the thread would permanently stall waiting for a lock it can never acquire. Reentrancy saves us from deadlock in situations like this.</para>
<example id="ch02list07" label="2.7" role="Listing" xreflabel="2.7" condition="27">
<title id="ch02list07__title">Code that would Deadlock if Intrinsic Locks were Not Reentrant.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class Widget {
    public <emphasis role="strong">synchronized</emphasis> void doSomething() {
        ...
    <emphasis role="strong">}</emphasis>
}

public class LoggingWidget extends Widget {
    public <emphasis role="strong">synchronized</emphasis> void doSomething() {
        System.out.println(toString() + ": calling doSomething");
        <emphasis role="strong">super.doSomething();</emphasis>
    }
}
</programlisting>
</example>
</section>
</section>
<section id="ch02lev1sec4" condition="27" label="2.4" xreflabel="2.4"><?docpage num="27"?>
<title id="ch02lev1sec4__title">Guarding State with Locks</title>
<para>Because locks enable serialized <footnote id="ch02fn08" label="8"><para>Serializing access to an object has nothing to do with object serialization (turning an object into a byte stream); serializing access means that threads take turns accessing the object exclusively, rather than doing so concurrently.</para></footnote> access to the code paths they guard, we can use them to construct protocols for guaranteeing exclusive access to shared state. Following these protocols consistently can ensure state consistency.</para>
<para>Compound actions on shared state, such as incrementing a hit counter (read-modify-write) or lazy initialization (check-then-act), must be made atomic to avoid race conditions. Holding a lock for the <emphasis>entire duration</emphasis> of a compound action can make that compound action atomic. However, just wrapping the compound action with a <literal>synchronized</literal> block is not sufficient; if synchronization is used to coordinate access to a variable, it is needed <emphasis>everywhere that variable is accessed</emphasis>. Further, when using locks to coordinate access to a variable, the <emphasis>same</emphasis> lock must be used wherever that variable is accessed.</para>
<para><?docpage num="28"?><indexterm id="iddle1095" significance="normal"><?indexkey A?><?primarykey annotations?><?secondarykey %?><primary><emphasis role="strong">annotations</emphasis></primary><secondary><literal>@GuardedBy</literal></secondary></indexterm><indexterm id="iddle1178" significance="normal"><?indexkey A?><?primarykey audit(ing) tools?><primary><emphasis role="strong">audit(ing) tools</emphasis></primary></indexterm><indexterm id="iddle1326" significance="normal"><?indexkey C?><?primarykey cascading effects?><primary><emphasis role="strong">cascading effects</emphasis></primary></indexterm><indexterm id="iddle1327" significance="normal"><?indexkey C?><?primarykey cascading effects?><?secondarykey OF THREAD SAFETY REQUIREMENTS?><primary><emphasis role="strong">cascading effects</emphasis></primary><secondary>of thread safety requirements</secondary></indexterm><indexterm id="iddle2035" significance="normal"><?indexkey E?><?primarykey enforcement?><primary><emphasis role="strong">enforcement</emphasis></primary></indexterm><indexterm id="iddle2036" significance="normal"><?indexkey E?><?primarykey enforcement?><?secondarykey LOCKING POLICIES, LACK OF?><primary><emphasis role="strong">enforcement</emphasis></primary><secondary>locking policies, lack of</secondary></indexterm><indexterm id="iddle2364" significance="normal"><?indexkey F?><?primarykey FindBugs code auditing tool?><?secondarykey LOCKING FAILURES DETECTED BY?><primary><emphasis role="strong">FindBugs code auditing tool</emphasis></primary><secondary>locking failures detected by</secondary></indexterm><indexterm id="iddle2475" significance="normal"><?indexkey G?><?primarykey guarded?><primary><emphasis role="strong">guarded</emphasis></primary></indexterm><indexterm id="iddle2476" significance="normal"><?indexkey G?><?primarykey guarded?><?secondarykey OBJECTS?><primary><emphasis role="strong">guarded</emphasis></primary><secondary>objects</secondary></indexterm><indexterm id="iddle2595" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SYNCHRONIZATION?><?tertiarykey SHARED STATE REQUIREMENTS FOR?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>synchronization</secondary><tertiary>shared state requirements for</tertiary></indexterm><indexterm id="iddle2836" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><?secondarykey LIMITATIONS OF?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><secondary>limitations of</secondary></indexterm><indexterm id="iddle3112" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><?tertiarykey LIMITATIONS OF?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary><tertiary>limitations of</tertiary></indexterm><indexterm id="iddle3130" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey PROTOCOLS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>protocols</secondary></indexterm><indexterm id="iddle3131" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey PROTOCOLS?><?tertiarykey SHARED STATE REQUIREMENTS FOR?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>protocols</secondary><tertiary>shared state requirements for</tertiary></indexterm><indexterm id="iddle3367" significance="normal"><?indexkey O?><?primarykey objects?><primary><emphasis role="strong">objects</emphasis></primary></indexterm><indexterm id="iddle3368" significance="normal"><?indexkey O?><?primarykey objects?><?secondarykey GUARDED?><primary><emphasis role="strong">objects</emphasis></primary><secondary>guarded</secondary></indexterm><indexterm id="iddle3595" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SYNCHRONIZATION?><?tertiarykey SHARED STATE REQUIREMENTS FOR?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>synchronization</secondary><tertiary>shared state requirements for</tertiary></indexterm><indexterm id="iddle3710" significance="normal"><?indexkey P?><?primarykey protocol(s)?><?secondarykey LOCKING?><primary><emphasis role="strong">protocol(s)</emphasis></primary><secondary>locking</secondary></indexterm><indexterm id="iddle3711" significance="normal"><?indexkey P?><?primarykey protocol(s)?><?secondarykey LOCKING?><?tertiarykey SHARED STATE REQUIREMENTS FOR?><primary><emphasis role="strong">protocol(s)</emphasis></primary><secondary>locking</secondary><tertiary>shared state requirements for</tertiary></indexterm><indexterm id="iddle4569" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey POLICY?><?tertiarykey SHARED STATE REQUIREMENTS FOR?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>policy</secondary><tertiary>shared state requirements for</tertiary></indexterm><indexterm id="iddle4940" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey CODE AUDITING?><primary><emphasis role="strong">tools</emphasis></primary><secondary>code auditing</secondary></indexterm><indexterm id="iddle4941" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey CODE AUDITING?><?tertiarykey LOCKING FAILURES DETECTED BY?><primary><emphasis role="strong">tools</emphasis></primary><secondary>code auditing</secondary><tertiary>locking failures detected by</tertiary></indexterm>It is a common mistake to assume that synchronization needs to be used only when <emphasis>writing</emphasis> to shared variables; <emphasis>this is simply not true</emphasis>. (The reasons for this will become clearer in <link linkend="ch03lev1sec1" preference="0">Section 3.1</link>.)</para>
<sidebar float="1" id="ch02sb09" condition="28"><title/>
<para>For each mutable state variable that may be accessed by more than one thread, <emphasis>all</emphasis> accesses to that variable must be performed with the <emphasis>same</emphasis> lock held. In this case, we say that the variable is <emphasis>guarded by</emphasis> that lock.</para>
</sidebar>
<para>In <literal>SynchronizedFactorizer</literal> in <link linkend="ch02list06" preference="0">Listing 2.6</link>, <literal>lastNumber</literal> and <literal>lastFactors</literal> are guarded by the servlet object’s intrinsic lock; this is documented by the <literal>@GuardedBy</literal> annotation.</para>
<para>There is no inherent relationship between an object’s intrinsic lock and its state; an object’s fields need not be guarded by its intrinsic lock, though this is a perfectly valid locking convention that is used by many classes. Acquiring the lock associated with an object does <emphasis>not</emphasis> prevent other threads from accessing that object—the only thing that acquiring a lock prevents any other thread from doing is acquiring that same lock. The fact that every object has a built-in lock is just a convenience so that you needn’t explicitly create lock objects. <footnote id="ch02fn09" label="9"><para>In retrospect, this design decision was probably a bad one: not only can it be confusing, but it forces JVM implementors to make tradeoffs between object size and locking performance.</para></footnote> It is up to you to construct <emphasis>locking protocols</emphasis> or <emphasis>synchronization policies</emphasis> that let you access shared state safely, and to use them consistently throughout your program.</para>
<sidebar float="1" id="ch02sb10" condition="28"><title/>
<para>Every shared, mutable variable should be guarded by exactly one lock. Make it clear to maintainers which lock that is.</para>
</sidebar>
<para>A common locking convention is to encapsulate all mutable state within an object and to protect it from concurrent access by synchronizing any code path that accesses mutable state using the object’s intrinsic lock. This pattern is used by many thread-safe classes, such as <literal>Vector</literal> and other synchronized collection classes. In such cases, all the variables in an object’s state are guarded by the object’s intrinsic lock. However, there is nothing special about this pattern, and neither the compiler nor the runtime enforces this (or any other) pattern of locking. <footnote id="ch02fn10" label="10"><para>Code auditing tools like FindBugs can identify when a variable is frequently but not always accessed with a lock held, which may indicate a bug.</para></footnote> It is also easy to subvert this locking protocol accidentally by adding a new method or code path and forgetting to use synchronization.</para>
<para>Not all data needs to be guarded by locks—only mutable data that will be accessed from multiple threads. In <link linkend="ch01" preference="0">Chapter 1</link>, we described how adding a simple asynchronous event such as a <literal>TimerTask</literal> can create thread safety requirements that ripple throughout your program, especially if your program state is poorly encapsulated. Consider a single-threaded program that processes a large amount of data. Single-threaded programs require no synchronization, because no data is shared across threads. Now imagine you want to add a feature to create periodic <?docpage num="29"?><indexterm id="iddle1427" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey SYNCHRONIZATION REQUIREMENTS?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>synchronization requirements</secondary></indexterm><indexterm id="iddle2544" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INVARIANTS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>invariants</secondary></indexterm><indexterm id="iddle2545" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INVARIANTS?><?tertiarykey LOCKING REQUIREMENTS FOR?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>invariants</secondary><tertiary>locking requirements for</tertiary></indexterm><indexterm id="iddle2857" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey MULTIVARIABLE?><?tertiarykey LOCKING REQUIREMENTS FOR?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>multivariable</secondary><tertiary>locking requirements for</tertiary></indexterm><indexterm id="iddle3025" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey PERFORMANCE AND?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>performance and</secondary></indexterm><indexterm id="iddle3026" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey PERFORMANCE AND?><?tertiarykey IN SERVLETS WITH STATE?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>performance and</secondary><tertiary>in servlets with state</tertiary></indexterm><indexterm id="iddle3276" significance="normal"><?indexkey M?><?primarykey multivariable invariants?><?secondarykey LOCKING REQUIREMENTS FOR?><primary><emphasis role="strong">multivariable invariants</emphasis></primary><secondary>locking requirements for</secondary></indexterm><indexterm id="iddle3497" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey LIVENESS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>liveness</secondary></indexterm><indexterm id="iddle3498" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey LIVENESS?><?tertiarykey IN SERVLETS WITH STATE?><primary><emphasis role="strong">performance</emphasis></primary><secondary>liveness</secondary><tertiary>in servlets with state</tertiary></indexterm><indexterm id="iddle4206" significance="normal"><?indexkey S?><?primarykey servlets?><?secondarykey STATEFUL, THREAD-SAFETY ISSUES?><?tertiarykey LIVENESS AND PERFORMANCE?><primary><emphasis role="strong">servlets</emphasis></primary><secondary>stateful, thread-safety issues</secondary><tertiary>liveness and performance</tertiary></indexterm><indexterm id="iddle4419" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey SERVLETS WITH?><?tertiarykey THREAD-SAFETY ISSUES, LIVENESS AND PERFORMANCE CONCERNS?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>servlets with</secondary><tertiary>thread-safety issues, liveness and performance concerns</tertiary></indexterm><indexterm id="iddle4738" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey ISSUES, LIVENESS AND PERFORMANCE?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>issues, liveness and performance</secondary></indexterm>snapshots of its progress, so that it does not have to start again from the beginning if it crashes or must be stopped. You might choose to do this with a <literal>TimerTask</literal> that goes off every ten minutes, saving the program state to a file.</para>
<para>Since the <literal>TimerTask</literal> will be called from another thread (one managed by <literal>Timer</literal>), any data involved in the snapshot is now accessed by two threads: the main program thread and the <literal>Timer</literal> thread. This means that not only must the <literal>TimerTask</literal> code use synchronization when accessing the program state, but so must any code path in the rest of the program that touches that same data. What used to require no synchronization now requires synchronization throughout the program.</para>
<para>When a variable is guarded by a lock—meaning that <emphasis>every</emphasis> access to that variable is performed with that lock held—you’ve ensured that only one thread at a time can access that variable. When a class has invariants that involve more than one state variable, there is an additional requirement: each variable participating in the invariant must be guarded by the <emphasis>same</emphasis> lock. This allows you to access or update them in a single atomic operation, preserving the invariant. <literal>SynchronizedFactorizer</literal> demonstrates this rule: both the cached number and the cached factors are guarded by the servlet object’s intrinsic lock.</para>
<sidebar float="1" id="ch02sb11" condition="29"><title/>
<para>For every invariant that involves more than one variable, <emphasis>all</emphasis> the variables involved in that invariant must be guarded by the <emphasis>same</emphasis> lock.</para>
</sidebar>
<para>If synchronization is the cure for race conditions, why not just declare every method <literal>synchronized</literal>? It turns out that such indiscriminate application of <literal>synchronized</literal> might be either too much or too little synchronization. Merely synchronizing every method, as <literal>Vector</literal> does, is not enough to render compound actions on a <literal>Vector</literal> atomic:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">if (!vector.contains(element))
    vector.add(element);
</programlisting>
</informalexample>
<para role="continued">This attempt at a put-if-absent operation has a race condition, even though both <literal>contains</literal> and <literal>add</literal> are atomic. While synchronized methods can make individual operations atomic, additional locking is requiredwhen multiple operations are combined into a compound action. (See <link linkend="ch04lev1sec4" preference="0">Section 4.4</link> for some techniques for safely adding additional atomic operations to thread-safe objects.) At the same time, synchronizing every method can lead to liveness or performance problems, as we saw in <literal>SynchronizedFactorizer</literal>.</para>
</section>
<section id="ch02lev1sec5" condition="29" label="2.5" xreflabel="2.5"><?docpage num="29"?>
<title id="ch02lev1sec5__title">Liveness and Performance</title>
<para>In <literal>UnsafeCachingFactorizer</literal>, we introduced some caching into our factoring servlet in the hope of improving performance. Caching required some shared state, which in turn required synchronization to maintain the integrity of that state. But the way we used synchronization in <literal>SynchronizedFactorizer</literal> makes it perform badly. The synchronization policy for <literal>SynchronizedFactorizer</literal> is to <?docpage num="30"?><indexterm id="iddle1474" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey POOR?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>poor</secondary></indexterm><indexterm id="iddle3531" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey SYNCHRONIZED BLOCK SCOPE?><primary><emphasis role="strong">performance</emphasis></primary><secondary><literal>synchronized</literal> block scope</secondary></indexterm><indexterm id="iddle4111" significance="normal"><?indexkey S?><?primarykey scope/scoped?><?secondarykey SYNCHRONIZED BLOCK?><primary><emphasis role="strong">scope/scoped</emphasis></primary><secondary><literal>synchronized</literal> block</secondary></indexterm><indexterm id="iddle4480" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey PERFORMANCE IMPROVEMENT?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>performance improvement</secondary></indexterm>guard each state variable with the servlet object’s intrinsic lock, and that policy was implemented by synchronizing the entirety of the <literal>service</literal> method. This simple, coarse-grained approach restored safety, but at a high price.</para>
<para>Because <literal>service</literal> is <literal>synchronized</literal>, only one thread may execute it at once. This subverts the intended use of the servlet framework—that servlets be able to handle multiple requests simultaneously—and can result in frustrated users if the load is high enough. If the servlet is busy factoring a large number, other clients have to wait until the current request is complete before the servlet can start on the new number. If the system has multiple CPUs, processors may remain idle even if the load is high. In any case, even short-running requests, such as those for which the value is cached, may take an unexpectedly long time because they must wait for previous long-running requests to complete.</para>
<para><link linkend="ch02fig01" preference="1">Figure 2.1</link> shows what happens when multiple requests arrive for the synchronized factoring servlet: they queue up and are handled sequentially. We would describe this web application as exhibiting <emphasis>poor concurrency</emphasis>: the number of simultaneous invocations is limited not by the availability of processing resources, but by the structure of the application itself. Fortunately, it is easy to improve the concurrency of the servlet while maintaining thread safety by narrowing the scope of the <literal>synchronized</literal> block. You should be careful not to make the scope of the <literal>synchronized</literal> block <emphasis>too</emphasis> small; you would not want to divide an operation that should be atomic into more than one <literal>synchronized</literal> block. But it is reasonable to try to exclude from <literal>synchronized</literal> blocks long-running operations that do not affect shared state, so that other threads are not prevented from accessing the shared state while the long-running operation is in progress.</para>
<figure float="1" id="ch02fig01" label="2.1" xreflabel="2.1" condition="30">

<title id="ch02fig01__title">Poor Concurrency of <literal>SynchronizedFactorizer</literal>.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="191" fileref="graphics/02fig01.gif" format="GIF" width="394"/></imageobject>

</mediaobject>
</figure>
<para><literal>CachedFactorizer</literal> in <link linkend="ch02list08" preference="0">Listing 2.8</link> restructures the servlet to use two separate <literal>synchronized</literal> blocks, each limited to a short section of code. One guards the check-then-act sequence that tests whether we can just return the cached result, and the other guards updating both the cached number and the cached factors. As a bonus, we’ve reintroduced the hit counter and added a “cache hit” counter as well, updating them within the initial <literal>synchronized</literal> block. Because these counters constitute shared mutable state as well, we must use synchronization everywhere they are accessed. The portions of code that are outside the <literal>synchronized</literal> blocks operate exclusively on local (stack-based) variables, which are not <?docpage num="31"?><indexterm id="iddle2093" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CACHEDFACTORIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>CachedFactorizer</literal></secondary></indexterm>shared across threads and therefore do not require synchronization.</para>
<example id="ch02list08" label="2.8" role="Listing" xreflabel="2.8" condition="31">
<title id="ch02list08__title">Servlet that Caches its Last Request and Result.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class CachedFactorizer implements Servlet {
    @GuardedBy("this") private BigInteger lastNumber;
    @GuardedBy("this") private BigInteger[] lastFactors;
    @GuardedBy("this") private long hits;
    @GuardedBy("this") private long cacheHits;

    public <emphasis role="strong">synchronized</emphasis> long getHits() { return hits; }
    public <emphasis role="strong">synchronized</emphasis> double getCacheHitRatio() {
        return (double) cacheHits / (double) hits;
    <emphasis role="strong">}</emphasis>

    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = null;
        <emphasis role="strong">synchronized (this)</emphasis> {
            ++hits;
            if (i.equals(lastNumber)) {
                ++cacheHits;
                factors = lastFactors.clone();
            }
        }
        if (factors == null) {
            factors = factor(i);
            <emphasis role="strong">synchronized (this)</emphasis>  {
                lastNumber = i;
                lastFactors = factors.clone();
            }
        <emphasis role="strong">}</emphasis>
        encodeIntoResponse(resp, factors);
    <emphasis role="strong">}</emphasis>
}
</programlisting>
</example>
<para><literal>CachedFactorizer</literal> no longer uses <literal>AtomicLong</literal> for the hit counter, instead reverting to using a <literal>long</literal> field. It would be safe to use <literal>AtomicLong</literal> here, but there is less benefit than there was in <literal>CountingFactorizer</literal>. Atomic variables are useful for effecting atomic operations on a single variable, but since we are already using <literal>synchronized</literal> blocks to construct atomic operations, using two different synchronization mechanisms would be confusing and would offer no performance or safety benefit.</para>
<para>The restructuring of <literal>CachedFactorizer</literal> provides a balance between simplicity (synchronizing the entire method) and concurrency (synchronizing the shortest <?docpage num="32"?><indexterm id="iddle2551" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey LOCK?><?tertiarykey HOLDING?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>lock</secondary><tertiary>holding</tertiary></indexterm><indexterm id="iddle2566" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey PERFORMANCE?><?tertiarykey SIMPLICITY VS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>performance</secondary><tertiary>simplicity vs</tertiary></indexterm><indexterm id="iddle2583" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SIMPLICITY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>simplicity</secondary></indexterm><indexterm id="iddle2584" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SIMPLICITY?><?tertiarykey PERFORMANCE VS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>simplicity</secondary><tertiary>performance vs</tertiary></indexterm>possible code paths). Acquiring and releasing a lock has some overhead, so it is undesirable to break down <literal>synchronized</literal> blocks <emphasis>too</emphasis> far (such as factoring <literal>++hits</literal> into its own <literal>synchronized</literal> block), even if this would not compromise atomicity. <literal>CachedFactorizer</literal> holds the lock when accessing state variables and for the duration of compound actions, but releases it before executing the potentially long-running factorization operation. This preserves thread safety without unduly affecting concurrency; the code paths in each of the <literal>synchronized</literal> blocks are “short enough”.</para>
<para>Deciding how big or small to make <literal>synchronized</literal> blocks may require tradeoffs among competing design forces, including safety (which must not be compromised), simplicity, and performance. Sometimes simplicity and performance are at odds with each other, although as <literal>CachedFactorizer</literal> illustrates, a reasonable balance can usually be found.</para>
<sidebar float="1" id="ch02sb12" condition="32"><title/>
<para>There is frequently a tension between simplicity and performance. When implementing a synchronization policy, resist the temptation to prematurely sacriflce simplicity (potentially compromising safety) for the sake of performance.</para>
</sidebar>
<para>Whenever you use locking, you should be aware of what the code in the block is doing and how likely it is to take a long time to execute. Holding a lock for a long time, either because you are doing something compute-intensive or because you execute a potentially blocking operation, introduces the risk of liveness or performance problems.</para>
<sidebar float="1" id="ch02sb13" condition="32"><title/>
<para>Avoid holding locks during lengthy computations or operations at risk of not completing quickly such as network or console I/O.</para>
</sidebar>
</section>

</chapter>

<chapter id="ch03" label="3" xreflabel="3" condition="33">
<?docpage num="33"?>
<title id="ch03__title">Sharing Objects</title>


<para><indexterm id="iddle1031" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey VISIBILITY ROLE IN?><primary><emphasis role="strong">access</emphasis></primary><secondary>visibility role in</secondary></indexterm><indexterm id="iddle1753" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey SHARING?><primary><emphasis role="strong">data</emphasis></primary><secondary>sharing</secondary><seealso> <link linkend="iddle3444" preference="0"><emphasis role="strong">page renderer examples</emphasis></link>.</seealso></indexterm><indexterm id="iddle3209" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey VISIBILITY?><primary><emphasis role="strong">memory</emphasis></primary><secondary>visibility</secondary></indexterm><indexterm id="iddle3211" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey VISIBILITY?><?tertiarykey SYNCHRONIZED EFFECT?><primary><emphasis role="strong">memory</emphasis></primary><secondary>visibility</secondary><tertiary><literal>synchronized</literal> effect</tertiary></indexterm><indexterm id="iddle3362" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey SHARING?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>sharing</secondary></indexterm><indexterm id="iddle4237" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey OBJECTS?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>objects</secondary></indexterm><indexterm id="iddle4408" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey MODIFICATION?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>modification</secondary></indexterm><indexterm id="iddle4409" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey MODIFICATION?><?tertiarykey VISIBILITY ROLE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>modification</secondary><tertiary>visibility role</tertiary></indexterm><indexterm id="iddle4548" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey DATA SHARING REQUIREMENTS FOR?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>data sharing requirements for</secondary></indexterm><indexterm id="iddle4560" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey MEMORY VISIBILITY USE OF?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>memory visibility use of</secondary></indexterm><indexterm id="iddle5105" significance="normal"><?indexkey V?><?primarykey visibility?><?secondarykey MEMORY?><primary><emphasis role="strong">visibility</emphasis></primary><secondary>memory</secondary></indexterm><indexterm id="iddle5107" significance="normal"><?indexkey V?><?primarykey visibility?><?secondarykey MEMORY?><?tertiarykey SYNCHRONIZATION ROLE?><primary><emphasis role="strong">visibility</emphasis></primary><secondary>memory</secondary><tertiary>synchronization role</tertiary></indexterm>We stated at the beginning of <link linkend="ch02" preference="0">Chapter 2</link> that writing correct concurrent programs is primarily about managing access to shared, mutable state. That chapter was about using synchronization to prevent multiple threads from accessing the same data at the same time; this chapter examines techniques for sharing and publishing objects so they can be safely accessed by multiple threads. Together, they lay the foundation for building thread-safe classes and safely structuring concurrent applications using the <literal>java.util.concurrent</literal> library classes.</para>
<para>We have seen how <literal>synchronized</literal> blocks and methods can ensure that operations execute atomically, but it is a common misconception that <literal>synchronized</literal> is <emphasis>only</emphasis> about atomicity or demarcating “critical sections”. Synchronization also has another significant, and subtle, aspect: <emphasis>memory visibility</emphasis>. We want not only to prevent one thread from modifying the state of an object when another is using it, but also to ensure that when a thread modifies the state of an object, other threads can actually <emphasis>see</emphasis> the changes that were made. But without synchronization, this may not happen. You can ensure that objects are published safely either by using explicit synchronization or by taking advantage of the synchronization built into library classes.</para>



<section id="ch03lev1sec1" condition="33" label="3.1" xreflabel="3.1"><?docpage num="33"?>
<title id="ch03lev1sec1__title">Visibility</title>
<para>Visibility is subtle because the things that can go wrong are so counterintuitive. In a single-threaded environment, if you write a value to a variable and later read that variable with no intervening writes, you can expect to get the same value back. This seems only natural. It may be hard to accept at first, but when the reads and writes occur in different threads, <emphasis>this is simply not the case</emphasis>. In general, there is <emphasis>no</emphasis> guarantee that the reading thread will see a value written by another thread on a timely basis, or even at all. In order to ensure visibility of memory writes across threads, you must use synchronization.</para>
<para><literal>NoVisibility</literal> in <link linkend="ch03list01" preference="0">Listing 3.1</link> illustrates what can go wrong when threads share data without synchronization. Two threads, the main thread and the reader thread, access the shared variables <literal>ready</literal> and <literal>number</literal>. The main thread starts the reader thread and then sets <literal>number</literal> to 42 and <literal>ready</literal> to <literal>true</literal>. The reader <?docpage num="34"?><?docpage num="35"?><indexterm id="iddle1141" significance="normal"><?indexkey A?><?primarykey atomic variables?><?secondarykey STRATEGIES FOR USE?><primary><emphasis role="strong">atomic variables</emphasis></primary><secondary>strategies for use</secondary></indexterm><indexterm id="iddle1428" significance="normal"><?indexkey C?><?primarykey computation?><primary><emphasis role="strong">computation</emphasis></primary></indexterm><indexterm id="iddle1429" significance="normal"><?indexkey C?><?primarykey computation?><?secondarykey COMPUTE-INTENSIVE CODE?><primary><emphasis role="strong">computation</emphasis></primary><secondary>compute-intensive code</secondary></indexterm><indexterm id="iddle1430" significance="normal"><?indexkey C?><?primarykey computation?><?secondarykey COMPUTE-INTENSIVE CODE?><?tertiarykey IMPACT ON LOCKING BEHAVIOR?><primary><emphasis role="strong">computation</emphasis></primary><secondary>compute-intensive code</secondary><tertiary>impact on locking behavior</tertiary></indexterm><indexterm id="iddle1939" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey TRADEOFFS?><?tertiarykey SYNCHRONIZED BLOCK?><primary><emphasis role="strong">design</emphasis></primary><secondary>tradeoffs</secondary><tertiary>synchronized block</tertiary></indexterm><indexterm id="iddle2146" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey NOVISIBILITY?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>NoVisibility</literal></secondary></indexterm><indexterm id="iddle2618" significance="normal"><?indexkey H?><?primarykey hardware?><?secondarykey JVM INTERACTION?><primary><emphasis role="strong">hardware</emphasis></primary><secondary>JVM interaction</secondary></indexterm><indexterm id="iddle2619" significance="normal"><?indexkey H?><?primarykey hardware?><?secondarykey JVM INTERACTION?><?tertiarykey REORDERING?><primary><emphasis role="strong">hardware</emphasis></primary><secondary>JVM interaction</secondary><tertiary>reordering</tertiary></indexterm><indexterm id="iddle3398" significance="normal"><?indexkey O?><?primarykey order(ing)?><primary><emphasis role="strong">order(ing)</emphasis></primary><seealso> <link linkend="iddle3203" preference="0"><emphasis role="strong">memory</emphasis>, reordering</link>.</seealso></indexterm><indexterm id="iddle3399" significance="normal"><?indexkey O?><?primarykey order(ing)?><primary><emphasis role="strong">order(ing)</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle3496" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey JVM INTERACTION WITH HARDWARE REORDERING?><primary><emphasis role="strong">performance</emphasis></primary><secondary>JVM interaction with hardware reordering</secondary></indexterm><indexterm id="iddle3529" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey SIMPLICITY VS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>simplicity vs</secondary></indexterm><indexterm id="iddle3530" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey SIMPLICITY VS?><?tertiarykey IN REFACTORING SYNCHRONIZED BLOCKS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>simplicity vs</secondary><tertiary>in refactoring <literal>synchronized</literal> blocks</tertiary></indexterm><indexterm id="iddle3847" significance="normal"><?indexkey R?><?primarykey reordering?><primary><emphasis role="strong">reordering</emphasis></primary><seealso> <link linkend="iddle1086" preference="0"><emphasis role="strong">analysis</emphasis>, deadlock</link>.</seealso></indexterm><indexterm id="iddle3848" significance="normal"><?indexkey R?><?primarykey reordering?><primary><emphasis role="strong">reordering</emphasis></primary><seealso> <link linkend="iddle1714" preference="0"><emphasis role="strong">CPU utilization</emphasis>, optimization</link>.</seealso></indexterm><indexterm id="iddle3849" significance="normal"><?indexkey R?><?primarykey reordering?><primary><emphasis role="strong">reordering</emphasis></primary><seealso> <link linkend="iddle3124" preference="0"><emphasis role="strong">lock(ing)</emphasis>, ordering</link>.</seealso></indexterm><indexterm id="iddle3850" significance="normal"><?indexkey R?><?primarykey reordering?><primary><emphasis role="strong">reordering</emphasis></primary><seealso> <link linkend="iddle3124" preference="0"><emphasis role="strong">lock(ing)</emphasis>, ordering</link>.</seealso></indexterm><indexterm id="iddle3851" significance="normal"><?indexkey R?><?primarykey reordering?><primary><emphasis role="strong">reordering</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle3852" significance="normal"><?indexkey R?><?primarykey reordering?><primary><emphasis role="strong">reordering</emphasis></primary><seealso> <link linkend="iddle48911" preference="0"><emphasis role="strong">time/timing</emphasis></link>.</seealso></indexterm><indexterm id="iddle4286" significance="normal"><?indexkey S?><?primarykey simplicity?><?secondarykey PERFORMANCE VS?><primary><emphasis role="strong">simplicity</emphasis></primary><secondary>performance vs</secondary></indexterm><indexterm id="iddle4287" significance="normal"><?indexkey S?><?primarykey simplicity?><?secondarykey PERFORMANCE VS?><?tertiarykey IN REFACTORING SYNCHRONIZED BLOCKS?><primary><emphasis role="strong">simplicity</emphasis></primary><secondary>performance vs</secondary><tertiary>in refactoring <literal>synchronized</literal> blocks</tertiary></indexterm><indexterm id="iddle4456" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey ATOMIC VARIABLE USE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>atomic variable use</secondary></indexterm>thread spins until it sees <literal>ready</literal> is <literal>true</literal>, and then prints out <literal>number</literal>. While it may seem obvious that <literal>NoVisibility</literal> will print 42, it is in fact possible that it will print zero, or never terminate at all! Because it does not use adequate synchronization, there is no guarantee that the values of <literal>ready</literal> and <literal>number</literal> written by the main thread will be visible to the reader thread.</para>
<example id="ch03list01" label="3.1" role="Listing" xreflabel="3.1" condition="34">
<title id="ch03list01__title">Sharing Variables without Synchronization. <emphasis>Don’t Do this</emphasis>.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class NoVisibility {
    private static boolean ready;
    private static int number;

    private static class ReaderThread extends Thread {
        public void run() {
            while (!ready)
                Thread.yield();
            System.out.println(number);
        }
    }

    public static void main(String[] args) {
        new ReaderThread().start();
        number = 42;
        ready = true;
    }
}
</programlisting>
</example>
<para><literal>NoVisibility</literal> could loop forever because the value of <literal>ready</literal> might never become visible to the reader thread. Even more strangely, <literal>NoVisibility</literal> could print zero because the write to <literal>ready</literal> might be made visible to the reader thread <emphasis>before</emphasis> the write to <literal>number</literal>, a phenomenon known as <emphasis>reordering</emphasis>. There is no guarantee that operations in one thread will be performed in the order given by the program, as long as the reordering is not detectable from within <emphasis>that</emphasis> thread—<emphasis>even if the reordering is apparent to other threads</emphasis>.<footnote id="ch03fn01" label="1"><para>This may seem like a broken design, but it is meant to allow JVMs to take full advantage of the performance of modern multiprocessor hardware. For example, in the absence of synchronization, the Java Memory Model permits the compiler to reorder operations and cache values in registers, and permits CPUs to reorder operations and cache values in processor-specific caches. For more details, see <link linkend="ch16" preference="0">Chapter 16</link>.</para></footnote> When the main thread writes first to <literal>number</literal> and then to <literal>ready</literal> without synchronization, the reader thread could see those writes happen in the opposite order—or not at all.</para>
<sidebar float="1" id="ch03sb01" condition="34"><title/>
<para><?docpage num="35"?><indexterm id="iddle1686" significance="normal"><?indexkey C?><?primarykey corruption?><?secondarykey DATA?><?tertiarykey CAUSES, STALE DATA?><primary><emphasis role="strong">corruption</emphasis></primary><secondary>data</secondary><tertiary>causes, stale data</tertiary></indexterm><indexterm id="iddle1761" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey STALE?><primary><emphasis role="strong">data</emphasis></primary><secondary>stale</secondary></indexterm><indexterm id="iddle2227" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey CAUSES?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>causes</secondary></indexterm><indexterm id="iddle2228" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey CAUSES?><?tertiarykey STALE DATA?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>causes</secondary><tertiary>stale data</tertiary></indexterm><indexterm id="iddle2305" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey CAUSES?><primary><emphasis role="strong">failure</emphasis></primary><secondary>causes</secondary></indexterm><indexterm id="iddle2306" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey CAUSES?><?tertiarykey STALE DATA?><primary><emphasis role="strong">failure</emphasis></primary><secondary>causes</secondary><tertiary>stale data</tertiary></indexterm><indexterm id="iddle2558" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey OPERATION ORDERING?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>operation ordering</secondary></indexterm><indexterm id="iddle2559" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey OPERATION ORDERING?><?tertiarykey SYNCHRONIZATION ROLE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>operation ordering</secondary><tertiary>synchronization role</tertiary></indexterm><indexterm id="iddle3409" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey OPERATION?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>operation</secondary></indexterm><indexterm id="iddle3410" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey OPERATION?><?tertiarykey SYNCHRONIZATION ROLE?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>operation</secondary><tertiary>synchronization role</tertiary></indexterm><indexterm id="iddle4364" significance="normal"><?indexkey S?><?primarykey stale data?><primary><emphasis role="strong">stale data</emphasis></primary></indexterm><indexterm id="iddle4561" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey OPERATION ORDERING ROLE?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>operation ordering role</secondary></indexterm><indexterm id="iddle4730" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey AND MUTABLE DATA?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>and mutable data</secondary></indexterm>In the absence of synchronization, the compiler, processor, and runtime can do some downright weird things to the order in which operations appear to execute. Attempts to reason about the order in which memory actions “must” happen in insufflciently synchronized multithreaded programs will almost certainly be incorrect.</para>
</sidebar>
<para><literal>NoVisibility</literal> is about as simple as a concurrent program can get—two threads and two shared variables—and yet it is still all too easy to come to the wrong conclusions about what it does or even whether it will terminate. Reasoning about insufficiently synchronized concurrent programs is prohibitively difficult.</para>
<para>This may all sound a little scary, and it should. Fortunately, there’s an easy way to avoid these complex issues: <emphasis>always use the proper synchronization whenever data is shared across threads.</emphasis></para>
<section id="ch03lev2sec1" label="3.1.1" xreflabel="3.1.1">
<title id="ch03lev2sec1__title">Stale Data</title>
<para><literal>NoVisibility</literal> demonstrated one of the ways that insufficiently synchronized programs can cause surprising results: <emphasis>stale data</emphasis>. When the reader thread examines <literal>ready</literal>, it may see an out-of-date value. Unless synchronization is used <emphasis>every time a variable is accessed</emphasis>, it is possible to see a stale value for that variable. Worse, staleness is not all-or-nothing: a thread can see an up-to-date value of one variable but a stale value of another variable that was written first.</para>
<para>When food is stale, it is usually still edible—just less enjoyable. But stale data can be more dangerous. While an out-of-date hit counter in a web application might not be so bad,<footnote id="ch03fn02" label="2"><para>Reading data without synchronization is analogous to using the <literal>READ_UNCOMMITTED</literal> isolation level in a database, where you are willing to trade accuracy for performance. However, in the case of unsynchronized reads, you are trading away a greater degree of accuracy, since the visible value for a shared variable can be arbitrarily stale.</para></footnote> stale values can cause serious safety or liveness failures. In <literal>NoVisibility</literal>, stale values could cause it to print the wrong value or prevent the program from terminating. Things can get even more complicated with stale values of object references, such as the link pointers in a linked list implementation. <emphasis>Stale data can cause serious and confusing failures such as unexpected exceptions, corrupted data structures, inaccurate computations, and infinite loops.</emphasis></para>
<para><literal>MutableInteger</literal> in <link linkend="ch03list02" preference="0">Listing 3.2</link> is not thread-safe because the <literal>value</literal> field is accessed from both <literal>get</literal> and <literal>set</literal> without synchronization. Among other hazards, it is susceptible to stale values: if one thread calls <literal>set</literal>, other threads calling <literal>get</literal> may or may not see that update.</para>
<para>We can make <literal>MutableInteger</literal> thread safe by synchronizing the getter and setter as shown in <literal>SynchronizedInteger</literal> in <link linkend="ch03list03" preference="0">Listing 3.3</link>. Synchronizing only the setter would not be sufficient: threads calling <literal>get</literal> would still be able to see stale values.</para>

<para><?docpage num="36"?></para><example id="ch03list02" label="3.2" role="Listing" xreflabel="3.2" condition="36">

<title id="ch03list02__title">Non-thread-safe Mutable Integer Holder.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@NotThreadSafe
public class MutableInteger {
    private int value;

    public int  get() { return value; }
    public void set(int value) { this.value = value; }
}
</programlisting>
</example>
<example id="ch03list03" label="3.3" role="Listing" xreflabel="3.3" condition="36">
<title id="ch03list03__title">Thread-safe Mutable Integer Holder.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class SynchronizedInteger {
    <emphasis role="strong">@GuardedBy("this")</emphasis> private int value;

    public <emphasis role="strong">synchronized</emphasis> int get() { return value; }
    public <emphasis role="strong">synchronized</emphasis> void set(int value) { this.value = value; }
}
</programlisting>
</example>
</section>
<section id="ch03lev2sec2" label="3.1.2" xreflabel="3.1.2">
<title id="ch03lev2sec2__title">Nonatomic 64-bit Operations</title>
<para><indexterm id="iddle1001" significance="normal"><?indexkey %?><?primarykey 64-bit operations?><primary><emphasis role="strong">64-bit operations</emphasis></primary></indexterm><indexterm id="iddle1002" significance="normal"><?indexkey %?><?primarykey 64-bit operations?><?secondarykey NONATOMIC NATURE OF?><primary><emphasis role="strong">64-bit operations</emphasis></primary><secondary>nonatomic nature of</secondary></indexterm><indexterm id="iddle1147" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey %?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>64-bit operations</secondary></indexterm><indexterm id="iddle1148" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey %?><?tertiarykey NONATOMIC NATURE OF?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>64-bit operations</secondary><tertiary>nonatomic nature of</tertiary></indexterm><indexterm id="iddle1751" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey NONATOMIC?><primary><emphasis role="strong">data</emphasis></primary><secondary>nonatomic</secondary></indexterm><indexterm id="iddle1752" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey NONATOMIC?><?tertiarykey %?><primary><emphasis role="strong">data</emphasis></primary><secondary>nonatomic</secondary><tertiary>64-bit operations</tertiary></indexterm><indexterm id="iddle2140" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MUTABLEINTEGER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>MutableInteger</literal></secondary></indexterm><indexterm id="iddle2192" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SYNCHRONIZEDINTEGER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SynchronizedInteger</literal></secondary></indexterm><indexterm id="iddle2839" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><?secondarykey VISIBILITY MANAGEMENT WITH?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><secondary>visibility management with</secondary></indexterm><indexterm id="iddle3161" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey VISIBILITY AND?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>visibility and</secondary></indexterm><indexterm id="iddle3300" significance="normal"><?indexkey N?><?primarykey nonatomic 64-bit operations?><primary><emphasis role="strong">nonatomic 64-bit operations</emphasis></primary></indexterm><indexterm id="iddle3374" significance="normal"><?indexkey O?><?primarykey operations?><primary><emphasis role="strong">operations</emphasis></primary></indexterm><indexterm id="iddle3375" significance="normal"><?indexkey O?><?primarykey operations?><?secondarykey %?><primary><emphasis role="strong">operations</emphasis></primary><secondary>64-bit, nonatomic nature of</secondary></indexterm><indexterm id="iddle5104" significance="normal"><?indexkey V?><?primarykey visibility?><?secondarykey LOCK MANAGEMENT OF?><primary><emphasis role="strong">visibility</emphasis></primary><secondary>lock management of</secondary></indexterm>When a thread reads a variable without synchronization, it may see a stale value, but at least it sees a value that was actually placed there by some thread rather than some random value. This safety guarantee is called <emphasis>out-of-thin-air safety</emphasis>.</para>
<para>Out-of-thin-air safety applies to all variables, with one exception: 64-bit numeric variables (<literal>double</literal> and <literal>long</literal>) that are not declared <literal>volatile</literal> (see <link linkend="ch03lev2sec4" preference="0">Section 3.1.4</link>). The Java Memory Model requires fetch and store operations to be atomic, but for nonvolatile <literal>long</literal> and <literal>double</literal> variables, the JVM is permitted to treat a 64-bit read or write as two separate 32-bit operations. If the reads and writes occur in different threads, it is therefore possible to read a nonvolatile <literal>long</literal> and get back the high 32 bits of one value and the low 32 bits of another.<footnote id="ch03fn03" label="3"><para>When the Java Virtual Machine Specification was written, many widely used processor architectures could not efficiently provide atomic 64-bit arithmetic operations.</para></footnote> Thus, even if you don’t care about stale values, it is not safe to use shared mutable <literal>long</literal> and <literal>double</literal> variables in multithreaded programs unless they are declared <literal>volatile</literal> or guarded by a lock.</para>
</section>
<section id="ch03lev2sec3" label="3.1.3" xreflabel="3.1.3">
<title id="ch03lev2sec3__title">Locking and Visibility</title>
<para>Intrinsic locking can be used to guarantee that one thread sees the effects of another in a predictable manner, as illustrated by <link linkend="ch03fig01" preference="1">Figure 3.1</link>. When thread <emphasis>A</emphasis> executes a <literal>synchronized</literal> block, and subsequently thread <emphasis>B</emphasis> enters a <literal>synchronized</literal> block guarded by the same lock, the values of variables that were visible to <emphasis>A</emphasis> prior to releasing the lock are guaranteed to be visible to <emphasis>B</emphasis> upon acquiring the<?docpage num="37"?><indexterm id="iddle5064" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey VOLATILE?><primary><emphasis role="strong">variables</emphasis></primary><secondary>volatile</secondary></indexterm><indexterm id="iddle5122" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey VARIABLES?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>variables</secondary></indexterm>lock. In other words, everything <emphasis>A</emphasis> did in or prior to a <literal>synchronized</literal> block is visible to <emphasis>B</emphasis> when it executes a <literal>synchronized</literal> block guarded by the same lock. <emphasis>Without synchronization, there is no such guarantee.</emphasis></para>
<figure float="1" id="ch03fig01" label="3.1" xreflabel="3.1" condition="37">

<title id="ch03fig01__title">Visibility Guarantees for Synchronization.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="386" fileref="graphics/03fig01.gif" format="GIF" width="500"/></imageobject>

</mediaobject>
</figure>
<para>We can now give the other reason for the rule requiring all threads to synchronize on the <emphasis>same</emphasis> lock when accessing a shared mutable variable—to guarantee that values written by one thread are made visible to other threads. Otherwise, if a thread reads a variable without holding the appropriate lock, it might see a stale value.</para>
<sidebar float="1" id="ch03sb02" condition="37"><title/>
<para>Locking is not just about mutual exclusion; it is also about memory visibility. To ensure that all threads see the most up-to-date values of shared mutable variables, the reading and writing threads must synchronize on a common lock.</para>
</sidebar>
</section>
<section id="ch03lev2sec4" label="3.1.4" xreflabel="3.1.4">
<title id="ch03lev2sec4__title">Volatile Variables</title>
<para>The Java language also provides an alternative, weaker form of synchronization, <emphasis>volatile variables</emphasis>, to ensure that updates to a variable are propagated predictably <?docpage num="38"?><indexterm id="iddle1832" significance="normal"><?indexkey D?><?primarykey debugging?><?secondarykey JVM OPTIMIZATION PITFALLS?><primary><emphasis role="strong">debugging</emphasis></primary><secondary>JVM optimization pitfalls</secondary></indexterm><indexterm id="iddle2398" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey ISSUES AND CAUSES?><?tertiarykey VOLATILE VARIABLES?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>issues and causes</secondary><tertiary>volatile variables</tertiary></indexterm><indexterm id="iddle2610" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey VOLATILE VARIABLES?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>volatile variables</secondary></indexterm><indexterm id="iddle2640" significance="normal"><?indexkey H?><?primarykey hoisting?><primary><emphasis role="strong">hoisting</emphasis></primary></indexterm><indexterm id="iddle2641" significance="normal"><?indexkey H?><?primarykey hoisting?><?secondarykey VARIABLES?><primary><emphasis role="strong">hoisting</emphasis></primary><secondary>variables</secondary></indexterm><indexterm id="iddle2642" significance="normal"><?indexkey H?><?primarykey hoisting?><?secondarykey VARIABLES?><?tertiarykey AS JVM OPTIMIZATION PITFALL?><primary><emphasis role="strong">hoisting</emphasis></primary><secondary>variables</secondary><tertiary>as JVM optimization pitfall</tertiary></indexterm><indexterm id="iddle2919" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey OPTIMIZATION PITFALLS?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>optimization pitfalls</secondary></indexterm><indexterm id="iddle3383" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey JVM?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>JVM</secondary></indexterm><indexterm id="iddle3384" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey JVM?><?tertiarykey PITFALLS?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>JVM</secondary><tertiary>pitfalls</tertiary></indexterm><indexterm id="iddle3857" significance="normal"><?indexkey R?><?primarykey reordering?><?secondarykey VOLATILE VARIABLES WARNING?><primary><emphasis role="strong">reordering</emphasis></primary><secondary>volatile variables warning</secondary></indexterm><indexterm id="iddle4245" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey VOLATILE VARIABLES AS MECHANISM FOR?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>volatile variables as mechanism for</secondary></indexterm><indexterm id="iddle4445" significance="normal"><?indexkey S?><?primarykey status?><primary><emphasis role="strong">status</emphasis></primary></indexterm><indexterm id="iddle4446" significance="normal"><?indexkey S?><?primarykey status?><?secondarykey FLAG?><primary><emphasis role="strong">status</emphasis></primary><secondary>flag</secondary></indexterm><indexterm id="iddle4447" significance="normal"><?indexkey S?><?primarykey status?><?secondarykey FLAG?><?tertiarykey VOLATILE VARIABLE USE WITH?><primary><emphasis role="strong">status</emphasis></primary><secondary>flag</secondary><tertiary>volatile variable use with</tertiary></indexterm><indexterm id="iddle4580" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey VOLATILE VARIABLES VS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>volatile variables vs</secondary></indexterm><indexterm id="iddle5050" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey HOISTING?><primary><emphasis role="strong">variables</emphasis></primary><secondary>hoisting</secondary></indexterm><indexterm id="iddle5051" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey HOISTING?><?tertiarykey AS JVM OPTIMIZATION PITFALL?><primary><emphasis role="strong">variables</emphasis></primary><secondary>hoisting</secondary><tertiary>as JVM optimization pitfall</tertiary></indexterm><indexterm id="iddle5063" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey VOLATILE?><primary><emphasis role="strong">variables</emphasis></primary><secondary>volatile</secondary></indexterm><indexterm id="iddle5121" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey VARIABLES?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>variables</secondary></indexterm>to other threads. When a field is declared <literal>volatile</literal>, the compiler and runtime are put on notice that this variable is shared and that operations on it should not be reordered with other memory operations. Volatile variables are not cached in registers or in caches where they are hidden from other processors, so a read of a volatile variable always returns the most recent write by any thread.</para>
<para>A good way to think about volatile variables is to imagine that they behave roughly like the <literal>SynchronizedInteger</literal> class in <link linkend="ch03list03" preference="0">Listing 3.3</link>, replacing reads and writes of the volatile variable with calls to <literal>get</literal> and <literal>set</literal>.<footnote id="ch03fn04" label="4"><para>This analogy is not exact; the memory visibility effects of <literal>SynchronizedInteger</literal> are actually slightly stronger than those of volatile variables. See <link linkend="ch16" preference="0">Chapter 16</link>.</para></footnote> Yet accessing a volatile variable performs no locking and so cannot cause the executing thread to block, making volatile variables a lighter-weight synchronization mechanism than <literal>synchronized</literal>.<footnote id="ch03fn05" label="5"><para>Volatile reads are only slightly more expensive than nonvolatile reads on most current processor architectures.</para></footnote></para>
<para>The visibility effects of volatile variables extend beyond the value of the volatile variable itself. When thread <emphasis>A</emphasis> writes to a volatile variable and subsequently thread <emphasis>B</emphasis> reads that same variable, the values of <emphasis>all</emphasis> variables that were visible to <emphasis>A</emphasis> prior to writing to the volatile variable become visible to <emphasis>B</emphasis> after reading the volatile variable. So from a memory visibility perspective, writing a volatile variable is like exiting a <literal>synchronized</literal> block and reading a volatile variable is like entering a <literal>synchronized</literal> block. However, we do not recommend relying too heavily on volatile variables for visibility; code that relies on volatile variables for visibility of arbitrary state is more fragile and harder to understand than code that uses locking.</para>
<sidebar float="1" id="ch03sb03" condition="38"><title/>
<para>Use <literal>volatile</literal> variables only when they simplify implementing and verifying your synchronization policy; avoid using <literal>volatile</literal> variables when veryfing correctness would require subtle reasoning about visibility. Good uses of <literal>volatile</literal> variables include ensuring the visibility of their own state, that of the object they refer to, or indicating that an important lifecycle event (such as initialization or shutdown) has occurred.</para>
</sidebar>
<para><link linkend="ch03list04" preference="0">Listing 3.4</link> illustrates a typical use of volatile variables: checking a status flag to determine when to exit a loop. In this example, our anthropomorphized thread is trying to get to sleep by the time-honored method of counting sheep. For this example to work, the <literal>asleep</literal> flag must be volatile. Otherwise, the thread might not notice when <literal>asleep</literal> has been set by another thread.<footnote id="ch03fn06" label="6"><para>Debugging tip: For server applications, be sure to always specify the <literal>-server</literal> JVM command line switch when invoking the JVM, even for development and testing. The server JVM performs more optimization than the client JVM, such as hoisting variables out of a loop that are not modified in the loop; code that might appear to work in the development environment (client JVM) can break in the deployment environment (server JVM). For example, had we “forgotten” to declare the variable <literal>asleep</literal> as <literal>volatile</literal> in <link linkend="ch03list04" preference="0">Listing 3.4</link>, the server JVM could hoist the test out of the loop (turning it into an infinite loop), but the client JVM would not. An infinite loop that shows up in development is far less costly than one that only shows up in production.</para></footnote> We could instead have <?docpage num="39"?><indexterm id="iddle1142" significance="normal"><?indexkey A?><?primarykey atomic variables?><?secondarykey VOLATILE VARIABLES VS?><primary><emphasis role="strong">atomic variables</emphasis></primary><secondary>volatile variables vs</secondary></indexterm><indexterm id="iddle1404" significance="normal"><?indexkey C?><?primarykey completion?><?secondarykey VOLATILE VARIABLE USE WITH?><primary><emphasis role="strong">completion</emphasis></primary><secondary>volatile variable use with</secondary></indexterm><indexterm id="iddle2021" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey PUBLICATION DANGERS FOR?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>publication dangers for</secondary></indexterm><indexterm id="iddle2046" significance="normal"><?indexkey E?><?primarykey escape?><primary><emphasis role="strong">escape</emphasis></primary></indexterm><indexterm id="iddle2050" significance="normal"><?indexkey E?><?primarykey escape?><?secondarykey PUBLICATION AND?><primary><emphasis role="strong">escape</emphasis></primary><secondary>publication and</secondary></indexterm><indexterm id="iddle2821" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey VOLATILE VARIABLE USE WITH?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>volatile variable use with</secondary></indexterm><indexterm id="iddle2863" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey PUBLICATION DANGERS FOR?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>publication dangers for</secondary></indexterm><indexterm id="iddle3162" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey VOLATILE VARIABLES VS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>volatile variables vs</secondary></indexterm><indexterm id="iddle3717" significance="normal"><?indexkey P?><?primarykey publication?><primary><emphasis role="strong">publication</emphasis></primary><seealso> <link linkend="iddle2512" preference="0"><emphasis role="strong">guidelines</emphasis>, confinement</link>.</seealso></indexterm><indexterm id="iddle3718" significance="normal"><?indexkey P?><?primarykey publication?><primary><emphasis role="strong">publication</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle3719" significance="normal"><?indexkey P?><?primarykey publication?><primary><emphasis role="strong">publication</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle3720" significance="normal"><?indexkey P?><?primarykey publication?><primary><emphasis role="strong">publication</emphasis></primary><seealso> <link linkend="iddle1754" preference="0"><emphasis role="strong">data</emphasis>, sharing, access coordination</link>.</seealso></indexterm><indexterm id="iddle3721" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey ESCAPE AND?><primary><emphasis role="strong">publication</emphasis></primary><secondary>escape and</secondary></indexterm><indexterm id="iddle4107" significance="normal"><?indexkey S?><?primarykey scope/scoped?><?secondarykey ESCAPING?><primary><emphasis role="strong">scope/scoped</emphasis></primary><secondary>escaping</secondary></indexterm><indexterm id="iddle4108" significance="normal"><?indexkey S?><?primarykey scope/scoped?><?secondarykey ESCAPING?><?tertiarykey PUBLICATION AS MECHANISM FOR?><primary><emphasis role="strong">scope/scoped</emphasis></primary><secondary>escaping</secondary><tertiary>publication as mechanism for</tertiary></indexterm><indexterm id="iddle4133" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey VOLATILE?><primary><emphasis role="strong">semantics</emphasis></primary><secondary><literal>volatile</literal></secondary></indexterm><indexterm id="iddle5046" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey ATOMIC?><?tertiarykey VOLATILE VARIABLES VS?><primary><emphasis role="strong">variables</emphasis></primary><secondary>atomic</secondary><tertiary>volatile variables vs</tertiary></indexterm><indexterm id="iddle5066" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey VOLATILE?><?tertiarykey ATOMIC VARIABLE VS?><primary><emphasis role="strong">variables</emphasis></primary><secondary>volatile</secondary><tertiary>atomic variable vs</tertiary></indexterm><indexterm id="iddle5124" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey VARIABLES?><?tertiarykey ATOMIC VARIABLE VS?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>variables</secondary><tertiary>atomic variable vs</tertiary></indexterm>used locking to ensure visibility of changes to <literal>asleep</literal>, but that would have made the code more cumbersome.</para>
<example id="ch03list04" label="3.4" role="Listing" xreflabel="3.4" condition="39">
<title id="ch03list04__title">Counting Sheep.</title>
<programlisting format="linespecific" linenumbering="unnumbered"><emphasis role="strong">volatile</emphasis> boolean asleep;
...
    while (!asleep)
        countSomeSheep();
</programlisting>
</example>
<para>Volatile variables are convenient, but they have limitations. The most common use for volatile variables is as a completion, interruption, or status flag, such as the <literal>asleep</literal> flag in <link linkend="ch03list04" preference="0">Listing 3.4</link>. Volatile variables can be used for other kinds of state information, but more care is required when attempting this. For example, the semantics of <literal>volatile</literal> are not strong enough to make the increment operation (<literal>count++</literal>) atomic, unless you can guarantee that the variable is written only from a single thread. (Atomic variables do provide atomic read-modify-write support and can often be used as “better volatile variables”; see <link linkend="ch15" preference="0">Chapter 15</link>.)</para>
<sidebar float="1" id="ch03sb04" condition="39"><title/>
<para>Locking can guarantee both visibility and atomicity; volatile variables can only guarantee visibility.</para>
</sidebar>
<para>You can use volatile variables only when all the following criteria are met:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Writes to the variable do not depend on its current value, or you can ensure that only a single thread ever updates the value;</para></listitem>
<listitem><para>The variable does not participate in invariants with other state variables; and</para></listitem>
<listitem><para>Locking is not required for any other reason while the variable is being accessed.</para></listitem>
</itemizedlist>
</section>
</section>
<section id="ch03lev1sec2" condition="39" label="3.2" xreflabel="3.2"><?docpage num="39"?>
<title id="ch03lev1sec2__title">Publication and Escape</title>
<para><emphasis>Publishing</emphasis> an object means making it available to code outside of its current scope, such as by storing a reference to it where other code can find it, returning it from a nonprivate method, or passing it to a method in another class. In many situations, we want to ensure that objects and their internals are <emphasis>not</emphasis> published. In other situations, we do want to publish an object for general use, but doing so in a thread-safe manner may require synchronization. Publishing internal state variables can compromise encapsulation and make it more difficult to preserve invariants; publishing objects before they are fully constructed can compromise thread safety. An object that is published when it should not have been is said to have <emphasis>escaped</emphasis>. <link linkend="ch03lev1sec5" preference="0">Section 3.5</link> covers idioms for safe publication; right now, we look at how an object can escape.</para>
<para><?docpage num="40"?><indexterm id="iddle1068" significance="normal"><?indexkey A?><?primarykey alien method?><primary><emphasis role="strong">alien method</emphasis></primary><seealso> <link linkend="iddle4050" preference="0"><emphasis role="strong">safety</emphasis>, untrusted code behavior</link>.</seealso></indexterm><indexterm id="iddle1070" significance="normal"><?indexkey A?><?primarykey alien method?><?secondarykey PUBLICATION RISKS?><primary><emphasis role="strong">alien method</emphasis></primary><secondary>publication risks</secondary></indexterm><indexterm id="iddle2212" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey UNSAFESTATES?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>UnsafeStates</literal></secondary></indexterm><indexterm id="iddle3791" significance="normal"><?indexkey R?><?primarykey reachability?><primary><emphasis role="strong">reachability</emphasis></primary></indexterm><indexterm id="iddle3792" significance="normal"><?indexkey R?><?primarykey reachability?><?secondarykey PUBLICATION AFFECTED BY?><primary><emphasis role="strong">reachability</emphasis></primary><secondary>publication affected by</secondary></indexterm>The most blatant form of publication is to store a reference in a public static field, where any class and thread could see it, as in <link linkend="ch03list05" preference="0">Listing 3.5</link>. The <literal>initialize</literal> method instantiates a new <literal>HashSet</literal> and publishes it by storing a reference to it into <literal>knownSecrets</literal>.</para>
<example id="ch03list05" label="3.5" role="Listing" xreflabel="3.5" condition="40">
<title id="ch03list05__title">Publishing an Object.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public static Set&lt;Secret&gt; knownSecrets;

public void initialize() {
    knownSecrets = new HashSet&lt;Secret&gt;();
}
</programlisting>
</example>
<para>Publishing one object may indirectly publish others. If you add a <literal>Secret</literal> to the published <literal>knownSecrets</literal> set, you’ve also published that <literal>Secret</literal>, because any code can iterate the <literal>Set</literal> and obtain a reference to the new <literal>Secret</literal>. Similarly, returning a reference from a nonprivate method also publishes the returned object. <literal>UnsafeStates</literal> in <link linkend="ch03list06" preference="0">Listing 3.6</link> publishes the supposedly private array of state abbreviations.</para>
<example id="ch03list06" label="3.6" role="Listing" xreflabel="3.6" condition="40">
<title id="ch03list06__title">Allowing Internal Mutable State to Escape. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">class UnsafeStates {
    private String[] states = new String[] {
        "AK", "AL" ...
    };
    public String[] getStates() { return states; }
}
</programlisting>
</example>
<para>Publishing <literal>states</literal> in this way is problematic because any caller can modify its contents. In this case, the <literal>states</literal> array has escaped its intended scope, because what was supposed to be private state has been effectively made public.</para>
<para>Publishing an object also publishes any objects referred to by its nonprivate fields. More generally, any object that is <emphasis>reachable</emphasis> from a published object by following some chain of nonprivate field references and method calls has also been published.</para>
<para>From the perspective of a class <emphasis>C</emphasis>, an <emphasis>alien</emphasis> method is one whose behavior is not fully specified by <emphasis>C</emphasis>. This includes methods in other classes as well as overrideable methods (neither <literal>private</literal> nor <literal>final</literal>) in <emphasis>C</emphasis> itself. Passing an object to an alien method must also be considered publishing that object. Since you can’t know what code will actually be invoked, you don’t know that the alien method won’t publish the object or retain a reference to it that might later be used from another thread.</para>
<para>Whether another thread actually does something with a published reference doesn’t really matter, because the risk of misuse is still present.<footnote id="ch03fn07" label="7"><para>If someone steals your password and posts it on the <literal>alt.free-passwords</literal> newsgroup, that information has escaped: whether or not someone has (yet) used those credentials to create mischief, your account has still been compromised. Publishing a reference poses the same sort of risk.</para></footnote> Once an object <?docpage num="41"?><indexterm id="iddle1566" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey OBJECT?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary>object</secondary></indexterm><indexterm id="iddle1567" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey OBJECT?><?tertiarykey PUBLICATION RISKS?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary>object</secondary><tertiary>publication risks</tertiary></indexterm><indexterm id="iddle1568" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey OBJECT?><?tertiarykey THREAD HANDLING ISSUES?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary>object</secondary><tertiary>thread handling issues</tertiary></indexterm><indexterm id="iddle2199" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey THISESCAPE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ThisEscape</literal></secondary></indexterm><indexterm id="iddle2601" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey THIS REFERENCE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary><literal>this</literal> reference</secondary></indexterm><indexterm id="iddle2602" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey THIS REFERENCE?><?tertiarykey PUBLICATION RISKS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary><literal>this</literal> reference</secondary><tertiary>publication risks</tertiary></indexterm><indexterm id="iddle2745" significance="normal"><?indexkey I?><?primarykey inner classes?><primary><emphasis role="strong">inner classes</emphasis></primary></indexterm><indexterm id="iddle2746" significance="normal"><?indexkey I?><?primarykey inner classes?><?secondarykey PUBLICATION RISKS?><primary><emphasis role="strong">inner classes</emphasis></primary><secondary>publication risks</secondary></indexterm><indexterm id="iddle4718" significance="normal"><?indexkey T?><?primarykey this reference?><primary><emphasis role="strong">this reference</emphasis></primary></indexterm><indexterm id="iddle4719" significance="normal"><?indexkey T?><?primarykey this reference?><?secondarykey PUBLICATION RISKS?><primary><emphasis role="strong">this reference</emphasis></primary><secondary>publication risks</secondary></indexterm>escapes, you have to assume that another class or thread may, maliciously or carelessly, misuse it. This is a compelling reason to use encapsulation: it makes it practical to analyze programs for correctness and harder to violate design constraints accidentally.</para>
<para>A final mechanism by which an object or its internal state can be published is to publish an inner class instance, as shown in <literal>ThisEscape</literal> in <link linkend="ch03list07" preference="0">Listing 3.7</link>. When <literal>ThisEscape</literal> publishes the <literal>EventListener</literal>, it implicitly publishes the enclosing <literal>ThisEscape</literal> instance as well, because inner class instances contain a hidden reference to the enclosing instance.</para>
<example id="ch03list07" label="3.7" role="Listing" xreflabel="3.7" condition="41">
<title id="ch03list07__title">Implicitly Allowing the <literal>this</literal> Reference to Escape. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class ThisEscape {
    public ThisEscape(EventSource source) {
        source.registerListener(
            new EventListener() {
                public void onEvent(Event e) {
                    doSomething(e);
                }
            });
    }
}
</programlisting>
</example>
<section id="ch03lev2sec5" label="3.2.1" xreflabel="3.2.1">
<title id="ch03lev2sec5__title">Safe Construction Practices</title>
<para><literal>ThisEscape</literal> illustrates an important special case of escape—when the <literal>this</literal> references escapes during construction. When the inner <literal>EventListener</literal> instance is published, so is the enclosing <literal>ThisEscape</literal> instance. But an object is in a predictable, consistent state only after its constructor returns, so publishing an object from within its constructor can publish an incompletely constructed object. This is true <emphasis>even if the publication is the last statement in the constructor.</emphasis> If the <literal>this</literal> reference escapes during construction, the object is considered <emphasis>not properly constructed</emphasis>.<footnote id="ch03fn08" label="8"><para>More specifically, the <literal>this</literal> reference should not escape from the <emphasis>thread</emphasis> until after the constructor returns. The <literal>this</literal> reference can be stored somewhere by the constructor so long as it is not <emphasis>used</emphasis> by another thread until after construction. <literal>SafeListener</literal> in <link linkend="ch03list08" preference="0">Listing 3.8</link> uses this technique.</para></footnote></para>
<sidebar float="1" id="ch03sb05" condition="41"><title/>
<para>Do not allow the <literal>this</literal> reference to escape during construction.</para>
</sidebar>
<para>A common mistake that can let the <literal>this</literal> reference escape during construction is to start a thread from a constructor. When an object creates a thread from its constructor, it almost always shares its <literal>this</literal> reference with the new thread, either explicitly (by passing it to the constructor) or implicitly (because the <literal>Thread</literal> or <?docpage num="42"?><indexterm id="iddle1436" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1537" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle1538" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle1982" significance="normal"><?indexkey E?><?primarykey EDT (event dispatch thread)?><?secondarykey THREAD CONFINEMENT USE?><primary><emphasis role="strong">EDT (event dispatch thread)</emphasis></primary><secondary>thread confinement use</secondary></indexterm><indexterm id="iddle2170" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SAFELISTENER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SafeListener</literal></secondary></indexterm><indexterm id="iddle2292" significance="normal"><?indexkey F?><?primarykey factory(s)?><?secondarykey METHODS?><primary><emphasis role="strong">factory(s)</emphasis></primary><secondary>methods</secondary></indexterm><indexterm id="iddle2293" significance="normal"><?indexkey F?><?primarykey factory(s)?><?secondarykey METHODS?><?tertiarykey CONSTRUCTOR USE WITH?><primary><emphasis role="strong">factory(s)</emphasis></primary><secondary>methods</secondary><tertiary>constructor use with</tertiary></indexterm><indexterm id="iddle4297" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><?secondarykey AS SYNCHRONIZATION ALTERNATIVE?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><secondary>as synchronization alternative</secondary></indexterm><indexterm id="iddle4524" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey THREAD?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle4525" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey THREAD?><?tertiarykey CONFINEMENT?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>thread</secondary><tertiary>confinement</tertiary></indexterm><indexterm id="iddle4748" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><seealso> <link linkend="iddle2512" preference="0"><emphasis role="strong">guidelines</emphasis>, confinement</link>.</seealso></indexterm><indexterm id="iddle4749" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle4750" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary></indexterm><literal>Runnable</literal> is an inner class of the owning object). The new thread might then be able to see the owning object before it is fully constructed. There’s nothing wrong with <emphasis>creating</emphasis> a thread in a constructor, but it is best not to <emphasis>start</emphasis> the thread immediately. Instead, expose a <literal>start</literal> or <literal>initialize</literal> method that starts the owned thread. (See <link linkend="ch07" preference="0">Chapter 7</link> for more on service lifecycle issues.) Calling an overrideable instance method (one that is neither <literal>private</literal> nor <literal>final</literal>) from the constructor can also allow the <literal>this</literal> reference to escape.</para>
<para>If you are tempted to register an event listener or start a thread from a constructor, you can avoid the improper construction by using a private constructor and a public factory method, as shown in <literal>SafeListener</literal> in <link linkend="ch03list08" preference="0">Listing 3.8</link>.</para>
<example id="ch03list08" label="3.8" role="Listing" xreflabel="3.8" condition="42">
<title id="ch03list08__title">Using a Factory Method to Prevent the <literal>this</literal> Reference from Escaping During Construction.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class SafeListener {
    private final EventListener listener;

    private SafeListener() {
        listener = new EventListener() {
            public void onEvent(Event e) {
                doSomething(e);
            }
        };
    }

    public static SafeListener newInstance(EventSource source) {
        SafeListener safe = new SafeListener();
        source.registerListener(safe.listener);
        return safe;
    }
}
</programlisting>
</example>
</section>
</section>
<section id="ch03lev1sec3" condition="42" label="3.3" xreflabel="3.3"><?docpage num="42"?>
<title id="ch03lev1sec3__title">Thread Confinement</title>
<para>Accessing shared, mutable data requires using synchronization; one way to avoid this requirement is to <emphasis>not share</emphasis>. If data is only accessed from a single thread, no synchronization is needed. This technique, <emphasis>thread confinement</emphasis>, is one of the simplest ways to achieve thread safety. When an object is confined to a thread, such usage is automatically thread-safe even if the confined object itself is not [CPJ 2.3.2].</para>
<para>Swing uses thread confinement extensively. The Swing visual components and data model objects are not thread safe; instead, safety is achieved by confining them to the Swing event dispatch thread. To use Swing properly, code running in threads other than the event thread should not access these objects. (To make this easier, Swing provides the <literal>invokeLater</literal> mechanism to schedule a <literal>Runnable</literal> for <?docpage num="43"?><indexterm id="iddle1046" significance="normal"><?indexkey A?><?primarykey ad-hoc thread confinement?><primary><emphasis role="strong">ad-hoc thread confinement</emphasis></primary><seealso> <link linkend="iddle2512" preference="0"><emphasis role="strong">guidelines</emphasis>, confinement</link>.</seealso></indexterm><indexterm id="iddle1539" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><?tertiarykey AD-HOC?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary><tertiary>ad-hoc</tertiary></indexterm><indexterm id="iddle1547" significance="normal"><?indexkey C?><?primarykey Connection?><primary><emphasis role="strong">Connection</emphasis></primary></indexterm><indexterm id="iddle1548" significance="normal"><?indexkey C?><?primarykey Connection?><?secondarykey THREAD CONFINEMENT USE?><primary><emphasis role="strong">Connection</emphasis></primary><secondary>thread confinement use</secondary></indexterm><indexterm id="iddle1782" significance="normal"><?indexkey D?><?primarykey database(s)?><?secondarykey JDBC CONNECTION?><primary><emphasis role="strong">database(s)</emphasis></primary><secondary>JDBC <literal>Connection</literal></secondary></indexterm><indexterm id="iddle1783" significance="normal"><?indexkey D?><?primarykey database(s)?><?secondarykey JDBC CONNECTION?><?tertiarykey THREAD CONFINEMENT USE?><primary><emphasis role="strong">database(s)</emphasis></primary><secondary>JDBC <literal>Connection</literal></secondary><tertiary>thread confinement use</tertiary></indexterm><indexterm id="iddle1798" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey AVOIDANCE?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>avoidance</secondary></indexterm><indexterm id="iddle1799" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey AVOIDANCE?><?tertiarykey AND THREAD CONFINEMENT?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>avoidance</secondary><tertiary>and thread confinement</tertiary></indexterm><indexterm id="iddle1931" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey THREAD CONFINEMENT?><primary><emphasis role="strong">design</emphasis></primary><secondary>thread confinement</secondary></indexterm><indexterm id="iddle2395" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey ISSUES AND CAUSES?><?tertiarykey ISSUE?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>issues and causes</secondary><tertiary>issue</tertiary></indexterm><indexterm id="iddle2905" significance="normal"><?indexkey J?><?primarykey JDBC (Java Database Connectivity)?><primary><emphasis role="strong">JDBC (Java Database Connectivity)</emphasis></primary></indexterm><indexterm id="iddle2906" significance="normal"><?indexkey J?><?primarykey JDBC (Java Database Connectivity)?><?secondarykey CONNECTION?><primary><emphasis role="strong">JDBC (Java Database Connectivity)</emphasis></primary><secondary><literal>Connection</literal></secondary></indexterm><indexterm id="iddle2907" significance="normal"><?indexkey J?><?primarykey JDBC (Java Database Connectivity)?><?secondarykey CONNECTION?><?tertiarykey THREAD CONFINEMENT USE?><primary><emphasis role="strong">JDBC (Java Database Connectivity)</emphasis></primary><secondary><literal>Connection</literal></secondary><tertiary>thread confinement use</tertiary></indexterm><indexterm id="iddle3035" significance="normal"><?indexkey L?><?primarykey local variables?><?secondarykey FOR THREAD CONFINEMENT?><primary><emphasis role="strong">local variables</emphasis></primary><secondary>for thread confinement</secondary></indexterm><indexterm id="iddle3601" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey THREAD CONFINEMENT?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>thread confinement</secondary></indexterm><indexterm id="iddle4298" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><?secondarykey DEADLOCK AVOIDANCE ADVANTAGES?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><secondary>deadlock avoidance advantages</secondary></indexterm><indexterm id="iddle4751" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><?tertiarykey AD-HOC?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><tertiary>ad-hoc</tertiary></indexterm><indexterm id="iddle4851" significance="normal"><?indexkey T?><?primarykey ThreadLocal?><?secondarykey FOR THREAD CONFINEMENT?><primary><emphasis role="strong">ThreadLocal</emphasis></primary><secondary>for thread confinement</secondary></indexterm><indexterm id="iddle5128" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey VARIABLES?><?tertiarykey THREAD CONFINEMENT USE WITH?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>variables</secondary><tertiary>thread confinement use with</tertiary></indexterm>execution in the event thread.) Many concurrency errors in Swing applications stem from improper use of these confined objects from another thread.</para>
<para>Another common application of thread confinement is the use of pooled JDBC (Java Database Connectivity) <literal>Connection</literal> objects. The JDBC specification does not require that <literal>Connection</literal> objects be thread-safe.<footnote id="ch03fn09" label="9"><para>The connection <emphasis>pool</emphasis> implementations provided by application servers are thread-safe; connection pools are necessarily accessed from multiple threads, so a non-thread-safe implementation would not make sense.</para></footnote> In typical server applications, a thread acquires a connection from the pool, uses it for processing a single request, and returns it. Since most requests, such as servlet requests or EJB (Enterprise JavaBeans) calls, are processed synchronously by a single thread, and the pool will not dispense the same connection to another thread until it has been returned, this pattern of connection management implicitly confines the <literal>Connection</literal> to that thread for the duration of the request.</para>
<para>Just as the language has no mechanism for enforcing that a variable is guarded by a lock, it has no means of confining an object to a thread. Thread confinement is an element of your program’s design that must be enforced by its implementation. The language and core libraries provide mechanisms that can help in maintaining thread confinement—local variables and the <literal>ThreadLocal</literal> class—but even with these, it is still the programmer’s responsibility to ensure that thread-confined objects do not escape from their intended thread.</para>
<section id="ch03lev2sec6" label="3.3.1" xreflabel="3.3.1">
<title id="ch03lev2sec6__title">Ad-hoc Thread Confinement</title>
<para><emphasis>Ad-hoc thread confinement</emphasis> describes when the responsibility for maintaining thread confinement falls entirely on the implementation. Ad-hoc thread confinement can be fragile because none of the language features, such as visibility modifiers or local variables, helps confine the object to the target thread. In fact, references to thread-confined objects such as visual components or data models in GUI applications are often held in public fields.</para>
<para>The decision to use thread confinement is often a consequence of the decision to implement a particular subsystem, such as the GUI, as a single-threaded subsystem. Single-threaded subsystems can sometimes offer a simplicity benefit that outweighs the fragility of ad-hoc thread confinement.<footnote id="ch03fn10" label="10"><para>Another reason to make a subsystem single-threaded is deadlock avoidance; this is one of the primary reasons most GUI frameworks are single-threaded. Single-threaded subsystems are covered in <link linkend="ch09" preference="0">Chapter 9</link>.</para></footnote></para>
<para>A special case of thread confinement applies to volatile variables. It is safe to perform read-modify-write operations on shared volatile variables as long as you ensure that the volatile variable is only written from a single thread. In this case, you are confining the <emphasis>modification</emphasis> to a single thread to prevent race conditions, and the visibility guarantees for volatile variables ensure that other threads see the most up-to-date value.</para>
<para>Because of its fragility, ad-hoc thread confinement should be used sparingly; if possible, use one of the stronger forms of thread confinment (stack confinement or <literal>ThreadLocal</literal>) instead.</para>
</section>
<section id="ch03lev2sec7" condition="44" label="3.3.2" xreflabel="3.3.2">
<?docpage num="44"?>
<title id="ch03lev2sec7__title">Stack Confinement</title>
<para><indexterm id="iddle1535" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey STACK?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>stack</secondary></indexterm><indexterm id="iddle1536" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey STACK?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>stack</secondary></indexterm><indexterm id="iddle2013" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey INVARIANT MANAGEMENT WITH?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>invariant management with</secondary></indexterm><indexterm id="iddle2402" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey SOLUTIONS?><?tertiarykey STACK CONFINEMENT VS. AD-HOC THREAD CONFINEMENT?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>solutions</secondary><tertiary>stack confinement vs. ad-hoc thread confinement</tertiary></indexterm><indexterm id="iddle2850" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey ENCAPSULATION?><?tertiarykey VALUE FOR?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>encapsulation</secondary><tertiary>value for</tertiary></indexterm><indexterm id="iddle3036" significance="normal"><?indexkey L?><?primarykey local variables?><?secondarykey STACK CONFINEMENT USE?><primary><emphasis role="strong">local variables</emphasis></primary><secondary>stack confinement use</secondary></indexterm><indexterm id="iddle3360" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey REFERENCES?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>references</secondary></indexterm><indexterm id="iddle3361" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey REFERENCES?><?tertiarykey AND STACK CONFINEMENT?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>references</secondary><tertiary>and stack confinement</tertiary></indexterm><indexterm id="iddle3653" significance="normal"><?indexkey P?><?primarykey primitive?><primary><emphasis role="strong">primitive</emphasis></primary></indexterm><indexterm id="iddle3654" significance="normal"><?indexkey P?><?primarykey primitive?><?secondarykey LOCAL VARIABLES, SAFETY OF?><primary><emphasis role="strong">primitive</emphasis></primary><secondary>local variables, safety of</secondary></indexterm><indexterm id="iddle3821" significance="normal"><?indexkey R?><?primarykey references?><primary><emphasis role="strong">references</emphasis></primary></indexterm><indexterm id="iddle3822" significance="normal"><?indexkey R?><?primarykey references?><?secondarykey STACK CONFINEMENT PRECAUTIONS?><primary><emphasis role="strong">references</emphasis></primary><secondary>stack confinement precautions</secondary></indexterm><indexterm id="iddle4356" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey CONFINEMENT?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>confinement</secondary><seealso> <link linkend="iddle2512" preference="0"><emphasis role="strong">guidelines</emphasis>, confinement</link>.</seealso></indexterm><indexterm id="iddle4357" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey CONFINEMENT?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>confinement</secondary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle4358" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey CONFINEMENT?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>confinement</secondary></indexterm><indexterm id="iddle4756" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><?tertiarykey STACK?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><tertiary>stack</tertiary></indexterm><indexterm id="iddle4757" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><?tertiarykey STACK?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><tertiary>stack</tertiary></indexterm><indexterm id="iddle5052" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey LOCAL?><primary><emphasis role="strong">variables</emphasis></primary><secondary>local</secondary></indexterm><indexterm id="iddle5053" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey LOCAL?><?tertiarykey STACK CONFINEMENT USE?><primary><emphasis role="strong">variables</emphasis></primary><secondary>local</secondary><tertiary>stack confinement use</tertiary></indexterm><emphasis>Stack confinement</emphasis> is a special case of thread confinement in which an object can only be reached through local variables. Just as encapsulation can make it easier to preserve invariants, local variables can make it easier to confine objects to a thread. Local variables are intrinsically confined to the executing thread; they exist on the executing thread’s stack, which is not accessible to other threads. Stack confinement (also called <emphasis>within-thread</emphasis> or <emphasis>thread-local</emphasis> usage, but not to be confused with the <literal>ThreadLocal</literal> library class) is simpler to maintain and less fragile than ad-hoc thread confinement.</para>
<para>For primitively typed local variables, such as <literal>numPairs</literal> in <literal>loadTheArk</literal> in <link linkend="ch03list09" preference="0">Listing 3.9</link>, you cannot violate stack confinement even if you tried. There is no way to obtain a reference to a primitive variable, so the language semantics ensure that primitive local variables are always stack confined.</para>
<example id="ch03list09" label="3.9" role="Listing" xreflabel="3.9" condition="44">
<title id="ch03list09__title">Thread Confinement of Local Primitive and Reference Variables.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public int loadTheArk(Collection&lt;Animal&gt; candidates) {
    SortedSet&lt;Animal&gt; animals;
    int numPairs = 0;
    Animal candidate = null;

    <emphasis>// animals confined to method, don't let them escape!</emphasis>
    animals = new TreeSet&lt;Animal&gt;(new SpeciesGenderComparator());
    animals.addAll(candidates);
    for (Animal a : animals) {
        if (candidate == null || !candidate.isPotentialMate(a))
            candidate = a;
        else {
            ark.load(new AnimalPair(candidate, a));
            ++numPairs;
            candidate = null;
        }
    }
    return numPairs;
}
</programlisting>
</example>
<para>Maintaining stack confinement for object references requires a little more assistance from the programmer to ensure that the referent does not escape. In <literal>loadTheArk</literal>, we instantiate a <literal>TreeSet</literal> and store a reference to it in <literal>animals</literal>. At this point, there is exactly one reference to the <literal>Set</literal>, held in a local variable and therefore confined to the executing thread. However, if we were to publish a reference to the <literal>Set</literal> (or any of its internals), the confinement would be violated and the animals would escape.</para>
<para>Using a non-thread-safe object in a within-thread context is still thread-safe. However, be careful: the design requirement that the object be confined to the executing thread, or the awareness that the confined object is not thread-safe, <?docpage num="45"?><indexterm id="iddle1546" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><?tertiarykey THREADLOCAL?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary><tertiary><literal>ThreadLocal</literal></tertiary></indexterm><indexterm id="iddle1549" significance="normal"><?indexkey C?><?primarykey Connection?><?secondarykey THREADLOCAL VARIABLE USE WITH?><primary><emphasis role="strong">Connection</emphasis></primary><secondary><literal>ThreadLocal</literal> variable use with</secondary></indexterm><indexterm id="iddle1965" significance="normal"><?indexkey D?><?primarykey documentation?><?secondarykey IMPORTANCE?><?tertiarykey STACK CONFINEMENT USAGE?><primary><emphasis role="strong">documentation</emphasis></primary><secondary>importance</secondary><tertiary>stack confinement usage</tertiary></indexterm><indexterm id="iddle2448" significance="normal"><?indexkey G?><?primarykey global variables?><primary><emphasis role="strong">global variables</emphasis></primary></indexterm><indexterm id="iddle2449" significance="normal"><?indexkey G?><?primarykey global variables?><?secondarykey THREADLOCAL VARIABLES USE WITH?><primary><emphasis role="strong">global variables</emphasis></primary><secondary>ThreadLocal variables use with</secondary></indexterm><indexterm id="iddle4305" significance="normal"><?indexkey S?><?primarykey Singleton pattern?><primary><emphasis role="strong">Singleton pattern</emphasis></primary></indexterm><indexterm id="iddle4306" significance="normal"><?indexkey S?><?primarykey Singleton pattern?><?secondarykey THREADLOCAL VARIABLES USE WITH?><primary><emphasis role="strong">Singleton pattern</emphasis></primary><secondary><literal>ThreadLocal</literal> variables use with</secondary></indexterm><indexterm id="iddle4670" significance="normal"><?indexkey T?><?primarykey temporary objects?><primary><emphasis role="strong">temporary objects</emphasis></primary></indexterm><indexterm id="iddle4671" significance="normal"><?indexkey T?><?primarykey temporary objects?><?secondarykey AND THREADLOCAL VARIABLES?><primary><emphasis role="strong">temporary objects</emphasis></primary><secondary>and <literal>ThreadLocal</literal> variables</secondary></indexterm><indexterm id="iddle4758" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><?tertiarykey THREADLOCAL?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><tertiary><literal>ThreadLocal</literal></tertiary></indexterm><indexterm id="iddle4849" significance="normal"><?indexkey T?><?primarykey ThreadLocal?><primary><emphasis role="strong">ThreadLocal</emphasis></primary></indexterm><indexterm id="iddle5062" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey THREADLOCAL?><primary><emphasis role="strong">variables</emphasis></primary><secondary><literal>ThreadLocal</literal></secondary></indexterm>often exists only in the head of the developer when the code is written. If the assumption of within-thread usage is not clearly documented, future maintainers might mistakenly allow the object to escape.</para>
</section>
<section id="ch03lev2sec8" label="3.3.3" xreflabel="3.3.3">
<title id="ch03lev2sec8__title">ThreadLocal</title>
<para>A more formal means of maintaining thread confinement is <literal>ThreadLocal</literal>, which allows you to associate a per-thread value with a value-holding object. <literal>Thread-Local</literal> provides <literal>get</literal> and <literal>set</literal> accessormethods that maintain a separate copy of the value for each thread that uses it, so a <literal>get</literal> returns the most recent value passed to <literal>set</literal> <emphasis>from the currently executing thread</emphasis>.</para>
<para>Thread-local variables are often used to prevent sharing in designs based on mutable Singletons or global variables. For example, a single-threaded application might maintain a global database connection that is initialized at startup to avoid having to pass a <literal>Connection</literal> to every method. Since JDBC connections may not be thread-safe, a multithreaded application that uses a global connection without additional coordination is not thread-safe either. By using a <literal>ThreadLocal</literal> to store the JDBC connection, as in <literal>ConnectionHolder</literal> in <link linkend="ch03list10" preference="0">Listing 3.10</link>, each thread will have its own connection.</para>
<example id="ch03list10" label="3.10" role="Listing" xreflabel="3.10" condition="45">
<title id="ch03list10__title">Using <literal>ThreadLocal</literal> to Ensure thread Confinement.</title>
<programlisting format="linespecific" linenumbering="unnumbered">private static ThreadLocal&lt;Connection&gt; connectionHolder
    = new ThreadLocal&lt;Connection&gt;() {
        public Connection initialValue() {
            return DriverManager.getConnection(DB_URL);
        }
    };

public static Connection getConnection() {
    return connectionHolder.get();
}
</programlisting>
</example>
<para>This technique can also be used when a frequently used operation requires a temporary object such as a buffer and wants to avoid reallocating the temporary object on each invocation. For example, before Java 5.0, <literal>Integer.toString</literal> used a <literal>ThreadLocal</literal> to store the 12-byte buffer used for formatting its result, rather than using a shared static buffer (which would require locking) or allocating a new buffer for each invocation.<footnote id="ch03fn11" label="11"><para>This technique is unlikely to be a performance win unless the operation is performed very frequently or the allocation is unusually expensive. In Java 5.0, it was replaced with the more straightforward approach of allocating a new buffer for every invocation, suggesting that for something as mundane as a temporary buffer, it is not a performance win.</para></footnote></para>
<para>When a thread calls <literal>ThreadLocal.get</literal> for the first time, <literal>initialValue</literal> is consulted to provide the initial value for that thread. Conceptually, you can think of a <literal>ThreadLocal&lt;T&gt;</literal> as holding a <literal>Map&lt;Thread,T&gt;</literal> that stores the thread-specific <?docpage num="46"?><indexterm id="iddle1109" significance="normal"><?indexkey A?><?primarykey application(s)?><?secondarykey FRAMEWORKS, AND THREADLOCAL?><primary><emphasis role="strong">application(s)</emphasis></primary><secondary>frameworks, and ThreadLocal</secondary></indexterm><indexterm id="iddle1983" significance="normal"><?indexkey E?><?primarykey Effective Java Programming Language Guide?><primary><emphasis role="strong"><emphasis>Effective Java Programming Language Guide</emphasis></emphasis></primary></indexterm><indexterm id="iddle2408" significance="normal"><?indexkey F?><?primarykey frameworks?><?secondarykey APPLICATION?><primary><emphasis role="strong">frameworks</emphasis></primary><secondary>application</secondary></indexterm><indexterm id="iddle2409" significance="normal"><?indexkey F?><?primarykey frameworks?><?secondarykey APPLICATION?><?tertiarykey AND THREADLOCAL?><primary><emphasis role="strong">frameworks</emphasis></primary><secondary>application</secondary><tertiary>and <literal>ThreadLocal</literal></tertiary></indexterm><indexterm id="iddle2532" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey IMMUTABILITY?><?tertiarykey OBJECTS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>immutability</secondary><tertiary>objects</tertiary></indexterm><indexterm id="iddle2705" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><seealso> <link linkend="iddle1284" preference="0"><emphasis role="strong">cache/caching</emphasis>, implementation issues, atomic/atomicity</link>.</seealso></indexterm><indexterm id="iddle2706" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle2711" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><?secondarykey OBJECTS?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><secondary>objects</secondary></indexterm><indexterm id="iddle2860" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey PRESERVATION OF?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>preservation of</secondary></indexterm><indexterm id="iddle2861" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey PRESERVATION OF?><?tertiarykey IMMUTABLE OBJECT USE?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>preservation of</secondary><tertiary>immutable object use</tertiary></indexterm><indexterm id="iddle3350" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey IMMUTABLE?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>immutable</secondary></indexterm><indexterm id="iddle4126" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey OF MULTITHREADED ENVIRONMENTS?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>of multithreaded environments</secondary></indexterm><indexterm id="iddle4127" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey OF MULTITHREADED ENVIRONMENTS?><?tertiarykey THREADLOCAL VARIABLE CONSIDERATIONS?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>of multithreaded environments</secondary><tertiary><literal>ThreadLocal</literal> variable considerations</tertiary></indexterm><indexterm id="iddle4852" significance="normal"><?indexkey T?><?primarykey ThreadLocal?><?secondarykey RISKS OF?><primary><emphasis role="strong">ThreadLocal</emphasis></primary><secondary>risks of</secondary></indexterm>values, though this is not how it is actually implemented. The thread-specific values are stored in the <literal>Thread</literal> object itself; when the thread terminates, the thread-specific values can be garbage collected.</para>
<para>If you are porting a single-threaded application to a multithreaded environment, you can preserve thread safety by converting shared global variables into <literal>ThreadLocal</literal>s, if the semantics of the shared globals permits this; an applicationwide cache would not be as useful if it were turned into a number of thread-local caches.</para>
<para><literal>ThreadLocal</literal> is widely used in implementing application frameworks. For example, J2EE containers associate a transaction context with an executing thread for the duration of an EJB call. This is easily implemented using a static <literal>Thread-Local</literal> holding the transaction context: when framework code needs to determine what transaction is currently running, it fetches the transaction context from this <literal>ThreadLocal</literal>. This is convenient in that it reduces the need to pass execution context information into every method, but couples any code that uses this mechanism to the framework.</para>
<para>It is easy to abuse <literal>ThreadLocal</literal> by treating its thread confinement property as a license to use global variables or as a means of creating “hidden” method arguments. Like global variables, thread-local variables can detract from reusability and introduce hidden couplings among classes, and should therefore be used with care.</para>
</section>
</section>
<section id="ch03lev1sec4" condition="46" label="3.4" xreflabel="3.4"><?docpage num="46"?>
<title id="ch03lev1sec4__title">Immutability</title>
<para>The other end-run around the need to synchronize is to use <emphasis>immutable</emphasis> objects [EJ Item 13]. Nearly all the atomicity and visibility hazards we’ve described so far, such as seeing stale values, losing updates, or observing an object to be in an inconsistent state, have to do with the vagaries of multiple threads trying to access the same mutable state at the same time. If an object’s state cannot be modified, these risks and complexities simply go away.</para>
<para>An immutable object is one whose state cannot be changed after construction. Immutable objects are inherently thread-safe; their invariants are established by the constructor, and if their state cannot be changed, these invariants always hold.</para>
<sidebar float="1" id="ch03sb06" condition="46"><title/>
<para>Immutable objects are always thread-safe.</para>
</sidebar>
<para>Immutable objects are <emphasis>simple</emphasis>. They can only be in one state, which is carefully controlled by the constructor. One of the most difficult elements of program design is reasoning about the possible states of complex objects. Reasoning about the state of immutable objects, on the other hand, is trivial.</para>
<para>Immutable objects are also <emphasis>safer</emphasis>. Passing a mutable object to untrusted code, or otherwise publishing it where untrusted code could find it, is dangerous—the untrusted code might modify its state, or, worse, retain a reference to it and modify its state later from another thread. On the other hand, immutable objects cannot be subverted in this manner by malicious or buggy code, so they are safe <?docpage num="47"?><indexterm id="iddle2204" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey THREESTOOGES?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ThreeStooges</literal></secondary></indexterm><indexterm id="iddle2353" significance="normal"><?indexkey F?><?primarykey final?><?secondarykey IMMUTABILITY NOT GUARANTEED BY?><primary><emphasis role="strong">final</emphasis></primary><secondary>immutability not guaranteed by</secondary></indexterm><indexterm id="iddle2376" significance="normal"><?indexkey F?><?primarykey flexibility?><?secondarykey IMMUTABLE OBJECT DESIGN FOR?><primary><emphasis role="strong">flexibility</emphasis></primary><secondary>immutable object design for</secondary></indexterm><indexterm id="iddle2533" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey IMMUTABILITY?><?tertiarykey REQUIREMENTS FOR?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>immutability</secondary><tertiary>requirements for</tertiary></indexterm><indexterm id="iddle2713" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><?secondarykey OBJECTS?><?tertiarykey REQUIREMENTS FOR?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><secondary>objects</secondary><tertiary>requirements for</tertiary></indexterm><indexterm id="iddle4496" significance="normal"><?indexkey S?><?primarykey String?><primary><emphasis role="strong">String</emphasis></primary></indexterm><indexterm id="iddle4497" significance="normal"><?indexkey S?><?primarykey String?><?secondarykey IMMUTABILITY CHARACTERISTICS?><primary><emphasis role="strong">String</emphasis></primary><secondary>immutability characteristics</secondary></indexterm><indexterm id="iddle5016" significance="normal"><?indexkey U?><?primarykey updating?><?secondarykey IMMUTABLE OBJECTS?><primary><emphasis role="strong">updating</emphasis></primary><secondary>immutable objects</secondary></indexterm>to share and publish freely without the need to make defensive copies [EJ Item 24].</para>
<para>Neither the Java Language Specification nor the Java Memory Model formally defines immutability, but immutability is <emphasis>not</emphasis> equivalent to simply declaring all fields of an object <literal>final</literal>. An object whose fields are all final may still be mutable, since final fields can hold references to mutable objects.</para>
<sidebar float="1" id="ch03sb07" condition="47"><title/>
<para>An object is <emphasis>immutable</emphasis> if:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Its state cannot be modifled after construction;</para></listitem>
<listitem><para>All its flelds are <literal>final</literal>;<footnote id="ch03fn12" label="12"><para>It is technically possible to have an immutable object without all fields being final—<literal>String</literal> is such a class—but this relies on delicate reasoning about benign data races that requires a deep understanding of the Java Memory Model. (For the curious: <literal>String</literal> lazily computes the hash code the first time <literal>hashCode</literal> is called and caches it in a nonfinal field, but this works only because that field can take on only one nondefault value that is the same every time it is computed because it is derived deterministically from immutable state. Don’t try this at home.)</para></footnote> and</para></listitem>
<listitem><para>It is <emphasis>properly constructed</emphasis> (the <literal>this</literal> reference does not escape during construction).</para></listitem>
</itemizedlist>
</sidebar>
<para>Immutable objects can still use mutable objects internally to manage their state, as illustrated by <literal>ThreeStooges</literal> in <link linkend="ch03list11" preference="0">Listing 3.11</link>. While the <literal>Set</literal> that stores the names is mutable, the design of <literal>ThreeStooges</literal> makes it impossible to modify that <literal>Set</literal> after construction. The <literal>stooges</literal> reference is <literal>final</literal>, so all object state is reached through a <literal>final</literal> field. The last requirement, proper construction, is easily met since the constructor does nothing that would cause the <literal>this</literal> reference to become accessible to code other than the constructor and its caller.</para>
<example id="ch03list11" label="3.11" role="Listing" xreflabel="3.11" condition="47">
<title id="ch03list11__title">Immutable Class Built Out of Mutable Underlying Objects.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@Immutable
public final class ThreeStooges {
    private final Set&lt;String&gt; stooges = new HashSet&lt;String&gt;();

    public ThreeStooges() {
        stooges.add("Moe");
        stooges.add("Larry");
        stooges.add("Curly");
    }

    public boolean isStooge(String name) {
        return stooges.contains(name);
    }
}
</programlisting>
</example>
<para role="continued">Because program state changes all the time, you might be tempted to think that immutable objects are of limited use, but this is not the case. There is a difference <?docpage num="48"?><indexterm id="iddle1073" significance="normal"><?indexkey A?><?primarykey allocation?><?secondarykey IMMUTABLE OBJECTS AND?><primary><emphasis role="strong">allocation</emphasis></primary><secondary>immutable objects and</secondary></indexterm><indexterm id="iddle1158" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey IMMUTABLE OBJECT USE FOR?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>immutable object use for</secondary></indexterm><indexterm id="iddle1726" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey OF IMMUTABLE OBJECTS?><primary><emphasis role="strong">creation</emphasis></primary><secondary>of immutable objects</secondary></indexterm><indexterm id="iddle1920" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PRINCIPLES?><primary><emphasis role="strong">design</emphasis></primary><secondary>principles</secondary></indexterm><indexterm id="iddle1921" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PRINCIPLES?><?tertiarykey SIMPLICITY OF FINAL FIELDS?><primary><emphasis role="strong">design</emphasis></primary><secondary>principles</secondary><tertiary>simplicity of final fields</tertiary></indexterm><indexterm id="iddle2343" significance="normal"><?indexkey F?><?primarykey fields?><?secondarykey INITIALIZATION SAFETY?><primary><emphasis role="strong">fields</emphasis></primary><secondary>initialization safety</secondary></indexterm><indexterm id="iddle2344" significance="normal"><?indexkey F?><?primarykey fields?><?secondarykey INITIALIZATION SAFETY?><?tertiarykey FINAL FIELD GUARANTEES?><primary><emphasis role="strong">fields</emphasis></primary><secondary>initialization safety</secondary><tertiary>final field guarantees</tertiary></indexterm><indexterm id="iddle2350" significance="normal"><?indexkey F?><?primarykey final?><primary><emphasis role="strong">final</emphasis></primary></indexterm><indexterm id="iddle2351" significance="normal"><?indexkey F?><?primarykey final?><?secondarykey AND IMMUTABLE OBJECTS?><primary><emphasis role="strong">final</emphasis></primary><secondary>and immutable objects</secondary></indexterm><indexterm id="iddle2527" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey FINAL FIELD USE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>final field use</secondary></indexterm><indexterm id="iddle2568" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey PRIVATE FIELD USE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>private field use</secondary></indexterm><indexterm id="iddle2712" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><?secondarykey OBJECTS?><?tertiarykey PUBLICATION WITH VOLATILE?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><secondary>objects</secondary><tertiary>publication with volatile</tertiary></indexterm><indexterm id="iddle2742" significance="normal"><?indexkey I?><?primarykey initialization?><?secondarykey SAFETY?><?tertiarykey FINAL FIELD GUARANTEES?><primary><emphasis role="strong">initialization</emphasis></primary><secondary>safety</secondary><tertiary>final field guarantees</tertiary></indexterm><indexterm id="iddle3352" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey IMMUTABLE?><?tertiarykey PUBLICATION USING VOLATILE?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>immutable</secondary><tertiary>publication using volatile</tertiary></indexterm><indexterm id="iddle3485" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey AND IMMUTABLE OBJECTS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>and immutable objects</secondary></indexterm><indexterm id="iddle3725" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey OF IMMUTABLE OBJECTS?><primary><emphasis role="strong">publication</emphasis></primary><secondary>of immutable objects</secondary></indexterm><indexterm id="iddle3726" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey OF IMMUTABLE OBJECTS?><?tertiarykey VOLATILE USE?><primary><emphasis role="strong">publication</emphasis></primary><secondary>of immutable objects</secondary><tertiary>volatile use</tertiary></indexterm><indexterm id="iddle3780" significance="normal"><?indexkey R?><?primarykey race conditions?><?secondarykey AVOIDANCE?><primary><emphasis role="strong">race conditions</emphasis></primary><secondary>avoidance</secondary></indexterm><indexterm id="iddle3781" significance="normal"><?indexkey R?><?primarykey race conditions?><?secondarykey AVOIDANCE?><?tertiarykey IMMUTABLE OBJECT USE?><primary><emphasis role="strong">race conditions</emphasis></primary><secondary>avoidance</secondary><tertiary>immutable object use</tertiary></indexterm><indexterm id="iddle4124" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey FINAL FIELDS?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>final fields</secondary></indexterm><indexterm id="iddle5119" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey PUBLISHING IMMUTABLE OBJECTS WITH?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>publishing immutable objects with</secondary></indexterm>between an <emphasis>object</emphasis> being immutable and the <emphasis>reference</emphasis> to it being immutable. Program state stored in immutable objects can still be updated by “replacing” immutable objects with a new instance holding new state; the next section offers an example of this technique.<footnote id="ch03fn13" label="13"><para>Many developers fear that this approach will create performance problems, but these fears are usually unwarranted. Allocation is cheaper than you might think, and immutable objects offer additional performance advantages such as reduced need for locking or defensive copies and reduced impact on generational garbage collection.</para></footnote></para>
<section id="ch03lev2sec9" label="3.4.1" xreflabel="3.4.1">
<title id="ch03lev2sec9__title">Final Fields</title>
<para>The <literal>final</literal> keyword, a more limited version of the <literal>const</literal> mechanism from C++, supports the construction of immutable objects. Final fields can’t be modified (although the objects they refer to can be modified if they are mutable), but they also have special semantics under the Java Memory Model. It is the use of final fields that makes possible the guarantee of <emphasis>initialization safety</emphasis> (see <link linkend="ch03lev2sec12" preference="0">Section 3.5.2</link>) that lets immutable objects be freely accessed and shared without synchronization.</para>
<para>Even if an object is mutable, making some fields <literal>final</literal> can still simplify reasoning about its state, since limiting the mutability of an object restricts its set of possible states. An object that is “mostly immutable” but has one or two mutable state variables is still simpler than one that has many mutable variables. Declaring fields <literal>final</literal> also documents to maintainers that these fields are not expected to change.</para>
<sidebar float="1" id="ch03sb08" condition="48"><title/>
<para>Just as it is a good practice to make all fields <literal>private</literal> unless they need greater visibility [EJ Item 12], it is a good practice to make all fields <literal>final</literal> unless they need to be mutable.</para>
</sidebar>
</section>
<section id="ch03lev2sec10" label="3.4.2" xreflabel="3.4.2">
<title id="ch03lev2sec10__title">Example: Using Volatile to Publish Immutable Objects</title>
<para>In <literal>UnsafeCachingFactorizer</literal> on page <link linkend="ch02list05" preference="0" role="pageref">24</link>,we tried to use two <literal>AtomicReference</literal>s to store the last number and last factors, but this was not thread-safe because we could not fetch or update the two related values atomically. Using volatile variables for these values would not be thread-safe for the same reason. However, immutable objects can sometimes provide a weak form of atomicity.</para>
<para>The factoring servlet performs two operations that must be atomic: updating the cached result and conditionally fetching the cached factors if the cached number matches the requested number. Whenever a group of related data items must be acted on atomically, consider creating an immutable holder class for them, such as <literal>OneValueCache</literal><footnote id="ch03fn14" label="14"><para><literal>OneValueCache</literal> wouldn’t be immutable without the <literal>copyOf</literal> calls in the constructor and getter. <literal>Arrays.copyOf</literal> was added as a convenience in Java 6; <literal>clone</literal> would also work.</para></footnote> in <link linkend="ch03list12" preference="0">Listing 3.12</link>.</para>
<para>Race conditions in accessing or updating multiple related variables can be eliminated by using an immutable object to hold all the variables. With a mutable <?docpage num="49"?><indexterm id="iddle2149" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey ONEVALUECACHE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>OneValueCache</literal></secondary></indexterm><indexterm id="iddle2851" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey IMMUTABLE OBJECT USE?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>immutable object use</secondary></indexterm><indexterm id="iddle3061" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey AVOIDANCE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>avoidance</secondary></indexterm><indexterm id="iddle3062" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey AVOIDANCE?><?tertiarykey IMMUTABLE OBJECTS USE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>avoidance</secondary><tertiary>immutable objects use</tertiary></indexterm><indexterm id="iddle3732" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey SAFETY GUIDELINES?><primary><emphasis role="strong">publication</emphasis></primary><secondary>safety guidelines</secondary></indexterm><indexterm id="iddle5108" significance="normal"><?indexkey V?><?primarykey visibility?><?secondarykey VOLATILE REFERENCE USE?><primary><emphasis role="strong">visibility</emphasis></primary><secondary>volatile reference use</secondary></indexterm>holder object, you would have to use locking to ensure atomicity; with an immutable one, once a thread acquires a reference to it, it need never worry about another thread modifying its state. If the variables are to be updated, a new holder object is created, but any threads working with the previous holder still see it in a consistent state.</para>
<example id="ch03list12" label="3.12" role="Listing" xreflabel="3.12" condition="49">
<title id="ch03list12__title">Immutable Holder for Caching a Number and its Factors.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@Immutable
class OneValueCache {
    private final BigInteger lastNumber;
    private final BigInteger[] lastFactors;

    public OneValueCache(BigInteger i,
                         BigInteger[] factors) {
        lastNumber  = i;
        lastFactors = Arrays.copyOf(factors, factors.length);
    }

    public BigInteger[] getFactors(BigInteger i) {
        if (lastNumber == null || !lastNumber.equals(i))
            return null;
        else
            return Arrays.copyOf(lastFactors, lastFactors.length);
    }
}
</programlisting>
</example>
<para><literal>VolatileCachedFactorizer</literal> in <link linkend="ch03list13" preference="0">Listing 3.13</link> uses a <literal>OneValueCache</literal> to store the cached number and factors. When a thread sets the volatile <literal>cache</literal> field to reference a new <literal>OneValueCache</literal>, the new cached data becomes immediately visible to other threads.</para>
<para>The cache-related operations cannot interfere with each other because <literal>One-ValueCache</literal> is immutable and the <literal>cache</literal> field is accessed only once in each of the relevant code paths. This combination of an immutable holder object for multiple state variables related by an invariant, and a volatile reference used to ensure its timely visibility, allows <literal>VolatileCachedFactorizer</literal> to be thread-safe even though it does no explicit locking.</para>
</section>
</section>
<section id="ch03lev1sec5" condition="49" label="3.5" xreflabel="3.5"><?docpage num="49"?>
<title id="ch03lev1sec5__title">Safe Publication</title>
<para>So far we have focused on ensuring that an object <emphasis>not</emphasis> be published, such as when it is supposed to be confined to a thread or within another object. Of course, sometimes we <emphasis>do</emphasis> want to share objects across threads, and in this case we must do so safely. Unfortunately, simply storing a reference to an object into a public field, as in <link linkend="ch03list14" preference="0">Listing 3.14</link>, is <emphasis>not</emphasis> enough to publish that object safely.</para>

<para><?docpage num="50"?></para><example id="ch03list13" label="3.13" role="Listing" xreflabel="3.13" condition="50">

<title id="ch03list13__title">Caching the Last Result Using a Volatile Reference to an Immutable Holder Object.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class VolatileCachedFactorizer implements Servlet {
    private volatile OneValueCache cache =
        new OneValueCache(null, null);

    public void service(ServletRequest req, ServletResponse resp) {
        BigInteger i = extractFromRequest(req);
        BigInteger[] factors = cache.getFactors(i);
        if (factors == null) {
            factors = factor(i);
            cache = new OneValueCache(i, factors);
        }
        encodeIntoResponse(resp, factors);
    }
}
</programlisting>
</example>
<example id="ch03list14" label="3.14" role="Listing" xreflabel="3.14" condition="50">
<title id="ch03list14__title">Publishing an Object without Adequate Synchronization. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered"><emphasis>// Unsafe publication</emphasis>
public Holder holder;

public void initialize() {
    holder = new Holder(42);
}
</programlisting>
</example>
<para><indexterm id="iddle1569" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey PARTIAL?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary>partial</secondary></indexterm><indexterm id="iddle1570" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey PARTIAL?><?tertiarykey UNSAFE PUBLICATION INFLUENCE?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary>partial</secondary><tertiary>unsafe publication influence</tertiary></indexterm><indexterm id="iddle2216" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey VOLATILECACHEDFACTORIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>VolatileCachedFactorizer</literal></secondary></indexterm><indexterm id="iddle3723" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey IMPROPER?><primary><emphasis role="strong">publication</emphasis></primary><secondary>improper</secondary></indexterm>You may be surprised at how badly this harmless-looking example could fail. Because of visibility problems, the <literal>Holder</literal> could appear to another thread to be in an inconsistent state, even though its invariants were properly established by its constructor! This improper publication could allow another thread to observe a <emphasis>partially constructed object</emphasis>.</para>
<section id="ch03lev2sec11" label="3.5.1" xreflabel="3.5.1">
<title id="ch03lev2sec11__title">Improper Publication: When Good Objects Go Bad</title>
<para>You cannot rely on the integrity of partially constructed objects. An observing thread could see the object in an inconsistent state, and then later see its state suddenly change, even though it has not been modified since publication. In fact, if the <literal>Holder</literal> in <link linkend="ch03list15" preference="0">Listing 3.15</link> is published using the unsafe publication idiom in <link linkend="ch03list14" preference="0">Listing 3.14</link>, and a thread other than the publishing thread were to call <literal>assertSanity</literal>, it could throw <literal>AssertionError</literal>!<footnote id="ch03fn15" label="15"><para>The problem here is not the <literal>Holder</literal> class itself, but that the <literal>Holder</literal> is not properly published. However, <literal>Holder</literal> can be made immune to improper publication by declaring the <literal>n</literal> field to be <literal>final</literal>, which would make <literal>Holder</literal> immutable; see <link linkend="ch03lev2sec12" preference="0">Section 3.5.2</link>.</para></footnote></para>

<para><?docpage num="51"?><?docpage num="52"?></para><example id="ch03list15" label="3.15" role="Listing" xreflabel="3.15" condition="51">

<title id="ch03list15__title">Class at Risk of Failure if Not Properly Published.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class Holder {
    private int n;

    public Holder(int n) { this.n = n; }

    public void assertSanity() {
        if (n != n)
            throw new AssertionError("This statement is false.");
    }
}
</programlisting>
</example>
<para><indexterm id="iddle2150" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey ONEVALUECACHE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>OneValueCache</literal></secondary></indexterm><indexterm id="iddle2709" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><?secondarykey INITIALIZATION SAFETY GUARANTEES?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><secondary>initialization safety guarantees</secondary></indexterm><indexterm id="iddle2718" significance="normal"><?indexkey I?><?primarykey improper publication?><primary><emphasis role="strong">improper publication</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle2740" significance="normal"><?indexkey I?><?primarykey initialization?><?secondarykey SAFETY?><primary><emphasis role="strong">initialization</emphasis></primary><secondary>safety</secondary></indexterm><indexterm id="iddle2741" significance="normal"><?indexkey I?><?primarykey initialization?><?secondarykey SAFETY?><?tertiarykey AND IMMUTABLE OBJECTS?><primary><emphasis role="strong">initialization</emphasis></primary><secondary>safety</secondary><tertiary>and immutable objects</tertiary></indexterm><indexterm id="iddle2896" significance="normal"><?indexkey J?><?primarykey Java Memory Model (JMM)?><?secondarykey INITIALIZATION SAFETY GUARANTEES FOR IMMUTABLE OBJECTS?><primary><emphasis role="strong">Java Memory Model (JMM)</emphasis></primary><secondary>initialization safety guarantees for immutable objects</secondary></indexterm><indexterm id="iddle3351" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey IMMUTABLE?><?tertiarykey INITIALIZATION SAFETY?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>immutable</secondary><tertiary>initialization safety</tertiary></indexterm><indexterm id="iddle3722" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey IMPROPER?><primary><emphasis role="strong">publication</emphasis></primary><secondary>improper</secondary></indexterm><indexterm id="iddle4033" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey INITIALIZATION?><primary><emphasis role="strong">safety</emphasis></primary><secondary>initialization</secondary></indexterm><indexterm id="iddle4034" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey INITIALIZATION?><?tertiarykey GUARANTEES FOR IMMUTABLE OBJECTS?><primary><emphasis role="strong">safety</emphasis></primary><secondary>initialization</secondary><tertiary>guarantees for immutable objects</tertiary></indexterm><indexterm id="iddle4365" significance="normal"><?indexkey S?><?primarykey stale data?><?secondarykey IMPROPER PUBLICATION RISK?><primary><emphasis role="strong">stale data</emphasis></primary><secondary>improper publication risk</secondary></indexterm>Because synchronization was not used to make the <literal>Holder</literal> visible to other threads, we say the <literal>Holder</literal> was <emphasis>not properly published</emphasis>. Two things can go wrong with improperly published objects. Other threads could see a stale value for the <literal>holder</literal> field, and thus see a <literal>null</literal> reference or other older value even though a value has been placed in <literal>holder</literal>. But far worse, other threads could see an up-todate value for the <literal>holder</literal> reference, but stale values for the <emphasis>state</emphasis> of the <literal>Holder</literal>.<footnote id="ch03fn16" label="16"><para>While it may seem that field values set in a constructor are the first values written to those fields and therefore that there are no “older” values to see as stale values, the <literal>Object</literal> constructor first writes the default values to all fields before subclass constructors run. It is therefore possible to see the default value for a field as a stale value.</para></footnote> To make things even less predictable, a thread may see a stale value the first time it reads a field and then a more up-to-date value the next time, which is why <literal>assertSanity</literal> can throw <literal>AssertionError</literal>.</para>
<para>At the risk of repeating ourselves, some very strange things can happen when data is shared across threads without sufficient synchronization.</para>
</section>
<section id="ch03lev2sec12" label="3.5.2" xreflabel="3.5.2">
<title id="ch03lev2sec12__title">Immutable Objects and Initialization Safety</title>
<para>Because immutable objects are so important, the JavaMemory Model offers a special guarantee of <emphasis>initialization safety</emphasis> for sharing immutable objects. As we’ve seen, that an object reference becomes visible to another thread does not necessarily mean that the state of that object is visible to the consuming thread. In order to guarantee a consistent view of the object’s state, synchronization is needed.</para>
<para>Immutable objects, on the other hand, can be safely accessed <emphasis>even when synchronization is not used to publish the object reference</emphasis>. For this guarantee of initialization safety to hold, all of the requirements for immutability must be met: unmodi-fiable state, all fields are <literal>final</literal>, and proper construction. (If <literal>Holder</literal> in <link linkend="ch03list15" preference="0">Listing 3.15</link> were immutable, <literal>assertSanity</literal> could not throw <literal>AssertionError</literal>, even if the <literal>Holder</literal> was not properly published.)</para>
<sidebar float="1" id="ch03sb09" condition="51"><title/>
<para><?docpage num="52"?><emphasis>Immutable</emphasis> objects can be used safely by any thread without additional synchronization, even when synchronization is not used to publish them.</para>
</sidebar>
<para>This guarantee extends to the values of all final fields of properly constructed objects; final fields can be safely accessed without additional synchronization. However, if final fields refer to mutable objects, synchronization is still required to access the state of the objects they refer to.</para>
</section>
<section id="ch03lev2sec13" label="3.5.3" xreflabel="3.5.3">
<title id="ch03lev2sec13__title">Safe Publication Idioms</title>
<para>Objects that are not immutable must be <emphasis>safely published</emphasis>, which usually entails synchronization by both the publishing and the consuming thread. For the moment, let’s focus on ensuring that the consuming thread can see the object in its aspublished state; we’ll deal with visibility of modifications made after publication soon.</para>
<sidebar float="1" id="ch03sb10" condition="51"><title/>
<para>To publish an object safely, both the reference to the object and the object’s state must be made visible to other threads at the same time. A properly constructed object can be safely published by:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Initializing an object reference from a static initializer;</para></listitem>
<listitem><para>Storing a reference to it into a <literal>volatile</literal> field or <literal>AtomicReference</literal>;</para></listitem>
<listitem><para>Storing a reference to it into a <literal>final</literal> field of a properly constructed object; or</para></listitem>
<listitem><para>Storing a reference to it into a field that is properly guarded by a lock.</para></listitem>
</itemizedlist>
</sidebar>
<para>The internal synchronization in thread-safe collections means that placing an object in a thread-safe collection, such as a <literal>Vector</literal> or <literal>synchronizedList</literal>, fulfills the last of these requirements. If thread <emphasis>A</emphasis> places object <emphasis>X</emphasis> in a thread-safe collection and thread <emphasis>B</emphasis> subsequently retrieves it, <emphasis>B</emphasis> is guaranteed to see the state of <emphasis>X</emphasis> as <emphasis>A</emphasis> left it, even though the application code that hands <emphasis>X</emphasis> off in this manner has no <emphasis>explicit</emphasis> synchronization. The thread-safe library collections offer the following safe publication guarantees, even if the Javadoc is less than clear on the subject:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Placing a key or value in a <literal>Hashtable</literal>, <literal>synchronizedMap</literal>, or <literal>Concurrent-Map</literal> safely publishes it to any thread that retrieves it from the <literal>Map</literal> (whether directly or via an iterator);</para></listitem>
<listitem><para>Placing an element in a <literal>Vector</literal>, <literal>CopyOnWriteArrayList</literal>, <literal>CopyOnWrite-ArraySet</literal>, <literal>synchronizedList</literal>, or <literal>synchronizedSet</literal> safely publishes it to any thread that retrieves it from the collection;</para></listitem>
<listitem><para>Placing an element on a <literal>BlockingQueue</literal> or a <literal>ConcurrentLinkedQueue</literal> safely publishes it to any thread that retrieves it from the queue.</para></listitem>
</itemizedlist>
<para role="continued"><?docpage num="53"?><indexterm id="iddle1785" significance="normal"><?indexkey D?><?primarykey Date?><primary><emphasis role="strong">Date</emphasis></primary></indexterm><indexterm id="iddle1786" significance="normal"><?indexkey D?><?primarykey Date?><?secondarykey EFFECTIVELY IMMUTABLE USE?><primary><emphasis role="strong">Date</emphasis></primary><secondary>effectively immutable use</secondary></indexterm><indexterm id="iddle2240" significance="normal"><?indexkey E?><?primarykey Exchanger?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">Exchanger</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle2426" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">Future</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle2530" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey IMMUTABILITY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>immutability</secondary></indexterm><indexterm id="iddle2531" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey IMMUTABILITY?><?tertiarykey EFFECTIVELY IMMUTABLE OBJECTS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>immutability</secondary><tertiary>effectively immutable objects</tertiary></indexterm><indexterm id="iddle2708" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><?secondarykey EFFECTIVELY IMMUTABLE OBJECTS?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><secondary>effectively immutable objects</secondary></indexterm><indexterm id="iddle2888" significance="normal"><?indexkey J?><?primarykey Java Language Specification, The?><primary><emphasis role="strong"><emphasis>Java Language Specification, The</emphasis></emphasis></primary></indexterm><indexterm id="iddle3348" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey EFFECTIVELY IMMUTABLE?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>effectively immutable</secondary></indexterm><indexterm id="iddle4437" significance="normal"><?indexkey S?><?primarykey static?><primary><emphasis role="strong">static</emphasis></primary></indexterm><indexterm id="iddle4438" significance="normal"><?indexkey S?><?primarykey static?><?secondarykey INITIALIZER?><primary><emphasis role="strong">static</emphasis></primary><secondary>initializer</secondary></indexterm><indexterm id="iddle4439" significance="normal"><?indexkey S?><?primarykey static?><?secondarykey INITIALIZER?><?tertiarykey SAFE PUBLICATION MECHANISM?><primary><emphasis role="strong">static</emphasis></primary><secondary>initializer</secondary><tertiary>safe publication mechanism</tertiary></indexterm>Other handoff mechanisms in the class library (such as <literal>Future</literal> and <literal>Exchanger</literal>) also constitute safe publication; we will identify these as providing safe publication as they are introduced.</para>
<para>Using a static initializer is often the easiest and safest way to publish objects that can be statically constructed:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">public static Holder holder = new Holder(42);
</programlisting>
</informalexample>
<para role="continued">Static initializers are executed by the JVM at class initialization time; because of internal synchronization in the JVM, this mechanism is guaranteed to safely publish any objects initialized in this way [JLS 12.4.2].</para>
</section>
<section id="ch03lev2sec14" label="3.5.4" xreflabel="3.5.4">
<title id="ch03lev2sec14__title">Effectively Immutable Objects</title>
<para>Safe publication is sufficient for other threads to safely access objects that are not going to be modified after publication without additional synchronization. The safe publication mechanisms all guarantee that the as-published state of an object is visible to all accessing threads as soon as the reference to it is visible, and if that state is not going to be changed again, this is sufficient to ensure that any access is safe.</para>
<para>Objects that are not technically immutable, but whose state will not be modified after publication, are called <emphasis>effectively immutable</emphasis>. They do not need to meet the strict definition of immutability in <link linkend="ch03lev1sec4" preference="0">Section 3.4</link>; they merely need to be treated by the program as if they were immutable after they are published. Using effectively immutable objects can simplify development and improve performance by reducing the need for synchronization.</para>
<sidebar float="1" id="ch03sb11" condition="53"><title/>
<para>Safely published <emphasis>effectively immutable</emphasis> objects can be used safely by any thread without additional synchronization.</para>
</sidebar>
<para>For example, <literal>Date</literal> is mutable,<footnote id="ch03fn17" label="17"><para>This was probably a mistake in the class library design.</para></footnote> but if you use it as if it were immutable, you may be able to eliminate the locking that would otherwise be required when sharing a <literal>Date</literal> across threads. Suppose you want to maintain a <literal>Map</literal> storing the last login time of each user:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">public Map&lt;String, Date&gt; lastLogin =
    Collections.synchronizedMap(new HashMap&lt;String, Date&gt;());
</programlisting>
</informalexample>
<para role="continued">If the <literal>Date</literal> values are not modified after they are placed in the <literal>Map</literal>, then the synchronization in the <literal>synchronizedMap</literal> implementation is sufficient to publish the <literal>Date</literal> values safely, and no additional synchronization is needed when accessing them.</para>
</section>
<section id="ch03lev2sec15" condition="54" label="3.5.5" xreflabel="3.5.5">
<?docpage num="54"?>
<title id="ch03lev2sec15__title">Mutable Objects</title>
<para><indexterm id="iddle1175" significance="normal"><?indexkey A?><?primarykey AtomicReference?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">AtomicReference</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle1238" significance="normal"><?indexkey B?><?primarykey BlockingQueue?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">BlockingQueue</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle1383" significance="normal"><?indexkey C?><?primarykey Collections.synchronizedList?><primary><emphasis role="strong">Collections.synchronizedList</emphasis></primary></indexterm><indexterm id="iddle1384" significance="normal"><?indexkey C?><?primarykey Collections.synchronizedList?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">Collections.synchronizedList</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle1486" significance="normal"><?indexkey C?><?primarykey ConcurrentLinkedQueue?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">ConcurrentLinkedQueue</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle1489" significance="normal"><?indexkey C?><?primarykey ConcurrentMap?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">ConcurrentMap</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle1666" significance="normal"><?indexkey C?><?primarykey CopyOnWriteArrayList?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">CopyOnWriteArrayList</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle1669" significance="normal"><?indexkey C?><?primarykey CopyOnWriteArraySet?><primary><emphasis role="strong">CopyOnWriteArraySet</emphasis></primary></indexterm><indexterm id="iddle1670" significance="normal"><?indexkey C?><?primarykey CopyOnWriteArraySet?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">CopyOnWriteArraySet</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle2354" significance="normal"><?indexkey F?><?primarykey final?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">final</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle2569" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey PUBLICATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>publication</secondary></indexterm><indexterm id="iddle2593" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SYNCHRONIZATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>synchronization</secondary></indexterm><indexterm id="iddle2594" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SYNCHRONIZATION?><?tertiarykey IMMUTABLE OBJECTS AS REPLACEMENT FOR?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>synchronization</secondary><tertiary>immutable objects as replacement for</tertiary></indexterm><indexterm id="iddle2627" significance="normal"><?indexkey H?><?primarykey hashcodes/hashtables?><?secondarykey HASHTABLE?><?tertiarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">hashcodes/hashtables</emphasis></primary><secondary><literal>Hashtable</literal></secondary><tertiary>safe publication use</tertiary></indexterm><indexterm id="iddle2700" significance="normal"><?indexkey I?><?primarykey idioms?><?secondarykey SAFE PUBLICATION?><primary><emphasis role="strong">idioms</emphasis></primary><secondary>safe publication</secondary></indexterm><indexterm id="iddle2958" significance="normal"><?indexkey L?><?primarykey library?><primary><emphasis role="strong">library</emphasis></primary></indexterm><indexterm id="iddle2959" significance="normal"><?indexkey L?><?primarykey library?><?secondarykey THREAD-SAFE COLLECTIONS?><primary><emphasis role="strong">library</emphasis></primary><secondary>thread-safe collections</secondary></indexterm><indexterm id="iddle2960" significance="normal"><?indexkey L?><?primarykey library?><?secondarykey THREAD-SAFE COLLECTIONS?><?tertiarykey SAFE PUBLICATION GUARANTEES?><primary><emphasis role="strong">library</emphasis></primary><secondary>thread-safe collections</secondary><tertiary>safe publication guarantees</tertiary></indexterm><indexterm id="iddle3002" significance="normal"><?indexkey L?><?primarykey lists?><?secondarykey COPYONWRITEARRAYLIST?><primary><emphasis role="strong">lists</emphasis></primary><secondary><literal>CopyOnWriteArrayList</literal></secondary></indexterm><indexterm id="iddle3003" significance="normal"><?indexkey L?><?primarykey lists?><?secondarykey COPYONWRITEARRAYLIST?><?tertiarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">lists</emphasis></primary><secondary><literal>CopyOnWriteArrayList</literal></secondary><tertiary>safe publication use</tertiary></indexterm><indexterm id="iddle3728" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey SAFE?><?tertiarykey IDIOMS FOR?><primary><emphasis role="strong">publication</emphasis></primary><secondary>safe</secondary><tertiary>idioms for</tertiary></indexterm><indexterm id="iddle4038" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey PUBLICATION?><primary><emphasis role="strong">safety</emphasis></primary><secondary>publication</secondary></indexterm><indexterm id="iddle4039" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey PUBLICATION?><?tertiarykey IDIOMS FOR?><primary><emphasis role="strong">safety</emphasis></primary><secondary>publication</secondary><tertiary>idioms for</tertiary></indexterm><indexterm id="iddle4216" significance="normal"><?indexkey S?><?primarykey set(s)?><?secondarykey COPYONWRITEARRAYSET?><?tertiarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">set(s)</emphasis></primary><secondary><literal>CopyOnWriteArraySet</literal></secondary><tertiary>safe publication use</tertiary></indexterm><indexterm id="iddle4555" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey IMMUTABLE OBJECTS AS REPLACEMENT?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>immutable objects as replacement</secondary></indexterm><indexterm id="iddle4583" significance="normal"><?indexkey S?><?primarykey synchronizedList (Collections)?><primary><emphasis role="strong">synchronizedList (Collections)</emphasis></primary></indexterm><indexterm id="iddle4584" significance="normal"><?indexkey S?><?primarykey synchronizedList (Collections)?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">synchronizedList (Collections)</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle5071" significance="normal"><?indexkey V?><?primarykey Vector?><primary><emphasis role="strong">Vector</emphasis></primary></indexterm><indexterm id="iddle5072" significance="normal"><?indexkey V?><?primarykey Vector?><?secondarykey AS SAFE PUBLICATION USE?><primary><emphasis role="strong">Vector</emphasis></primary><secondary>as safe publication use</secondary></indexterm><indexterm id="iddle5120" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey SAFE PUBLICATION USE?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>safe publication use</secondary></indexterm><indexterm id="iddle1967" significance="normal"><?indexkey D?><?primarykey documentation?><?secondarykey SAFE PUBLICATION REQUIREMENTS?><primary><emphasis role="strong">documentation</emphasis></primary><secondary>safe publication requirements</secondary></indexterm><indexterm id="iddle2477" significance="normal"><?indexkey G?><?primarykey guarded?><?secondarykey OBJECTS?><primary><emphasis role="strong">guarded</emphasis></primary><secondary>objects</secondary></indexterm><indexterm id="iddle2570" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey PUBLICATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>publication</secondary></indexterm><indexterm id="iddle2582" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SHARING OBJECTS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>sharing objects</secondary></indexterm><indexterm id="iddle3279" significance="normal"><?indexkey M?><?primarykey mutable?><?secondarykey OBJECTS?><primary><emphasis role="strong">mutable</emphasis></primary><secondary>objects</secondary></indexterm><indexterm id="iddle3280" significance="normal"><?indexkey M?><?primarykey mutable?><?secondarykey OBJECTS?><?tertiarykey SAFE PUBLICATION OF?><primary><emphasis role="strong">mutable</emphasis></primary><secondary>objects</secondary><tertiary>safe publication of</tertiary></indexterm><indexterm id="iddle3349" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey GUARDED?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>guarded</secondary></indexterm><indexterm id="iddle3353" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey MUTABLE?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>mutable</secondary></indexterm><indexterm id="iddle3354" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey MUTABLE?><?tertiarykey SAFE PUBLICATION OF?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>mutable</secondary><tertiary>safe publication of</tertiary></indexterm><indexterm id="iddle3591" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SHARING OBJECTS?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>sharing objects</secondary></indexterm><indexterm id="iddle3730" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey SAFE?><?tertiarykey OF MUTABLE OBJECTS?><primary><emphasis role="strong">publication</emphasis></primary><secondary>safe</secondary><tertiary>of mutable objects</tertiary></indexterm><indexterm id="iddle4041" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey PUBLICATION?><?tertiarykey OF MUTABLE OBJECTS?><primary><emphasis role="strong">safety</emphasis></primary><secondary>publication</secondary><tertiary>of mutable objects</tertiary></indexterm><indexterm id="iddle4235" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey MUTABLE OBJECTS?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>mutable objects</secondary></indexterm><indexterm id="iddle4236" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey MUTABLE OBJECTS?><?tertiarykey GUIDELINES?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>mutable objects</secondary><tertiary>guidelines</tertiary></indexterm>If an object may be modified after construction, safe publication ensures only the visibility of the as-published state. Synchronization must be used not only to publish a mutable object, but also every time the object is accessed to ensure visibility of subsequent modifications. To share mutable objects safely, they must be safely published <emphasis>and</emphasis> be either thread-safe or guarded by a lock.</para>
<sidebar float="1" id="ch03sb12" condition="54"><title/>
<para>The publication requirements for an object depend on its mutability:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para><emphasis>Immutable objects</emphasis> can be published through any mechanism;</para></listitem>
<listitem><para><emphasis>Effectively immutable objects</emphasis> must be safely published;</para></listitem>
<listitem><para><emphasis>Mutable objects</emphasis> must be safely published, and must be either threadsafe or guarded by a lock.</para></listitem>
</itemizedlist>
</sidebar>
</section>
<section id="ch03lev2sec16" label="3.5.6" xreflabel="3.5.6">
<title id="ch03lev2sec16__title">Sharing Objects Safely</title>
<para>Whenever you acquire a reference to an object, you should know what you are allowed to do with it. Do you need to acquire a lock before using it? Are you allowed to modify its state, or only to read it? Many concurrency errors stem from failing to understand these “rules of engagement” for a shared object. When you publish an object, you should document how the object can be accessed.</para>
<sidebar float="1" id="ch03sb13" condition="54"><title/>
<para>The most useful policies for using and sharing objects in a concurrent program are:</para>
<itemizedlist mark="none" spacing="normal">
<listitem><formalpara><title><emphasis role="strong"><?design?>Thread-confined.</emphasis></title><para>A thread-confined object is owned exclusively by and confined to one thread, and can be modifled by its owning thread.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Shared read-only.</emphasis></title><para>A shared read-only object can be accessed concurrently by multiple threads without additional synchronization, but cannot be modified by any thread. Shared read-only objects include immutable and effectively immutable objects.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Shared thread-safe.</emphasis></title><para>A thread-safe object performs synchronization internally, so multiple threads can freely access it through its public interface without further synchronization.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Guarded.</emphasis></title><para>A guarded object can be accessed only with a specific lock held. Guarded objects include those that are encapsulated within other thread-safe objects and published objects that are known to be guarded by a specific lock.</para></formalpara></listitem>
</itemizedlist>
</sidebar>
</section>
</section>

</chapter>

<chapter id="ch04" label="4" xreflabel="4" condition="55">
<?docpage num="55"?>
<title id="ch04__title">Composing Objects</title>


<para><indexterm id="iddle1349" significance="normal"><?indexkey C?><?primarykey class(es)?><?secondarykey THREAD-SAFE?><primary><emphasis role="strong">class(es)</emphasis></primary><secondary>thread-safe</secondary></indexterm><indexterm id="iddle1350" significance="normal"><?indexkey C?><?primarykey class(es)?><?secondarykey THREAD-SAFE?><?tertiarykey AND OBJECT COMPOSITION?><primary><emphasis role="strong">class(es)</emphasis></primary><secondary>thread-safe</secondary><tertiary>and object composition</tertiary></indexterm><indexterm id="iddle1410" significance="normal"><?indexkey C?><?primarykey composition?><?secondarykey OF OBJECTS?><primary><emphasis role="strong">composition</emphasis></primary><secondary>of objects</secondary></indexterm><indexterm id="iddle1911" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey OF THREAD-SAFE CLASSES?><primary><emphasis role="strong">design</emphasis></primary><secondary>of thread-safe classes</secondary></indexterm><indexterm id="iddle1912" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey OF THREAD-SAFE CLASSES?><?tertiarykey GUIDELINES?><primary><emphasis role="strong">design</emphasis></primary><secondary>of thread-safe classes</secondary><tertiary>guidelines</tertiary></indexterm><indexterm id="iddle2031" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey THREAD-SAFETY ROLE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>thread-safety role</secondary></indexterm><indexterm id="iddle2609" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey THREADS?><?tertiarykey SAFETY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>threads</secondary><tertiary>safety</tertiary></indexterm><indexterm id="iddle2862" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey PRESERVATION OF?><?tertiarykey MECHANISMS AND SYNCHRONIZATION POLICY ROLE?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>preservation of</secondary><tertiary>mechanisms and synchronization policy role</tertiary></indexterm><indexterm id="iddle3345" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey COMPOSING?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>composing</secondary></indexterm><indexterm id="iddle3363" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey STATE?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle3364" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey STATE?><?tertiarykey COMPONENTS OF?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>state</secondary><tertiary>components of</tertiary></indexterm><indexterm id="iddle3592" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SYNCHRONIZATION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>synchronization</secondary></indexterm><indexterm id="iddle3636" significance="normal"><?indexkey P?><?primarykey postconditions?><?secondarykey PRESERVATION OF?><primary><emphasis role="strong">postconditions</emphasis></primary><secondary>preservation of</secondary></indexterm><indexterm id="iddle3637" significance="normal"><?indexkey P?><?primarykey postconditions?><?secondarykey PRESERVATION OF?><?tertiarykey MECHANISMS AND SYNCHRONIZATION POLICY ROLE?><primary><emphasis role="strong">postconditions</emphasis></primary><secondary>preservation of</secondary><tertiary>mechanisms and synchronization policy role</tertiary></indexterm><indexterm id="iddle4412" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey OBJECT?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>object</secondary></indexterm><indexterm id="iddle4413" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey OBJECT?><?tertiarykey COMPONENTS OF?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>object</secondary><tertiary>components of</tertiary></indexterm><indexterm id="iddle4503" significance="normal"><?indexkey S?><?primarykey structuring?><primary><emphasis role="strong">structuring</emphasis></primary></indexterm><indexterm id="iddle4504" significance="normal"><?indexkey S?><?primarykey structuring?><?secondarykey THREAD-SAFE CLASSES?><primary><emphasis role="strong">structuring</emphasis></primary><secondary>thread-safe classes</secondary></indexterm><indexterm id="iddle4505" significance="normal"><?indexkey S?><?primarykey structuring?><?secondarykey THREAD-SAFE CLASSES?><?tertiarykey OBJECT COMPOSITION USE?><primary><emphasis role="strong">structuring</emphasis></primary><secondary>thread-safe classes</secondary><tertiary>object composition use</tertiary></indexterm><indexterm id="iddle4563" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey POLICY?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>policy</secondary></indexterm>So far, we’ve covered the low-level basics of thread safety and synchronization. But we don’t want to have to analyze each memory access to ensure that our program is thread-safe; we want to be able to take thread-safe components and safely compose them into larger components or programs. This chapter covers patterns for structuring classes that can make it easier to make them thread-safe and to maintain them without accidentally undermining their safety guarantees.</para>



<section id="ch04lev1sec1" condition="55" label="4.1" xreflabel="4.1"><?docpage num="55"?>
<title id="ch04lev1sec1__title">Designing a Thread-safe Class</title>
<para>While it is possible to write a thread-safe program that stores all its state in public static fields, it is a lot harder to verify its thread safety or to modify it so that it remains thread-safe than one that uses encapsulation appropriately. Encapsulation makes it possible to determine that a class is thread-safe without having to examine the entire program.</para>
<sidebar float="1" id="ch04sb01" condition="55"><title/>
<para>The design process for a thread-safe class should include these three basic elements:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Identify the variables that form the object’s state;</para></listitem>
<listitem><para>Identify the invariants that constrain the state variables;</para></listitem>
<listitem><para>Establish a policy for managing concurrent access to the object’s state.</para></listitem>
</itemizedlist>
</sidebar>
<para role="continued">An object’s state starts with its fields. If they are all of primitive type, the fields comprise the entire state. <literal>Counter</literal> in <link linkend="ch04list01" preference="0">Listing 4.1</link> has only one field, so the <literal>value</literal> field comprises its entire state. The state of an object with <emphasis>n</emphasis> primitive fields is just the <emphasis>n</emphasis>-tuple of its field values; the state of a 2D <literal>Point</literal> is its (<emphasis>x</emphasis>, <emphasis>y</emphasis>) value. If the object has fields that are references to other objects, its state will encompass fields from the referenced objects as well. For example, the state of a <literal>LinkedList</literal> includes the state of all the link node objects belonging to the list.</para>
<para>The <emphasis>synchronization policy</emphasis> defines how an object coordinates access to its state without violating its invariants or postconditions. It specifies what combination of <?docpage num="56"?><indexterm id="iddle1154" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey AND STATE TRANSITION CONSTRAINTS?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>and state transition constraints</secondary></indexterm><indexterm id="iddle1542" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><?tertiarykey ROLE, SYNCHRONIZATION POLICY SPECIFICATION?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary><tertiary>role, synchronization policy specification</tertiary></indexterm><indexterm id="iddle1562" significance="normal"><?indexkey C?><?primarykey constraints?><?secondarykey STATE TRANSITION?><primary><emphasis role="strong">constraints</emphasis></primary><secondary>state transition</secondary></indexterm><indexterm id="iddle2104" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey COUNTER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Counter</literal></secondary></indexterm><indexterm id="iddle2714" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><?secondarykey ROLE IN SYNCHRONIZATION POLICY?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><secondary>role in synchronization policy</secondary></indexterm><indexterm id="iddle3142" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ROLE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>role</secondary></indexterm><indexterm id="iddle3143" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ROLE?><?tertiarykey SYNCHRONIZATION POLICY?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>role</secondary><tertiary>synchronization policy</tertiary></indexterm><indexterm id="iddle3890" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey SYNCHRONIZATION?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>synchronization</secondary></indexterm><indexterm id="iddle3891" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey SYNCHRONIZATION?><?tertiarykey SYNCHRONIZATION POLICY COMPONENT?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>synchronization</secondary><tertiary>synchronization policy component</tertiary></indexterm><indexterm id="iddle4335" significance="normal"><?indexkey S?><?primarykey space?><primary><emphasis role="strong">space</emphasis></primary></indexterm><indexterm id="iddle4336" significance="normal"><?indexkey S?><?primarykey space?><?secondarykey STATE?><primary><emphasis role="strong">space</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle4421" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey SPACE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>space</secondary></indexterm><indexterm id="iddle4429" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey TRANSITION CONSTRAINTS?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>transition constraints</secondary></indexterm><indexterm id="iddle4571" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey REQUIREMENTS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>requirements</secondary></indexterm><indexterm id="iddle4572" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey REQUIREMENTS?><?tertiarykey SYNCHRONIZATION POLICY COMPONENT?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>requirements</secondary><tertiary>synchronization policy component</tertiary></indexterm><indexterm id="iddle4755" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><?tertiarykey ROLE, SYNCHRONIZATION POLICY SPECIFICATION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><tertiary>role, synchronization policy specification</tertiary></indexterm><indexterm id="iddle4960" significance="normal"><?indexkey T?><?primarykey transition?><?secondarykey STATE TRANSITION CONSTRAINTS?><primary><emphasis role="strong">transition</emphasis></primary><secondary>state transition constraints</secondary></indexterm>immutability, thread confinement, and locking is used to maintain thread safety, and which variables are guarded by which locks. To ensure that the class can be analyzed and maintained, document the synchronization policy.</para>
<example id="ch04list01" label="4.1" role="Listing" xreflabel="4.1" condition="56">
<title id="ch04list01__title">Simple Thread-safe Counter Using the Java Monitor Pattern.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public final class Counter {
    <emphasis role="strong">@GuardedBy("this")</emphasis>  private long value = 0;

    public <emphasis role="strong">synchronized</emphasis>  long getValue() {
        return value;
    }
    public  <emphasis role="strong">synchronized</emphasis>  long increment() {
        if (value == Long.MAX_VALUE)
            throw new IllegalStateException("counter overflow");
        return ++value;
    }
}
</programlisting>
</example>
<section id="ch04lev2sec1" label="4.1.1" xreflabel="4.1.1">
<title id="ch04lev2sec1__title">Gathering Synchronization Requirements</title>
<para>Making a class thread-safe means ensuring that its invariants hold under concurrent access; this requires reasoning about its state. Objects and variables have a <emphasis>state space</emphasis>: the range of possible states they can take on. The smaller this state space, the easier it is to reason about. By using final fields wherever practical, you make it simpler to analyze the possible states an object can be in. (In the extreme case, immutable objects can only be in a single state.)</para>
<para>Many classes have invariants that identify certain states as <emphasis>valid</emphasis> or <emphasis>invalid</emphasis>. The <literal>value</literal> field in <literal>Counter</literal> is a <literal>long</literal>. The state space of a <literal>long</literal> ranges from <literal>Long.MIN_VALUE</literal> to <literal>Long.MAX_VALUE</literal>, but <literal>Counter</literal> places constraints on <literal>value</literal>; negative values are not allowed.</para>
<para>Similarly, operations may have postconditions that identify certain <emphasis>state transitions</emphasis> as invalid. If the current state of a <literal>Counter</literal> is 17, the <emphasis>only</emphasis> valid next state is 18. When the next state is derived from the current state, the operation is necessarily a compound action. Not all operations impose state transition constraints; when updating a variable that holds the current temperature, its previous state does not affect the computation.</para>
<para>Constraints placed on states or state transitions by invariants and postconditions create additional synchronization or encapsulation requirements. If certain states are invalid, then the underlying state variables must be encapsulated, otherwise client code could put the object into an invalid state. If an operation has invalid state transitions, it must be made atomic. On the other hand, if the class does not impose any such constraints, we may be able to relax encapsulation or serialization requirements to obtain greater flexibility or better performance.</para>
<para><?docpage num="57"?><indexterm id="iddle1150" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey AND MULTIVARIABLE INVARIANTS?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>and multivariable invariants</secondary></indexterm><indexterm id="iddle1237" significance="normal"><?indexkey B?><?primarykey BlockingQueue?><?secondarykey AND STATE-BASED PRECONDITIONS?><primary><emphasis role="strong">BlockingQueue</emphasis></primary><secondary>and state-based preconditions</secondary></indexterm><indexterm id="iddle1437" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1727" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey OF STATE-DEPENDENT METHODS?><primary><emphasis role="strong">creation</emphasis></primary><secondary>of state-dependent methods</secondary></indexterm><indexterm id="iddle1878" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey STATE?><?tertiarykey OPERATIONS?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>state</secondary><tertiary>operations</tertiary></indexterm><indexterm id="iddle1896" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey CLASS?><primary><emphasis role="strong">design</emphasis></primary><secondary>class</secondary></indexterm><indexterm id="iddle1897" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey CLASS?><?tertiarykey STATE OWNERSHIP AS ELEMENT OF?><primary><emphasis role="strong">design</emphasis></primary><secondary>class</secondary><tertiary>state ownership as element of</tertiary></indexterm><indexterm id="iddle2546" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INVARIANTS?><?tertiarykey THREAD SAFETY IMPORTANCE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>invariants</secondary><tertiary>thread safety importance</tertiary></indexterm><indexterm id="iddle2567" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey POSTCONDITIONS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>postconditions</secondary></indexterm><indexterm id="iddle2855" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey MULTIVARIABLE?><?tertiarykey ATOMICITY REQUIREMENTS?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>multivariable</secondary><tertiary>atomicity requirements</tertiary></indexterm><indexterm id="iddle3273" significance="normal"><?indexkey M?><?primarykey multivariable invariants?><?secondarykey ATOMICITY REQUIREMENTS?><primary><emphasis role="strong">multivariable invariants</emphasis></primary><secondary>atomicity requirements</secondary></indexterm><indexterm id="iddle3376" significance="normal"><?indexkey O?><?primarykey operations?><?secondarykey STATE-DEPENDENT?><primary><emphasis role="strong">operations</emphasis></primary><secondary>state-dependent</secondary></indexterm><indexterm id="iddle3441" significance="normal"><?indexkey O?><?primarykey ownership?><?secondarykey STATE?><primary><emphasis role="strong">ownership</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle3442" significance="normal"><?indexkey O?><?primarykey ownership?><?secondarykey STATE?><?tertiarykey CLASS DESIGN ISSUES?><primary><emphasis role="strong">ownership</emphasis></primary><secondary>state</secondary><tertiary>class design issues</tertiary></indexterm><indexterm id="iddle3647" significance="normal"><?indexkey P?><?primarykey precondition(s)?><?secondarykey STATE-BASED?><?tertiarykey MANAGEMENT?><primary><emphasis role="strong">precondition(s)</emphasis></primary><secondary>state-based</secondary><tertiary>management</tertiary></indexterm><indexterm id="iddle4144" significance="normal"><?indexkey S?><?primarykey Semaphore?><?secondarykey STATE-BASED PRECONDITION MANAGEMENT WITH?><primary><emphasis role="strong">Semaphore</emphasis></primary><secondary>state-based precondition management with</secondary></indexterm><indexterm id="iddle4390" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey DEPENDENT?><?tertiarykey OPERATIONS?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>dependent</secondary><tertiary>operations</tertiary></indexterm><indexterm id="iddle4415" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey OWNERSHIP?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>ownership</secondary></indexterm><indexterm id="iddle4416" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey OWNERSHIP?><?tertiarykey CLASS DESIGN ISSUES?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>ownership</secondary><tertiary>class design issues</tertiary></indexterm><indexterm id="iddle5054" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey MULTIVARIABLE INVARIANT REQUIREMENTS FOR ATOMICITY?><primary><emphasis role="strong">variables</emphasis></primary><secondary>multivariable invariant requirements for atomicity</secondary></indexterm>A class can also have invariants that constrain multiple state variables. A number range class, like <literal>NumberRange</literal> in <link linkend="ch04list10" preference="0">Listing 4.10</link>, typically maintains state variables for the lower and upper bounds of the range. These variables must obey the constraint that the lower bound be less than or equal to the upper bound. Multivariable invariants like this one create atomicity requirements: related variables must be fetched or updated in a single atomic operation. You cannot update one, release and reacquire the lock, and then update the others, since this could involve leaving the object in an invalid state when the lock was released. When multiple variables participate in an invariant, the lock that guards them must be held for the duration of any operation that accesses the related variables.</para>
<sidebar float="1" id="ch04sb02" condition="57"><title/>
<para>You cannot ensure thread safety without understanding an object’s invariants and postconditions. Constraints on the valid values or state transitions for state variables can create atomicity and encapsulation requirements.</para>
</sidebar>
</section>
<section id="ch04lev2sec2" label="4.1.2" xreflabel="4.1.2">
<title id="ch04lev2sec2__title">State-dependent Operations</title>
<para>Class invariants and method postconditions constrain the valid states and state transitions for an object. Some objects also have methods with state-based <emphasis>preconditions</emphasis>. For example, you cannot remove an item from an empty queue; a queue must be in the “nonempty” state before you can remove an element. Operations with state-based preconditions are called <emphasis>state-dependent</emphasis> [CPJ 3].</para>
<para>In a single-threaded program, if a precondition does not hold, the operation has no choice but to fail. But in a concurrent program, the precondition may become true later due to the action of another thread. Concurrent programs add the possibility of waiting until the precondition becomes true, and then proceeding with the operation.</para>
<para>The built-in mechanisms for efficiently waiting for a condition to become true—<literal>wait</literal> and <literal>notify</literal>—are tightly bound to intrinsic locking, and can be difficult to use correctly. To create operations that wait for a precondition to become true before proceeding, it is often easier to use existing library classes, such as blocking queues or semaphores, to provide the desired state-dependent behavior. Blocking library classes such as <literal>BlockingQueue</literal>, <literal>Semaphore</literal>, and other <emphasis>synchronizers</emphasis> are covered in <link linkend="ch05" preference="0">Chapter 5</link>; creating state-dependent classes using the low-level mechanisms provided by the platform and class library is covered in <link linkend="ch14" preference="0">Chapter 14</link>.</para>
</section>
<section id="ch04lev2sec3" label="4.1.3" xreflabel="4.1.3">
<title id="ch04lev2sec3__title">State Ownership</title>
<para>We implied in <link linkend="ch04lev1sec1" preference="0">Section 4.1</link> that an object’s state could be a subset of the fields in the object graph rooted at that object. Why might it be a subset? Under what conditions are fields reachable from a given object <emphasis>not</emphasis> part of that object’s state?</para>
<para>When defining which variables form an object’s state, we want to consider only the data that object <emphasis>owns</emphasis>. Ownership is not embodied explicitly in the language, but is instead an element of class design. If you allocate and populate <?docpage num="58"?><indexterm id="iddle1534" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey INSTANCE?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>instance</secondary></indexterm><indexterm id="iddle2012" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey INSTANCE CONFINEMENT RELATIONSHIP WITH?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>instance confinement relationship with</secondary></indexterm><indexterm id="iddle2025" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey STATE?><?tertiarykey OWNERSHIP RELATIONSHIP WITH?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>state</secondary><tertiary>ownership relationship with</tertiary></indexterm><indexterm id="iddle2669" significance="normal"><?indexkey H?><?primarykey HttpSession?><primary><emphasis role="strong">HttpSession</emphasis></primary></indexterm><indexterm id="iddle2670" significance="normal"><?indexkey H?><?primarykey HttpSession?><?secondarykey THREAD-SAFETY REQUIREMENTS?><primary><emphasis role="strong">HttpSession</emphasis></primary><secondary>thread-safety requirements</secondary></indexterm><indexterm id="iddle2749" significance="normal"><?indexkey I?><?primarykey instance confinement?><primary><emphasis role="strong">instance confinement</emphasis></primary></indexterm><indexterm id="iddle3173" significance="normal"><?indexkey L?><?primarykey logical state?><primary><emphasis role="strong">logical state</emphasis></primary></indexterm><indexterm id="iddle3438" significance="normal"><?indexkey O?><?primarykey ownership?><primary><emphasis role="strong">ownership</emphasis></primary></indexterm><indexterm id="iddle3439" significance="normal"><?indexkey O?><?primarykey ownership?><?secondarykey SHARED?><primary><emphasis role="strong">ownership</emphasis></primary><secondary>shared</secondary></indexterm><indexterm id="iddle3440" significance="normal"><?indexkey O?><?primarykey ownership?><?secondarykey SPLIT?><primary><emphasis role="strong">ownership</emphasis></primary><secondary>split</secondary></indexterm><indexterm id="iddle3467" significance="normal"><?indexkey P?><?primarykey passivation?><primary><emphasis role="strong">passivation</emphasis></primary></indexterm><indexterm id="iddle3468" significance="normal"><?indexkey P?><?primarykey passivation?><?secondarykey IMPACT ON HTTPSESSION THREADSAFETY REQUIREMENTS?><primary><emphasis role="strong">passivation</emphasis></primary><secondary>impact on <literal>HttpSession</literal> threadsafety requirements</secondary></indexterm><indexterm id="iddle4044" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey SPLIT OWNERSHIP CONCERNS?><primary><emphasis role="strong">safety</emphasis></primary><secondary>split ownership concerns</secondary></indexterm><indexterm id="iddle4179" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey IMPACT ON HTTPSESSION THREADSAFETY REQUIREMENTS?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>impact on <literal>HttpSession</literal> threadsafety requirements</secondary></indexterm><indexterm id="iddle4352" significance="normal"><?indexkey S?><?primarykey split(ing)?><?secondarykey OWNERSHIP?><primary><emphasis role="strong">split(ing)</emphasis></primary><secondary>ownership</secondary></indexterm><indexterm id="iddle4403" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey LOGICAL?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>logical</secondary></indexterm><indexterm id="iddle4490" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey SPLIT OWNERSHIP SAFETY?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>split ownership safety</secondary></indexterm>a <literal>HashMap</literal>, you are creating multiple objects: the <literal>HashMap</literal> object, a number of <literal>Map.Entry</literal> objects used by the implementation of <literal>HashMap</literal>, and perhaps other internal objects as well. The logical state of a <literal>HashMap</literal> includes the state of all its <literal>Map.Entry</literal> and internal objects, even though they are implemented as separate objects.</para>
<para>For better or worse, garbage collection lets us avoid thinking carefully about ownership. When passing an object to a method in C++, you have to think fairly carefully about whether you are transferring ownership, engaging in a short-term loan, or envisioning long-term joint ownership. In Java, all these same ownership models are possible, but the garbage collector reduces the cost of many of the common errors in reference sharing, enabling less-than-precise thinking about ownership.</para>
<para>In many cases, ownership and encapsulation go together—the object encapsulates the state it owns and owns the state it encapsulates. It is the owner of a given state variable that gets to decide on the locking protocol used to maintain the integrity of that variable’s state. Ownership implies control, but once you publish a reference to a mutable object, you no longer have exclusive control; at best, you might have “shared ownership”. A class usually does not own the objects passed to its methods or constructors, unless the method is designed to explicitly transfer ownership of objects passed in (such as the synchronized collection wrapper factory methods).</para>
<para>Collection classes often exhibit a form of “split ownership”, in which the collection owns the state of the collection infrastructure, but client code owns the objects stored in the collection. An example is <literal>ServletContext</literal> from the servlet framework. <literal>ServletContext</literal> provides a <literal>Map</literal>-like object container service to servlets where they can register and retrieve application objects by name with <literal>setAttribute</literal> and <literal>getAttribute</literal>. The <literal>ServletContext</literal> object implemented by the servlet container must be thread-safe, because it will necessarily be accessed by multiple threads. Servlets need not use synchronization when calling <literal>set-Attribute</literal> and <literal>getAttribute</literal>, but they may have to use synchronization when <emphasis>using</emphasis> the objects stored in the <literal>ServletContext</literal>. These objects are owned by the application; they are being stored for safekeeping by the servlet container on the application’s behalf. Like all shared objects, they must be shared safely; in order to prevent interference from multiple threads accessing the same object concurrently, they should either be thread-safe, effectively immutable, or explicitly guarded by a lock.<footnote id="ch04fn1" label="1"><para>Interestingly, the <literal>HttpSession</literal> object, which performs a similar function in the servlet framework, may have stricter requirements. Because the servlet container may access the objects in the <literal>HttpSession</literal> so they can be serialized for replication or passivation, they must be thread-safe because the container will be accessing them as well as the web application. (We say “may have” since replication and passivation is outside of the servlet specification but is a common feature of servlet containers.)</para></footnote>
</para>
</section>
</section>
<section id="ch04lev1sec2" condition="58" label="4.2" xreflabel="4.2"><?docpage num="58"?>
<title id="ch04lev1sec2__title">Instance Confinement</title>
<para>If an object is not thread-safe, several techniques can still let it be used safely in a multithreaded program. You can ensure that it is only accessed from a single thread (thread confinement), or that all access to it is properly guarded by a lock.</para>
<para><?docpage num="59"?><indexterm id="iddle1342" significance="normal"><?indexkey C?><?primarykey class(es)?><primary><emphasis role="strong">class(es)</emphasis></primary></indexterm><indexterm id="iddle1343" significance="normal"><?indexkey C?><?primarykey class(es)?><?secondarykey AS INSTANCE CONFINEMENT CONTEXT?><primary><emphasis role="strong">class(es)</emphasis></primary><secondary>as instance confinement context</secondary></indexterm><indexterm id="iddle1438" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1533" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey INSTANCE?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>instance</secondary></indexterm><indexterm id="iddle2048" significance="normal"><?indexkey E?><?primarykey escape?><?secondarykey PREVENTION?><primary><emphasis role="strong">escape</emphasis></primary><secondary>prevention</secondary></indexterm><indexterm id="iddle2049" significance="normal"><?indexkey E?><?primarykey escape?><?secondarykey PREVENTION?><?tertiarykey IN INSTANCE CONFINEMENT?><primary><emphasis role="strong">escape</emphasis></primary><secondary>prevention</secondary><tertiary>in instance confinement</tertiary></indexterm><indexterm id="iddle2153" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PERSONSET?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>PersonSet</literal></secondary></indexterm><indexterm id="iddle2520" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey ENCAPSULATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>encapsulation</secondary></indexterm><indexterm id="iddle2747" significance="normal"><?indexkey I?><?primarykey instance confinement?><primary><emphasis role="strong">instance confinement</emphasis></primary><seealso> <link linkend="iddle2512" preference="0"><emphasis role="strong">guidelines</emphasis>, confinement</link>.</seealso></indexterm><indexterm id="iddle2748" significance="normal"><?indexkey I?><?primarykey instance confinement?><primary><emphasis role="strong">instance confinement</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle2956" significance="normal"><?indexkey L?><?primarykey lexical scope?><primary><emphasis role="strong">lexical scope</emphasis></primary></indexterm><indexterm id="iddle2957" significance="normal"><?indexkey L?><?primarykey lexical scope?><?secondarykey AS INSTANCE CONFINEMENT CONTEXT?><primary><emphasis role="strong">lexical scope</emphasis></primary><secondary>as instance confinement context</secondary></indexterm><indexterm id="iddle3059" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey AND INSTANCE CONFINEMENT?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>and instance confinement</secondary></indexterm><indexterm id="iddle4217" significance="normal"><?indexkey S?><?primarykey set(s)?><?secondarykey PERSONSET EXAMPLE?><primary><emphasis role="strong">set(s)</emphasis></primary><secondary><literal>PersonSet</literal> example</secondary></indexterm><indexterm id="iddle4745" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey AS INSTANCE CONFINEMENT CONTEXT?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>as instance confinement context</secondary></indexterm>Encapsulation simplifies making classes thread-safe by promoting <emphasis>instance confinement</emphasis>, often just called <emphasis>confinement</emphasis> [CPJ 2.3.3]. When an object is encapsulated within another object, all code paths that have access to the encapsulated object are known and can be therefore be analyzed more easily than if that object were accessible to the entire program. Combining confinement with an appropriate locking discipline can ensure that otherwise non-thread-safe objects are used in a thread-safe manner.</para>
<sidebar float="1" id="ch04sb03" condition="59"><title/>
<para>Encapsulating data within an object confines access to the data to the object’s methods, making it easier to ensure that the data is always accessed with the appropriate lock held.</para>
</sidebar>
<para>Confined objects must not escape their intended scope. An object may be confined to a class instance (such as a private class member), a lexical scope (such as a local variable), or a thread (such as an object that is passed from method to method within a thread, but not supposed to be shared across threads). Objects don’t escape on their own, of course—they need help from the developer, who assists by publishing the object beyond its intended scope.</para>
<para><literal>PersonSet</literal> in <link linkend="ch04list02" preference="0">Listing 4.2</link> illustrates how confinement and locking can work together to make a class thread-safe even when its component state variables are not. The state of <literal>PersonSet</literal> is managed by a <literal>HashSet</literal>, which is not thread-safe. But because <literal>mySet</literal> is private and not allowed to escape, the <literal>HashSet</literal> is confined to the <literal>PersonSet</literal>. The only code paths that can access <literal>mySet</literal> are <literal>addPerson</literal> and <literal>containsPerson</literal>, and each of these acquires the lock on the <literal>PersonSet</literal>. All its state is guarded by its intrinsic lock, making <literal>PersonSet</literal> thread-safe.</para>
<example id="ch04list02" label="4.2" role="Listing" xreflabel="4.2" condition="59">
<title id="ch04list02__title">Using Confinement to Ensure Thread Safety.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class PersonSet {
    @GuardedBy("this")
    private final Set&lt;Person&gt; mySet = new HashSet&lt;Person&gt;();

    public synchronized void addPerson(Person p) {
        mySet.add(p);
    }

    public synchronized boolean containsPerson(Person p) {
        return mySet.contains(p);
    }
}
</programlisting>
</example>
<para>This example makes no assumptions about the thread-safety of <literal>Person</literal>, but if it is mutable, additional synchronization will be needed when accessing a <literal>Person</literal> retrieved from a <literal>PersonSet</literal>. The most reliable way to do this would be to make <?docpage num="60"?><indexterm id="iddle1842" significance="normal"><?indexkey D?><?primarykey Decorator pattern?><primary><emphasis role="strong">Decorator pattern</emphasis></primary></indexterm><indexterm id="iddle1843" significance="normal"><?indexkey D?><?primarykey Decorator pattern?><?secondarykey COLLECTION CLASS USE FOR WRAPPER FACTORIES?><primary><emphasis role="strong">Decorator pattern</emphasis></primary><secondary>collection class use for wrapper factories</secondary></indexterm><indexterm id="iddle1946" significance="normal"><?indexkey D?><?primarykey design patterns?><?secondarykey EXAMPLES?><primary><emphasis role="strong">design patterns</emphasis></primary><secondary>examples</secondary><see> <link linkend="iddle5168" preference="0"><emphasis role="strong">wrapper(s)</emphasis>, factories, Decorator pattern</link>.</see></indexterm><indexterm id="iddle1947" significance="normal"><?indexkey D?><?primarykey design patterns?><?secondarykey EXAMPLES?><primary><emphasis role="strong">design patterns</emphasis></primary><secondary>examples</secondary><see> <link linkend="iddle3287" preference="0"><emphasis role="strong">MVC (model-view-controller) pattern</emphasis></link>.</see></indexterm><indexterm id="iddle1948" significance="normal"><?indexkey D?><?primarykey design patterns?><?secondarykey EXAMPLES?><primary><emphasis role="strong">design patterns</emphasis></primary><secondary>examples</secondary><see> <link linkend="iddle1579" preference="0"><emphasis role="strong">consumers</emphasis>, producer-consumer pattern</link>.</see></indexterm><indexterm id="iddle1949" significance="normal"><?indexkey D?><?primarykey design patterns?><?secondarykey EXAMPLES?><primary><emphasis role="strong">design patterns</emphasis></primary><secondary>examples</secondary><see> <link linkend="iddle4305" preference="0"><emphasis role="strong">Singleton pattern</emphasis></link>.</see></indexterm><indexterm id="iddle2051" significance="normal"><?indexkey E?><?primarykey escape?><?secondarykey RISK FACTORS?><primary><emphasis role="strong">escape</emphasis></primary><secondary>risk factors</secondary></indexterm><indexterm id="iddle2052" significance="normal"><?indexkey E?><?primarykey escape?><?secondarykey RISK FACTORS?><?tertiarykey IN INSTANCE CONFINEMENT?><primary><emphasis role="strong">escape</emphasis></primary><secondary>risk factors</secondary><tertiary>in instance confinement</tertiary></indexterm><indexterm id="iddle2374" significance="normal"><?indexkey F?><?primarykey flexibility?><?secondarykey AND INSTANCE CONFINEMENT?><primary><emphasis role="strong">flexibility</emphasis></primary><secondary>and instance confinement</secondary></indexterm><indexterm id="iddle2512" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey CONFINEMENT?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>confinement</secondary></indexterm><indexterm id="iddle2638" significance="normal"><?indexkey H?><?primarykey Hoare, C. A. R.?><primary><emphasis role="strong">Hoare, C. A. R.</emphasis></primary></indexterm><indexterm id="iddle2639" significance="normal"><?indexkey H?><?primarykey Hoare, C. A. R.?><?secondarykey JAVA MONITOR PATTERN INSPIRED BY (BIBLIOGRAPHIC REFERENCE)?><primary><emphasis role="strong">Hoare, C. A. R.</emphasis></primary><secondary>Java monitor pattern inspired by (bibliographic reference)</secondary></indexterm><indexterm id="iddle2897" significance="normal"><?indexkey J?><?primarykey Java monitor pattern?><primary><emphasis role="strong">Java monitor pattern</emphasis></primary></indexterm><indexterm id="iddle2898" significance="normal"><?indexkey J?><?primarykey Java monitor pattern?><primary><emphasis role="strong">Java monitor pattern</emphasis></primary></indexterm><indexterm id="iddle3056" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><?tertiarykey PROTOCOLS, INSTANCE CONFINEMENT USE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary><tertiary>protocols, instance confinement use</tertiary></indexterm><indexterm id="iddle3244" significance="normal"><?indexkey M?><?primarykey monitor(s)?><primary><emphasis role="strong">monitor(s)</emphasis></primary><seealso> <link linkend="iddle1638" preference="0"><emphasis role="strong">conventions</emphasis>, Java monitor pattern</link>.</seealso></indexterm><indexterm id="iddle3708" significance="normal"><?indexkey P?><?primarykey protocol(s)?><?secondarykey LOCK ACQUISITION?><primary><emphasis role="strong">protocol(s)</emphasis></primary><secondary>lock acquisition</secondary></indexterm><indexterm id="iddle3709" significance="normal"><?indexkey P?><?primarykey protocol(s)?><?secondarykey LOCK ACQUISITION?><?tertiarykey INSTANCE CONFINEMENT USE?><primary><emphasis role="strong">protocol(s)</emphasis></primary><secondary>lock acquisition</secondary><tertiary>instance confinement use</tertiary></indexterm><indexterm id="iddle5166" significance="normal"><?indexkey W?><?primarykey wrapper(s)?><primary><emphasis role="strong">wrapper(s)</emphasis></primary></indexterm><indexterm id="iddle5167" significance="normal"><?indexkey W?><?primarykey wrapper(s)?><?secondarykey FACTORIES?><primary><emphasis role="strong">wrapper(s)</emphasis></primary><secondary>factories</secondary></indexterm><indexterm id="iddle5168" significance="normal"><?indexkey W?><?primarykey wrapper(s)?><?secondarykey FACTORIES?><?tertiarykey DECORATOR PATTERN?><primary><emphasis role="strong">wrapper(s)</emphasis></primary><secondary>factories</secondary><tertiary>Decorator pattern</tertiary></indexterm><literal>Person</literal> thread-safe; less reliable would be to guard the <literal>Person</literal> objects with a lock and ensure that all clients follow the protocol of acquiring the appropriate lock before accessing the <literal>Person</literal>.</para>
<para>Instance confinement is one of the easiest ways to build thread-safe classes. It also allows flexibility in the choice of locking strategy; <literal>PersonSet</literal> happened to use its own intrinsic lock to guard its state, but any lock, consistently used, would do just as well. Instance confinement also allows different state variables to be guarded by different locks. (For an example of a class that uses multiple lock objects to guard its state, see <literal>ServerStatus</literal> on <link linkend="ch11list06" preference="0" role="pageref">236</link>.)</para>
<para>There are many examples of confinement in the platform class libraries, including some classes that exist solely to turn non-thread-safe classes into threadsafe ones. The basic collection classes such as <literal>ArrayList</literal> and <literal>HashMap</literal> are not thread-safe, but the class library provides wrapper factory methods (<literal>Collections.synchronizedList</literal> and friends) so they can be used safely in multithreaded environments. These factories use the Decorator pattern (<link linkend="biblio01_011" preference="0">Gamma et al., 1995</link>) to wrap the collection with a synchronized wrapper object; the wrapper implements each method of the appropriate interface as a synchronized method that forwards the request to the underlying collection object. So long as the wrapper object holds the only reachable reference to the underlying collection (i.e., the underlying collection is confined to the wrapper), the wrapper object is then thread-safe. The Javadoc for these methods warns that all access to the underlying collection must be made through the wrapper.</para>
<para>Of course, it is still possible to violate confinement by publishing a supposedly confined object; if an object is intended to be confined to a specific scope, then letting it escape from that scope is a bug. Confined objects can also escape by publishing other objects such as iterators or inner class instances that may indirectly publish the confined objects.</para>
<sidebar float="1" id="ch04sb04" condition="60"><title/>
<para>Confinement makes it easier to build thread-safe classes because a class that confines its state can be analyzed for thread safety without having to examine the whole program.</para>
</sidebar>
<section id="ch04lev2sec4" label="4.2.1" xreflabel="4.2.1">
<title id="ch04lev2sec4__title">The Java Monitor Pattern</title>
<para>Following the principle of instance confinement to its logical conclusion leads you to the <emphasis>Java monitor pattern</emphasis>.<footnote id="ch04fn02" label="2"><para>The Java monitor pattern is inspired by Hoare’s work on <emphasis>monitors</emphasis> (<link linkend="biblio01_018" preference="0">Hoare, 1974</link>), though there are significant differences between this pattern and a true monitor. The bytecode instructions for entering and exiting a synchronized block are even called <literal>monitorenter</literal> and <literal>monitorexit</literal>, and Java’s built-in (intrinsic) locks are sometimes called <emphasis>monitor locks</emphasis> or <emphasis>monitors</emphasis>.</para></footnote> An object following the Java monitor pattern encapsulates all its mutable state and guards it with the object’s own intrinsic lock.</para>
<para><literal>Counter</literal> in <link linkend="ch04list01" preference="0">Listing 4.1</link> shows a typical example of this pattern. It encapsulates one state variable, <literal>value</literal>, and all access to that state variable is through the methods of <literal>Counter</literal>, which are all synchronized.</para>
<para><?docpage num="61"?><indexterm id="iddle1632" significance="normal"><?indexkey C?><?primarykey control flow?><?secondarykey MODEL-VIEW-CONTROLLER PATTERN?><?tertiarykey VEHICLE TRACKING EXAMPLE?><primary><emphasis role="strong">control flow</emphasis></primary><secondary>model-view-controller pattern</secondary><tertiary>vehicle tracking example</tertiary></indexterm><indexterm id="iddle1638" significance="normal"><?indexkey C?><?primarykey conventions?><?secondarykey JAVA MONITOR PATTERN?><primary><emphasis role="strong">conventions</emphasis></primary><secondary>Java monitor pattern</secondary></indexterm><indexterm id="iddle2159" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PRIVATELOCK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>PrivateLock</literal></secondary></indexterm><indexterm id="iddle2491" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey MVC PATTERN USE?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>MVC pattern use</secondary></indexterm><indexterm id="iddle2492" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey MVC PATTERN USE?><?tertiarykey IN VEHICLE TRACKING EXAMPLE?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>MVC pattern use</secondary><tertiary>in vehicle tracking example</tertiary></indexterm><indexterm id="iddle2900" significance="normal"><?indexkey J?><?primarykey Java monitor pattern?><?secondarykey VEHICLE TRACKING EXAMPLE?><primary><emphasis role="strong">Java monitor pattern</emphasis></primary><secondary>vehicle tracking example</secondary></indexterm><indexterm id="iddle3023" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey IMPROPER LOCK ACQUISITION RISK OF?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>improper lock acquisition risk of</secondary></indexterm><indexterm id="iddle3051" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><?tertiarykey IMPROPER, LIVENESS RISK?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary><tertiary>improper, liveness risk</tertiary></indexterm><indexterm id="iddle3113" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><?tertiarykey PRIVATE LOCKS VS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary><tertiary>private locks vs</tertiary></indexterm><indexterm id="iddle3128" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey PRIVATE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>private</secondary></indexterm><indexterm id="iddle3129" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey PRIVATE?><?tertiarykey INTRINSIC LOCKS VS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>private</secondary><tertiary>intrinsic locks vs</tertiary></indexterm><indexterm id="iddle3227" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey MODEL-VIEW-CONTROLLER PATTERN?><?tertiarykey VEHICLE TRACKING EXAMPLE?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>model-view-controller pattern</secondary><tertiary>vehicle tracking example</tertiary></indexterm><indexterm id="iddle3289" significance="normal"><?indexkey M?><?primarykey MVC (model-view-controller) pattern?><?secondarykey VEHICLE TRACKING EXAMPLE USE OF?><primary><emphasis role="strong">MVC (model-view-controller) pattern</emphasis></primary><secondary>vehicle tracking example use of</secondary></indexterm><indexterm id="iddle3668" significance="normal"><?indexkey P?><?primarykey private?><?secondarykey LOCKS?><primary><emphasis role="strong">private</emphasis></primary><secondary>locks</secondary></indexterm><indexterm id="iddle3669" significance="normal"><?indexkey P?><?primarykey private?><?secondarykey LOCKS?><?tertiarykey JAVA MONITOR PATTERN VS?><primary><emphasis role="strong">private</emphasis></primary><secondary>locks</secondary><tertiary>Java monitor pattern vs</tertiary></indexterm><indexterm id="iddle4283" significance="normal"><?indexkey S?><?primarykey simplicity?><?secondarykey JAVA MONITOR PATTERN ADVANTAGE?><primary><emphasis role="strong">simplicity</emphasis></primary><secondary>Java monitor pattern advantage</secondary></indexterm><indexterm id="iddle4476" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey MONITOR?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>monitor</secondary></indexterm><indexterm id="iddle4477" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey MONITOR?><?tertiarykey VEHICLE TRACKING EXAMPLE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>monitor</secondary><tertiary>vehicle tracking example</tertiary></indexterm><indexterm id="iddle5080" significance="normal"><?indexkey V?><?primarykey vehicle tracking example?><?secondarykey MONITOR STRATEGY?><primary><emphasis role="strong">vehicle tracking example</emphasis></primary><secondary>monitor strategy</secondary></indexterm><indexterm id="iddle5082" significance="normal"><?indexkey V?><?primarykey vehicle tracking example?><?secondarykey THREAD-SAFE OBJECT COMPOSITION DESIGN?><primary><emphasis role="strong">vehicle tracking example</emphasis></primary><secondary>thread-safe object composition design</secondary></indexterm><indexterm id="iddle5089" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey MODEL-VIEW-CONTROLLER PATTERN?><?tertiarykey VEHICLE TRACKING EXAMPLE?><primary><emphasis role="strong">views</emphasis></primary><secondary>model-view-controller pattern</secondary><tertiary>vehicle tracking example</tertiary></indexterm>The Java monitor pattern is used by many library classes, such as <literal>Vector</literal> and <literal>Hashtable</literal>. Sometimes a more sophisticated synchronization policy is needed; <link linkend="ch11" preference="0">Chapter 11</link> shows how to improve scalability through finer-grained locking strategies. The primary advantage of the Java monitor pattern is its simplicity.</para>
<para>The Java monitor pattern is merely a convention; any lock object could be used to guard an object’s state so long as it is used consistently. <link linkend="ch04list03" preference="0">Listing 4.3</link> illustrates a class that uses a private lock to guard its state.</para>
<example id="ch04list03" label="4.3" role="Listing" xreflabel="4.3" condition="61">
<title id="ch04list03__title">Guarding State with a Private Lock.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class PrivateLock {
    private final Object myLock = new Object();
    @GuardedBy("myLock") Widget widget;

    void someMethod() {
        synchronized(myLock) {
            // Access or modify the state of widget
        }
    }
}
</programlisting>
</example>
<para>There are advantages to using a private lock object instead of an object’s intrinsic lock (or any other publicly accessible lock). Making the lock object private encapsulates the lock so that client code cannot acquire it, whereas a publicly accessible lock allows client code to participate in its synchronization policy—correctly or incorrectly. Clients that improperly acquire another object’s lock could cause liveness problems, and verifying that a publicly accessible lock is properly used requires examining the entire program rather than a single class.</para>
</section>
<section id="ch04lev2sec5" label="4.2.2" xreflabel="4.2.2">
<title id="ch04lev2sec5__title">Example: Tracking Fleet Vehicles</title>
<para><literal>Counter</literal> in <link linkend="ch04list01" preference="0">Listing 4.1</link> is a concise, but trivial, example of the Java monitor pattern. Let’s build a slightly less trivial example: a “vehicle tracker” for dispatching fleet vehicles such as taxicabs, police cars, or delivery trucks. We’ll build it first using the monitor pattern, and then see how to relax some of the encapsulation requirements while retaining thread safety.</para>
<para>Each vehicle is identified by a <literal>String</literal> and has a location represented by (<emphasis>x</emphasis>, <emphasis>y</emphasis>) coordinates. The <literal>VehicleTracker</literal> classes encapsulate the identity and locations of the known vehicles, making them well-suited as a data model in a modelview-controller GUI application where it might be shared by a view thread and multiple updater threads. The view thread would fetch the names and locations of the vehicles and render them on a display:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">Map&lt;String, Point&gt; locations = vehicles.getLocations();
for (String key : locations.keySet())
    renderVehicle(key, locations.get(key));
</programlisting>
</informalexample>
<para role="continued"><?docpage num="62"?><indexterm id="iddle1550" significance="normal"><?indexkey C?><?primarykey consistent/consistency?><primary><emphasis role="strong">consistent/consistency</emphasis></primary></indexterm><indexterm id="iddle1551" significance="normal"><?indexkey C?><?primarykey consistent/consistency?><?secondarykey COPY TIMELINESS VS?><primary><emphasis role="strong">consistent/consistency</emphasis></primary><secondary>copy timeliness vs</secondary></indexterm><indexterm id="iddle1552" significance="normal"><?indexkey C?><?primarykey consistent/consistency?><?secondarykey COPY TIMELINESS VS?><?tertiarykey AS DESIGN TRADEOFF?><primary><emphasis role="strong">consistent/consistency</emphasis></primary><secondary>copy timeliness vs</secondary><tertiary>as design tradeoff</tertiary></indexterm><indexterm id="iddle1662" significance="normal"><?indexkey C?><?primarykey copying?><?secondarykey DATA?><primary><emphasis role="strong">copying</emphasis></primary><secondary>data</secondary></indexterm><indexterm id="iddle1663" significance="normal"><?indexkey C?><?primarykey copying?><?secondarykey DATA?><?tertiarykey THREAD SAFETY CONSEQUENCES?><primary><emphasis role="strong">copying</emphasis></primary><secondary>data</secondary><tertiary>thread safety consequences</tertiary></indexterm><indexterm id="iddle1863" significance="normal"><?indexkey D?><?primarykey delegation?><?secondarykey THREAD SAFETY?><?tertiarykey MANAGEMENT?><primary><emphasis role="strong">delegation</emphasis></primary><secondary>thread safety</secondary><tertiary>management</tertiary></indexterm><indexterm id="iddle1940" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey TRADEOFFS?><?tertiarykey TIMELINESS VS. CONSISTENCY?><primary><emphasis role="strong">design</emphasis></primary><secondary>tradeoffs</secondary><tertiary>timeliness vs. consistency</tertiary></indexterm><indexterm id="iddle4734" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey DELEGATION?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>delegation</secondary></indexterm>Similarly, the updater threads would modify vehicle locations with data received from GPS devices or entered manually by a dispatcher through a GUI interface:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">void vehicleMoved(VehicleMovedEvent evt) {
    Point loc = evt.getNewLocation();
    vehicles.setLocation(evt.getVehicleId(), loc.x, loc.y);
}
</programlisting>
</informalexample>
<para role="continued">Since the view thread and the updater threads will access the data model concurrently, it must be thread-safe. <link linkend="ch04list04" preference="0">Listing 4.4</link> shows an implementation of the vehicle tracker using the Java monitor pattern that uses <literal>MutablePoint</literal> in <link linkend="ch04list05" preference="0">Listing 4.5</link> for representing the vehicle locations.</para>
<para>Even though <literal>MutablePoint</literal> is not thread-safe, the tracker class is. Neither the map nor any of the mutable points it contains is ever published. When we need to a return vehicle locations to callers, the appropriate values are copied using either the <literal>MutablePoint</literal> copy constructor or <literal>deepCopy</literal>, which creates a new <literal>Map</literal> whose values are copies of the keys and values from the old <literal>Map</literal>.<footnote id="ch04fn03" label="3"><para>Note that <literal>deepCopy</literal> can’t just wrap the <literal>Map</literal> with an <literal>unmodifiableMap</literal>, because that protects only the <emphasis>collection</emphasis> from modification; it does not prevent callers from modifying the mutable objects stored in it. For the same reason, populating the <literal>HashMap</literal> in <literal>deepCopy</literal> via a copy constructor wouldn’t work either, because only the <emphasis>references</emphasis> to the points would be copied, not the point objects themselves.</para></footnote></para>
<para>This implementation maintains thread safety in part by copying mutable data before returning it to the client. This is usually not a performance issue, but could become one <emphasis>if</emphasis> the set of vehicles is very large.<footnote id="ch04fn04" label="4"><para>Because<literal>deepCopy</literal> is called from a <literal>synchronized</literal> method, the tracker’s intrinsic lock is held for the duration of what might be a long-running copy operation, and this could degrade the responsiveness of the user interface when many vehicles are being tracked.</para></footnote> Another consequence of copying the data on each call to <literal>getLocation</literal> is that the contents of the returned collection do not change even if the underlying locations change. Whether this is good or bad depends on your requirements. It could be a benefit if there are internal consistency requirements on the location set, in which case returning a consistent snapshot is critical, or a drawback if callers require up-to-date information for each vehicle and therefore need to refresh their snapshot more often.</para>
</section>
</section>
<section id="ch04lev1sec3" condition="62" label="4.3" xreflabel="4.3"><?docpage num="62"?><?docpage num="63"?>
<title id="ch04lev1sec3__title">Delegating Thread Safety</title>
<para>All but the most trivial objects are composite objects. The Java monitor pattern is useful when building classes from scratch or composing classes out of objects that are not thread-safe. But what if the components of our class are already thread-safe? Do we need to add an additional layer of thread safety? The answer is . . . “it depends”. In some cases a composite made of thread-safe components is thread-safe (<link linkend="ch04list07" preference="0">Listings 4.7</link> and <link linkend="ch04list09" preference="0">4.9</link>), and in others it is merely a good start (<link linkend="ch04list10" preference="0">4.10</link>).</para>
<para>In <literal>CountingFactorizer</literal> on page 23, we added an <literal>AtomicLong</literal> to an otherwise stateless object, and the resulting composite object was still thread-safe. Since the state of <literal>CountingFactorizer</literal> <emphasis>is</emphasis> the state of the thread-safe <literal>AtomicLong</literal>, and since <literal>CountingFactorizer</literal> imposes no additional validity constraints on the state of the <?docpage num="64"?><indexterm id="iddle2139" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MONITORVEHICLETRACKER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>MonitorVehicleTracker</literal></secondary></indexterm><indexterm id="iddle2141" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MUTABLEPOINT?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>MutablePoint</literal></secondary></indexterm><indexterm id="iddle2154" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey POINT?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Point</literal></secondary></indexterm><indexterm id="iddle4461" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey DELEGATION?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>delegation</secondary></indexterm><indexterm id="iddle4462" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey DELEGATION?><?tertiarykey VEHICLE TRACKING EXAMPLE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>delegation</secondary><tertiary>vehicle tracking example</tertiary></indexterm><indexterm id="iddle5078" significance="normal"><?indexkey V?><?primarykey vehicle tracking example?><primary><emphasis role="strong">vehicle tracking example</emphasis></primary></indexterm><indexterm id="iddle5079" significance="normal"><?indexkey V?><?primarykey vehicle tracking example?><?secondarykey DELEGATION STRATEGY?><primary><emphasis role="strong">vehicle tracking example</emphasis></primary><secondary>delegation strategy</secondary></indexterm>counter, it is easy to see that <literal>CountingFactorizer</literal> is thread-safe. We could say that <literal>CountingFactorizer</literal> <emphasis>delegates</emphasis> its thread safety responsibilities to the <literal>AtomicLong</literal>: <literal>CountingFactorizer</literal> is thread-safe because <literal>AtomicLong</literal> is.<footnote id="ch04fn05" label="5"><para>If <literal>count</literal> were not <literal>final</literal>, the thread safety analysis of <literal>CountingFactorizer</literal> would be more complicated. If <literal>CountingFactorizer</literal> could modify <literal>count</literal> to reference a different <literal>AtomicLong</literal>, we would then have to ensure that this update was visible to all threads that might access the count, and that there were no race conditions regarding the value of the <literal>count</literal> reference. This is another good reason to use <literal>final</literal> fields wherever practical.</para></footnote></para>
<example id="ch04list04" label="4.4" role="Listing" xreflabel="4.4" condition="63">
<?docpage num="63"?>
<title id="ch04list04__title">Monitor-based Vehicle Tracker Implementation.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class MonitorVehicleTracker {
    @GuardedBy("this")
    private final Map&lt;String, MutablePoint&gt; locations;

    public MonitorVehicleTracker(
            Map&lt;String, MutablePoint&gt; locations) {
        this.locations = deepCopy(locations);
    }

    public <emphasis role="strong">synchronized</emphasis> Map&lt;String, MutablePoint&gt; getLocations() {
        return deepCopy(locations);
    }

    public <emphasis role="strong">synchronized</emphasis>  MutablePoint getLocation(String id) {
        MutablePoint loc = locations.get(id);
        return loc == null ? null : new MutablePoint(loc);
    }

    public <emphasis role="strong">synchronized</emphasis>  void setLocation(String id, int x, int y) {
        MutablePoint loc = locations.get(id);
        if (loc == null)
            throw new IllegalArgumentException("No such ID: " + id);
        loc.x = x;
        loc.y = y;
    }

    private static Map&lt;String, MutablePoint&gt; deepCopy(
            Map&lt;String, MutablePoint&gt; m) {
        Map&lt;String, MutablePoint&gt; result =
                new HashMap&lt;String, MutablePoint&gt;();
        for (String id : m.keySet())
            result.put(id, new MutablePoint(m.get(id)));
        return Collections.unmodifiableMap(result);
    }
}

public class MutablePoint { <emphasis>/*  Listing 4.5  */</emphasis> }
</programlisting>
</example>
<example id="ch04list05" label="4.5" role="Listing" xreflabel="4.5" condition="64">
<title id="ch04list05__title">Mutable Point Class Similar to <literal>Java.awt.Point</literal>.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@NotThreadSafe
public class MutablePoint {
    public int x, y;

    public MutablePoint() { x = 0; y = 0; }
    public MutablePoint(MutablePoint p) {
        this.x = p.x;
        this.y = p.y;
    }
}
</programlisting>
</example>
<section id="ch04lev2sec6" label="4.3.1" xreflabel="4.3.1">
<title id="ch04lev2sec6__title">Example: Vehicle Tracker Using Delegation</title>
<para>As a more substantial example of delegation, let’s construct a version of the vehicle tracker that delegates to a thread-safe class. We store the locations in a <literal>Map</literal>, so we start with a thread-safe <literal>Map</literal> implementation, <literal>ConcurrentHashMap</literal>. We also store the location using an immutable <literal>Point</literal> class instead of <literal>MutablePoint</literal>, shown in <link linkend="ch04list06" preference="0">Listing 4.6</link>.</para>
<example id="ch04list06" label="4.6" role="Listing" xreflabel="4.6" condition="64">
<title id="ch04list06__title">Immutable <literal>Point</literal> class used by <literal>DelegatingVehicleTracker</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@Immutable
public class Point {
    public final int x, y;

    public Point(int x, int y) {
        this.x = x;
        this.y = y;
    }
}
</programlisting>
</example>
<para><literal>Point</literal> is thread-safe because it is immutable. Immutable values can be freely shared and published, so we no longer need to copy the locations when returning them.</para>
<para><?docpage num="65"?><indexterm id="iddle2107" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey DELEGATINGVEHICLETRACKER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>DelegatingVehicleTracker</literal></secondary></indexterm><literal>DelegatingVehicleTracker</literal> in <link linkend="ch04list07" preference="0">Listing 4.7</link> does not use any explicit synchronization; all access to state is managed by <literal>ConcurrentHashMap</literal>, and all the keys and values of the <literal>Map</literal> are immutable.</para>
<example id="ch04list07" label="4.7" role="Listing" xreflabel="4.7" condition="65">
<title id="ch04list07__title">Delegating Thread Safety to a <literal>ConcurrentHashMap</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class DelegatingVehicleTracker {
    private <emphasis role="strong">final</emphasis> ConcurrentMap&lt;String, Point&gt; locations;
    private <emphasis role="strong">final</emphasis> Map&lt;String, Point&gt; unmodifiableMap;

    public DelegatingVehicleTracker(Map&lt;String, Point&gt; points) {
        locations = new <emphasis role="strong">ConcurrentHashMap</emphasis>&lt;String, Point&gt;(points);
        unmodifiableMap = <emphasis role="strong">Collections.unmodifiableMap</emphasis>(locations);
    }

    public Map&lt;String, Point&gt; getLocations() {
        return unmodifiableMap;
    }

    public Point getLocation(String id) {
        return locations.get(id);
    }

    public void setLocation(String id, int x, int y) {
        if (locations.replace(id, new Point(x, y)) == null)
            throw new IllegalArgumentException(
                "invalid vehicle name: " + id);
    }
}
</programlisting>
</example>
<para>If we had used the original <literal>MutablePoint</literal> class instead of <literal>Point</literal>, we would be breaking encapsulation by letting <literal>getLocations</literal> publish a reference to mutable state that is not thread-safe. Notice that we’ve changed the behavior of the vehicle tracker class slightly; while the monitor version returned a snapshot of the locations, the delegating version returns an unmodifiable but “live” view of the vehicle locations. This means that if thread <emphasis>A</emphasis> calls <literal>getLocations</literal> and thread <emphasis>B</emphasis> later modifies the location of some of the points, those changes are reflected in the <literal>Map</literal> returned to thread <emphasis>A</emphasis>. As we remarked earlier, this can be a benefit (more up-to-date data) or a liability (potentially inconsistent view of the fleet), depending on your requirements.</para>
<para>If an unchanging view of the fleet is required, <literal>getLocations</literal> could instead return a shallow copy of the <literal>locations</literal> map. Since the contents of the <literal>Map</literal> are immutable, only the structure of the <literal>Map</literal>, not the contents, must be copied, as shown in <link linkend="ch04list08" preference="0">Listing 4.8</link> (which returns a plain <literal>HashMap</literal>, since <literal>getLocations</literal> did not promise to return a thread-safe <literal>Map</literal>).</para>

<para><?docpage num="66"?></para><example id="ch04list08" label="4.8" role="Listing" xreflabel="4.8" condition="66">

<title id="ch04list08__title">Returning a Static Copy of the Location Set Instead of a “Live” One.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public Map&lt;String, Point&gt; getLocations() {
    return Collections.unmodifiableMap(
            new HashMap&lt;String, Point&gt;(locations));
}
</programlisting>
</example>
</section>
<section id="ch04lev2sec7" label="4.3.2" xreflabel="4.3.2">
<title id="ch04lev2sec7__title">Independent State Variables</title>
<para><indexterm id="iddle1553" significance="normal"><?indexkey C?><?primarykey consistent/consistency?><?secondarykey DATA VIEW TIMELINESS VS?><primary><emphasis role="strong">consistent/consistency</emphasis></primary><secondary>data view timeliness vs</secondary></indexterm><indexterm id="iddle1554" significance="normal"><?indexkey C?><?primarykey consistent/consistency?><?secondarykey DATA VIEW TIMELINESS VS?><?tertiarykey AS DESIGN TRADEOFF?><primary><emphasis role="strong">consistent/consistency</emphasis></primary><secondary>data view timeliness vs</secondary><tertiary>as design tradeoff</tertiary></indexterm><indexterm id="iddle1941" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey TRADEOFFS?><?tertiarykey TIMELINESS VS. CONSISTENCY?><primary><emphasis role="strong">design</emphasis></primary><secondary>tradeoffs</secondary><tertiary>timeliness vs. consistency</tertiary></indexterm><indexterm id="iddle2215" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey VISUALCOMPONENT?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>VisualComponent</literal></secondary></indexterm><indexterm id="iddle2728" significance="normal"><?indexkey I?><?primarykey independent/independence?><?secondarykey STATE VARIABLES?><primary><emphasis role="strong">independent/independence</emphasis></primary><secondary>state variables</secondary></indexterm><indexterm id="iddle2729" significance="normal"><?indexkey I?><?primarykey independent/independence?><?secondarykey STATE VARIABLES?><primary><emphasis role="strong">independent/independence</emphasis></primary><secondary>state variables</secondary></indexterm><indexterm id="iddle2852" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey INDEPENDENT STATE VARIABLES REQUIREMENTS?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>independent state variables requirements</secondary></indexterm><indexterm id="iddle3886" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey INDEPENDENT STATE VARIABLES?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>independent state variables</secondary></indexterm><indexterm id="iddle4432" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey VARIABLES?><?tertiarykey INDEPENDENT?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>variables</secondary><tertiary>independent</tertiary></indexterm><indexterm id="iddle4433" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey VARIABLES?><?tertiarykey INDEPENDENT?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>variables</secondary><tertiary>independent</tertiary></indexterm><indexterm id="iddle5057" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey STATE?><?tertiarykey INDEPENDENT?><primary><emphasis role="strong">variables</emphasis></primary><secondary>state</secondary><tertiary>independent</tertiary></indexterm><indexterm id="iddle5058" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey STATE?><?tertiarykey INDEPENDENT?><primary><emphasis role="strong">variables</emphasis></primary><secondary>state</secondary><tertiary>independent</tertiary></indexterm><indexterm id="iddle5092" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey TIMELINESS VS. CONSISTENCY?><primary><emphasis role="strong">views</emphasis></primary><secondary>timeliness vs. consistency</secondary></indexterm>The delegation examples so far delegate to a single, thread-safe state variable. We can also delegate thread safety to more than one underlying state variable as long as those underlying state variables are <emphasis>independent</emphasis>, meaning that the composite class does not impose any invariants involving the multiple state variables.</para>
<para><literal>VisualComponent</literal> in <link linkend="ch04list09" preference="0">Listing 4.9</link> is a graphical component that allows clients to register listeners for mouse and keystroke events. It maintains a list of registered listeners of each type, so that when an event occurs the appropriate listeners can be invoked. But there is no relationship between the set of mouse listeners and key listeners; the two are independent, and therefore <literal>VisualComponent</literal> can delegate its thread safety obligations to two underlying thread-safe lists.</para>
<example id="ch04list09" label="4.9" role="Listing" xreflabel="4.9" condition="66">
<title id="ch04list09__title">Delegating Thread Safety to Multiple Underlying State Variables.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class VisualComponent {
    private final List&lt;KeyListener&gt; keyListeners
        = new CopyOnWriteArrayList&lt;KeyListener&gt;();
    private final List&lt;MouseListener&gt; mouseListeners
        = new CopyOnWriteArrayList&lt;MouseListener&gt;();

    public void addKeyListener(KeyListener listener) {
        keyListeners.add(listener);
    }

    public void addMouseListener(MouseListener listener) {
        mouseListeners.add(listener);
    }

    public void removeKeyListener(KeyListener listener) {
        keyListeners.remove(listener);
    }

    public void removeMouseListener(MouseListener listener) {
        mouseListeners.remove(listener);
    }
}
</programlisting>
</example>
<para><literal>VisualComponent</literal> uses a <literal>CopyOnWriteArrayList</literal> to store each listener list; this <?docpage num="67"?><indexterm id="iddle1151" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey AND MULTIVARIABLE INVARIANTS?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>and multivariable invariants</secondary></indexterm><indexterm id="iddle1335" significance="normal"><?indexkey C?><?primarykey check-then-act operation?><?secondarykey MULTIVARIABLE INVARIANT ISSUES?><primary><emphasis role="strong">check-then-act operation</emphasis></primary><secondary>multivariable invariant issues</secondary></indexterm><indexterm id="iddle1862" significance="normal"><?indexkey D?><?primarykey delegation?><?secondarykey THREAD SAFETY?><?tertiarykey FAILURE CAUSES?><primary><emphasis role="strong">delegation</emphasis></primary><secondary>thread safety</secondary><tertiary>failure causes</tertiary></indexterm><indexterm id="iddle2147" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey NUMBERRANGE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>NumberRange</literal></secondary></indexterm><indexterm id="iddle2856" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey MULTIVARIABLE?><?tertiarykey ATOMICITY REQUIREMENTS?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>multivariable</secondary><tertiary>atomicity requirements</tertiary></indexterm><indexterm id="iddle3274" significance="normal"><?indexkey M?><?primarykey multivariable invariants?><?secondarykey ATOMICITY REQUIREMENTS?><primary><emphasis role="strong">multivariable invariants</emphasis></primary><secondary>atomicity requirements</secondary></indexterm>is a thread-safe <literal>List</literal> implementation particularly suited for managing listener lists (see <link linkend="ch05lev2sec6" preference="0">Section 5.2.3</link>). Each <literal>List</literal> is thread-safe, and because there are no constraints coupling the state of one to the state of the other, <literal>VisualComponent</literal> can delegate its thread safety responsibilities to the underlying <literal>mouseListeners</literal> and <literal>keyListeners</literal> objects.</para>
</section>
<section id="ch04lev2sec8" label="4.3.3" xreflabel="4.3.3">
<title id="ch04lev2sec8__title">When Delegation Fails</title>
<para>Most composite classes are not as simple as <literal>VisualComponent</literal>: they have invariants that relate their component state variables. <literal>NumberRange</literal> in <link linkend="ch04list10" preference="0">Listing 4.10</link> uses two <literal>AtomicInteger</literal>s to manage its state, but imposes an additional constraint—that the first number be less than or equal to the second.</para>
<example id="ch04list10" label="4.10" role="Listing" xreflabel="4.10" condition="67">
<title id="ch04list10__title">Number Range Class that does Not Sufficiently Protect Its Invariants. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class NumberRange {
    // <emphasis>INVARIANT: lower &lt;= upper</emphasis>
    private final AtomicInteger lower = new AtomicInteger(0);
    private final AtomicInteger upper = new AtomicInteger(0);

    public void setLower(int i) {
        // <emphasis>Warning -- unsafe check-then-act</emphasis>
        if (i &gt; upper.get())
            throw new IllegalArgumentException(
                    "can't set lower to " + i + " &gt; upper");
        lower.set(i);
    }

    public void setUpper(int i) {
        // <emphasis>Warning -- unsafe check-then-act</emphasis>
        if (i &lt; lower.get())
            throw new IllegalArgumentException(
                    "can't set upper to " + i + " &lt; lower");
        upper.set(i);
    }

    public boolean isInRange(int i) {
        return (i &gt;= lower.get() &amp;&amp; i &lt;= upper.get());
    }
}
</programlisting>
</example>
<para><literal>NumberRange</literal> is not thread-safe; it does not preserve the invariant that constrains <literal>lower</literal> and <literal>upper</literal>. The <literal>setLower</literal> and <literal>setUpper</literal> methods <emphasis>attempt</emphasis> to respect this invariant, but do so poorly. Both <literal>setLower</literal> and <literal>setUpper</literal> are check-then-act sequences, but they do not use sufficient locking to make them atomic. If the number range holds (0, 10), and one thread calls <literal>setLower(5)</literal> while another thread <?docpage num="68"?><?docpage num="69"?><indexterm id="iddle2590" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey STATE?><?tertiarykey VARIABLES, INDEPENDENT?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>state</secondary><tertiary>variables, independent</tertiary></indexterm><indexterm id="iddle2844" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey AND STATE VARIABLE PUBLICATION?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>and state variable publication</secondary></indexterm><indexterm id="iddle3733" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey STATE VARIABLES?><primary><emphasis role="strong">publication</emphasis></primary><secondary>state variables</secondary></indexterm><indexterm id="iddle3734" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey STATE VARIABLES?><?tertiarykey SAFETY, REQUIREMENTS FOR?><primary><emphasis role="strong">publication</emphasis></primary><secondary>state variables</secondary><tertiary>safety, requirements for</tertiary></indexterm><indexterm id="iddle4435" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey VARIABLES?><?tertiarykey SAFE PUBLICATION REQUIREMENTS?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>variables</secondary><tertiary>safe publication requirements</tertiary></indexterm><indexterm id="iddle5061" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey STATE?><?tertiarykey SAFE PUBLICATION REQUIREMENTS?><primary><emphasis role="strong">variables</emphasis></primary><secondary>state</secondary><tertiary>safe publication requirements</tertiary></indexterm><indexterm id="iddle5068" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey VOLATILE?><?tertiarykey MULTIVARIABLE INVARIANTS PROHIBITED FROM?><primary><emphasis role="strong">variables</emphasis></primary><secondary>volatile</secondary><tertiary>multivariable invariants prohibited from</tertiary></indexterm><indexterm id="iddle5127" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey VARIABLES?><?tertiarykey MULTIVARIABLE INVARIANTS PROHIBITED FROM?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>variables</secondary><tertiary>multivariable invariants prohibited from</tertiary></indexterm>calls <literal>setUpper(4)</literal>, with some unlucky timing both will pass the checks in the setters and both modifications will be applied. The result is that the range now holds (5, 4)—an invalid state. So while the underlying <literal>AtomicInteger</literal>s are thread-safe, the composite class is not. Because the underlying state variables <literal>lower</literal> and <literal>upper</literal> are not independent, <literal>NumberRange</literal> cannot simply delegate thread safety to its thread-safe state variables.</para>
<para><literal>NumberRange</literal> could be made thread-safe by using locking to maintain its invariants, such as guarding <literal>lower</literal> and <literal>upper</literal> with a common lock. It must also avoid publishing <literal>lower</literal> and <literal>upper</literal> to prevent clients from subverting its invariants.</para>
<para>If a class has compound actions, as <literal>NumberRange</literal> does, delegation alone is again not a suitable approach for thread safety. In these cases, the class must provide its own locking to ensure that compound actions are atomic, unless the entire compound action can also be delegated to the underlying state variables.</para>
<sidebar float="1" id="ch04sb05" condition="68"><title/>
<para>If a class is composed of multiple <emphasis>independent</emphasis> thread-safe state variables and has no operations that have any invalid state transitions, then it can delegate thread safety to the underlying state variables.</para>
</sidebar>
<para>The problem that prevented <literal>NumberRange</literal> from being thread-safe even though its state components were thread-safe is very similar to one of the rules about volatile variables described in <link linkend="ch03lev2sec4" preference="0">Section 3.1.4</link>: a variable is suitable for being declared <literal>volatile</literal> only if it does not participate in invariants involving other state variables.</para>
</section>
<section id="ch04lev2sec9" label="4.3.4" xreflabel="4.3.4">
<title id="ch04lev2sec9__title">Publishing Underlying State Variables</title>
<para>When you delegate thread safety to an object’s underlying state variables, under what conditions can you publish those variables so that other classes can modify them as well? Again, the answer depends on what invariants your class imposes on those variables. While the underlying <literal>value</literal> field in <literal>Counter</literal> could take on any integer value, <literal>Counter</literal> constrains it to take on only positive values, and the increment operation constrains the set of valid next states given any current state. If you were to make the <literal>value</literal> field public, clients could change it to an invalid value, so publishing it would render the class incorrect. On the other hand, if a variable represents the current temperature or the ID of the last user to log on, then having another class modify this value at any time probably would not violate any invariants, so publishing this variable might be acceptable. (It still may not be a good idea, since publishing mutable variables constrains future development and opportunities for subclassing, but it would not <emphasis>necessarily</emphasis> render the class not thread-safe.)</para>
<sidebar float="1" id="ch04sb06" condition="68"><title/>
<para><?docpage num="69"?>If a state variable is thread-safe, does not participate in any invariants that constrain its value, and has no prohibited state transitions for any of its operations, then it can safely be published.</para>
</sidebar>
<para>For example, it would be safe to publish <literal>mouseListeners</literal> or <literal>keyListeners</literal> in <literal>VisualComponent</literal>. Because <literal>VisualComponent</literal> does not impose any constraints on the valid states of its listener lists, these fields could be made public or otherwise published without compromising thread safety.</para>
</section>
<section id="ch04lev2sec10" label="4.3.5" xreflabel="4.3.5">
<title id="ch04lev2sec10__title">Example: Vehicle Tracker that Publishes Its State</title>
<para>Let’s construct another version of the vehicle tracker that publishes its underlying mutable state. Again, we need to modify the interface a little bit to accommodate this change, this time using mutable but thread-safe points.</para>
<example id="ch04list11" label="4.11" role="Listing" xreflabel="4.11" condition="68">
<title id="ch04list11__title">Thread-safe Mutable Point Class.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class SafePoint {
    @GuardedBy("this") private int x, y;

    private SafePoint(int[] a) { this(a[0], a[1]); }

    public SafePoint(SafePoint p) { this(p.get()); }

    public SafePoint(int x, int y) {
        this.x = x;
        this.y = y;
    }

    public synchronized int[] get() {
        return new int[] { x, y };
    }

    public synchronized void set(int x, int y) {
        this.x = x;
        this.y = y;
    }
}
</programlisting>
</example>
<para><literal>SafePoint</literal> in <link linkend="ch04list11" preference="0">Listing 4.11</link> provides a getter that retrieves both the <emphasis>x</emphasis> and <emphasis>y</emphasis> values at once by returning a two-element array.<footnote id="ch04fn06" label="6"><para>The private constructor exists to avoid the race condition that would occur if the copy constructor were implemented as <literal>this(p.x, p.y)</literal>; this is an example of the <emphasis>private constructor capture idiom</emphasis> (<link linkend="biblio01_004" preference="0">Bloch and Gafter, 2005</link>).</para></footnote> If we provided separate getters <?docpage num="70"?><indexterm id="iddle1206" significance="normal"><?indexkey B?><?primarykey Bloch, Joshua?><primary><emphasis role="strong">Bloch, Joshua</emphasis></primary></indexterm><indexterm id="iddle1207" significance="normal"><?indexkey B?><?primarykey Bloch, Joshua?><?secondarykey %?><primary><emphasis role="strong">Bloch, Joshua</emphasis></primary><secondary>(bibliographic reference)</secondary></indexterm><indexterm id="iddle1571" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey PRIVATE CONSTRUCTOR CAPTURE IDIOM?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary>private constructor capture idiom</secondary></indexterm><indexterm id="iddle2171" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SAFEPOINT?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SafePoint</literal></secondary></indexterm><indexterm id="iddle2698" significance="normal"><?indexkey I?><?primarykey idioms?><?secondarykey PRIVATE CONSTRUCTOR CAPTURE?><primary><emphasis role="strong">idioms</emphasis></primary><secondary>private constructor capture</secondary></indexterm><indexterm id="iddle3666" significance="normal"><?indexkey P?><?primarykey private?><primary><emphasis role="strong">private</emphasis></primary></indexterm><indexterm id="iddle3667" significance="normal"><?indexkey P?><?primarykey private?><?secondarykey CONSTRUCTOR CAPTURE IDIOM?><primary><emphasis role="strong">private</emphasis></primary><secondary>constructor capture idiom</secondary></indexterm><indexterm id="iddle4961" significance="normal"><?indexkey T?><?primarykey transition?><?secondarykey STATE TRANSITION CONSTRAINTS?><?tertiarykey IMPACT ON SAFE STATE VARIABLE PUBLICATION?><primary><emphasis role="strong">transition</emphasis></primary><secondary>state transition constraints</secondary><tertiary>impact on safe state variable publication</tertiary></indexterm><indexterm id="iddle5081" significance="normal"><?indexkey V?><?primarykey vehicle tracking example?><?secondarykey STATE VARIABLE PUBLICATION STRATEGY?><primary><emphasis role="strong">vehicle tracking example</emphasis></primary><secondary>state variable publication strategy</secondary></indexterm><indexterm id="iddle1555" significance="normal"><?indexkey C?><?primarykey consistent/consistency?><?secondarykey DATA VIEW TIMELINESS VS?><?tertiarykey AS DESIGN TRADEOFF?><primary><emphasis role="strong">consistent/consistency</emphasis></primary><secondary>data view timeliness vs</secondary><tertiary>as design tradeoff</tertiary></indexterm><indexterm id="iddle1942" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey TRADEOFFS?><?tertiarykey TIMELINESS VS. CONSISTENCY?><primary><emphasis role="strong">design</emphasis></primary><secondary>tradeoffs</secondary><tertiary>timeliness vs. consistency</tertiary></indexterm><indexterm id="iddle5093" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey TIMELINESS VS. CONSISTENCY?><primary><emphasis role="strong">views</emphasis></primary><secondary>timeliness vs. consistency</secondary></indexterm>for <emphasis>x</emphasis> and <emphasis>y</emphasis>, then the values could change between the time one coordinate is retrieved and the other, resulting in a caller seeing an inconsistent value: an (<emphasis>x</emphasis>, <emphasis>y</emphasis>) location where the vehicle never was. Using <literal>SafePoint</literal>, we can construct a vehicle tracker that publishes the underlying mutable state without undermining thread safety, as shown in the <literal>PublishingVehicleTracker</literal> class in <link linkend="ch04list12" preference="0">Listing 4.12</link>.</para>
<example id="ch04list12" label="4.12" role="Listing" xreflabel="4.12" condition="70">
<title id="ch04list12__title">Vehicle Tracker that Safely Publishes Underlying State.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class PublishingVehicleTracker {
    private final Map&lt;String, SafePoint&gt; locations;
    private final Map&lt;String, SafePoint&gt; unmodifiableMap;

    public PublishingVehicleTracker(
                            Map&lt;String, SafePoint&gt; locations) {
        this.locations
            = new ConcurrentHashMap&lt;String, SafePoint&gt;(locations);
        this.unmodifiableMap
            = Collections.unmodifiableMap(this.locations);
    }

    public Map&lt;String, SafePoint&gt; getLocations() {
        return unmodifiableMap;
    }

    public SafePoint getLocation(String id) {
        return locations.get(id);
    }

    public void setLocation(String id, int x, int y) {
        if (!locations.containsKey(id))
            throw new IllegalArgumentException(
                "invalid vehicle name: " + id);
        locations.get(id).set(x, y);
      }
}
</programlisting>
</example>
<para><literal>PublishingVehicleTracker</literal> derives its thread safety from delegation to an underlying <literal>ConcurrentHashMap</literal>, but this time the contents of the <literal>Map</literal> are thread-safe mutable points rather than immutable ones. The <literal>getLocation</literal> method returns an unmodifiable copy of the underlying <literal>Map</literal>. Callers cannot add or remove vehicles, but could change the location of one of the vehicles by mutating the <literal>SafePoint</literal> values in the returned <literal>Map</literal>. Again, the “live” nature of the <literal>Map</literal> may be a benefit or a drawback, depending on the requirements. <literal>PublishingVehicleTracker</literal> is thread-safe, but would not be so if it imposed any additional constraints on the valid values for vehicle locations. If it needed to be able to “veto” changes to <?docpage num="71"?><indexterm id="iddle1164" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey PUT-IF-ABSENT?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>put-if-absent</secondary></indexterm><indexterm id="iddle1344" significance="normal"><?indexkey C?><?primarykey class(es)?><?secondarykey EXTENSION?><primary><emphasis role="strong">class(es)</emphasis></primary><secondary>extension</secondary></indexterm><indexterm id="iddle1345" significance="normal"><?indexkey C?><?primarykey class(es)?><?secondarykey EXTENSION?><?tertiarykey STRATEGIES AND RISKS?><primary><emphasis role="strong">class(es)</emphasis></primary><secondary>extension</secondary><tertiary>strategies and risks</tertiary></indexterm><indexterm id="iddle1722" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey CLASS?><primary><emphasis role="strong">creation</emphasis></primary><secondary>class</secondary></indexterm><indexterm id="iddle1723" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey CLASS?><?tertiarykey EXISTING THREAD-SAFE CLASS REUSE ADVANTAGES OVER?><primary><emphasis role="strong">creation</emphasis></primary><secondary>class</secondary><tertiary>existing thread-safe class reuse advantages over</tertiary></indexterm><indexterm id="iddle2010" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey IMPLEMENTATION?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>implementation</secondary></indexterm><indexterm id="iddle2011" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey IMPLEMENTATION?><?tertiarykey CLASS EXTENSION VIOLATION OF?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>implementation</secondary><tertiary>class extension violation of</tertiary></indexterm><indexterm id="iddle2028" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey SYNCHRONIZATION POLICY?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>synchronization policy</secondary></indexterm><indexterm id="iddle2029" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey SYNCHRONIZATION POLICY?><?tertiarykey AND CLIENT-SIDE LOCKING?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>synchronization policy</secondary><tertiary>and client-side locking</tertiary></indexterm><indexterm id="iddle2288" significance="normal"><?indexkey E?><?primarykey extending?><?secondarykey EXISTING THREAD-SAFE CLASSES?><?tertiarykey STRATEGIES AND RISKS?><primary><emphasis role="strong">extending</emphasis></primary><secondary>existing thread-safe classes</secondary><tertiary>strategies and risks</tertiary></indexterm><indexterm id="iddle2391" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey ISSUES AND CAUSES?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>issues and causes</secondary></indexterm><indexterm id="iddle2392" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey ISSUES AND CAUSES?><?tertiarykey AS CLASS EXTENSION?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>issues and causes</secondary><tertiary>as class extension</tertiary></indexterm><indexterm id="iddle2414" significance="normal"><?indexkey F?><?primarykey functionality?><primary><emphasis role="strong">functionality</emphasis></primary></indexterm><indexterm id="iddle2415" significance="normal"><?indexkey F?><?primarykey functionality?><?secondarykey EXTENDING FOR EXISTING THREAD-SAFE CLASSES?><primary><emphasis role="strong">functionality</emphasis></primary><secondary>extending for existing thread-safe classes</secondary></indexterm><indexterm id="iddle2416" significance="normal"><?indexkey F?><?primarykey functionality?><?secondarykey EXTENDING FOR EXISTING THREAD-SAFE CLASSES?><?tertiarykey STRATEGIES AND RISKS?><primary><emphasis role="strong">functionality</emphasis></primary><secondary>extending for existing thread-safe classes</secondary><tertiary>strategies and risks</tertiary></indexterm><indexterm id="iddle3593" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SYNCHRONIZATION?><?tertiarykey REQUIREMENTS, IMPACT ON CLASS EXTENSION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>synchronization</secondary><tertiary>requirements, impact on class extension</tertiary></indexterm><indexterm id="iddle3594" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SYNCHRONIZATION?><?tertiarykey REQUIREMENTS, IMPACT ON CLASS MODIFICATION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>synchronization</secondary><tertiary>requirements, impact on class modification</tertiary></indexterm><indexterm id="iddle3737" significance="normal"><?indexkey P?><?primarykey put-if-absent operation?><?secondarykey AS COMPOUND ACTION?><primary><emphasis role="strong">put-if-absent operation</emphasis></primary><secondary>as compound action</secondary></indexterm><indexterm id="iddle3738" significance="normal"><?indexkey P?><?primarykey put-if-absent operation?><?secondarykey AS COMPOUND ACTION?><?tertiarykey ATOMICITY REQUIREMENTS?><primary><emphasis role="strong">put-if-absent operation</emphasis></primary><secondary>as compound action</secondary><tertiary>atomicity requirements</tertiary></indexterm><indexterm id="iddle3997" significance="normal"><?indexkey R?><?primarykey reuse?><primary><emphasis role="strong">reuse</emphasis></primary></indexterm><indexterm id="iddle3998" significance="normal"><?indexkey R?><?primarykey reuse?><?secondarykey EXISTING THREAD-SAFE CLASSES?><primary><emphasis role="strong">reuse</emphasis></primary><secondary>existing thread-safe classes</secondary></indexterm><indexterm id="iddle3999" significance="normal"><?indexkey R?><?primarykey reuse?><?secondarykey EXISTING THREAD-SAFE CLASSES?><?tertiarykey STRATEGIES AND RISKS?><primary><emphasis role="strong">reuse</emphasis></primary><secondary>existing thread-safe classes</secondary><tertiary>strategies and risks</tertiary></indexterm><indexterm id="iddle4492" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey THREAD-SAFE CLASS EXTENSION?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>thread-safe class extension</secondary></indexterm><indexterm id="iddle4565" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey POLICY?><?tertiarykey ENCAPSULATION, CLIENT-SIDE LOCKING VIOLATION OF?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>policy</secondary><tertiary>encapsulation, client-side locking violation of</tertiary></indexterm><indexterm id="iddle4567" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey POLICY?><?tertiarykey REQUIREMENTS, IMPACT ON CLASS EXTENSION?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>policy</secondary><tertiary>requirements, impact on class extension</tertiary></indexterm><indexterm id="iddle4568" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey POLICY?><?tertiarykey REQUIREMENTS, IMPACT ON CLASS MODIFICATION?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>policy</secondary><tertiary>requirements, impact on class modification</tertiary></indexterm>vehicle locations or to take action when a location changes, the approach taken by <literal>PublishingVehicleTracker</literal> would not be appropriate.</para>
</section>
</section>
<section id="ch04lev1sec4" condition="71" label="4.4" xreflabel="4.4"><?docpage num="71"?>
<title id="ch04lev1sec4__title">Adding Functionality to Existing Thread-safe Classes</title>
<para>The Java class library contains many useful “building block” classes. Reusing existing classes is often preferable to creating new ones: reuse can reduce development effort, development risk (because the existing components are already tested), and maintenance cost. Sometimes a thread-safe class that supports all of the operations we want already exists, but often the best we can find is a class that supports <emphasis>almost</emphasis> all the operations we want, and then we need to add a new operation to it without undermining its thread safety.</para>
<para>As an example, let’s say we need a thread-safe <literal>List</literal> with an atomic put-ifabsent operation. The synchronized <literal>List</literal> implementations nearly do the job, since they provide the <literal>contains</literal> and <literal>add</literal> methods from which we can construct a put-if-absent operation.</para>
<para>The concept of put-if-absent is straightforward enough—check to see if an element is in the collection before adding it, and do not add it if it is already there. (Your “check-then-act” warning bells should be going off now.) The requirement that the class be thread-safe implicitly adds another requirement—that operations like put-if-absent be <emphasis>atomic</emphasis>. Any reasonable interpretation suggests that, if you take a <literal>List</literal> that does not contain object <emphasis>X</emphasis>, and add <emphasis>X</emphasis> twice with put-if-absent, the resulting collection contains only one copy of <emphasis>X</emphasis>. But, if put-if-absent were not atomic, with some unlucky timing two threads could both see that <emphasis>X</emphasis> was not present and both add <emphasis>X</emphasis>, resulting in two copies of <emphasis>X</emphasis>.</para>
<para>The safest way to add a new atomic operation is to modify the original class to support the desired operation, but this is not always possible because you may not have access to the source code or may not be free to modify it. If you can modify the original class, you need to understand the implementation’s synchronization policy so that you can enhance it in a manner consistent with its original design. Adding the new method directly to the class means that all the code that implements the synchronization policy for that class is still contained in one source file, facilitating easier comprehension and maintenance.</para>
<para>Another approach is to extend the class, assuming it was designed for extension. <literal>BetterVector</literal> in <link linkend="ch04list13" preference="0">Listing 4.13</link> extends <literal>Vector</literal> to add a <literal>putIfAbsent</literal> method. Extending <literal>Vector</literal> is straightforward enough, but not all classes expose enough of their state to subclasses to admit this approach.</para>
<para>Extension is more fragile than adding code directly to a class, because the implementation of the synchronization policy is now distributed over multiple, separately maintained source files. If the underlying class were to change its synchronization policy by choosing a different lock to guard its state variables, the subclass would subtly and silently break, because it no longer used the right lock to control concurrent access to the base class’s state. (The synchronization policy of <literal>Vector</literal> is fixed by its specification, so <literal>BetterVector</literal> would not suffer from this problem.)</para>

<para><?docpage num="72"?></para><example id="ch04list13" label="4.13" role="Listing" xreflabel="4.13" condition="72">

<title id="ch0413__title">Extending <literal>Vector</literal> to have a Put-if-absent Method.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class BetterVector&lt;E&gt; extends Vector&lt;E&gt; {
    public <emphasis role="strong">synchronized</emphasis> boolean putIfAbsent(E x) {
        boolean absent = !contains(x);
        if (absent)
            add(x);
        return absent;
    }
}
</programlisting>
</example>
<section id="ch04lev2sec11" label="4.4.1" xreflabel="4.4.1">
<title id="ch04lev2sec11__title">Client-side Locking</title>
<para><indexterm id="iddle1346" significance="normal"><?indexkey C?><?primarykey class(es)?><?secondarykey EXTENSION?><?tertiarykey WITH HELPER CLASSES?><primary><emphasis role="strong">class(es)</emphasis></primary><secondary>extension</secondary><tertiary>with helper classes</tertiary></indexterm><indexterm id="iddle1356" significance="normal"><?indexkey C?><?primarykey client(s)?><primary><emphasis role="strong">client(s)</emphasis></primary><seealso> <link linkend="iddle4187" preference="0"><emphasis role="strong">server</emphasis></link>.</seealso></indexterm><indexterm id="iddle1359" significance="normal"><?indexkey C?><?primarykey client-side locking?><primary><emphasis role="strong">client-side locking</emphasis></primary><seealso> <link linkend="iddle2879" preference="0"><emphasis role="strong">iterators/iteration</emphasis>, locking</link>.</seealso></indexterm><indexterm id="iddle2083" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BETTERVECTOR?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BetterVector</literal></secondary></indexterm><indexterm id="iddle2633" significance="normal"><?indexkey H?><?primarykey helper classes?><primary><emphasis role="strong">helper classes</emphasis></primary></indexterm><indexterm id="iddle2634" significance="normal"><?indexkey H?><?primarykey helper classes?><?secondarykey AND EXTENDING CLASS FUNCTIONALITY?><primary><emphasis role="strong">helper classes</emphasis></primary><secondary>and extending class functionality</secondary></indexterm><indexterm id="iddle3065" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CLIENT-SIDE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>client-side</secondary></indexterm><indexterm id="iddle4187" significance="normal"><?indexkey S?><?primarykey server?><primary><emphasis role="strong">server</emphasis></primary><seealso> <link linkend="iddle1356" preference="0"><emphasis role="strong">client(s)</emphasis></link>.</seealso></indexterm>For an <literal>ArrayList</literal> wrapped with a <literal>Collections.synchronizedList</literal> wrapper, neither of these approaches—adding a method to the original class or extending the class—works because the client code does not even know the class of the <literal>List</literal> object returned from the synchronized wrapper factories. A third strategy is to extend the functionality of the class without extending the class itself by placing extension code in a “helper” class.</para>
<para><link linkend="ch04list14" preference="0">Listing 4.14</link> shows a failed attempt to create a helper class with an atomic put-if-absent operation for operating on a thread-safe <literal>List</literal>.</para>
<example id="ch04list14" label="4.14" role="Listing" xreflabel="4.14" condition="72">
<title id="ch04list14__title">Non-thread-safe Attempt to Implement Put-if-absent. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@NotThreadSafe
public class ListHelper&lt;E&gt; {
    public List&lt;E&gt; list =
        Collections.synchronizedList(new ArrayList&lt;E&gt;());
    ...
    public <emphasis role="strong">synchronized</emphasis> boolean putIfAbsent(E x) {
        boolean absent = !list.contains(x);
        if (absent)
            list.add(x);
        return absent;
    }
}
</programlisting>
</example>
<para>Why wouldn’t this work? After all, <literal>putIfAbsent</literal> is <literal>synchronized</literal>, right? The problem is that it synchronizes on the <emphasis>wrong lock</emphasis>. Whatever lock the <literal>List</literal> uses to guard its state, it sure isn’t the lock on the <literal>ListHelper</literal>. <literal>ListHelper</literal> provides only the <emphasis>illusion of synchronization</emphasis>; the various list operations, while all <literal>synchronized</literal>, use different locks, which means that <literal>putIfAbsent</literal> is <emphasis>not</emphasis> atomic relative to other operations on the <literal>List</literal>. So there is no guarantee that another thread won’t modify the list while <literal>putIfAbsent</literal> is executing.</para>
<para><?docpage num="73"?><indexterm id="iddle1347" significance="normal"><?indexkey C?><?primarykey class(es)?><?secondarykey SYNCHRONIZED WRAPPER?><primary><emphasis role="strong">class(es)</emphasis></primary><secondary>synchronized wrapper</secondary></indexterm><indexterm id="iddle1348" significance="normal"><?indexkey C?><?primarykey class(es)?><?secondarykey SYNCHRONIZED WRAPPER?><?tertiarykey CLIENT-SIDE LOCKING SUPPORT?><primary><emphasis role="strong">class(es)</emphasis></primary><secondary>synchronized wrapper</secondary><tertiary>client-side locking support</tertiary></indexterm><indexterm id="iddle1360" significance="normal"><?indexkey C?><?primarykey client-side locking?><primary><emphasis role="strong">client-side locking</emphasis></primary></indexterm><indexterm id="iddle1363" significance="normal"><?indexkey C?><?primarykey client-side locking?><?secondarykey CLASS EXTENSION RELATIONSHIP TO?><primary><emphasis role="strong">client-side locking</emphasis></primary><secondary>class extension relationship to</secondary></indexterm><indexterm id="iddle1407" significance="normal"><?indexkey C?><?primarykey composition?><primary><emphasis role="strong">composition</emphasis></primary><seealso> <link linkend="iddle4461" preference="0"><emphasis role="strong">strategies</emphasis>, delegation</link>.</seealso></indexterm><indexterm id="iddle1408" significance="normal"><?indexkey C?><?primarykey composition?><primary><emphasis role="strong">composition</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle1409" significance="normal"><?indexkey C?><?primarykey composition?><?secondarykey AS ROBUST FUNCTIONALITY EXTENSION MECHANISM?><primary><emphasis role="strong">composition</emphasis></primary><secondary>as robust functionality extension mechanism</secondary></indexterm><indexterm id="iddle1837" significance="normal"><?indexkey D?><?primarykey decomposition?><primary><emphasis role="strong">decomposition</emphasis></primary><seealso> <link linkend="iddle2400" preference="0"><emphasis role="strong">fragility</emphasis>, solutions, composition</link>.</seealso></indexterm><indexterm id="iddle1838" significance="normal"><?indexkey D?><?primarykey decomposition?><primary><emphasis role="strong">decomposition</emphasis></primary><seealso> <link linkend="iddle4461" preference="0"><emphasis role="strong">strategies</emphasis>, delegation</link>.</seealso></indexterm><indexterm id="iddle1839" significance="normal"><?indexkey D?><?primarykey decomposition?><primary><emphasis role="strong">decomposition</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle1855" significance="normal"><?indexkey D?><?primarykey delegation?><primary><emphasis role="strong">delegation</emphasis></primary><seealso> <link linkend="iddle2400" preference="0"><emphasis role="strong">fragility</emphasis>, solutions, composition</link>.</seealso></indexterm><indexterm id="iddle1856" significance="normal"><?indexkey D?><?primarykey delegation?><primary><emphasis role="strong">delegation</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle1857" significance="normal"><?indexkey D?><?primarykey delegation?><primary><emphasis role="strong">delegation</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle1984" significance="normal"><?indexkey E?><?primarykey Effective Java Programming Language Guide?><primary><emphasis role="strong"><emphasis>Effective Java Programming Language Guide</emphasis></emphasis></primary></indexterm><indexterm id="iddle2130" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey LISTHELPER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ListHelper</literal></secondary></indexterm><indexterm id="iddle2285" significance="normal"><?indexkey E?><?primarykey extending?><primary><emphasis role="strong">extending</emphasis></primary></indexterm><indexterm id="iddle2286" significance="normal"><?indexkey E?><?primarykey extending?><?secondarykey EXISTING THREAD-SAFE CLASSES?><primary><emphasis role="strong">extending</emphasis></primary><secondary>existing thread-safe classes</secondary></indexterm><indexterm id="iddle2287" significance="normal"><?indexkey E?><?primarykey extending?><?secondarykey EXISTING THREAD-SAFE CLASSES?><?tertiarykey AND CLIENT-SIDE LOCKING?><primary><emphasis role="strong">extending</emphasis></primary><secondary>existing thread-safe classes</secondary><tertiary>and client-side locking</tertiary></indexterm><indexterm id="iddle2290" significance="normal"><?indexkey E?><?primarykey external locking?><primary><emphasis role="strong">external locking</emphasis></primary></indexterm><indexterm id="iddle2393" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey ISSUES AND CAUSES?><?tertiarykey AS CLIENT-SIDE LOCKING?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>issues and causes</secondary><tertiary>as client-side locking</tertiary></indexterm><indexterm id="iddle2399" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey SOLUTIONS?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>solutions</secondary></indexterm><indexterm id="iddle2400" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey SOLUTIONS?><?tertiarykey COMPOSITION?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>solutions</secondary><tertiary>composition</tertiary></indexterm><indexterm id="iddle2645" significance="normal"><?indexkey H?><?primarykey hooks?><primary><emphasis role="strong">hooks</emphasis></primary><seealso> <link linkend="iddle2285" preference="0"><emphasis role="strong">extending</emphasis></link>.</seealso></indexterm><indexterm id="iddle3066" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CLIENT-SIDE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>client-side</secondary></indexterm><indexterm id="iddle3070" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CLIENT-SIDE?><?tertiarykey VS. CLASS EXTENSION?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>client-side</secondary><tertiary>vs. class extension</tertiary></indexterm><indexterm id="iddle4292" significance="normal"><?indexkey S?><?primarykey single shutdown hook?><primary><emphasis role="strong">single shutdown hook</emphasis></primary><seealso> <link linkend="iddle4254" preference="0"><emphasis role="strong">shutdown</emphasis>, hooks</link>.</seealso></indexterm><indexterm id="iddle4581" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey WRAPPER?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>wrapper</secondary></indexterm><indexterm id="iddle4582" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey WRAPPER?><?tertiarykey CLIENT-SIDE LOCKING SUPPORT?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>wrapper</secondary><tertiary>client-side locking support</tertiary></indexterm><indexterm id="iddle5171" significance="normal"><?indexkey W?><?primarykey wrapper(s)?><?secondarykey SYNCHRONIZED WRAPPER CLASSES?><?tertiarykey CLIENT-SIDE LOCKING SUPPORT?><primary><emphasis role="strong">wrapper(s)</emphasis></primary><secondary>synchronized wrapper classes</secondary><tertiary>client-side locking support</tertiary></indexterm>To make this approach work, we have to use the <emphasis>same</emphasis> lock that the <literal>List</literal> uses by using <emphasis>client-side locking</emphasis> or <emphasis>external locking</emphasis>. Client-side locking entails guarding client code that uses some object <emphasis>X</emphasis> with the lock <emphasis>X</emphasis> uses to guard its own state. In order to use client-side locking, you must know what lock <emphasis>X</emphasis> uses.</para>
<para>The documentation for <literal>Vector</literal> and the synchronized wrapper classes states, albeit obliquely, that they support client-side locking, by using the intrinsic lock for the <literal>Vector</literal> or the wrapper collection (not the wrapped collection). <link linkend="ch04list15" preference="0">Listing 4.15</link> shows a <literal>putIfAbsent</literal> operation on a thread-safe <literal>List</literal> that correctly uses client-side locking.</para>
<example id="ch04list15" label="4.15" role="Listing" xreflabel="4.15" condition="73">
<title id="ch04list15__title">Implementing Put-if-absent with Client-side Locking.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ListHelper&lt;E&gt; {
    public List&lt;E&gt; list =
        Collections.synchronizedList(new ArrayList&lt;E&gt;());
    ...
    public boolean putIfAbsent(E x) {
        <emphasis role="strong">synchronized (list)</emphasis>  {
            boolean absent = !list.contains(x);
            if (absent)
                list.add(x);
            return absent;
        }
    }
}
</programlisting>
</example>
<para>If extending a class to add another atomic operation is fragile because it distributes the locking code for a class over multiple classes in an object hierarchy, client-side locking is even more fragile because it entails putting locking code for class <emphasis>C</emphasis> into classes that are totally unrelated to <emphasis>C</emphasis>. Exercise care when using client-side locking on classes that do not commit to their locking strategy.</para>
<para>Client-side locking has a lot in common with class extension—they both couple the behavior of the derived class to the implementation of the base class. Just as extension violates encapsulation of implementation [EJ Item 14], client-side locking violates encapsulation of synchronization policy.</para>
</section>
<section id="ch04lev2sec12" label="4.4.2" xreflabel="4.4.2">
<title id="ch04lev2sec12__title">Composition</title>
<para>There is a less fragile alternative for adding an atomic operation to an existing class: <emphasis>composition</emphasis>. <literal>ImprovedList</literal> in <link linkend="ch04list16" preference="0">Listing 4.16</link> implements the <literal>List</literal> operations by delegating them to an underlying <literal>List</literal> instance, and adds an atomic <literal>putIfAbsent</literal> method. (Like <literal>Collections.synchronizedList</literal> and other collections wrappers, <literal>ImprovedList</literal> assumes that once a list is passed to its constructor, the client will not use the underlying list directly again, accessing it only through the <literal>ImprovedList</literal>.)</para>

<para><?docpage num="74"?></para><example id="ch04list16" label="4.16" role="Listing" xreflabel="4.16" condition="74">

<title id="ch04list16__title">Implementing Put-if-absent Using Composition.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ImprovedList&lt;T&gt; implements List&lt;T&gt; {
    private final List&lt;T&gt; list;

    public ImprovedList(List&lt;T&gt; list) { this.list = list; }

    public synchronized boolean putIfAbsent(T x) {
        boolean contains = list.contains(x);
        if (contains)
            list.add(x);
        return !contains;
    }

    public synchronized void clear() { list.clear(); }
    // <emphasis>... similarly delegate other List methods</emphasis>
}
</programlisting>
</example>
<para><indexterm id="iddle1966" significance="normal"><?indexkey D?><?primarykey documentation?><?secondarykey OF SYNCHRONIZATION POLICIES?><primary><emphasis role="strong">documentation</emphasis></primary><secondary>of synchronization policies</secondary></indexterm><indexterm id="iddle2008" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey COMPOSITION USE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>composition use</secondary></indexterm><indexterm id="iddle2122" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey IMPROVEDLIST?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ImprovedList</literal></secondary></indexterm><indexterm id="iddle2131" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey LISTHELPER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ListHelper</literal></secondary></indexterm><indexterm id="iddle2899" significance="normal"><?indexkey J?><?primarykey Java monitor pattern?><?secondarykey COMPOSITION USE?><primary><emphasis role="strong">Java monitor pattern</emphasis></primary><secondary>composition use</secondary></indexterm><indexterm id="iddle3490" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey COMPOSITION FUNCTIONALITY EXTENSION MECHANISM?><primary><emphasis role="strong">performance</emphasis></primary><secondary>composition functionality extension mechanism</secondary></indexterm><indexterm id="iddle3892" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey SYNCHRONIZATION POLICY DOCUMENTATION?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>synchronization policy documentation</secondary></indexterm><indexterm id="iddle4564" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey POLICY?><?tertiarykey DOCUMENTATION REQUIREMENTS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>policy</secondary><tertiary>documentation requirements</tertiary></indexterm><literal>ImprovedList</literal> adds an additional level of locking using its own intrinsic lock. It does not care whether the underlying <literal>List</literal> is thread-safe, because it provides its own consistent locking that provides thread safety even if the <literal>List</literal> is not thread-safe or changes its locking implementation. While the extra layer of synchronization may add some small performance penalty,<footnote id="ch04fn07" label="7"><para>The penalty will be small because the synchronization on the underlying <literal>List</literal> is guaranteed to be uncontended and therefore fast; see <link linkend="ch11" preference="0">Chapter 11</link>.</para></footnote> the implementation in <literal>ImprovedList</literal> is less fragile than attempting to mimic the locking strategy of another object. In effect, we’ve used the Java monitor pattern to encapsulate an existing <literal>List</literal>, and this is guaranteed to provide thread safety so long as our class holds the only outstanding reference to the underlying <literal>List</literal>.</para>
</section>
</section>
<section id="ch04lev1sec5" condition="74" label="4.5" xreflabel="4.5"><?docpage num="74"?>
<title id="ch04lev1sec5__title">Documenting Synchronization Policies</title>
<para>Documentation is one of the most powerful (and, sadly, most underutilized) tools for managing thread safety. Users look to the documentation to find out if a class is thread-safe, and maintainers look to the documentation to understand the implementation strategy so they can maintain it without inadvertently compromising safety. Unfortunately, both of these constituencies usually find less information in the documentation than they’d like.</para>
<sidebar float="1" id="ch04sb07" condition="74"><title/>
<para>Document a class’s thread safety guarantees for its clients; document its synchronization policy for its maintainers.</para>
</sidebar>
<para><?docpage num="75"?><indexterm id="iddle1097" significance="normal"><?indexkey A?><?primarykey annotations?><?secondarykey %?><?tertiarykey SYNCHRONIZATION POLICY DOCUMENTATION USE?><primary><emphasis role="strong">annotations</emphasis></primary><secondary><literal>@GuardedBy</literal></secondary><tertiary>synchronization policy documentation use</tertiary></indexterm><indexterm id="iddle2482" significance="normal"><?indexkey G?><?primarykey GuardedBy?><?secondarykey AND DOCUMENTING SYNCHRONIZATION POLICY?><primary sortas="GuardedBy"><emphasis role="strong">@GuardedBy</emphasis></primary><secondary>and documenting synchronization policy</secondary></indexterm>Each use of <literal>synchronized</literal>, <literal>volatile</literal>, or any thread-safe class reflects a <emphasis>synchronization policy</emphasis> defining a strategy for ensuring the integrity of data in the face of concurrent access. That policy is an element of your program’s design, and should be documented. Of course, the best time to document design decisions is at design time. Weeks or months later, the details may be a blur—so write it down before you forget.</para>
<para>Crafting a synchronization policy requires a number of decisions: which variables to make <literal>volatile</literal>, which variables to guard with locks, which lock(s) guard which variables, which variables to make immutable or confine to a thread, which operations must be atomic, etc. Some of these are strictly implementation details and should be documented for the sake of future maintainers, but some affect the publicly observable locking behavior of your class and should be documented as part of its specification.</para>
<para>At the very least, document the thread safety guarantees made by a class. Is it thread-safe? Does it make callbacks with a lock held? Are there any specific locks that affect its behavior? Don’t force clients to make risky guesses. If you don’t want to commit to supporting client-side locking, that’s fine, but say so. If you want clients to be able to create new atomic operations on your class, as we did in <link linkend="ch04lev1sec4" preference="0">Section 4.4</link>, you need to document which locks they should acquire to do so safely. If you use locks to guard state, document this for future maintainers, because it’s so easy—the <literal>@GuardedBy</literal> annotation will do the trick. If you use more subtle means to maintain thread safety, document them because they may not be obvious to maintainers.</para>
<para>The current state of affairs in thread safety documentation, even in the platform library classes, is not encouraging. How many times have you looked at the Javadoc for a class and wondered whether it was thread-safe?<footnote id="ch04fn08" label="8"><para>If you’ve never wondered this, we admire your optimism.</para></footnote> Most classes don’t offer any clue either way. Many official Java technology specifications, such as servlets and JDBC, woefully underdocument their thread safety promises and requirements.</para>
<para>While prudence suggests that we not assume behaviors that aren’t part of the specification, we have work to get done, and we are often faced with a choice of bad assumptions. Should we assume an object is thread-safe because it seems that it ought to be? Should we assume that access to an object can be made thread-safe by acquiring its lock first? (This risky technique works only if we control <emphasis>all</emphasis> the code that accesses that object; otherwise, it provides only the illusion of thread safety.) Neither choice is very satisfying.</para>
<para>To make matters worse, our intuition may often be wrong on which classes are “probably thread-safe” and which are not. As an example, <literal>java.text.SimpleDateFormat</literal> isn’t thread-safe, but the Javadoc neglected to mention this until JDK 1.4. That this particular class isn’t thread-safe comes as a surprise to many developers. How many programs mistakenly create a shared instance of a nonthread-safe object and used it from multiple threads, unaware that this might cause erroneous results under heavy load?</para>
<para>The problem with <literal>SimpleDateFormat</literal> could be avoided by not assuming a class is thread-safe if it doesn’t say so. On the other hand, it is impossible to <?docpage num="76"?>develop a servlet-based application without making some pretty questionable assumptions about the thread safety of container-provided objects like <literal>HttpSession</literal>. Don’t make your customers or colleagues have to make guesses like this.</para>
<section id="ch04lev2sec13" label="4.5.1" xreflabel="4.5.1">
<title id="ch04lev2sec13__title">Interpreting Vague Documentation</title>
<para>Many Java technology specifications are silent, or at least unforthcoming, about thread safety guarantees and requirements for interfaces such as <literal>ServletContext</literal>, <literal>HttpSession</literal>, or <literal>DataSource</literal>.<footnote id="ch04fn09" label="9"><para>We find it particularly frustrating that these omissions persist despite multiple major revisions of the specifications.</para></footnote> Since these interfaces are implemented by your container or database vendor, you often can’t look at the code to see what it does. Besides, you don’t want to rely on the implementation details of one particular JDBC driver—you want to be compliant with the standard so your code works properly with any JDBC driver. But the words “thread” and “concurrent” do not appear at all in the JDBC specification, and appear frustratingly rarely in the servlet specification. So what do you do?</para>
<para>You are going to have to guess. One way to improve the quality of your guess is to interpret the specification from the perspective of someone who will <emphasis>implement</emphasis> it (such as a container or database vendor), as opposed to someone who will merely use it. Servlets are always called from a container-managed thread, and it is safe to assume that if there is more than one such thread, the container knows this. The servlet container makes available certain objects that provide service to multiple servlets, such as <literal>HttpSession</literal> or <literal>ServletContext</literal>. So the servlet container should expect to have these objects accessed concurrently, since it has created multiple threads and called methods like <literal>Servlet.service</literal> from them that could reasonably be expected to access the <literal>ServletContext</literal>.</para>
<para>Since it is impossible to imagine a single-threaded context in which these objects would be useful, one has to assume that they have been made thread-safe, even though the specification does not explicitly require this. Besides, if they required client-side locking, on what lock should the client code synchronize? The documentation doesn’t say, and it seems absurd to guess. This “reasonable assumption” is further bolstered by the examples in the specification and official tutorials that show how to access <literal>ServletContext</literal> or <literal>HttpSession</literal> and do not use any client-side synchronization.</para>
<para>On the other hand, the objects placed in the <literal>ServletContext</literal> or <literal>HttpSession</literal> with <literal>setAttribute</literal> are owned by the web application, not the servlet container. The servlet specification does not suggest any mechanism for coordinating concurrent access to shared attributes. So attributes stored by the container on behalf of the web application should be thread-safe or effectively immutable. If all the container did was store these attributes on behalf of the web application, another option would be to ensure that they are consistently guarded by a lock when accessed from servlet application code. But because the container may want to serialize objects in the <literal>HttpSession</literal> for replication or passivation purposes, and the servlet container can’t possibly know your locking protocol, you should make them thread-safe.</para>
<para><?docpage num="77"?><?docpage num="78"?>One can make a similar inference about the JDBC <literal>DataSource</literal> interface, which represents a pool of reusable database connections. A <literal>DataSource</literal> provides service to an application, and it doesn’t make much sense in the context of a singlethreaded application. It is hard to imagine a use case that doesn’t involve calling <literal>getConnection</literal> from multiple threads. And, as with servlets, the examples in the JDBC specification do not suggest the need for any client-side locking in the many code examples using <literal>DataSource</literal>. So, even though the specification doesn’t promise that <literal>DataSource</literal> is thread-safe or require container vendors to provide a thread-safe implementation, by the same “it would be absurd if it weren’t” argument, we have no choice but to assume that <literal>DataSource.getConnection</literal> does not require additional client-side locking.</para>
<para>On the other hand, we would not make the same argument about the JDBC <literal>Connection</literal> objects dispensed by the <literal>DataSource</literal>, since these are not necessarily intended to be shared by other activities until they are returned to the pool. So if an activity that obtains a JDBC <literal>Connection</literal> spans multiple threads, it must take responsibility for ensuring that access to the <literal>Connection</literal> is properly guarded by synchronization. (In most applications, activities that use a JDBC <literal>Connection</literal> are implemented so as to confine the <literal>Connection</literal> to a specific thread anyway.)</para>
</section>
</section>

</chapter>

<chapter id="ch05" label="5" xreflabel="5" condition="79">
<?docpage num="79"?>
<title id="ch05__title">Building Blocks</title>


<para><indexterm id="iddle1333" significance="normal"><?indexkey C?><?primarykey check-then-act operation?><?secondarykey COMPOUND ACTION?><primary><emphasis role="strong">check-then-act operation</emphasis></primary><secondary>compound action</secondary></indexterm><indexterm id="iddle1334" significance="normal"><?indexkey C?><?primarykey check-then-act operation?><?secondarykey COMPOUND ACTION?><?tertiarykey IN COLLECTION OPERATIONS?><primary><emphasis role="strong">check-then-act operation</emphasis></primary><secondary>compound action</secondary><tertiary>in collection operations</tertiary></indexterm><indexterm id="iddle1361" significance="normal"><?indexkey C?><?primarykey client-side locking?><?secondarykey AND COMPOUND ACTIONS?><primary><emphasis role="strong">client-side locking</emphasis></primary><secondary>and compound actions</secondary></indexterm><indexterm id="iddle1377" significance="normal"><?indexkey C?><?primarykey collections?><?secondarykey CONCURRENT?><?tertiarykey BUILDING BLOCK?><primary><emphasis role="strong">collections</emphasis></primary><secondary>concurrent</secondary><tertiary>building block</tertiary></indexterm><indexterm id="iddle1381" significance="normal"><?indexkey C?><?primarykey collections?><?secondarykey SYNCHRONIZED?><primary><emphasis role="strong">collections</emphasis></primary><secondary>synchronized</secondary></indexterm><indexterm id="iddle1385" significance="normal"><?indexkey C?><?primarykey Collections.synchronizedXxx?><primary><emphasis role="strong">Collections.synchronizedXxx</emphasis></primary></indexterm><indexterm id="iddle1386" significance="normal"><?indexkey C?><?primarykey Collections.synchronizedXxx?><?secondarykey SYNCHRONIZED COLLECTION CREATION?><primary><emphasis role="strong">Collections.synchronizedXxx</emphasis></primary><secondary>synchronized collection creation</secondary></indexterm><indexterm id="iddle1425" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey IN SYNCHRONIZED COLLECTION CLASS USE?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>in synchronized collection class use</secondary></indexterm><indexterm id="iddle1426" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey IN SYNCHRONIZED COLLECTION CLASS USE?><?tertiarykey MECHANISMS FOR HANDLING?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>in synchronized collection class use</secondary><tertiary>mechanisms for handling</tertiary></indexterm><indexterm id="iddle1458" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey BUILDING BLOCKS?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>building blocks</secondary></indexterm><indexterm id="iddle1650" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey THREAD?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle1651" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey THREAD?><?tertiarykey CONCURRENCY MECHANISMS FOR?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>thread</secondary><tertiary>concurrency mechanisms for</tertiary></indexterm><indexterm id="iddle2295" significance="normal"><?indexkey F?><?primarykey factory(s)?><?secondarykey METHODS?><?tertiarykey SYNCHRONIZED COLLECTIONS?><primary><emphasis role="strong">factory(s)</emphasis></primary><secondary>methods</secondary><tertiary>synchronized collections</tertiary></indexterm><indexterm id="iddle2626" significance="normal"><?indexkey H?><?primarykey hashcodes/hashtables?><?secondarykey HASHTABLE?><primary><emphasis role="strong">hashcodes/hashtables</emphasis></primary><secondary><literal>Hashtable</literal></secondary></indexterm><indexterm id="iddle2873" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey AS COMPOUND ACTION?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>as compound action</secondary></indexterm><indexterm id="iddle2874" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey AS COMPOUND ACTION?><?tertiarykey IN COLLECTION OPERATIONS?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>as compound action</secondary><tertiary>in collection operations</tertiary></indexterm><indexterm id="iddle3067" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CLIENT-SIDE?><?tertiarykey AND COMPOUND ACTIONS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>client-side</secondary><tertiary>and compound actions</tertiary></indexterm><indexterm id="iddle3295" significance="normal"><?indexkey N?><?primarykey navigation?><primary><emphasis role="strong">navigation</emphasis></primary></indexterm><indexterm id="iddle3296" significance="normal"><?indexkey N?><?primarykey navigation?><?secondarykey AS COMPOUND ACTION?><primary><emphasis role="strong">navigation</emphasis></primary><secondary>as compound action</secondary></indexterm><indexterm id="iddle3297" significance="normal"><?indexkey N?><?primarykey navigation?><?secondarykey AS COMPOUND ACTION?><?tertiarykey IN COLLECTION OPERATIONS?><primary><emphasis role="strong">navigation</emphasis></primary><secondary>as compound action</secondary><tertiary>in collection operations</tertiary></indexterm><indexterm id="iddle4542" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey COLLECTIONS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>collections</secondary></indexterm><indexterm id="iddle4544" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey COLLECTIONS?><?tertiarykey PROBLEMS WITH?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>collections</secondary><tertiary>problems with</tertiary></indexterm><indexterm id="iddle4545" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey CONCURRENT BUILDING BLOCKS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>concurrent building blocks</secondary></indexterm><indexterm id="iddle5073" significance="normal"><?indexkey V?><?primarykey Vector?><?secondarykey AS SYNCHRONIZED COLLECTION?><primary><emphasis role="strong">Vector</emphasis></primary><secondary>as synchronized collection</secondary></indexterm><indexterm id="iddle5075" significance="normal"><?indexkey V?><?primarykey Vector?><?secondarykey CHECK-THEN-ACT OPERATIONS?><primary><emphasis role="strong">Vector</emphasis></primary><secondary>check-then-act operations</secondary></indexterm><indexterm id="iddle5169" significance="normal"><?indexkey W?><?primarykey wrapper(s)?><?secondarykey SYNCHRONIZED WRAPPER CLASSES?><primary><emphasis role="strong">wrapper(s)</emphasis></primary><secondary>synchronized wrapper classes</secondary></indexterm><indexterm id="iddle5170" significance="normal"><?indexkey W?><?primarykey wrapper(s)?><?secondarykey SYNCHRONIZED WRAPPER CLASSES?><?tertiarykey AS SYNCHRONIZED COLLECTION CLASSES?><primary><emphasis role="strong">wrapper(s)</emphasis></primary><secondary>synchronized wrapper classes</secondary><tertiary>as synchronized collection classes</tertiary></indexterm>The last chapter explored several techniques for constructing thread-safe classes, including delegating thread safety to existing thread-safe classes. Where practical, delegation is one of the most effective strategies for creating thread-safe classes: just let existing thread-safe classes manage all the state.</para>
<para>The platform libraries include a rich set of concurrent building blocks, such as thread-safe collections and a variety of <emphasis>synchronizers</emphasis> that can coordinate the control flow of cooperating threads. This chapter covers the most useful concurrent building blocks, especially those introduced in Java 5.0 and Java 6, and some patterns for using them to structure concurrent applications.</para>



<section id="ch05lev1sec1" condition="79" label="5.1" xreflabel="5.1"><?docpage num="79"?>
<title id="ch05lev1sec1__title">Synchronized Collections</title>
<para>The <emphasis>synchronized collection classes</emphasis> include <literal>Vector</literal> and <literal>Hashtable</literal>, part of the original JDK, as well as their cousins added in JDK 1.2, the synchronized wrapper classes created by the <literal>Collections.synchronizedXxx</literal> factory methods. These classes achieve thread safety by encapsulating their state and synchronizing every public method so that only one thread at a time can access the collection state.</para>
<section id="ch05lev2sec1" label="5.1.1" xreflabel="5.1.1">
<title id="ch05lev2sec1__title">Problems with Synchronized Collections</title>
<para>The synchronized collections are thread-safe, but you may sometimes need to use additional client-side locking to guard compound actions. Common compound actions on collections include iteration (repeatedly fetch elements until the collection is exhausted), navigation (find the next element after this one according to some order), and conditional operations such as put-if-absent (check if a <literal>Map</literal> has a mapping for key <emphasis>K</emphasis>, and if not, add the mapping (<emphasis>K</emphasis>,<emphasis>V</emphasis>)). With a synchronized collection, these compound actions are still technically thread-safe even without client-side locking, but they may not behave as you might expect when other threads can concurrently modify the collection.</para>
<para><link linkend="ch05list01" preference="0">Listing 5.1</link> shows two methods that operate on a <literal>Vector</literal>, <literal>getLast</literal> and <literal>delete-Last</literal>, both of which are check-then-act sequences. Each calls <literal>size</literal> to determine <?docpage num="80"?><indexterm id="iddle1156" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey CLIENT-SIDE LOCKING SUPPORT FOR?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>client-side locking support for</secondary></indexterm><indexterm id="iddle1721" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey ATOMIC COMPOUND ACTIONS?><primary><emphasis role="strong">creation</emphasis></primary><secondary>atomic compound actions</secondary></indexterm><indexterm id="iddle2875" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey ATOMICITY REQUIREMENTS DURING?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>atomicity requirements during</secondary></indexterm><indexterm id="iddle5074" significance="normal"><?indexkey V?><?primarykey Vector?><?secondarykey CHECK-THEN-ACT OPERATIONS?><primary><emphasis role="strong">Vector</emphasis></primary><secondary>check-then-act operations</secondary></indexterm><indexterm id="iddle5076" significance="normal"><?indexkey V?><?primarykey Vector?><?secondarykey CHECK-THEN-ACT OPERATIONS?><primary><emphasis role="strong">Vector</emphasis></primary><secondary>check-then-act operations</secondary></indexterm>the size of the array and uses the resulting value to retrieve or remove the last element.</para>
<example id="ch05list01" label="5.1" role="Listing" xreflabel="5.1" condition="80">
<title id="ch05list01__title">Compound Actions on a <literal>Vector</literal> that may Produce Confusing Results.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public static Object getLast(Vector list) {
    int lastIndex = list.size() - 1;
    return list.get(lastIndex);
}

public static void deleteLast(Vector list) {
    int lastIndex = list.size() - 1;
    list.remove(lastIndex);
}
</programlisting>
</example>
<para>These methods seem harmless, and in a sense they are—they can’t corrupt the <literal>Vector</literal>, no matter how many threads call them simultaneously. But the caller of these methods might have a different opinion. If thread <emphasis>A</emphasis> calls <literal>getLast</literal> on a <literal>Vector</literal> with ten elements, thread <emphasis>B</emphasis> calls <literal>deleteLast</literal> on the same <literal>Vector</literal>, and the operations are interleaved as shown in <link linkend="ch05fig01" preference="1">Figure 5.1</link>, <literal>getLast</literal> throws <literal>ArrayIndexOutOfBoundsException</literal>. Between the call to <literal>size</literal> and the subsequent call to <literal>get</literal> in <literal>getLast</literal>, the <literal>Vector</literal> shrank and the index computed in the first step is no longer valid. This is perfectly consistent with the specification of <literal>Vector</literal>—it throws an exception if asked for a nonexistent element. But this is not what a caller expects <literal>getLast</literal> to do, even in the face of concurrent modification, unless perhaps the <literal>Vector</literal> was empty to begin with.</para>
<figure float="1" id="ch05fig01" label="5.1" xreflabel="5.1" condition="81">
<?docpage num="81"?>
<title id="ch05fig01__title">Interleaving of <literal>Getlast</literal> and <literal>Deletelast</literal> that throws <literal>ArrayIndexOut-OfBoundsException</literal>.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="128" fileref="graphics/05fig01.gif" format="GIF" width="500"/></imageobject>

</mediaobject>
</figure>
<para>Because the synchronized collections commit to a synchronization policy that supports client-side locking, <footnote id="ch05fn01" label="1"><para>This is documented only obliquely in the Java 5.0 Javadoc, as an example of the correct iteration idiom.</para></footnote> it is possible to create new operations that are atomic with respect to other collection operations as long as we know which lock to use. The synchronized collection classes guard each method with the lock on the synchronized collection object itself. By acquiring the collection lock we can make <literal>getLast</literal> and <literal>deleteLast</literal> atomic, ensuring that the size of the <literal>Vector</literal> does not change between calling <literal>size</literal> and <literal>get</literal>, as shown in <link linkend="ch05list02" preference="0">Listing 5.2</link>.</para>
<para>The risk that the size of the list might change between a call to <literal>size</literal> and the corresponding call to <literal>get</literal> is also present when we iterate through the elements of a <literal>Vector</literal> as shown in <link linkend="ch05list03" preference="0">Listing 5.3</link>.</para>
<para>This iteration idiom relies on a leap of faith that other threads will not modify the <literal>Vector</literal> between the calls to <literal>size</literal> and <literal>get</literal>. In a single-threaded environment, this assumption is perfectly valid, but when other threads may concurrently modify the <literal>Vector</literal> it can lead to trouble. Just as with <literal>getLast</literal>, if another thread deletes an element while you are iterating through the <literal>Vector</literal> and the operations are interleaved unluckily, this iteration idiom throws <literal>ArrayIndexOutOfBoundsException</literal>.</para>

<para><?docpage num="81"?></para><example id="ch05list02" label="5.2" role="Listing" xreflabel="5.2" condition="81">

<title id="ch05list02__title">Compound Actions on <literal>Vector</literal> Using Client-side Locking.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public static Object getLast(Vector list) {
    <emphasis role="strong">synchronized (list)</emphasis> {
        int lastIndex = list.size() - 1;
        return list.get(lastIndex);
    }
}

public static void deleteLast(Vector list) {
    <emphasis role="strong">synchronized (list)</emphasis> {
        int lastIndex = list.size() - 1;
        list.remove(lastIndex);
    }
}
</programlisting>
</example>
<example id="ch05list03" label="5.3" role="Listing" xreflabel="5.3" condition="81">
<title id="ch05list03__title">Iteration that may Throw <literal>ArrayIndexOutOfBoundsException</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">for (int i = 0; i &lt; vector.size(); i++)
    doSomething(vector.get(i));
</programlisting>
</example>
<para><indexterm id="iddle2774" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey OPERATION?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>operation</secondary></indexterm><indexterm id="iddle2885" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey UNRELIABLE?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>unreliable</secondary></indexterm><indexterm id="iddle2886" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey UNRELIABLE?><?tertiarykey AND CLIENT-SIDE LOCKING?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>unreliable</secondary><tertiary>and client-side locking</tertiary></indexterm><indexterm id="iddle4060" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey CLIENT-SIDE LOCKING IMPACT ON?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>client-side locking impact on</secondary></indexterm><indexterm id="iddle5077" significance="normal"><?indexkey V?><?primarykey Vector?><?secondarykey CLIENT-SIDE LOCKING MANAGEMENT OF COMPOUND ACTIONS?><primary><emphasis role="strong">Vector</emphasis></primary><secondary>client-side locking management of compound actions</secondary></indexterm>Even though the iteration in <link linkend="ch05list03" preference="0">Listing 5.3</link> can throw an exception, this doesn’t mean <literal>Vector</literal> isn’t thread-safe. The state of the <literal>Vector</literal> is still valid and the exception is in fact in conformance with its specification. However, that something as mundane as fetching the last element or iteration throw an exception is clearly undesirable.</para>
<para>The problem of unreliable iteration can again be addressed by client-side locking, at some additional cost to scalability. By holding the <literal>Vector</literal> lock for the duration of iteration, as shown in <link linkend="ch05list04" preference="0">Listing 5.4</link>, we prevent other threads from modifying the <literal>Vector</literal> while we are iterating it. Unfortunately, we also prevent other threads from accessing it at all during this time, impairing concurrency.</para>

<para><?docpage num="82"?></para><example id="ch05list04" label="5.4" role="Listing" xreflabel="5.4" condition="82">

<title id="ch05list04__title">Iteration with Client-side Locking.</title>
<programlisting format="linespecific" linenumbering="unnumbered">synchronized (vector) {
    for (int i = 0; i &lt; vector.size(); i++)
        doSomething(vector.get(i));
}
</programlisting>
</example>
</section>
<section id="ch05lev2sec2" label="5.1.2" xreflabel="5.1.2">
<title id="ch05lev2sec2__title">Iterators and Concurrentmodificationexception</title>
<para><indexterm id="iddle1471" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey MODIFYING?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>modifying</secondary></indexterm><indexterm id="iddle1472" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey MODIFYING?><?tertiarykey SYNCHRONIZED COLLECTION PROBLEMS WITH?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>modifying</secondary><tertiary>synchronized collection problems with</tertiary></indexterm><indexterm id="iddle1492" significance="normal"><?indexkey C?><?primarykey ConcurrentModificationException?><?secondarykey FAIL-FAST ITERATORS USE?><primary><emphasis role="strong">ConcurrentModificationException</emphasis></primary><secondary>fail-fast iterators use</secondary></indexterm><indexterm id="iddle2233" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey THREAD-SAFE CLASS HANDLING?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>thread-safe class handling</secondary></indexterm><indexterm id="iddle2300" significance="normal"><?indexkey F?><?primarykey fail-fast iterators?><primary><emphasis role="strong">fail-fast iterators</emphasis></primary><seealso> <link linkend="iddle2870" preference="0"><emphasis role="strong">iterators/iteration</emphasis></link>.</seealso></indexterm><indexterm id="iddle2876" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey FAIL-FAST?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>fail-fast</secondary></indexterm><indexterm id="iddle2877" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey FAIL-FAST?><?tertiarykey CONCURRENTMODIFICATIONEXCEPTION EXCEPTION WITH?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>fail-fast</secondary><tertiary><literal>ConcurrentModificationException</literal> exception with</tertiary></indexterm><indexterm id="iddle3076" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONCURRENTMODIFICATIONEXCEPTION AVOIDANCE WITH?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary><literal>ConcurrentModificationException</literal> avoidance with</secondary></indexterm><indexterm id="iddle3239" significance="normal"><?indexkey M?><?primarykey modification?><primary><emphasis role="strong">modification</emphasis></primary></indexterm><indexterm id="iddle3240" significance="normal"><?indexkey M?><?primarykey modification?><?secondarykey CONCURRENT?><primary><emphasis role="strong">modification</emphasis></primary><secondary>concurrent</secondary></indexterm><indexterm id="iddle3241" significance="normal"><?indexkey M?><?primarykey modification?><?secondarykey CONCURRENT?><?tertiarykey SYNCHRONIZED COLLECTION PROBLEMS WITH?><primary><emphasis role="strong">modification</emphasis></primary><secondary>concurrent</secondary><tertiary>synchronized collection problems with</tertiary></indexterm>We use <literal>Vector</literal> for the sake of clarity in many of our examples, even though it is considered a “legacy” collection class. But the more “modern” collection classes do not eliminate the problem of compound actions. The standard way to iterate a <literal>Collection</literal> is with an <literal>Iterator</literal>, either explicitly or through the for-each loop syntax introduced in Java 5.0, but using iterators does not obviate the need to lock the collection during iteration if other threads can concurrently modify it. The iterators returned by the synchronized collections are not designed to deal with concurrent modification, and they are <emphasis>fail-fast</emphasis>—meaning that if they detect that the collection has changed since iteration began, they throw the unchecked <literal>ConcurrentModificationException</literal>.</para>
<para>These fail-fast iterators are not designed to be foolproof—they are designed to catch concurrency errors on a “good-faith-effort” basis and thus act only as early-warning indicators for concurrency problems. They are implemented by associating a modification count with the collection: if the modification count changes during iteration, <literal>hasNext</literal> or <literal>next</literal> throws <literal>ConcurrentModificationException</literal>. However, this check is done without synchronization, so there is a risk of seeing a stale value of the modification count and therefore that the iterator does not realize a modification has been made. This was a deliberate design tradeoff to reduce the performance impact of the concurrent modification detection code.<footnote id="ch05fn02" label="2"><para><literal>ConcurrentModificationException</literal> can arise in single-threaded code as well; this happens when objects are removed from the collection directly rather than through <literal>Iterator.remove</literal>.</para></footnote></para>
<para><link linkend="ch05list05" preference="0">Listing 5.5</link> illustrates iterating a collection with the for-each loop syntax. Internally, <literal>javac</literal> generates code that uses an <literal>Iterator</literal>, repeatedly calling <literal>hasNext</literal> and <literal>next</literal> to iterate the <literal>List</literal>. Just as with iterating the <literal>Vector</literal>, the way to prevent <literal>ConcurrentModificationException</literal> is to hold the collection lock for the duration of the iteration.</para>
<example id="ch05list05" label="5.5" role="Listing" xreflabel="5.5" condition="82">
<title id="ch05list05__title">Iterating a <literal>List</literal> with an <literal>Iterator</literal>.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">List&lt;Widget&gt; widgetList
    = Collections.synchronizedList(new ArrayList&lt;Widget&gt;());
...
<emphasis>// May throw ConcurrentModificationException</emphasis>
for (Widget w : widgetList)
    doSomething(w);
</programlisting>
</example>
<para><?docpage num="83"?><indexterm id="iddle1378" significance="normal"><?indexkey C?><?primarykey collections?><?secondarykey COPYING?><primary><emphasis role="strong">collections</emphasis></primary><secondary>copying</secondary></indexterm><indexterm id="iddle1379" significance="normal"><?indexkey C?><?primarykey collections?><?secondarykey COPYING?><?tertiarykey AS ALTERNATIVE TO LOCKING?><primary><emphasis role="strong">collections</emphasis></primary><secondary>copying</secondary><tertiary>as alternative to locking</tertiary></indexterm><indexterm id="iddle1659" significance="normal"><?indexkey C?><?primarykey copying?><primary><emphasis role="strong">copying</emphasis></primary></indexterm><indexterm id="iddle1660" significance="normal"><?indexkey C?><?primarykey copying?><?secondarykey COLLECTIONS?><primary><emphasis role="strong">copying</emphasis></primary><secondary>collections</secondary></indexterm><indexterm id="iddle1661" significance="normal"><?indexkey C?><?primarykey copying?><?secondarykey COLLECTIONS?><?tertiarykey AS ALTERNATIVE TO LOCKING?><primary><emphasis role="strong">copying</emphasis></primary><secondary>collections</secondary><tertiary>as alternative to locking</tertiary></indexterm><indexterm id="iddle1717" significance="normal"><?indexkey C?><?primarykey creation?><primary><emphasis role="strong">creation</emphasis></primary><seealso> <link linkend="iddle1378" preference="0"><emphasis role="strong">collections</emphasis>, copying</link>.</seealso></indexterm><indexterm id="iddle1718" significance="normal"><?indexkey C?><?primarykey creation?><primary><emphasis role="strong">creation</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle1719" significance="normal"><?indexkey C?><?primarykey creation?><primary><emphasis role="strong">creation</emphasis></primary><seealso> <link linkend="iddle3567" preference="0"><emphasis role="strong">policy(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1720" significance="normal"><?indexkey C?><?primarykey creation?><primary><emphasis role="strong">creation</emphasis></primary><seealso> <link linkend="iddle4645" preference="0"><emphasis role="strong">task(s)</emphasis>, representation</link>.</seealso></indexterm><indexterm id="iddle1809" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey LOCKING DURING ITERATION RISK OF?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>locking during iteration risk of</secondary></indexterm><indexterm id="iddle1935" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey TRADEOFFS?><primary><emphasis role="strong">design</emphasis></primary><secondary>tradeoffs</secondary></indexterm><indexterm id="iddle1936" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey TRADEOFFS?><?tertiarykey COLLECTION COPYING VS. LOCKING DURING ITERATION?><primary><emphasis role="strong">design</emphasis></primary><secondary>tradeoffs</secondary><tertiary>collection copying vs. locking during iteration</tertiary></indexterm><indexterm id="iddle2019" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey OF SYNCHRONIZATION?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>of synchronization</secondary></indexterm><indexterm id="iddle2020" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey OF SYNCHRONIZATION?><?tertiarykey HIDDEN ITERATOR MANAGEMENT THROUGH?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>of synchronization</secondary><tertiary>hidden iterator management through</tertiary></indexterm><indexterm id="iddle2024" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey STATE?><?tertiarykey INVARIANT PROTECTION USE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>state</secondary><tertiary>invariant protection use</tertiary></indexterm><indexterm id="iddle2291" significance="normal"><?indexkey F?><?primarykey factory(s)?><primary><emphasis role="strong">factory(s)</emphasis></primary><seealso> <link linkend="iddle4763" preference="0"><emphasis role="strong">thread(s)</emphasis>, creation</link>.</seealso></indexterm><indexterm id="iddle2521" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey ENCAPSULATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>encapsulation</secondary></indexterm><indexterm id="iddle2848" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey ENCAPSULATION?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>encapsulation</secondary></indexterm><indexterm id="iddle2849" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey ENCAPSULATION?><?tertiarykey STATE, PROTECTION OF?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>encapsulation</secondary><tertiary>state, protection of</tertiary></indexterm><indexterm id="iddle2878" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey HIDDEN?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>hidden</secondary></indexterm><indexterm id="iddle2881" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey LOCKING?><?tertiarykey DISADVANTAGES OF?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>locking</secondary><tertiary>disadvantages of</tertiary></indexterm><indexterm id="iddle3118" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ITERATION?><?tertiarykey DISADVANTAGES OF?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>iteration</secondary><tertiary>disadvantages of</tertiary></indexterm><indexterm id="iddle3499" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey LOCKING?><primary><emphasis role="strong">performance</emphasis></primary><secondary>locking</secondary></indexterm><indexterm id="iddle3500" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey LOCKING?><?tertiarykey DURING ITERATION IMPACT ON?><primary><emphasis role="strong">performance</emphasis></primary><secondary>locking</secondary><tertiary>during iteration impact on</tertiary></indexterm><indexterm id="iddle4072" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey LOCKING DURING ITERATION RISK OF?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>locking during iteration risk of</secondary></indexterm><indexterm id="iddle4373" significance="normal"><?indexkey S?><?primarykey starvation?><?secondarykey LOCKING DURING ITERATION RISK OF?><primary><emphasis role="strong">starvation</emphasis></primary><secondary>locking during iteration risk of</secondary></indexterm><indexterm id="iddle4397" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey ENCAPSULATION?><?tertiarykey INVARIANT PROTECTION USE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>encapsulation</secondary><tertiary>invariant protection use</tertiary></indexterm><indexterm id="iddle4549" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey ENCAPSULATION?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>encapsulation</secondary></indexterm><indexterm id="iddle4550" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey ENCAPSULATION?><?tertiarykey HIDDEN ITERATOR MANAGEMENT THROUGH?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>encapsulation</secondary><tertiary>hidden iterator management through</tertiary></indexterm>There are several reasons, however, why locking a collection during iteration may be undesirable. Other threads that need to access the collection will block until the iteration is complete; if the collection is large or the task performed for each element is lengthy, they could wait a long time. Also, if the collection is locked as in <link linkend="ch05list04" preference="0">Listing 5.4</link>, <literal>doSomething</literal> is being called with a lock held, which is a risk factor for deadlock (see <link linkend="ch10" preference="0">Chapter 10</link>). Even in the absence of starvation or deadlock risk, locking collections for significant periods of time hurts application scalability. The longer a lock is held, the more likely it is to be contended, and if many threads are blocked waiting for a lock throughput and CPU utilization can suffer (see <link linkend="ch11" preference="0">Chapter 11</link>).</para>
<para>An alternative to locking the collection during iteration is to clone the collection and iterate the copy instead. Since the clone is thread-confined, no other thread can modify it during iteration, eliminating the possibility of <literal>ConcurrentModificationException</literal>. (The collection still must be locked during the clone operation itself.) Cloning the collection has an obvious performance cost; whether this is a favorable tradeoff depends on many factors including the size of the collection, how much work is done for each element, the relative frequency of iteration compared to other collection operations, and responsiveness and throughput requirements.</para>
</section>
<section id="ch05lev2sec3" label="5.1.3" xreflabel="5.1.3">
<title id="ch05lev2sec3__title">Hidden Iterators</title>
<para>While locking can prevent iterators from throwing <literal>ConcurrentModificationException</literal>, you have to remember to use locking everywhere a shared collection might be iterated. This is trickier than it sounds, as iterators are sometimes hidden, as in <literal>HiddenIterator</literal> in <link linkend="ch05list06" preference="0">Listing 5.6</link>. There is no explicit iteration in <literal>HiddenIterator</literal>, but the code in bold entails iteration just the same. The string concatenation gets turned by the compiler into a call to <literal>StringBuilder</literal>.<literal>append(Object)</literal>, which in turn invokes the collection’s <literal>toString</literal> method—and the implementation of <literal>toString</literal> in the standard collections iterates the collection and calls <literal>toString</literal> on each element to produce a nicely formatted representation of the collection’s contents.</para>
<para>The <literal>addTenThings</literal> method could throw <literal>ConcurrentModificationException</literal>, because the collection is being iterated by <literal>toString</literal> in the process of preparing the debugging message. Of course, the real problem is that <literal>HiddenIterator</literal> is not thread-safe; the <literal>HiddenIterator</literal> lock should be acquired before using <literal>set</literal> in the <literal>println</literal> call, but debugging and logging code commonly neglect to do this.</para>
<para>The real lesson here is that the greater the distance between the state and the synchronization that guards it, the more likely that someone will forget to use proper synchronization when accessing that state. If <literal>HiddenIterator</literal> wrapped the <literal>HashSet</literal> with a <literal>synchronizedSet</literal>, encapsulating the synchronization, this sort of error would not occur.</para>
<sidebar float="1" id="ch05sb01" condition="83"><title/>
<para>Just as encapsulating an object’s state makes it easier to preserve its invariants, encapsulating its synchronization makes it easier to enforce its synchronization policy.</para>
</sidebar>

<para><?docpage num="84"?></para><example id="ch05list06" label="5.6" role="Listing" xreflabel="5.6" condition="84">

<title id="ch05list06__title">Iteration Hidden within String Concatenation. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class HiddenIterator {
    @GuardedBy("this")
    private final Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;();

    public synchronized void add(Integer i) { set.add(i); }
    public synchronized void remove(Integer i) { set.remove(i); }

    public void addTenThings() {
        Random r = new Random();
        for (int i = 0; i &lt; 10; i++)
            add(r.nextInt());
        <emphasis role="strong">System.out.println("DEBUG: added ten elements to " + set);</emphasis>
   }
}
</programlisting>
</example>
<para><indexterm id="iddle1236" significance="normal"><?indexkey B?><?primarykey BlockingQueue?><primary><emphasis role="strong">BlockingQueue</emphasis></primary></indexterm><indexterm id="iddle1376" significance="normal"><?indexkey C?><?primarykey collections?><?secondarykey CONCURRENT?><primary><emphasis role="strong">collections</emphasis></primary><secondary>concurrent</secondary></indexterm><indexterm id="iddle1382" significance="normal"><?indexkey C?><?primarykey collections?><?secondarykey SYNCHRONIZED?><?tertiarykey CONCURRENT COLLECTIONS VS?><primary><emphasis role="strong">collections</emphasis></primary><secondary>synchronized</secondary><tertiary>concurrent collections vs</tertiary></indexterm><indexterm id="iddle1416" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey CONCURRENT COLLECTION SUPPORT FOR?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>concurrent collection support for</secondary></indexterm><indexterm id="iddle1454" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey AND SYNCHRONIZED COLLECTIONS?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>and synchronized collections</secondary></indexterm><indexterm id="iddle1460" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey COLLECTIONS?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>collections</secondary></indexterm><indexterm id="iddle1480" significance="normal"><?indexkey C?><?primarykey ConcurrentHashMap?><primary><emphasis role="strong">ConcurrentHashMap</emphasis></primary></indexterm><indexterm id="iddle1483" significance="normal"><?indexkey C?><?primarykey ConcurrentLinkedQueue?><primary><emphasis role="strong">ConcurrentLinkedQueue</emphasis></primary></indexterm><indexterm id="iddle1487" significance="normal"><?indexkey C?><?primarykey ConcurrentMap?><primary><emphasis role="strong">ConcurrentMap</emphasis></primary></indexterm><indexterm id="iddle1664" significance="normal"><?indexkey C?><?primarykey CopyOnWriteArrayList?><primary><emphasis role="strong">CopyOnWriteArrayList</emphasis></primary></indexterm><indexterm id="iddle2121" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey HIDDENITERATOR?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>HiddenIterator</literal></secondary></indexterm><indexterm id="iddle2574" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SCALABILITY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>scalability</secondary></indexterm><indexterm id="iddle2624" significance="normal"><?indexkey H?><?primarykey hashcodes/hashtables?><?secondarykey CONCURRENTHASHMAP?><primary><emphasis role="strong">hashcodes/hashtables</emphasis></primary><secondary><literal>ConcurrentHashMap</literal></secondary></indexterm><indexterm id="iddle2993" significance="normal"><?indexkey L?><?primarykey List?><primary><emphasis role="strong">List</emphasis></primary></indexterm><indexterm id="iddle2994" significance="normal"><?indexkey L?><?primarykey List?><?secondarykey COPYONWRITEARRAYLIST AS CONCURRENT COLLECTION FOR?><primary><emphasis role="strong">List</emphasis></primary><secondary><literal>CopyOnWriteArrayList</literal> as concurrent collection for</secondary></indexterm><indexterm id="iddle3006" significance="normal"><?indexkey L?><?primarykey lists?><?secondarykey LIST?><primary><emphasis role="strong">lists</emphasis></primary><secondary><literal>List</literal></secondary></indexterm><indexterm id="iddle3007" significance="normal"><?indexkey L?><?primarykey lists?><?secondarykey LIST?><?tertiarykey COPYONWRITEARRAYLIST AS CONCURRENT REPLACEMENT?><primary><emphasis role="strong">lists</emphasis></primary><secondary><literal>List</literal></secondary><tertiary><literal>CopyOnWriteArrayList</literal> as concurrent replacement</tertiary></indexterm><indexterm id="iddle3178" significance="normal"><?indexkey M?><?primarykey Map?><primary><emphasis role="strong">Map</emphasis></primary></indexterm><indexterm id="iddle3179" significance="normal"><?indexkey M?><?primarykey Map?><?secondarykey CONCURRENTHASHMAP AS CONCURRENT REPLACEMENT?><primary><emphasis role="strong">Map</emphasis></primary><secondary><literal>ConcurrentHashMap</literal> as concurrent replacement</secondary></indexterm><indexterm id="iddle3739" significance="normal"><?indexkey P?><?primarykey put-if-absent operation?><?secondarykey CONCURRENT COLLECTION SUPPORT FOR?><primary><emphasis role="strong">put-if-absent operation</emphasis></primary><secondary>concurrent collection support for</secondary></indexterm><indexterm id="iddle3748" significance="normal"><?indexkey Q?><?primarykey Queue?><primary><emphasis role="strong">Queue</emphasis></primary></indexterm><indexterm id="iddle4061" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey CONCURRENT COLLECTIONS VS. SYNCHRONIZED COLLECTIONS?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>concurrent collections vs. synchronized collections</secondary></indexterm><indexterm id="iddle4543" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey COLLECTIONS?><?tertiarykey CONCURRENT COLLECTIONS VS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>collections</secondary><tertiary>concurrent collections vs</tertiary></indexterm>Iteration is also indirectly invoked by the collection’s <literal>hashCode</literal> and <literal>equals</literal> methods, which may be called if the collection is used as an element or key of another collection. Similarly, the <literal>containsAll</literal>, <literal>removeAll</literal>, and <literal>retainAll</literal> methods, as well as the constructors that take collections as arguments, also iterate the collection. All of these indirect uses of iteration can cause <literal>ConcurrentModificationException</literal>.</para>
</section>
</section>
<section id="ch05lev1sec2" condition="84" label="5.2" xreflabel="5.2"><?docpage num="84"?>
<title id="ch05lev1sec2__title">Concurrent Collections</title>
<para>Java 5.0 improves on the synchronized collections by providing several <emphasis>concurrent</emphasis> collection classes. Synchronized collections achieve their thread safety by serializing all access to the collection’s state. The cost of this approach is poor concurrency; when multiple threads contend for the collection-wide lock, throughput suffers.</para>
<para>The concurrent collections, on the other hand, are designed for concurrent access from multiple threads. Java 5.0 adds <literal>ConcurrentHashMap</literal>, a replacement for synchronized hash-based <literal>Map</literal> implementations, and <literal>CopyOnWriteArrayList</literal>, a replacement for synchronized <literal>List</literal> implementations for cases where traversal is the dominant operation. The new <literal>ConcurrentMap</literal> interface adds support for common compound actions such as put-if-absent, replace, and conditional remove.</para>
<sidebar float="1" id="ch05sb02" condition="84"><title/>
<para>Replacing synchronized collections with concurrent collections can offer dramatic scalability improvements with little risk.</para>
</sidebar>
<para>Java 5.0 also adds two new collection types, <literal>Queue</literal> and <literal>BlockingQueue</literal>. A <literal>Queue</literal> is intended to hold a set of elements temporarily while they await processing. Several implementations are provided, including <literal>ConcurrentLinkedQueue</literal>, a <?docpage num="85"?><indexterm id="iddle1461" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey CONCURRENTHASHMAP LOCKING STRATEGY ADVANTAGES?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary><literal>ConcurrentHashMap</literal> locking strategy advantages</secondary></indexterm><indexterm id="iddle1490" significance="normal"><?indexkey C?><?primarykey ConcurrentModificationException?><primary><emphasis role="strong">ConcurrentModificationException</emphasis></primary></indexterm><indexterm id="iddle1491" significance="normal"><?indexkey C?><?primarykey ConcurrentModificationException?><?secondarykey AVOIDING?><primary><emphasis role="strong">ConcurrentModificationException</emphasis></primary><secondary>avoiding</secondary></indexterm><indexterm id="iddle1493" significance="normal"><?indexkey C?><?primarykey ConcurrentSkipListMap?><primary><emphasis role="strong">ConcurrentSkipListMap</emphasis></primary></indexterm><indexterm id="iddle1494" significance="normal"><?indexkey C?><?primarykey ConcurrentSkipListSet?><primary><emphasis role="strong">ConcurrentSkipListSet</emphasis></primary></indexterm><indexterm id="iddle1558" significance="normal"><?indexkey C?><?primarykey consistent/consistency?><?secondarykey WEAKLY CONSISTENT ITERATORS?><primary><emphasis role="strong">consistent/consistency</emphasis></primary><secondary>weakly consistent iterators</secondary></indexterm><indexterm id="iddle1937" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey TRADEOFFS?><?tertiarykey CONCURRENT VS. SYNCHRONIZED COLLECTIONS?><primary><emphasis role="strong">design</emphasis></primary><secondary>tradeoffs</secondary><tertiary>concurrent vs. synchronized collections</tertiary></indexterm><indexterm id="iddle2879" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey LOCKING?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>locking</secondary></indexterm><indexterm id="iddle2880" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey LOCKING?><?tertiarykey CONCURRENT COLLECTION ELIMINATION OF NEED FOR?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>locking</secondary><tertiary>concurrent collection elimination of need for</tertiary></indexterm><indexterm id="iddle2887" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey WEAKLY CONSISTENT?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>weakly consistent</secondary></indexterm><indexterm id="iddle2990" significance="normal"><?indexkey L?><?primarykey linked lists?><?secondarykey LINKEDLIST?><primary><emphasis role="strong">linked lists</emphasis></primary><secondary><literal>LinkedList</literal></secondary></indexterm><indexterm id="iddle3005" significance="normal"><?indexkey L?><?primarykey lists?><?secondarykey LINKEDLIST?><primary><emphasis role="strong">lists</emphasis></primary><secondary><literal>LinkedList</literal></secondary></indexterm><indexterm id="iddle3044" significance="normal"><?indexkey L?><?primarykey lock(ing)?><primary><emphasis role="strong">lock(ing)</emphasis></primary><seealso> <link linkend="iddle2512" preference="0"><emphasis role="strong">guidelines</emphasis>, confinement</link>.</seealso></indexterm><indexterm id="iddle3045" significance="normal"><?indexkey L?><?primarykey lock(ing)?><primary><emphasis role="strong">lock(ing)</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm><indexterm id="iddle3046" significance="normal"><?indexkey L?><?primarykey lock(ing)?><primary><emphasis role="strong">lock(ing)</emphasis></primary><seealso> <link linkend="iddle1095" preference="0"><emphasis role="strong">annotations</emphasis>, <literal>@GuardedBy</literal></link>.</seealso></indexterm><indexterm id="iddle3047" significance="normal"><?indexkey L?><?primarykey lock(ing)?><primary><emphasis role="strong">lock(ing)</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle3048" significance="normal"><?indexkey L?><?primarykey lock(ing)?><primary><emphasis role="strong">lock(ing)</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle3075" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONCURRENTHASHMAP STRATEGY?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary><literal>ConcurrentHashMap</literal> strategy</secondary></indexterm><indexterm id="iddle3116" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ITERATION?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>iteration</secondary></indexterm><indexterm id="iddle3117" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ITERATION?><?tertiarykey CONCURRENT COLLECTION ELIMINATION OF NEED FOR?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>iteration</secondary><tertiary>concurrent collection elimination of need for</tertiary></indexterm><indexterm id="iddle3144" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey SCOPE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>scope</secondary><seealso> <link linkend="iddle3101" preference="0"><emphasis role="strong">lock(ing)</emphasis>, granularity</link>.</seealso></indexterm><indexterm id="iddle3153" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey STRIPING?><?tertiarykey CONCURRENTHASHMAP USE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>striping</secondary><tertiary><literal>ConcurrentHashMap</literal> use</tertiary></indexterm><indexterm id="iddle3552" significance="normal"><?indexkey P?><?primarykey pessimistic concurrency management?><primary><emphasis role="strong">pessimistic concurrency management</emphasis></primary><see> <link linkend="iddle3094" preference="0"><emphasis role="strong">lock(ing)</emphasis>, exclusive</link>.</see></indexterm><indexterm id="iddle3665" significance="normal"><?indexkey P?><?primarykey PriorityQueue?><primary><emphasis role="strong">PriorityQueue</emphasis></primary></indexterm><indexterm id="iddle4062" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey CONCURRENTHASHMAP ADVANTAGES?><primary><emphasis role="strong">scalability</emphasis></primary><secondary><literal>ConcurrentHashMap</literal> advantages</secondary></indexterm><indexterm id="iddle4134" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey WEAKLY CONSISTENT ITERATION?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>weakly consistent iteration</secondary></indexterm><indexterm id="iddle4218" significance="normal"><?indexkey S?><?primarykey set(s)?><?secondarykey SORTEDSET?><primary><emphasis role="strong">set(s)</emphasis></primary><secondary><literal>SortedSet</literal></secondary></indexterm><indexterm id="iddle4219" significance="normal"><?indexkey S?><?primarykey set(s)?><?secondarykey SORTEDSET?><?tertiarykey CONCURRENTSKIPLISTSET AS CONCURRENT REPLACEMENT?><primary><emphasis role="strong">set(s)</emphasis></primary><secondary><literal>SortedSet</literal></secondary><tertiary><literal>ConcurrentSkipListSet</literal> as concurrent replacement</tertiary></indexterm><indexterm id="iddle4220" significance="normal"><?indexkey S?><?primarykey set(s)?><?secondarykey TREESET?><primary><emphasis role="strong">set(s)</emphasis></primary><secondary><literal>TreeSet</literal></secondary></indexterm><indexterm id="iddle4221" significance="normal"><?indexkey S?><?primarykey set(s)?><?secondarykey TREESET?><?tertiarykey CONCURRENTSKIPLISTSET AS CONCURRENT REPLACEMENT?><primary><emphasis role="strong">set(s)</emphasis></primary><secondary><literal>TreeSet</literal></secondary><tertiary><literal>ConcurrentSkipListSet</literal> as concurrent replacement</tertiary></indexterm><indexterm id="iddle4331" significance="normal"><?indexkey S?><?primarykey SortedMap?><primary><emphasis role="strong">SortedMap</emphasis></primary></indexterm><indexterm id="iddle4332" significance="normal"><?indexkey S?><?primarykey SortedMap?><?secondarykey CONCURRENTSKIPLISTMAP AS CONCURRENT REPLACEMENT?><primary><emphasis role="strong">SortedMap</emphasis></primary><secondary><literal>ConcurrentSkipListMap</literal> as concurrent replacement</secondary></indexterm><indexterm id="iddle4333" significance="normal"><?indexkey S?><?primarykey SortedSet?><primary><emphasis role="strong">SortedSet</emphasis></primary></indexterm><indexterm id="iddle4334" significance="normal"><?indexkey S?><?primarykey SortedSet?><?secondarykey CONCURRENTSKIPLISTSET AS CONCURRENT REPLACEMENT?><primary><emphasis role="strong">SortedSet</emphasis></primary><secondary><literal>ConcurrentSkipListSet</literal> as concurrent replacement</secondary></indexterm><indexterm id="iddle4474" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey LOCKING?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>locking</secondary></indexterm><indexterm id="iddle4475" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey LOCKING?><?tertiarykey CONCURRENTHASHMAP ADVANTAGES?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>locking</secondary><tertiary><literal>ConcurrentHashMap</literal> advantages</tertiary></indexterm><indexterm id="iddle4502" significance="normal"><?indexkey S?><?primarykey striping?><?secondarykey LOCK?><?tertiarykey CONCURRENTHASHMAP USE?><primary><emphasis role="strong">striping</emphasis></primary><secondary>lock</secondary><tertiary>ConcurrentHashMap use</tertiary></indexterm><indexterm id="iddle4969" significance="normal"><?indexkey T?><?primarykey TreeMap?><primary><emphasis role="strong">TreeMap</emphasis></primary></indexterm><indexterm id="iddle4970" significance="normal"><?indexkey T?><?primarykey TreeMap?><?secondarykey CONCURRENTSKIPLISTMAP AS CONCURRENT REPLACEMENT?><primary><emphasis role="strong">TreeMap</emphasis></primary><secondary><literal>ConcurrentSkipListMap</literal> as concurrent replacement</secondary></indexterm><indexterm id="iddle4971" significance="normal"><?indexkey T?><?primarykey TreeSet?><primary><emphasis role="strong">TreeSet</emphasis></primary></indexterm><indexterm id="iddle4972" significance="normal"><?indexkey T?><?primarykey TreeSet?><?secondarykey CONCURRENTSKIPLISTSET AS CONCURRENT REPLACEMENT?><primary><emphasis role="strong">TreeSet</emphasis></primary><secondary><literal>ConcurrentSkipListSet</literal> as concurrent replacement</secondary></indexterm><indexterm id="iddle5152" significance="normal"><?indexkey W?><?primarykey weakly consistent iterators?><primary><emphasis role="strong">weakly consistent iterators</emphasis></primary><seealso> <link linkend="iddle2870" preference="0"><emphasis role="strong">iterators/iteration</emphasis></link>.</seealso></indexterm>traditional FIFO queue, and <literal>PriorityQueue</literal>, a (non concurrent) priority ordered queue. <literal>Queue</literal> operations do not block; if the queue is empty, the retrieval operation returns <literal>null</literal>. While you can simulate the behavior of a <literal>Queue</literal> with a <literal>List</literal>—in fact, <literal>LinkedList</literal> also implements <literal>Queue</literal>—the <literal>Queue</literal> classes were added because eliminating the random-access requirements of <literal>List</literal> admits more efficient concurrent implementations.</para>
<para><literal>BlockingQueue</literal> extends <literal>Queue</literal> to add blocking insertion and retrieval operations. If the queue is empty, a retrieval blocks until an element is available, and if the queue is full (for bounded queues) an insertion blocks until there is space available. Blocking queues are extremely useful in producer-consumer designs, and are covered in greater detail in <link linkend="ch05lev1sec3" preference="0">Section 5.3</link>.</para>
<para>Just as <literal>ConcurrentHashMap</literal> is a concurrent replacement for a synchronized hash-based <literal>Map</literal>, Java 6 adds <literal>ConcurrentSkipListMap</literal> and <literal>ConcurrentSkipListSet</literal>, which are concurrent replacements for a synchronized <literal>SortedMap</literal> or <literal>SortedSet</literal> (such as <literal>TreeMap</literal> or <literal>TreeSet</literal> wrapped with <literal>synchronizedMap</literal>).</para>
<section id="ch05lev2sec4" label="5.2.1" xreflabel="5.2.1">
<title id="ch05lev2sec4__title">ConcurrentHashMap</title>
<para>The synchronized collections classes hold a lock for the duration of each operation. Some operations, such as <literal>HashMap.get</literal> or <literal>List.contains</literal>, may involve more work than is initially obvious: traversing a hash bucket or list to find a specific object entails calling <literal>equals</literal> (which itself may involve a fair amount of computation) on a number of candidate objects. In a hash-based collection, if <literal>hashCode</literal> does not spread out hash values well, elements may be unevenly distributed among buckets; in the degenerate case, a poor hash function will turn a hash table into a linked list. Traversing a long list and calling <literal>equals</literal> on some or all of the elements can take a long time, and during that time no other thread can access the collection.</para>
<para><literal>ConcurrentHashMap</literal> is a hash-based <literal>Map</literal> like <literal>HashMap</literal>, but it uses an entirely different locking strategy that offers better concurrency and scalability. Instead of synchronizing every method on a common lock, restricting access to a single thread at a time, it uses a finer-grained locking mechanism called <emphasis>lock striping</emphasis> (see <link linkend="ch11lev2sec10" preference="0">Section 11.4.3</link>) to allow a greater degree of shared access. Arbitrarily many reading threads can access the map concurrently, readers can access the map concurrently with writers, and a limited number of writers can modify the map concurrently. The result is far higher throughput under concurrent access, with little performance penalty for single-threaded access.</para>
<para><literal>ConcurrentHashMap</literal>, along with the other concurrent collections, further improve on the synchronized collection classes by providing iterators that do not throw <literal>ConcurrentModificationException</literal>, thus eliminating the need to lock the collection during iteration. The iterators returned by <literal>ConcurrentHashMap</literal> are <emphasis>weakly consistent</emphasis> instead of fail-fast. A weakly consistent iterator can tolerate concurrent modification, traverses elements as they existed when the iterator was constructed, and may (but is not guaranteed to) reflect modifications to the collection after the construction of the iterator.</para>
<para>As with all improvements, there are still a few tradeoffs. The semantics of methods that operate on the entire <literal>Map</literal>, such as <literal>size</literal> and <literal>isEmpty</literal>, have been <?docpage num="86"?><indexterm id="iddle1020" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey EXCLUSIVE?><primary><emphasis role="strong">access</emphasis></primary><secondary>exclusive</secondary></indexterm><indexterm id="iddle1021" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey EXCLUSIVE?><?tertiarykey AND CONCURRENT COLLECTIONS?><primary><emphasis role="strong">access</emphasis></primary><secondary>exclusive</secondary><tertiary>and concurrent collections</tertiary></indexterm><indexterm id="iddle1163" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey MAP OPERATIONS?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary><literal>Map</literal> operations</secondary></indexterm><indexterm id="iddle1665" significance="normal"><?indexkey C?><?primarykey CopyOnWriteArrayList?><primary><emphasis role="strong">CopyOnWriteArrayList</emphasis></primary></indexterm><indexterm id="iddle1671" significance="normal"><?indexkey C?><?primarykey CopyOnWriteArraySet?><?secondarykey SYNCHRONIZED SET REPLACEMENT?><primary><emphasis role="strong">CopyOnWriteArraySet</emphasis></primary><secondary>synchronized <literal>Set</literal> replacement</secondary></indexterm><indexterm id="iddle1724" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey COLLECTION COPY?><primary><emphasis role="strong">creation</emphasis></primary><secondary>collection copy</secondary></indexterm><indexterm id="iddle1725" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey COLLECTION COPY?><?tertiarykey AS IMMUTABLE OBJECT STRATEGY?><primary><emphasis role="strong">creation</emphasis></primary><secondary>collection copy</secondary><tertiary>as immutable object strategy</tertiary></indexterm><indexterm id="iddle2995" significance="normal"><?indexkey L?><?primarykey List?><?secondarykey COPYONWRITEARRAYLIST AS CONCURRENT COLLECTION FOR?><primary><emphasis role="strong">List</emphasis></primary><secondary><literal>CopyOnWriteArrayList</literal> as concurrent collection for</secondary></indexterm><indexterm id="iddle3008" significance="normal"><?indexkey L?><?primarykey lists?><?secondarykey LIST?><?tertiarykey COPYONWRITEARRAYLIST AS CONCURRENT REPLACEMENT?><primary><emphasis role="strong">lists</emphasis></primary><secondary><literal>List</literal></secondary><tertiary><literal>CopyOnWriteArrayList</literal> as concurrent replacement</tertiary></indexterm><indexterm id="iddle3097" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey EXCLUSIVE?><?tertiarykey INABILITY TO USE, AS CONCURRENT-HASHMAP DISADVANTAGE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>exclusive</secondary><tertiary>inability to use, as <literal>Concurrent-HashMap</literal> disadvantage</tertiary></indexterm><indexterm id="iddle3181" significance="normal"><?indexkey M?><?primarykey Map?><?secondarykey ATOMIC OPERATIONS?><primary><emphasis role="strong">Map</emphasis></primary><secondary>atomic operations</secondary></indexterm><indexterm id="iddle3845" significance="normal"><?indexkey R?><?primarykey remove-if-equal operation?><primary><emphasis role="strong">remove-if-equal operation</emphasis></primary></indexterm><indexterm id="iddle3846" significance="normal"><?indexkey R?><?primarykey remove-if-equal operation?><?secondarykey AS ATOMIC COLLECTION OPERATION?><primary><emphasis role="strong">remove-if-equal operation</emphasis></primary><secondary>as atomic collection operation</secondary></indexterm><indexterm id="iddle3858" significance="normal"><?indexkey R?><?primarykey replace-if-equal operation?><primary><emphasis role="strong">replace-if-equal operation</emphasis></primary></indexterm><indexterm id="iddle3859" significance="normal"><?indexkey R?><?primarykey replace-if-equal operation?><?secondarykey AS ATOMIC COLLECTION OPERATION?><primary><emphasis role="strong">replace-if-equal operation</emphasis></primary><secondary>as atomic collection operation</secondary></indexterm><indexterm id="iddle4214" significance="normal"><?indexkey S?><?primarykey set(s)?><?secondarykey COPYONWRITEARRAYSET?><primary><emphasis role="strong">set(s)</emphasis></primary><secondary><literal>CopyOnWriteArraySet</literal></secondary></indexterm><indexterm id="iddle4215" significance="normal"><?indexkey S?><?primarykey set(s)?><?secondarykey COPYONWRITEARRAYSET?><?tertiarykey AS SYNCHRONIZED SET REPLACEMENT?><primary><emphasis role="strong">set(s)</emphasis></primary><secondary><literal>CopyOnWriteArraySet</literal></secondary><tertiary>as synchronized <literal>Set</literal> replacement</tertiary></indexterm><indexterm id="iddle4276" significance="normal"><?indexkey S?><?primarykey side-effects?><?secondarykey SYNCHRONIZED MAP IMPLEMENTATIONS?><primary><emphasis role="strong">side-effects</emphasis></primary><secondary>synchronized <literal>Map</literal> implementations</secondary></indexterm><indexterm id="iddle4277" significance="normal"><?indexkey S?><?primarykey side-effects?><?secondarykey SYNCHRONIZED MAP IMPLEMENTATIONS?><?tertiarykey NOT AVAILABLE FROM CONCURRENT-HASHMAP?><primary><emphasis role="strong">side-effects</emphasis></primary><secondary>synchronized <literal>Map</literal> implementations</secondary><tertiary>not available from <literal>Concurrent-HashMap</literal></tertiary></indexterm><indexterm id="iddle4928" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey WEAKLY CONSISTENT ITERATION SEMANTICS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>weakly consistent iteration semantics</secondary></indexterm>slightly weakened to reflect the concurrent nature of the collection. Since the result of <literal>size</literal> could be out of date by the time it is computed, it is really only an estimate, so <literal>size</literal> is allowed to return an approximation instead of an exact count. While at first this may seem disturbing, in reality methods like <literal>size</literal> and <literal>isEmpty</literal> are far less useful in concurrent environments because these quantities are moving targets. So the requirements for these operations were weakened to enable performance optimizations for the most important operations, primarily <literal>get</literal>, <literal>put</literal>, <literal>containsKey</literal>, and <literal>remove</literal>.</para>
<para>The one feature offered by the synchronized <literal>Map</literal> implementations but not by <literal>ConcurrentHashMap</literal> is the ability to lock the map for exclusive access. With <literal>Hashtable</literal> and <literal>synchronizedMap</literal>, acquiring the <literal>Map</literal> lock prevents any other thread from accessing it. This might be necessary in unusual cases such as adding several mappings atomically, or iterating the <literal>Map</literal> several times and needing to see the same elements in the same order. On the whole, though, this is a reasonable tradeoff: concurrent collections should be expected to change their contents continuously.</para>
<para>Because it has so many advantages and so few disadvantages compared to <literal>Hashtable</literal> or <literal>synchronizedMap</literal>, replacing synchronized <literal>Map</literal> implementations with <literal>ConcurrentHashMap</literal> in most cases results only in better scalability. Only if your application needs to lock the map for exclusive access <footnote id="ch05fn03" label="3"><para>Or if you are relying on the synchronization side effects of the synchronized <literal>Map</literal> implementations.</para></footnote> is <literal>ConcurrentHashMap</literal> not an appropriate drop-in replacement.</para>
</section>
<section id="ch05lev2sec5" label="5.2.2" xreflabel="5.2.2">
<title id="ch05lev2sec5__title">Additional Atomic Map Operations</title>
<para>Since a <literal>ConcurrentHashMap</literal> cannot be locked for exclusive access, we cannot use client-side locking to create new atomic operations such as put-if-absent, as we did for <literal>Vector</literal> in <link linkend="ch04lev2sec11" preference="0">Section 4.4.1</link>. Instead, a number of common compound operations such as put-if-absent, remove-if-equal, and replace-if-equal are implemented as atomic operations and specified by the <literal>ConcurrentMap</literal> interface, shown in <link linkend="ch05list07" preference="0">Listing 5.7</link>. If you find yourself adding such functionality to an existing synchronized <literal>Map</literal> implementation, it is probably a sign that you should consider using a <literal>ConcurrentMap</literal> instead.</para>
</section>
<section id="ch05lev2sec6" label="5.2.3" xreflabel="5.2.3">
<title id="ch05lev2sec6__title">CopyOnWriteArrayList</title>
<para><literal>CopyOnWriteArrayList</literal> is a concurrent replacement for a synchronized <literal>List</literal> that offers better concurrency in some common situations and eliminates the need to lock or copy the collection during iteration. (Similarly, <literal>CopyOnWriteArraySet</literal> is a concurrent replacement for a synchronized <literal>Set</literal>.)</para>
<para>The copy-on-write collections derive their thread safety from the fact that as long as an effectively immutable object is properly published, no further synchronization is required when accessing it. They implement mutability by creating and republishing a new copy of the collection every time it is modified. Iterators for the copy-on-write collections retain a reference to the backing array that was current at the start of iteration, and since this will never change, they need to <?docpage num="87"?><indexterm id="iddle1221" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey QUEUES?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>queues</secondary><seealso> <link linkend="iddle4136" preference="0"><emphasis role="strong">Semaphore</emphasis></link>.</seealso></indexterm><indexterm id="iddle1226" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey QUEUES?><?tertiarykey PRODUCER-CONSUMER PATTERN AND?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>queues</secondary><tertiary>producer-consumer pattern and</tertiary></indexterm><indexterm id="iddle1439" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1488" significance="normal"><?indexkey C?><?primarykey ConcurrentMap?><primary><emphasis role="strong">ConcurrentMap</emphasis></primary></indexterm><indexterm id="iddle1579" significance="normal"><?indexkey C?><?primarykey consumers?><?secondarykey PRODUCER-CONSUMER PATTERN?><primary><emphasis role="strong">consumers</emphasis></primary><secondary>producer-consumer pattern</secondary></indexterm><indexterm id="iddle1580" significance="normal"><?indexkey C?><?primarykey consumers?><?secondarykey PRODUCER-CONSUMER PATTERN?><?tertiarykey BLOCKING QUEUES AND?><primary><emphasis role="strong">consumers</emphasis></primary><secondary>producer-consumer pattern</secondary><tertiary>blocking queues and</tertiary></indexterm><indexterm id="iddle1844" significance="normal"><?indexkey D?><?primarykey decoupling?><primary><emphasis role="strong">decoupling</emphasis></primary></indexterm><indexterm id="iddle1845" significance="normal"><?indexkey D?><?primarykey decoupling?><?secondarykey OF ACTIVITIES?><primary><emphasis role="strong">decoupling</emphasis></primary><secondary>of activities</secondary></indexterm><indexterm id="iddle1846" significance="normal"><?indexkey D?><?primarykey decoupling?><?secondarykey OF ACTIVITIES?><?tertiarykey AS PRODUCER-CONSUMER PATTERN ADVANTAGE?><primary><emphasis role="strong">decoupling</emphasis></primary><secondary>of activities</secondary><tertiary>as producer-consumer pattern advantage</tertiary></indexterm><indexterm id="iddle1869" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey CODE?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>code</secondary></indexterm><indexterm id="iddle1870" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey CODE?><?tertiarykey AS REMOVAL, AS PRODUCERCONSUMER PATTERN ADVANTAGE?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>code</secondary><tertiary>as removal, as producerconsumer pattern advantage</tertiary></indexterm><indexterm id="iddle1938" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey TRADEOFFS?><?tertiarykey COPY-ON-WRITE COLLECTIONS?><primary><emphasis role="strong">design</emphasis></primary><secondary>tradeoffs</secondary><tertiary>copy-on-write collections</tertiary></indexterm><indexterm id="iddle2006" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey CODE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>code</secondary></indexterm><indexterm id="iddle2007" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey CODE?><?tertiarykey AS PRODUCER-CONSUMER PATTERN ADVANTAGE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>code</secondary><tertiary>as producer-consumer pattern advantage</tertiary></indexterm><indexterm id="iddle2070" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey NOTIFICATION?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>notification</secondary></indexterm><indexterm id="iddle2071" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey NOTIFICATION?><?tertiarykey COPY-ON-WRITE COLLECTION ADVANTAGES?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>notification</secondary><tertiary>copy-on-write collection advantages</tertiary></indexterm><indexterm id="iddle3242" significance="normal"><?indexkey M?><?primarykey modification?><?secondarykey FREQUENT NEED FOR?><primary><emphasis role="strong">modification</emphasis></primary><secondary>frequent need for</secondary></indexterm><indexterm id="iddle3243" significance="normal"><?indexkey M?><?primarykey modification?><?secondarykey FREQUENT NEED FOR?><?tertiarykey COPY-ON-WRITE COLLECTION NOT SUITED FOR?><primary><emphasis role="strong">modification</emphasis></primary><secondary>frequent need for</secondary><tertiary>copy-on-write collection not suited for</tertiary></indexterm><indexterm id="iddle3326" significance="normal"><?indexkey N?><?primarykey notification?><?secondarykey EVENT NOTIFICATION SYSTEMS?><primary><emphasis role="strong">notification</emphasis></primary><secondary>event notification systems</secondary></indexterm><indexterm id="iddle3327" significance="normal"><?indexkey N?><?primarykey notification?><?secondarykey EVENT NOTIFICATION SYSTEMS?><?tertiarykey COPY-ON-WRITE COLLECTION ADVANTAGES?><primary><emphasis role="strong">notification</emphasis></primary><secondary>event notification systems</secondary><tertiary>copy-on-write collection advantages</tertiary></indexterm><indexterm id="iddle3681" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey BLOCKING QUEUES AND?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>blocking queues and</secondary></indexterm><indexterm id="iddle3750" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey BLOCKING?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>blocking</secondary></indexterm><indexterm id="iddle3754" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey BLOCKING?><?tertiarykey PRODUCER-CONSUMER PATTERN AND?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>blocking</secondary><tertiary>producer-consumer pattern and</tertiary></indexterm><indexterm id="iddle4993" significance="normal"><?indexkey U?><?primarykey unbounded?><?secondarykey QUEUES?><primary><emphasis role="strong">unbounded</emphasis></primary><secondary>queues</secondary></indexterm><indexterm id="iddle4994" significance="normal"><?indexkey U?><?primarykey unbounded?><?secondarykey QUEUES?><?tertiarykey NONBLOCKING CHARACTERISTICS?><primary><emphasis role="strong">unbounded</emphasis></primary><secondary>queues</secondary><tertiary>nonblocking characteristics</tertiary></indexterm>synchronize only briefly to ensure visibility of the array contents. As a result, multiple threads can iterate the collection without interference from one another or from threads wanting to modify the collection. The iterators returned by the copy-on-write collections do not throw <literal>ConcurrentModificationException</literal> and return the elements exactly as they were at the time the iterator was created, regardless of subsequent modifications.</para>
<example id="ch05list07" label="5.7" role="Listing" xreflabel="5.7" condition="87">
<title id="ch05list07__title"><literal>ConcurrentMap</literal> Interface.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface ConcurrentMap&lt;K,V&gt; extends Map&lt;K,V&gt; {
    <emphasis>// Insert into map only if no value is mapped from K</emphasis>
    V putIfAbsent(K key, V value);

    <emphasis>// Remove only if K is mapped to V</emphasis>
    boolean remove(K key, V value);

    <emphasis>// Replace value only if K is mapped to oldValue</emphasis>
    boolean replace(K key, V oldValue, V newValue);

    <emphasis>// Replace value only if K is mapped to some value</emphasis>
    V replace(K key, V newValue);
}
</programlisting>
</example>
<para>Obviously, there is some cost to copying the backing array every time the collection is modified, especially if the collection is large; the copy-on-write collections are reasonable to use only when iteration is far more common than modification. This criterion exactly describes many event-notification systems: delivering a notification requires iterating the list of registered listeners and calling each one of them, and in most cases registering or unregistering an event listener is far less common than receiving an event notification. (See [CPJ 2.4.4] for more information on copy-on-write.)</para>
</section>
</section>
<section id="ch05lev1sec3" condition="87" label="5.3" xreflabel="5.3"><?docpage num="87"?>
<title id="ch05lev1sec3__title">Blocking Queues and the Producer-consumer Pattern</title>
<para>Blocking queues provide blocking <literal>put</literal> and <literal>take</literal> methods as well as the timed equivalents <literal>offer</literal> and <literal>poll</literal>. If the queue is full, <literal>put</literal> blocks until space becomes available; if the queue is empty, <literal>take</literal> blocks until an element is available. Queues can be bounded or unbounded; unbounded queues are never full, so a <literal>put</literal> on an unbounded queue never blocks.</para>
<para>Blocking queues support the <emphasis>producer-consumer</emphasis> design pattern. A producerconsumer design separates the identification of work to be done from the execution of that work by placing work items on a “to do” list for later processing, rather than processing them immediately as they are identified. The producerconsumer pattern simplifies development because it removes code dependencies between producer and consumer classes, and simplifies workload management <?docpage num="88"?><?docpage num="89"?><indexterm id="iddle1248" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey QUEUES?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>queues</secondary></indexterm><indexterm id="iddle1249" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey QUEUES?><?tertiarykey AND PRODUCER-CONSUMER PATTERN?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>queues</secondary><tertiary>and producer-consumer pattern</tertiary></indexterm><indexterm id="iddle1578" significance="normal"><?indexkey C?><?primarykey consumers?><?secondarykey BLOCKING QUEUES USE?><primary><emphasis role="strong">consumers</emphasis></primary><secondary>blocking queues use</secondary></indexterm><indexterm id="iddle2259" significance="normal"><?indexkey E?><?primarykey Executor framework?><?secondarykey AS PRODUCER-CONSUMER PATTERN?><primary><emphasis role="strong">Executor framework</emphasis></primary><secondary>as producer-consumer pattern</secondary></indexterm><indexterm id="iddle2379" significance="normal"><?indexkey F?><?primarykey flexibility?><?secondarykey RESOURCE MANAGEMENT?><primary><emphasis role="strong">flexibility</emphasis></primary><secondary>resource management</secondary></indexterm><indexterm id="iddle2380" significance="normal"><?indexkey F?><?primarykey flexibility?><?secondarykey RESOURCE MANAGEMENT?><?tertiarykey AS BLOCKING QUEUE ADVANTAGE?><primary><emphasis role="strong">flexibility</emphasis></primary><secondary>resource management</secondary><tertiary>as blocking queue advantage</tertiary></indexterm><indexterm id="iddle3622" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey AS PRODUCER-CONSUMER DESIGN?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>as producer-consumer design</tertiary></indexterm><indexterm id="iddle3773" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey WORK?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>work</secondary></indexterm><indexterm id="iddle3774" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey WORK?><?tertiarykey IN THREAD POOLS?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>work</secondary><tertiary>in thread pools</tertiary></indexterm><indexterm id="iddle3919" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey BLOCKING QUEUE ADVANTAGES?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>blocking queue advantages</tertiary></indexterm><indexterm id="iddle4007" significance="normal"><?indexkey R?><?primarykey robustness?><?secondarykey BLOCKING QUEUE ADVANTAGES?><primary><emphasis role="strong">robustness</emphasis></primary><secondary>blocking queue advantages</secondary></indexterm><indexterm id="iddle4796" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey AS PRODUCER-CONSUMER DESIGN?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>as producer-consumer design</tertiary></indexterm><indexterm id="iddle4862" significance="normal"><?indexkey T?><?primarykey throttling?><primary><emphasis role="strong">throttling</emphasis></primary></indexterm><indexterm id="iddle4863" significance="normal"><?indexkey T?><?primarykey throttling?><?secondarykey AS OVERLOAD MANAGEMENT MECHANISM?><primary><emphasis role="strong">throttling</emphasis></primary><secondary>as overload management mechanism</secondary></indexterm><indexterm id="iddle5156" significance="normal"><?indexkey W?><?primarykey work?><primary><emphasis role="strong">work</emphasis></primary></indexterm><indexterm id="iddle5157" significance="normal"><?indexkey W?><?primarykey work?><?secondarykey QUEUES?><primary><emphasis role="strong">work</emphasis></primary><secondary>queues</secondary></indexterm><indexterm id="iddle5158" significance="normal"><?indexkey W?><?primarykey work?><?secondarykey QUEUES?><?tertiarykey AND THREAD POOLS, AS PRODUCERCONSUMER DESIGN?><primary><emphasis role="strong">work</emphasis></primary><secondary>queues</secondary><tertiary>and thread pools, as producerconsumer design</tertiary></indexterm>by decoupling activities that may produce or consume data at different or variable rates.</para>
<para>In a producer-consumer design built around a blocking queue, producers place data onto the queue as it becomes available, and consumers retrieve data from the queue when they are ready to take the appropriate action. Producers don’t need to know anything about the identity or number of consumers, or even whether they are the only producer—all they have to do is place data items on the queue. Similarly, consumers need not know who the producers are or where the work came from. <literal>BlockingQueue</literal> simplifies the implementation of producerconsumer designs with any number of producers and consumers. One of the most common producer-consumer designs is a thread pool coupled with a work queue; this pattern is embodied in the <literal>Executor</literal> task execution framework that is the subject of <link linkend="ch06" preference="0">Chapters 6</link> and <link linkend="ch08" preference="0">8</link>.</para>
<para>The familiar division of labor for two people washing the dishes is an example of a producer-consumer design: one person washes the dishes and places them in the dish rack, and the other person retrieves the dishes from the rack and dries them. In this scenario, the dish rack acts as a blocking queue; if there are no dishes in the rack, the consumer waits until there are dishes to dry, and if the rack fills up, the producer has to stop washing until there is more space. This analogy extends to multiple producers (though there may be contention for the sink) and multiple consumers; each worker interacts only with the dish rack. No one needs to know how many producers or consumers there are, or who produced a given item of work.</para>
<para>The labels “producer” and “consumer” are relative; an activity that acts as a consumer in one context may act as a producer in another. Drying the dishes “consumes” clean wet dishes and “produces” clean dry dishes. A third person wanting to help might put away the dry dishes, in which case the drier is both a consumer and a producer, and there are now two shared work queues (each of which may block the drier from proceeding.)</para>
<para>Blocking queues simplify the coding of consumers, since <literal>take</literal> blocks until data is available. If the producers don’t generate work fast enough to keep the consumers busy, the consumers just wait until more work is available. Sometimes this is perfectly acceptable (as in a server application when no client is requesting service), and sometimes it indicates that the ratio of producer threads to consumer threads should be adjusted to achieve better utilization (as in a web crawler or other application in which there is effectively infinite work to do).</para>
<para>If the producers consistently generate work faster than the consumers can process it, eventually the application will run out of memory because work items will queue up without bound. Again, the blocking nature of <literal>put</literal> greatly simplifies coding of producers; if we use a <emphasis>bounded queue</emphasis>, then when the queue fills up the producers block, giving the consumers time to catch up because a blocked producer cannot generate more work.</para>
<para>Blocking queues also provide an <literal>offer</literal> method, which returns a failure status if the item cannot be enqueued. This enables you to create more flexible policies for dealing with overload, such as shedding load, serializing excess work items and writing them to disk, reducing the number of producer threads, or throttling producers in some other manner.</para>
<sidebar float="1" id="ch05sb03" condition="88"><title/>
<para>Bounded queues are a powerful resource management tool for building reliable applications: they make your program more robust to overload by throttling activities that threaten to produce more work than can be handled.</para>
</sidebar>
<para>While the producer-consumer pattern enables producer and consumer <emphasis>code</emphasis> to be decoupled from each other, their <emphasis>behavior</emphasis> is still coupled indirectly through the shared work queue. It is tempting to assume that the consumers will always keep up, so that you need not place any bounds on the size of work queues, but this is a prescription for rearchitecting your system later. <emphasis>Build resource management into your design early using blocking queues—it is a lot easier to do this up front than to retrofit it later.</emphasis> Blocking queues make this easy for a number of situations, but if blocking queues don’t fit easily into your design, you can create other blocking data structures using <literal>Semaphore</literal> (see <link linkend="ch05lev2sec12" preference="0">Section 5.5.3</link>).</para>
<para>The class library contains several implementations of <literal>BlockingQueue</literal>. <literal>LinkedBlockingQueue</literal> and <literal>ArrayBlockingQueue</literal> are FIFO queues, analogous to <literal>LinkedList</literal> and <literal>ArrayList</literal> but with better concurrent performance than a synchronized <literal>List</literal>. <literal>PriorityBlockingQueue</literal> is a priority-ordered queue, which is useful when you want to process elements in an order other than FIFO. Just like other sorted collections, <literal>PriorityBlockingQueue</literal> can compare elements according to their natural order (if they implement <literal>Comparable</literal>) or using a <literal>Comparator</literal>.</para>
<para>The last <literal>BlockingQueue</literal> implementation, <literal>SynchronousQueue</literal>, is not really a queue at all, in that it maintains no storage space for queued elements. Instead, it maintains a list of queued <emphasis>threads</emphasis> waiting to enqueue or dequeue an element. In the dish-washing analogy, this would be like having no dish rack, but instead handing the washed dishes directly to the next available dryer. While this may seem a strange way to implement a queue, it reduces the latency associated with moving data from producer to consumer because the work can be handed off directly. (In a traditional queue, the enqueue and dequeue operations must complete sequentially before a unit of work can be handed off.) The direct handoff also feeds back more information about the state of the task to the producer; when the handoff is accepted, it knows a consumer has taken responsibility for it, rather than simply letting it sit on a queue somewhere—much like the difference between handing a document to a colleague and merely putting it in her mailbox and hoping she gets it soon. Since a <literal>SynchronousQueue</literal> has no storage capacity, <literal>put</literal> and <literal>take</literal> will block unless another thread is already waiting to participate in the handoff. Synchronous queues are generally suitable only when there are enough consumers that there nearly always will be one ready to take the handoff.</para>
<section id="ch05lev2sec7" label="5.3.1" xreflabel="5.3.1">
<title id="ch05lev2sec7__title">Example: Desktop Search</title>
<para>One type of program that is amenable to decomposition into producers and consumers is an agent that scans local drives for documents and indexes them for later searching, similar to Google Desktop or the Windows Indexing service. <literal>DiskCrawler</literal> in <link linkend="ch05list08" preference="0">Listing 5.8</link> shows a producer task that searches a file hierarchy <?docpage num="90"?><indexterm id="iddle2115" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey FILECRAWLER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>FileCrawler</literal></secondary></indexterm><indexterm id="iddle2123" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey INDEXER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Indexer</literal></secondary></indexterm><indexterm id="iddle1121" significance="normal"><?indexkey A?><?primarykey ArrayBlockingQueue?><primary><emphasis role="strong">ArrayBlockingQueue</emphasis></primary></indexterm><indexterm id="iddle1390" significance="normal"><?indexkey C?><?primarykey comparison?><primary><emphasis role="strong">comparison</emphasis></primary></indexterm><indexterm id="iddle1391" significance="normal"><?indexkey C?><?primarykey comparison?><?secondarykey PRIORITY-ORDERED QUEUE USE?><primary><emphasis role="strong">comparison</emphasis></primary><secondary>priority-ordered queue use</secondary></indexterm><indexterm id="iddle1705" significance="normal"><?indexkey C?><?primarykey coupling?><?secondarykey BEHAVIOR?><primary><emphasis role="strong">coupling</emphasis></primary><secondary>behavior</secondary></indexterm><indexterm id="iddle1706" significance="normal"><?indexkey C?><?primarykey coupling?><?secondarykey BEHAVIOR?><?tertiarykey BLOCKING QUEUE HANDLING?><primary><emphasis role="strong">coupling</emphasis></primary><secondary>behavior</secondary><tertiary>blocking queue handling</tertiary></indexterm><indexterm id="iddle1840" significance="normal"><?indexkey D?><?primarykey decomposition?><?secondarykey PRODUCER-CONSUMER PATTERN?><primary><emphasis role="strong">decomposition</emphasis></primary><secondary>producer-consumer pattern</secondary></indexterm><indexterm id="iddle2345" significance="normal"><?indexkey F?><?primarykey FIFO queues?><primary><emphasis role="strong">FIFO queues</emphasis></primary></indexterm><indexterm id="iddle2346" significance="normal"><?indexkey F?><?primarykey FIFO queues?><?secondarykey BLOCKINGQUEUE IMPLEMENTATIONS?><primary><emphasis role="strong">FIFO queues</emphasis></primary><secondary><literal>BlockingQueue</literal> implementations</secondary></indexterm><indexterm id="iddle2987" significance="normal"><?indexkey L?><?primarykey linked lists?><?secondarykey LINKEDBLOCKINGQUEUE?><primary><emphasis role="strong">linked lists</emphasis></primary><secondary><literal>LinkedBlockingQueue</literal></secondary></indexterm><indexterm id="iddle3663" significance="normal"><?indexkey P?><?primarykey PriorityBlockingQueue?><primary><emphasis role="strong">PriorityBlockingQueue</emphasis></primary></indexterm><indexterm id="iddle3761" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey FIFO?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>FIFO</secondary></indexterm><indexterm id="iddle3764" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey PRIORITY-ORDERED?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>priority-ordered</secondary></indexterm><indexterm id="iddle3765" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey SYNCHRONOUS?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>synchronous</secondary></indexterm><indexterm id="iddle3766" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey SYNCHRONOUS?><?tertiarykey DESIGN CONSTRAINTS?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>synchronous</secondary><tertiary>design constraints</tertiary></indexterm><indexterm id="iddle4597" significance="normal"><?indexkey S?><?primarykey SynchronousQueue?><primary><emphasis role="strong">SynchronousQueue</emphasis></primary></indexterm><indexterm id="iddle4811" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey QUEUED?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>queued</secondary></indexterm><indexterm id="iddle4812" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey QUEUED?><?tertiarykey SYNCHRONOUSQUEUE MANAGEMENT OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>queued</secondary><tertiary><literal>SynchronousQueue</literal> management of</tertiary></indexterm><indexterm id="iddle1543" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><?tertiarykey SERIAL?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary><tertiary>serial</tertiary></indexterm><indexterm id="iddle1544" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><?tertiarykey SERIAL?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary><tertiary>serial</tertiary></indexterm><indexterm id="iddle3359" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey POOLS?><?tertiarykey SERIAL THREAD CONFINEMENT USE?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>pools</secondary><tertiary>serial thread confinement use</tertiary></indexterm><indexterm id="iddle3519" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey PRODUCER-CONSUMER PATTERN ADVANTAGES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>producer-consumer pattern advantages</secondary></indexterm><indexterm id="iddle3611" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey OBJECT?><?tertiarykey SERIAL THREAD CONFINEMENT USE?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>object</secondary><tertiary>serial thread confinement use</tertiary></indexterm><indexterm id="iddle3731" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey SAFE?><?tertiarykey SERIAL THREAD CONFINEMENT USE?><primary><emphasis role="strong">publication</emphasis></primary><secondary>safe</secondary><tertiary>serial thread confinement use</tertiary></indexterm><indexterm id="iddle4183" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey SERIAL THREAD CONFINEMENT?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>serial thread confinement</secondary></indexterm><indexterm id="iddle4184" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey SERIAL THREAD CONFINEMENT?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>serial thread confinement</secondary></indexterm><indexterm id="iddle4814" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SERIAL THREAD CONFINEMENT?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>serial thread confinement</secondary></indexterm><indexterm id="iddle4815" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SERIAL THREAD CONFINEMENT?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>serial thread confinement</secondary></indexterm>for files meeting an indexing criterion and puts their names on the work queue; <literal>Indexer</literal> in <link linkend="ch05list08" preference="0">Listing 5.8</link> shows the consumer task that takes file names from the queue and indexes them.</para>
<para>The producer-consumer pattern offers a thread-friendly means of decomposing the desktop search problem into simpler components. Factoring file-crawling and indexing into separate activities results in code that is more readable and reusable than with a monolithic activity that does both; each of the activities has only a single task to do, and the blocking queue handles all the flow control, so the code for each is simpler and clearer.</para>
<para>The producer-consumer pattern also enables several performance benefits. Producers and consumers can execute concurrently; if one is I/O-bound and the other is CPU-bound, executing them concurrently yields better overall throughput than executing them sequentially. If the producer and consumer activities are parallelizable to different degrees, tightly coupling them reduces parallelizability to that of the less parallelizable activity.</para>
<para><link linkend="ch05list09" preference="0">Listing 5.9</link> starts several crawlers and indexers, each in their own thread. As written, the consumer threads never exit, which prevents the program from terminating; we examine several techniques for addressing this problem in <link linkend="ch07" preference="0">Chapter 7</link>. While this example uses explicitly managed threads, many producer-consumer designs can be expressed using the <literal>Executor</literal> task execution framework, which itself uses the producer-consumer pattern.</para>
</section>
<section id="ch05lev2sec8" label="5.3.2" xreflabel="5.3.2">
<title id="ch05lev2sec8__title">Serial Thread Confinement</title>
<para>The blocking queue implementations in <literal>java.util.concurrent</literal> all contain sufficient internal synchronization to safely publish objects from a producer thread to the consumer thread.</para>
<para>For mutable objects, producer-consumer designs and blocking queues facilitate <emphasis>serial thread confinement</emphasis> for handing off ownership of objects from producers to consumers. A thread-confined object is owned exclusively by a single thread, but that ownership can be “transferred” by publishing it safely where only one other thread will gain access to it and ensuring that the publishing thread does not access it after the handoff. The safe publication ensures that the object’s state is visible to the new owner, and since the original owner will not touch it again, it is now confined to the new thread. The new owner may modify it freely since it has exclusive access.</para>
<para>Object pools exploit serial thread confinement, “lending” an object to a requesting thread. As long as the pool contains sufficient internal synchronization to publish the pooled object safely, and as long as the clients do not themselves publish the pooled object or use it after returning it to the pool, ownership can be transferred safely from thread to thread.</para>
<para>One could also use other publication mechanisms for transferring ownership of a mutable object, but it is necessary to ensure that only one thread receives the object being handed off. Blocking queues make this easy; with a little more work, it could also done with the atomic <literal>remove</literal> method of <literal>ConcurrentMap</literal> or the <literal>compareAndSet</literal> method of <literal>AtomicReference</literal>.</para>

<para><?docpage num="91"?></para><example id="ch05list08" label="5.8" role="Listing" xreflabel="5.8" condition="91">

<title id="ch05list08__title">Producer and Consumer Tasks in a Desktop Search Application.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class FileCrawler implements Runnable {
    private final BlockingQueue&lt;File&gt; fileQueue;
    private final FileFilter fileFilter;
    private final File root;
    ...
    public void run() {
        try {
            crawl(root);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }

    private void crawl(File root) throws InterruptedException {
        File[] entries = root.listFiles(fileFilter);
        if (entries != null) {
            for (File entry : entries)
                if (entry.isDirectory())
                    crawl(entry);
                else if (!alreadyIndexed(entry))
                    fileQueue.put(entry);
        }
    }
}

public class Indexer implements Runnable {
    private final BlockingQueue&lt;File&gt; queue;

    public Indexer(BlockingQueue&lt;File&gt; queue) {
        this.queue = queue;
    }

    public void run() {
        try {
            while (true)
                indexFile(queue.take());
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
}
</programlisting>
</example>

<para><?docpage num="92"?></para><example id="ch05list09" label="5.9" role="Listing" xreflabel="5.9" condition="92">

<title id="ch05list09__title">Starting the Desktop Search.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public static void startIndexing(File[] roots) {
    BlockingQueue&lt;File&gt; queue = new LinkedBlockingQueue&lt;File&gt;(BOUND);
    FileFilter filter = new FileFilter() {
        public boolean accept(File file) { return true; }
    };

    for (File root : roots)
        new Thread(new FileCrawler(queue, filter, root)).start();

    for (int i = 0; i &lt; N_CONSUMERS; i++)
        new Thread(new Indexer(queue)).start();
}
</programlisting>
</example>
</section>
<section id="ch05lev2sec9" label="5.3.3" xreflabel="5.3.3">
<title id="ch05lev2sec9__title">Deques and Work Stealing</title>
<para><indexterm id="iddle1066" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey WORK STEALING?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>work stealing</secondary></indexterm><indexterm id="iddle1067" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey WORK STEALING?><?tertiarykey DEQUES AND?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>work stealing</secondary><tertiary>deques and</tertiary></indexterm><indexterm id="iddle1124" significance="normal"><?indexkey A?><?primarykey ArrayDeque?><primary><emphasis role="strong">ArrayDeque</emphasis></primary></indexterm><indexterm id="iddle1208" significance="normal"><?indexkey B?><?primarykey block(ing)?><primary><emphasis role="strong">block(ing)</emphasis></primary></indexterm><indexterm id="iddle1213" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey INTERRUPTIBLE METHODS AND?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>interruptible methods and</secondary></indexterm><indexterm id="iddle1482" significance="normal"><?indexkey C?><?primarykey ConcurrentLinkedDeque?><primary><emphasis role="strong">ConcurrentLinkedDeque</emphasis></primary></indexterm><indexterm id="iddle1518" significance="normal"><?indexkey C?><?primarykey conditional?><primary><emphasis role="strong">conditional</emphasis></primary><seealso> <link linkend="iddle1208" preference="0"><emphasis role="strong">block(ing)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1576" significance="normal"><?indexkey C?><?primarykey consumers?><primary><emphasis role="strong">consumers</emphasis></primary><seealso> <link linkend="iddle1208" preference="0"><emphasis role="strong">block(ing)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1577" significance="normal"><?indexkey C?><?primarykey consumers?><primary><emphasis role="strong">consumers</emphasis></primary><seealso> <link linkend="iddle3678" preference="0"><emphasis role="strong">producer-consumer pattern</emphasis></link>.</seealso></indexterm><indexterm id="iddle1599" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey RESOURCE?><?tertiarykey DEQUE ADVANTAGES?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>resource</secondary><tertiary>deque advantages</tertiary></indexterm><indexterm id="iddle1886" significance="normal"><?indexkey D?><?primarykey Deque?><primary><emphasis role="strong">Deque</emphasis></primary></indexterm><indexterm id="iddle1890" significance="normal"><?indexkey D?><?primarykey deques?><?secondarykey WORK STEALING AND?><primary><emphasis role="strong">deques</emphasis></primary><secondary>work stealing and</secondary></indexterm><indexterm id="iddle2799" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey BLOCKING AND?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>blocking and</secondary></indexterm><indexterm id="iddle2985" significance="normal"><?indexkey L?><?primarykey linked lists?><primary><emphasis role="strong">linked lists</emphasis></primary></indexterm><indexterm id="iddle2986" significance="normal"><?indexkey L?><?primarykey linked lists?><?secondarykey LINKEDBLOCKINGDEQUE?><primary><emphasis role="strong">linked lists</emphasis></primary><secondary><literal>LinkedBlockingDeque</literal></secondary></indexterm><indexterm id="iddle3430" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey SOURCES?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>sources</secondary><see> <link linkend="iddle1208" preference="0"><emphasis role="strong">block(ing)</emphasis></link>.</see></indexterm><indexterm id="iddle3431" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey SOURCES?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>sources</secondary><see> <link linkend="iddle3078" preference="0"><emphasis role="strong">lock(ing)</emphasis>, contention</link>.</see></indexterm><indexterm id="iddle3432" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey SOURCES?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>sources</secondary><see> <link linkend="iddle1693" preference="0"><emphasis role="strong">cost(s)</emphasis>, thread, context switching</link>.</see></indexterm><indexterm id="iddle3433" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey SOURCES?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>sources</secondary><see> <link linkend="iddle3266" preference="0"><emphasis role="strong">multithreaded</emphasis></link>.</see></indexterm><indexterm id="iddle3434" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey SOURCES?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>sources</secondary><see> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</see></indexterm><indexterm id="iddle3435" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey SOURCES?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>sources</secondary><see> <link linkend="iddle4825" preference="0"><emphasis role="strong">thread(s)</emphasis>, suspension</link>.</see></indexterm><indexterm id="iddle3436" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey SOURCES?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>sources</secondary><see> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</see></indexterm><indexterm id="iddle3437" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey SOURCES?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>sources</secondary><see> <link linkend="iddle4786" preference="0"><emphasis role="strong">thread(s)</emphasis>, lifecycle</link>.</see></indexterm><indexterm id="iddle3689" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey WORK STEALING VS?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>work stealing vs</secondary></indexterm><indexterm id="iddle4100" significance="normal"><?indexkey S?><?primarykey scheduling?><?secondarykey WORK STEALING?><primary><emphasis role="strong">scheduling</emphasis></primary><secondary>work stealing</secondary></indexterm><indexterm id="iddle4101" significance="normal"><?indexkey S?><?primarykey scheduling?><?secondarykey WORK STEALING?><?tertiarykey DEQUES AND?><primary><emphasis role="strong">scheduling</emphasis></primary><secondary>work stealing</secondary><tertiary>deques and</tertiary></indexterm><indexterm id="iddle4747" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey BLOCKING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>blocking</secondary></indexterm><indexterm id="iddle5146" significance="normal"><?indexkey W?><?primarykey waking up?><primary><emphasis role="strong">waking up</emphasis></primary><seealso> <link linkend="iddle1208" preference="0"><emphasis role="strong">block(ing)</emphasis></link>.</seealso></indexterm><indexterm id="iddle5147" significance="normal"><?indexkey W?><?primarykey waking up?><primary><emphasis role="strong">waking up</emphasis></primary><seealso> <link linkend="iddle15051" preference="0"><emphasis role="strong">condition</emphasis></link>.</seealso></indexterm><indexterm id="iddle5148" significance="normal"><?indexkey W?><?primarykey waking up?><primary><emphasis role="strong">waking up</emphasis></primary><seealso> <link linkend="iddle3328" preference="0"><emphasis role="strong"><literal>notify</literal></emphasis></link>.</seealso></indexterm><indexterm id="iddle5149" significance="normal"><?indexkey W?><?primarykey waking up?><primary><emphasis role="strong">waking up</emphasis></primary><seealso> <link linkend="iddle4320" preference="0"><emphasis role="strong">sleeping</emphasis></link>.</seealso></indexterm><indexterm id="iddle5150" significance="normal"><?indexkey W?><?primarykey waking up?><primary><emphasis role="strong">waking up</emphasis></primary><seealso> <link linkend="iddle5129" preference="0"><emphasis role="strong">wait(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle5161" significance="normal"><?indexkey W?><?primarykey work?><?secondarykey SHARING?><primary><emphasis role="strong">work</emphasis></primary><secondary>sharing</secondary></indexterm><indexterm id="iddle5162" significance="normal"><?indexkey W?><?primarykey work?><?secondarykey SHARING?><?tertiarykey DEQUES ADVANTAGES FOR?><primary><emphasis role="strong">work</emphasis></primary><secondary>sharing</secondary><tertiary>deques advantages for</tertiary></indexterm><indexterm id="iddle5163" significance="normal"><?indexkey W?><?primarykey work?><?secondarykey STEALING SCHEDULING ALGORITHM?><primary><emphasis role="strong">work</emphasis></primary><secondary>stealing scheduling algorithm</secondary></indexterm><indexterm id="iddle5164" significance="normal"><?indexkey W?><?primarykey work?><?secondarykey STEALING SCHEDULING ALGORITHM?><?tertiarykey DEQUES AND?><primary><emphasis role="strong">work</emphasis></primary><secondary>stealing scheduling algorithm</secondary><tertiary>deques and</tertiary></indexterm>Java 6 also adds another two collection types, <literal>Deque</literal> (pronounced “deck”) and <literal>BlockingDeque</literal>, that extend <literal>Queue</literal> and <literal>BlockingQueue</literal>. A <literal>Deque</literal> is a doubleended queue that allows efficient insertion and removal from both the head and the tail. Implementations include <literal>ArrayDeque</literal> and <literal>LinkedBlockingDeque</literal>.</para>
<para>Just as blocking queues lend themselves to the producer-consumer pattern, deques lend themselves to a related pattern called <emphasis>work stealing</emphasis>. A producerconsumer design has one shared work queue for all consumers; in a work stealing design, every consumer has its own deque. If a consumer exhausts the work in its own deque, it can steal work from the <emphasis>tail</emphasis> of someone else’s deque. Work stealing can be more scalable than a traditional producer-consumer design because workers don’t contend for a shared work queue; most of the time they access only their own deque, reducing contention. When a worker has to access another’s queue, it does so from the tail rather than the head, further reducing contention.</para>
<para>Work stealing is well suited to problems in which consumers are also producers—when performing a unit of work is likely to result in the identification of more work. For example, processing a page in a web crawler usually results in the identification of new pages to be crawled. Similarly, many graph-exploring algorithms, such as marking the heap during garbage collection, can be efficiently parallelized using work stealing. When a worker identifies a new unit of work, it places it at the end of its own deque (or alternatively, in a <emphasis>work sharing</emphasis> design, on that of another worker); when its deque is empty, it looks for work at the end of someone else’s deque, ensuring that each worker stays busy.</para>
</section>
</section>
<section id="ch05lev1sec4" condition="92" label="5.4" xreflabel="5.4"><?docpage num="92"?>
<title id="ch05lev1sec4__title">Blocking and Interruptible Methods</title>
<para>Threads may <emphasis>block</emphasis>, or pause, for several reasons: waiting for I/O completion, waiting to acquire a lock, waiting to wake up from <literal>Thread.sleep</literal>, or waiting for the result of a computation in another thread. When a thread blocks, it is usually suspended and placed in one of the blocked thread states (<literal>BLOCKED</literal>, <literal>WAITING</literal>, or <?docpage num="93"?><indexterm id="iddle1641" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey END-OF-LIFECYCLE MECHANISMS?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>end-of-lifecycle mechanisms</secondary></indexterm><indexterm id="iddle1642" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey END-OF-LIFECYCLE MECHANISMS?><?tertiarykey INTERRUPTION AS?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>end-of-lifecycle mechanisms</secondary><tertiary>interruption as</tertiary></indexterm><indexterm id="iddle1929" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey STRATEGIES?><primary><emphasis role="strong">design</emphasis></primary><secondary>strategies</secondary></indexterm><indexterm id="iddle1930" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey STRATEGIES?><?tertiarykey FOR INTERRUPTEDEXCEPTION?><primary><emphasis role="strong">design</emphasis></primary><secondary>strategies</secondary><tertiary>for <literal>InterruptedException</literal></tertiary></indexterm><indexterm id="iddle2787" significance="normal"><?indexkey I?><?primarykey InterruptedException?><?secondarykey STRATEGIES FOR HANDLING?><primary><emphasis role="strong">InterruptedException</emphasis></primary><secondary>strategies for handling</secondary></indexterm><indexterm id="iddle2790" significance="normal"><?indexkey I?><?primarykey interruption(s)?><primary><emphasis role="strong">interruption(s)</emphasis></primary><seealso> <link linkend="iddle2646" preference="0"><emphasis role="strong">hooks</emphasis>, completion</link>.</seealso></indexterm><indexterm id="iddle2791" significance="normal"><?indexkey I?><?primarykey interruption(s)?><primary><emphasis role="strong">interruption(s)</emphasis></primary><seealso> <link linkend="iddle3324" preference="0"><emphasis role="strong">notification</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle2792" significance="normal"><?indexkey I?><?primarykey interruption(s)?><primary><emphasis role="strong">interruption(s)</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle2793" significance="normal"><?indexkey I?><?primarykey interruption(s)?><primary><emphasis role="strong">interruption(s)</emphasis></primary><seealso> <link linkend="iddle1398" preference="0"><emphasis role="strong">completion</emphasis>, notification</link>.</seealso></indexterm><indexterm id="iddle2794" significance="normal"><?indexkey I?><?primarykey interruption(s)?><primary><emphasis role="strong">interruption(s)</emphasis></primary><seealso> <link linkend="iddle4835" preference="0"><emphasis role="strong">thread(s)</emphasis>, termination</link>.</seealso></indexterm><indexterm id="iddle2795" significance="normal"><?indexkey I?><?primarykey interruption(s)?><primary><emphasis role="strong">interruption(s)</emphasis></primary><seealso> <link linkend="iddle4974" preference="0"><emphasis role="strong">trigger(ing)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2816" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey SWALLOWING?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>swallowing</secondary></indexterm><indexterm id="iddle2817" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey SWALLOWING?><?tertiarykey AS DISCOURAGED PRACTICE?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>swallowing</secondary><tertiary>as discouraged practice</tertiary></indexterm><indexterm id="iddle4125" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey OF INTERRUPTION?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>of interruption</secondary></indexterm><indexterm id="iddle4327" significance="normal"><?indexkey S?><?primarykey solutions?><primary><emphasis role="strong">solutions</emphasis></primary><seealso> <link linkend="iddle3584" preference="0"><emphasis role="strong">policy(s)</emphasis>, interruption</link>.</seealso></indexterm><indexterm id="iddle4328" significance="normal"><?indexkey S?><?primarykey solutions?><primary><emphasis role="strong">solutions</emphasis></primary><seealso> <link linkend="iddle3976" preference="0"><emphasis role="strong">result(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle4329" significance="normal"><?indexkey S?><?primarykey solutions?><primary><emphasis role="strong">solutions</emphasis></primary><seealso> <link linkend="iddle4483" preference="0"><emphasis role="strong">strategies</emphasis>, search</link>.</seealso></indexterm><indexterm id="iddle4330" significance="normal"><?indexkey S?><?primarykey solutions?><primary><emphasis role="strong">solutions</emphasis></primary><seealso> <link linkend="iddle4835" preference="0"><emphasis role="strong">thread(s)</emphasis>, termination</link>.</seealso></indexterm><indexterm id="iddle4463" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey DESIGN?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>design</secondary></indexterm><indexterm id="iddle4464" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey DESIGN?><?tertiarykey INTERRUPTION POLICY?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>design</secondary><tertiary>interruption policy</tertiary></indexterm><indexterm id="iddle4469" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey INTERRUPTEDEXCEPTION HANDLING?><primary><emphasis role="strong">strategies</emphasis></primary><secondary><literal>InterruptedException</literal> handling</secondary></indexterm><indexterm id="iddle4515" significance="normal"><?indexkey S?><?primarykey swallowing interrupts?><primary><emphasis role="strong">swallowing interrupts</emphasis></primary></indexterm><indexterm id="iddle4516" significance="normal"><?indexkey S?><?primarykey swallowing interrupts?><?secondarykey AS DISCOURAGED PRACTICE?><primary><emphasis role="strong">swallowing interrupts</emphasis></primary><secondary>as discouraged practice</secondary></indexterm><indexterm id="iddle4974" significance="normal"><?indexkey T?><?primarykey trigger(ing)?><primary><emphasis role="strong">trigger(ing)</emphasis></primary><seealso> <link linkend="iddle3584" preference="0"><emphasis role="strong">policy(s)</emphasis>, interruption</link>.</seealso></indexterm><literal>TIMED_WAITING</literal>). The distinction between a blocking operation and an ordinary operation that merely takes a long time to finish is that a blocked thread must wait for an event that is beyond its control before it can proceed—the I/O completes, the lock becomes available, or the external computation finishes. When that external event occurs, the thread is placed back in the <literal>RUNNABLE</literal> state and becomes eligible again for scheduling.</para>
<para>The <literal>put</literal> and <literal>take</literal> methods of <literal>BlockingQueue</literal> throw the checked <literal>InterruptedException</literal>, as do a number of other library methods such as <literal>Thread.sleep</literal>. When a method can throw <literal>InterruptedException</literal>, it is telling you that it is a blocking method, and further that if it is <emphasis>interrupted</emphasis>, it will make an effort to stop blocking early.</para>
<para><literal>Thread</literal> provides the <literal>interrupt</literal> method for interrupting a thread and for querying whether a thread has been interrupted. Each thread has a boolean property that represents its interrupted status; interrupting a thread sets this status.</para>
<para>Interruption is a <emphasis>cooperative</emphasis> mechanism. One thread cannot force another to stop what it is doing and do something else; when thread <emphasis>A</emphasis> interrupts thread <emphasis>B</emphasis>, <emphasis>A</emphasis> is merely requesting that <emphasis>B</emphasis> stop what it is doing when it gets to a convenient stopping point—if it feels like it. While there is nothing in the API or language specification that demands any specific application-level semantics for interruption, the most sensible use for interruption is to cancel an activity. Blocking methods that are responsive to interruption make it easier to cancel long-running activities on a timely basis.</para>
<para>When your code calls a method that throws <literal>InterruptedException</literal>, then your method is a blocking method too, and must have a plan for responding to interruption. For library code, there are basically two choices:</para>
<formalpara><title><emphasis role="strong"><?design?>Propagate the InterruptedException.</emphasis></title><para>This is often the most sensible policy if you can get away with it—just propagate the <literal>InterruptedException</literal> to your caller. This could involve not catching <literal>InterruptedException</literal>, or catching it and throwing it again after performing some brief activity-specific cleanup.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Restore the interrupt.</emphasis></title><para>Sometimes you cannot throw <literal>InterruptedException</literal>, for instance when your code is part of a <literal>Runnable</literal>. In these situations, you must catch <literal>InterruptedException</literal> and restore the interrupted status by calling <literal>interrupt</literal> on the current thread, so that code higher up the call stack can see that an interrupt was issued, as demonstrated in <link linkend="ch05list10" preference="0">Listing 5.10</link>.</para></formalpara>
<para role="continued">You can get much more sophisticated with interruption, but these two approaches should work in the vast majority of situations. But there is one thing you should <emphasis>not</emphasis> do with <literal>InterruptedException</literal>—catch it and do nothing in response. This deprives code higher up on the call stack of the opportunity to act on the interruption, because the evidence that the thread was interrupted is lost. <emphasis>The only situation in which it is acceptable to swallow an interrupt is when you are extending Thread and therefore control all the code higher up on the call stack.</emphasis> Cancellation and interruption are covered in greater detail in <link linkend="ch07" preference="0">Chapter 7</link>.</para>

<para><?docpage num="94"?></para><example id="ch05list10" label="5.10" role="Listing" xreflabel="5.10" condition="94">

<title id="ch05list10__title">Restoring the Interrupted Status so as Not to Swallow the Interrupt.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class TaskRunnable implements Runnable {
    BlockingQueue&lt;Task&gt; queue;
    ...
    public void run() {
        try {
            processTask(queue.take());
        } catch (InterruptedException e) {
             <emphasis>// restore interrupted status</emphasis>
             <emphasis role="strong">Thread.currentThread().interrupt();</emphasis>
        }
    }
}
</programlisting>
</example>
</section>
<section id="ch05lev1sec5" condition="94" label="5.5" xreflabel="5.5"><?docpage num="94"?>
<title id="ch05lev1sec5__title">Synchronizers</title>
<para><indexterm id="iddle1440" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1582" significance="normal"><?indexkey C?><?primarykey containers?><?secondarykey BLOCKING QUEUES AS?><primary><emphasis role="strong">containers</emphasis></primary><secondary>blocking queues as</secondary></indexterm><indexterm id="iddle1624" significance="normal"><?indexkey C?><?primarykey control flow?><?secondarykey COORDINATION?><primary><emphasis role="strong">control flow</emphasis></primary><secondary>coordination</secondary></indexterm><indexterm id="iddle1625" significance="normal"><?indexkey C?><?primarykey control flow?><?secondarykey COORDINATION?><?tertiarykey IN PRODUCER-CONSUMER PATTERN?><primary><emphasis role="strong">control flow</emphasis></primary><secondary>coordination</secondary><tertiary>in producer-consumer pattern</tertiary></indexterm><indexterm id="iddle1629" significance="normal"><?indexkey C?><?primarykey control flow?><?secondarykey LATCH CHARACTERISTICS?><primary><emphasis role="strong">control flow</emphasis></primary><secondary>latch characteristics</secondary></indexterm><indexterm id="iddle1653" significance="normal"><?indexkey C?><?primarykey coordination?><?secondarykey CONTROL FLOW?><primary><emphasis role="strong">coordination</emphasis></primary><secondary>control flow</secondary></indexterm><indexterm id="iddle1654" significance="normal"><?indexkey C?><?primarykey coordination?><?secondarykey CONTROL FLOW?><?tertiarykey PRODUCER-CONSUMER PATTERN, BLOCKING QUEUES USE?><primary><emphasis role="strong">coordination</emphasis></primary><secondary>control flow</secondary><tertiary>producer-consumer pattern, blocking queues use</tertiary></indexterm><indexterm id="iddle1728" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey SYNCHRONIZER?><primary><emphasis role="strong">creation</emphasis></primary><secondary>synchronizer</secondary></indexterm><indexterm id="iddle1903" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey CONTROL FLOW?><primary><emphasis role="strong">design</emphasis></primary><secondary>control flow</secondary></indexterm><indexterm id="iddle1904" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey CONTROL FLOW?><?tertiarykey LATCH CHARACTERISTICS?><primary><emphasis role="strong">design</emphasis></primary><secondary>control flow</secondary><tertiary>latch characteristics</tertiary></indexterm><indexterm id="iddle2026" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey STATE?><?tertiarykey SYNCHRONIZER ROLE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>state</secondary><tertiary>synchronizer role</tertiary></indexterm><indexterm id="iddle2194" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey TASKRUNNABLE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>TaskRunnable</literal></secondary></indexterm><indexterm id="iddle2446" significance="normal"><?indexkey G?><?primarykey gate?><?secondarykey AS LATCH ROLE?><primary><emphasis role="strong">gate</emphasis></primary><secondary>as latch role</secondary></indexterm><indexterm id="iddle2932" significance="normal"><?indexkey L?><?primarykey latch(es)?><primary><emphasis role="strong">latch(es)</emphasis></primary><seealso> <link linkend="iddle3194" preference="0"><emphasis role="strong">memory</emphasis>, barriers</link>.</seealso></indexterm><indexterm id="iddle2933" significance="normal"><?indexkey L?><?primarykey latch(es)?><primary><emphasis role="strong">latch(es)</emphasis></primary><seealso> <link linkend="iddle3750" preference="0"><emphasis role="strong">queue(s)</emphasis>, blocking</link>.</seealso></indexterm><indexterm id="iddle2934" significance="normal"><?indexkey L?><?primarykey latch(es)?><primary><emphasis role="strong">latch(es)</emphasis></primary><seealso> <link linkend="iddle4145" preference="0"><emphasis role="strong">semaphores</emphasis></link>.</seealso></indexterm><indexterm id="iddle2935" significance="normal"><?indexkey L?><?primarykey latch(es)?><primary><emphasis role="strong">latch(es)</emphasis></primary><seealso> <link linkend="iddle4585" preference="0"><emphasis role="strong">synchronizer(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2936" significance="normal"><?indexkey L?><?primarykey latch(es)?><primary><emphasis role="strong">latch(es)</emphasis></primary></indexterm><indexterm id="iddle3683" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey CONTROL FLOW COORDINATION?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>control flow coordination</secondary></indexterm><indexterm id="iddle3684" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey CONTROL FLOW COORDINATION?><?tertiarykey BLOCKING QUEUES USE?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>control flow coordination</secondary><tertiary>blocking queues use</tertiary></indexterm><indexterm id="iddle4398" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey ENCAPSULATION?><?tertiarykey SYNCHRONIZER ROLE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>encapsulation</secondary><tertiary>synchronizer role</tertiary></indexterm><indexterm id="iddle4585" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary><seealso> <link linkend="iddle4136" preference="0"><emphasis role="strong">Semaphore</emphasis></link>.</seealso></indexterm><indexterm id="iddle4586" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary><seealso> <link linkend="iddle1741" preference="0"><emphasis role="strong">CyclicBarrier</emphasis></link>.</seealso></indexterm><indexterm id="iddle4587" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary><seealso> <link linkend="iddle2940" preference="0"><emphasis role="strong">latch(es)</emphasis>, <literal>FutureTask</literal></link>.</seealso></indexterm><indexterm id="iddle4588" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary><seealso> <link linkend="iddle2238" preference="0"><emphasis role="strong">Exchanger</emphasis></link>.</seealso></indexterm><indexterm id="iddle4589" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary><seealso> <link linkend="iddle1697" preference="0"><emphasis role="strong">CountDownLatch</emphasis></link>.</seealso></indexterm><indexterm id="iddle4590" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary></indexterm>Blocking queues are unique among the collections classes: not only do they act as containers for objects, but they can also coordinate the control flow of producer and consumer threads because <literal>take</literal> and <literal>put</literal> block until the queue enters the desired state (not empty or not full).</para>
<para>A <emphasis>synchronizer</emphasis> is any object that coordinates the control flow of threads based on its state. Blocking queues can act as synchronizers; other types of synchronizers include semaphores, barriers, and latches. There are a number of synchronizer classes in the platform library; if these do not meet your needs, you can also create your own using the mechanisms described in <link linkend="ch14" preference="0">Chapter 14</link>.</para>
<para>All synchronizers share certain structural properties: they encapsulate state that determines whether threads arriving at the synchronizer should be allowed to pass or forced to wait, provide methods to manipulate that state, and provide methods to wait efficiently for the synchronizer to enter the desired state.</para>
<section id="ch05lev2sec10" label="5.5.1" xreflabel="5.5.1">
<title id="ch05lev2sec10__title">Latches</title>
<para>A <emphasis>latch</emphasis> is a synchronizer that can delay the progress of threads until it reaches its <emphasis>terminal</emphasis> state [CPJ 3.4.2]. A latch acts as a gate: until the latch reaches the terminal state the gate is closed and no thread can pass, and in the terminal state the gate opens, allowing all threads to pass. Once the latch reaches the terminal state, it cannot change state again, so it remains open forever. Latches can be used to ensure that certain activities do not proceed until other one-time activities complete, such as:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Ensuring that a computation does not proceed until resources it needs have been initialized. A simple binary (two-state) latch could be used to indicate “Resource <emphasis>R</emphasis> has been initialized”, and any activity that requires <emphasis>R</emphasis> would wait first on this latch.</para></listitem>
<listitem><para><?docpage num="95"?><?docpage num="96"?><indexterm id="iddle1700" significance="normal"><?indexkey C?><?primarykey CountDownLatch?><?secondarykey TESTHARNESS EXAMPLE USE?><primary><emphasis role="strong">CountDownLatch</emphasis></primary><secondary><literal>TestHarness</literal> example use</secondary></indexterm><indexterm id="iddle2197" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey TESTHARNESS?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>TestHarness</literal></secondary></indexterm><indexterm id="iddle1136" significance="normal"><?indexkey A?><?primarykey asynchrony/asynchronous?><?secondarykey TASKS?><?tertiarykey FUTURETASK HANDLING?><primary><emphasis role="strong">asynchrony/asynchronous</emphasis></primary><secondary>tasks</secondary><tertiary><literal>FutureTask</literal> handling</tertiary></indexterm><indexterm id="iddle1291" significance="normal"><?indexkey C?><?primarykey Callable?><?secondarykey FUTURETASK USE?><primary><emphasis role="strong">Callable</emphasis></primary><secondary><literal>FutureTask</literal> use</secondary></indexterm><indexterm id="iddle1300" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey AS FORM OF COMPLETION?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>as form of completion</secondary></indexterm><indexterm id="iddle1397" significance="normal"><?indexkey C?><?primarykey completion?><primary><emphasis role="strong">completion</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle1441" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1607" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey THREAD?><?tertiarykey LATCHES HELP WITH?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>thread</secondary><tertiary>latches help with</tertiary></indexterm><indexterm id="iddle1697" significance="normal"><?indexkey C?><?primarykey CountDownLatch?><primary><emphasis role="strong">CountDownLatch</emphasis></primary></indexterm><indexterm id="iddle2225" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey AS FORM OF COMPLETION?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>as form of completion</secondary></indexterm><indexterm id="iddle2423" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey CHARACTERISTICS OF?><primary><emphasis role="strong">Future</emphasis></primary><secondary>characteristics of</secondary></indexterm><indexterm id="iddle2430" significance="normal"><?indexkey F?><?primarykey FutureTask?><primary><emphasis role="strong">FutureTask</emphasis></primary></indexterm><indexterm id="iddle2432" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey AS LATCH?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>as latch</secondary></indexterm><indexterm id="iddle2940" significance="normal"><?indexkey L?><?primarykey latch(es)?><?secondarykey FUTURETASK?><primary><emphasis role="strong">latch(es)</emphasis></primary><secondary><literal>FutureTask</literal></secondary></indexterm><indexterm id="iddle3982" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey CALLABLE USE INSTEAD OF RUNNABLE?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary><literal>Callable</literal> use instead of <literal>Runnable</literal></secondary></indexterm><indexterm id="iddle4019" significance="normal"><?indexkey R?><?primarykey running?><?secondarykey FUTURETASK STATE?><primary><emphasis role="strong">running</emphasis></primary><secondary><literal>FutureTask</literal> state</secondary></indexterm><indexterm id="iddle4424" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey TASK?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle4425" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey TASK?><?tertiarykey IMPACT ON FUTURE.GET?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>task</secondary><tertiary>impact on Future.get</tertiary></indexterm><indexterm id="iddle4604" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey ASYNCHRONOUS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>asynchronous</secondary></indexterm><indexterm id="iddle4605" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey ASYNCHRONOUS?><?tertiarykey FUTURETASK HANDLING?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>asynchronous</secondary><tertiary><literal>FutureTask</literal> handling</tertiary></indexterm><indexterm id="iddle4654" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey STATE?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle4655" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey STATE?><?tertiarykey EFFECT ON FUTURE.GET?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>state</secondary><tertiary>effect on <literal>Future.get</literal></tertiary></indexterm><indexterm id="iddle5144" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey WAITING TO RUN?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>waiting to run</secondary></indexterm><indexterm id="iddle5145" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey WAITING TO RUN?><?tertiarykey FUTURETASK STATE?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>waiting to run</secondary><tertiary><literal>FutureTask</literal> state</tertiary></indexterm>Ensuring that a service does not start until other services on which it depends have started. Each service would have an associated binary latch; starting service <emphasis>S</emphasis> would involve first waiting on the latches for other services on which <emphasis>S</emphasis> depends, and then releasing the <emphasis>S</emphasis> latch after startup completes so any services that depend on <emphasis>S</emphasis> can then proceed.</para></listitem>
<listitem><para>Waiting until all the parties involved in an activity, for instance the players in a multi-player game, are ready to proceed. In this case, the latch reaches the terminal state after all the players are ready.</para></listitem>
</itemizedlist>
<para role="continued"><literal>CountDownLatch</literal> is a flexible latch implementation that can be used in any of these situations; it allows one or more threads to wait for a set of events to occur. The latch state consists of a counter initialized to a positive number, representing the number of events to wait for. The <literal>countDown</literal> method decrements the counter, indicating that an event has occurred, and the <literal>await</literal> methods wait for the counter to reach zero, which happens when all the events have occurred. If the counter is nonzero on entry, <literal>await</literal> blocks until the counter reaches zero, the waiting thread is interrupted, or the wait times out.</para>
<para><literal>TestHarness</literal> in <link linkend="ch05list11" preference="0">Listing 5.11</link> illustrates two common uses for latches. <literal>TestHarness</literal> creates a number of threads that run a given task concurrently. It uses two latches, a “starting gate” and an “ending gate”. The starting gate is initialized with a count of one; the ending gate is initialized with a count equal to the number of worker threads. The first thing each worker thread does is wait on the starting gate; this ensures that none of them starts working until they all are ready to start. The last thing each does is count down on the ending gate; this allows the master thread to wait efficiently until the last of the worker threads has finished, so it can calculate the elapsed time.</para>
<para>Why did we bother with the latches in <literal>TestHarness</literal> instead of just starting the threads immediately after they are created? Presumably, we wanted to measure how long it takes to run a task <emphasis>n</emphasis> times <emphasis>concurrently</emphasis>. If we simply created and started the threads, the threads started earlier would have a “head start” on the later threads, and the degree of contention would vary over time as the number of active threads increased or decreased. Using a starting gate allows the master thread to release all the worker threads at once, and the ending gate allows the master thread to wait for the <emphasis>last</emphasis> thread to finish rather than waiting sequentially for each thread to finish.</para>
</section>
<section id="ch05lev2sec11" label="5.5.2" xreflabel="5.5.2">
<title id="ch05lev2sec11__title">FutureTask</title>
<para><literal>FutureTask</literal> also acts like a latch. (<literal>FutureTask</literal> implements <literal>Future</literal>, which describes an abstract result-bearing computation [CPJ 4.3.3].) A computation represented by a <literal>FutureTask</literal> is implemented with a <literal>Callable</literal>, the result-bearing equivalent of <literal>Runnable</literal>, and can be in one of three states: waiting to run, running, or completed. Completion subsumes all the ways a computation can complete, including normal completion, cancellation, and exception. Once a <literal>FutureTask</literal> enters the completed state, it stays in that state forever.</para>
<para>The behavior of <literal>Future.get</literal> depends on the state of the task. If it is completed, <literal>get</literal> returns the result immediately, and otherwise blocks until the task transitions <?docpage num="97"?><indexterm id="iddle2039" significance="normal"><?indexkey E?><?primarykey Error?><primary><emphasis role="strong">Error</emphasis></primary></indexterm><indexterm id="iddle2040" significance="normal"><?indexkey E?><?primarykey Error?><?secondarykey CALLABLE HANDLING?><primary><emphasis role="strong">Error</emphasis></primary><secondary><literal>Callable</literal> handling</secondary></indexterm><indexterm id="iddle2156" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PRELOADER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Preloader</literal></secondary></indexterm><indexterm id="iddle2226" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey CALLABLE HANDLING?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary><literal>Callable</literal> handling</secondary></indexterm><indexterm id="iddle2261" significance="normal"><?indexkey E?><?primarykey Executor framework?><?secondarykey FUTURETASK USE?><primary><emphasis role="strong">Executor framework</emphasis></primary><secondary><literal>FutureTask</literal> use</secondary></indexterm><indexterm id="iddle2436" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey EXAMPLE USE?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>example use</secondary></indexterm>to the completed state and then returns the result or throws an exception. <literal>FutureTask</literal> conveys the result from the thread executing the computation to the thread(s) retrieving the result; the specification of <literal>FutureTask</literal> guarantees that this transfer constitutes a safe publication of the result.</para>
<example id="ch05list11" label="5.11" role="Listing" xreflabel="5.11" condition="96">
<?docpage num="96"?>
<title id="ch05list11__title">Using <literal>CountDownLatch</literal> for Starting and Stopping Threads in Timing Tests.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class TestHarness {
    public long timeTasks(int nThreads, final Runnable task)
            throws InterruptedException {
        final CountDownLatch startGate = new CountDownLatch(1);
        final CountDownLatch endGate = new CountDownLatch(nThreads);

        for (int i = 0; i &lt; nThreads; i++) {
            Thread t = new Thread() {
                public void run() {
                    try {
                        startGate.await();
                        try {
                            task.run();
                        } finally {
                            endGate.countDown();
                        }
                    } catch (InterruptedException ignored) { }
                }
            };
            t.start();
        }

        long start = System.nanoTime();
        startGate.countDown();
        endGate.await();
        long end = System.nanoTime();
        return end-start;
    }
}
</programlisting>
</example>
<para><literal>FutureTask</literal> is used by the <literal>Executor</literal> framework to represent asynchronous tasks, and can also be used to represent any potentially lengthy computation that can be started before the results are needed. <literal>Preloader</literal> in <link linkend="ch05list12" preference="0">Listing 5.12</link> uses <literal>FutureTask</literal> to perform an expensive computation whose results are needed later; by starting the computation early, you reduce the time you would have to wait later when you actually need the results.</para>
<example id="ch05list12" label="5.12" role="Listing" xreflabel="5.12" condition="97">
<title id="ch05list12__title">Using <literal>FutureTask</literal> to Preload Data that is Needed Later.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class Preloader {
    private final FutureTask&lt;ProductInfo&gt; future =
        new FutureTask&lt;ProductInfo&gt;(new Callable&lt;ProductInfo&gt;() {
            public ProductInfo call() throws DataLoadException {
                return loadProductInfo();
            }
        });
    private final Thread thread = new Thread(future);

    public void start() { thread.start(); }

    public ProductInfo get()
            throws DataLoadException, InterruptedException {
        try {
            return future.get();
        } catch (ExecutionException e) {
            Throwable cause = e.getCause();
            if (cause instanceof DataLoadException)
                throw (DataLoadException) cause;
            else
                throw launderThrowable(cause);
        }
    }
}
</programlisting>
</example>
<para><literal>Preloader</literal> creates a <literal>FutureTask</literal> that describes the task of loading product information from a database and a thread in which the computation will be performed. It provides a <literal>start</literal> method to start the thread, since it is inadvisable to start a thread from a constructor or static initializer. When the program later needs the <literal>ProductInfo</literal>, it can call <literal>get</literal>, which returns the loaded data if it is ready, or waits for the load to complete if not.</para>
<para>Tasks described by <literal>Callable</literal> can throw checked and unchecked exceptions, and any code can throw an <literal>Error</literal>. Whatever the task code may throw, it is <?docpage num="98"?><indexterm id="iddle1319" significance="normal"><?indexkey C?><?primarykey CancellationException?><primary><emphasis role="strong">CancellationException</emphasis></primary></indexterm><indexterm id="iddle1320" significance="normal"><?indexkey C?><?primarykey CancellationException?><?secondarykey CALLABLE HANDLING?><primary><emphasis role="strong">CancellationException</emphasis></primary><secondary><literal>Callable</literal> handling</secondary></indexterm><indexterm id="iddle1442" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1701" significance="normal"><?indexkey C?><?primarykey counting semaphores?><primary><emphasis role="strong">counting semaphores</emphasis></primary><seealso> <link linkend="iddle4136" preference="0"><emphasis role="strong">Semaphore</emphasis></link>.</seealso></indexterm><indexterm id="iddle2252" significance="normal"><?indexkey E?><?primarykey ExecutionException?><primary><emphasis role="strong">ExecutionException</emphasis></primary></indexterm><indexterm id="iddle2253" significance="normal"><?indexkey E?><?primarykey ExecutionException?><?secondarykey CALLABLE HANDLING?><primary><emphasis role="strong">ExecutionException</emphasis></primary><secondary><literal>Callable</literal> handling</secondary></indexterm><indexterm id="iddle2701" significance="normal"><?indexkey I?><?primarykey IllegalStateException?><primary><emphasis role="strong">IllegalStateException</emphasis></primary></indexterm><indexterm id="iddle2702" significance="normal"><?indexkey I?><?primarykey IllegalStateException?><?secondarykey CALLABLE HANDLING?><primary><emphasis role="strong">IllegalStateException</emphasis></primary><secondary><literal>Callable</literal> handling</secondary></indexterm><indexterm id="iddle3551" significance="normal"><?indexkey P?><?primarykey permits?><primary><emphasis role="strong">permits</emphasis></primary><seealso> <link linkend="iddle4145" preference="0"><emphasis role="strong">semaphores</emphasis></link>.</seealso></indexterm><indexterm id="iddle3612" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey RESOURCE?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>resource</secondary></indexterm><indexterm id="iddle3613" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey RESOURCE?><?tertiarykey SEMAPHORE USE?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>resource</secondary><tertiary>semaphore use</tertiary></indexterm><indexterm id="iddle3841" significance="normal"><?indexkey R?><?primarykey release?><?secondarykey PERMIT?><primary><emphasis role="strong">release</emphasis></primary><secondary>permit</secondary></indexterm><indexterm id="iddle3842" significance="normal"><?indexkey R?><?primarykey release?><?secondarykey PERMIT?><?tertiarykey SEMAPHORE MANAGEMENT?><primary><emphasis role="strong">release</emphasis></primary><secondary>permit</secondary><tertiary>semaphore management</tertiary></indexterm><indexterm id="iddle3936" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey POOLS?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>pools</secondary></indexterm><indexterm id="iddle3937" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey POOLS?><?tertiarykey SEMAPHORE USE?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>pools</secondary><tertiary>semaphore use</tertiary></indexterm><indexterm id="iddle4025" significance="normal"><?indexkey R?><?primarykey RuntimeException?><?secondarykey CALLABLE HANDLING?><primary><emphasis role="strong">RuntimeException</emphasis></primary><secondary><literal>Callable</literal> handling</secondary></indexterm><indexterm id="iddle4136" significance="normal"><?indexkey S?><?primarykey Semaphore?><primary><emphasis role="strong">Semaphore</emphasis></primary></indexterm><indexterm id="iddle4145" significance="normal"><?indexkey S?><?primarykey semaphores?><primary><emphasis role="strong">semaphores</emphasis></primary></indexterm><indexterm id="iddle4146" significance="normal"><?indexkey S?><?primarykey semaphores?><primary><emphasis role="strong">semaphores</emphasis></primary></indexterm><indexterm id="iddle4150" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey COUNTING?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>counting</secondary></indexterm><indexterm id="iddle4880" significance="normal"><?indexkey T?><?primarykey Throwable?><primary><emphasis role="strong">Throwable</emphasis></primary></indexterm><indexterm id="iddle4881" significance="normal"><?indexkey T?><?primarykey Throwable?><?secondarykey FUTURETASK HANDLING?><primary><emphasis role="strong">Throwable</emphasis></primary><secondary><literal>FutureTask</literal> handling</secondary></indexterm>wrapped in an <literal>ExecutionException</literal> and rethrown from <literal>Future.get</literal>. This complicates code that calls <literal>get</literal>, not only because it must deal with the possibility of <literal>ExecutionException</literal> (and the unchecked <literal>CancellationException</literal>), but also because the cause of the <literal>ExecutionException</literal> is returned as a <literal>Throwable</literal>, which is inconvenient to deal with.</para>
<para>When <literal>get</literal> throws an <literal>ExecutionException</literal> in <literal>Preloader</literal>, the cause will fall into one of three categories: a checked exception thrown by the <literal>Callable</literal>, a <literal>RuntimeException</literal>, or an <literal>Error</literal>. We must handle each of these cases separately, but we will use the <literal>launderThrowable</literal> utility method in <link linkend="ch05list13" preference="0">Listing 5.13</link> to encapsulate some of the messier exception-handling logic. Before calling <literal>launderThrowable</literal>, <literal>Preloader</literal> tests for the known checked exceptions and rethrows them. That leaves only unchecked exceptions, which <literal>Preloader</literal> handles by calling <literal>launderThrowable</literal> and throwing the result. If the <literal>Throwable</literal> passed to <literal>launderThrowable</literal> is an <literal>Error</literal>, <literal>launderThrowable</literal> rethrows it directly; if it is not a <literal>RuntimeException</literal>, it throws an <literal>IllegalStateException</literal> to indicate a logic error. That leaves only <literal>RuntimeException</literal>, which <literal>launderThrowable</literal> returns to its caller, and which the caller generally rethrows.</para>
<example id="ch05list13" label="5.13" role="Listing" xreflabel="5.13" condition="98">
<title id="ch05list13__title">Coercing an Unchecked <literal>Throwable</literal> to a <literal>RuntimeException</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered"><emphasis>/** If the Throwable is an Error, throw it; if it is a</emphasis>
 <emphasis>*  RuntimeException return it, otherwise throw IllegalStateException</emphasis>
 <emphasis>*/</emphasis>
public static RuntimeException launderThrowable(Throwable t) {
    if (t instanceof RuntimeException)
        return (RuntimeException) t;
    else if (t instanceof Error)
        throw (Error) t;
    else
        throw new IllegalStateException("Not unchecked", t);
}
</programlisting>
</example>
</section>
<section id="ch05lev2sec12" label="5.5.3" xreflabel="5.5.3">
<title id="ch05lev2sec12__title">Semaphores</title>
<para><emphasis>Counting semaphores</emphasis> are used to control the number of activities that can access a certain resource or perform a given action at the same time [CPJ 3.4.1]. Counting semaphores can be used to implement resource pools or to impose a bound on a collection.</para>
<para>A <literal>Semaphore</literal> manages a set of virtual <emphasis>permits</emphasis>; the initial number of permits is passed to the <literal>Semaphore</literal> constructor. Activities can acquire permits (as long as some remain) and release permits when they are done with them. If no permit is available, <literal>acquire</literal> blocks until one is (or until interrupted or the operation times out). The <literal>release</literal> method returns a permit to the semaphore. <footnote id="ch05fn04" label="4"><para>The implementation has no actual permit objects, and <literal>Semaphore</literal> does not associate dispensed permits with threads, so a permit acquired in one thread can be released from another thread. You can think of <literal>acquire</literal> as consuming a permit and <literal>release</literal> as creating one; a <literal>Semaphore</literal> is not limited to the number of permits it was created with.</para></footnote> A degenerate case <?docpage num="99"?><?docpage num="100"?><indexterm id="iddle1039" significance="normal"><?indexkey A?><?primarykey action(s)?><?secondarykey BARRIER?><primary><emphasis role="strong">action(s)</emphasis></primary><secondary>barrier</secondary></indexterm><indexterm id="iddle1060" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey PARALLEL ITERATIVE?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>parallel iterative</secondary></indexterm><indexterm id="iddle1061" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey PARALLEL ITERATIVE?><?tertiarykey BARRIER USE IN?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>parallel iterative</secondary><tertiary>barrier use in</tertiary></indexterm><indexterm id="iddle1189" significance="normal"><?indexkey B?><?primarykey barrier(s)?><primary><emphasis role="strong">barrier(s)</emphasis></primary><seealso> <link linkend="iddle2932" preference="0"><emphasis role="strong">latch(es)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1190" significance="normal"><?indexkey B?><?primarykey barrier(s)?><primary><emphasis role="strong">barrier(s)</emphasis></primary><seealso> <link linkend="iddle4145" preference="0"><emphasis role="strong">semaphores</emphasis></link>.</seealso></indexterm><indexterm id="iddle1191" significance="normal"><?indexkey B?><?primarykey barrier(s)?><primary><emphasis role="strong">barrier(s)</emphasis></primary><seealso> <link linkend="iddle4585" preference="0"><emphasis role="strong">synchronizer(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1192" significance="normal"><?indexkey B?><?primarykey barrier(s)?><primary><emphasis role="strong">barrier(s)</emphasis></primary></indexterm><indexterm id="iddle1194" significance="normal"><?indexkey B?><?primarykey barrier(s)?><?secondarykey ACTION?><primary><emphasis role="strong">barrier(s)</emphasis></primary><secondary>action</secondary></indexterm><indexterm id="iddle1197" significance="normal"><?indexkey B?><?primarykey barrier(s)?><?secondarykey POINT?><primary><emphasis role="strong">barrier(s)</emphasis></primary><secondary>point</secondary></indexterm><indexterm id="iddle1204" significance="normal"><?indexkey B?><?primarykey binary semaphore?><primary><emphasis role="strong">binary semaphore</emphasis></primary></indexterm><indexterm id="iddle1205" significance="normal"><?indexkey B?><?primarykey binary semaphore?><?secondarykey MUTEX USE?><primary><emphasis role="strong">binary semaphore</emphasis></primary><secondary>mutex use</secondary></indexterm><indexterm id="iddle1209" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey BOUNDED COLLECTIONS?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>bounded collections</secondary></indexterm><indexterm id="iddle1210" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey BOUNDED COLLECTIONS?><?tertiarykey SEMAPHORE MANAGEMENT OF?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>bounded collections</secondary><tertiary>semaphore management of</tertiary></indexterm><indexterm id="iddle1242" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey BLOCKING COLLECTIONS?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>blocking collections</secondary></indexterm><indexterm id="iddle1243" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey BLOCKING COLLECTIONS?><?tertiarykey SEMAPHORE MANAGEMENT OF?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>blocking collections</secondary><tertiary>semaphore management of</tertiary></indexterm><indexterm id="iddle1259" significance="normal"><?indexkey B?><?primarykey BrokenBarrierException?><primary><emphasis role="strong">BrokenBarrierException</emphasis></primary></indexterm><indexterm id="iddle1260" significance="normal"><?indexkey B?><?primarykey BrokenBarrierException?><?secondarykey PARALLEL ITERATIVE ALGORITHM USE?><primary><emphasis role="strong">BrokenBarrierException</emphasis></primary><secondary>parallel iterative algorithm use</secondary></indexterm><indexterm id="iddle1374" significance="normal"><?indexkey C?><?primarykey collections?><?secondarykey BOUNDED BLOCKING?><primary><emphasis role="strong">collections</emphasis></primary><secondary>bounded blocking</secondary></indexterm><indexterm id="iddle1375" significance="normal"><?indexkey C?><?primarykey collections?><?secondarykey BOUNDED BLOCKING?><?tertiarykey SEMAPHORE MANAGEMENT OF?><primary><emphasis role="strong">collections</emphasis></primary><secondary>bounded blocking</secondary><tertiary>semaphore management of</tertiary></indexterm><indexterm id="iddle1443" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1741" significance="normal"><?indexkey C?><?primarykey CyclicBarrier?><primary><emphasis role="strong">CyclicBarrier</emphasis></primary></indexterm><indexterm id="iddle2067" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey LATCH HANDLING BASED ON?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>latch handling based on</secondary></indexterm><indexterm id="iddle2443" significance="normal"><?indexkey G?><?primarykey gate?><primary><emphasis role="strong">gate</emphasis></primary><seealso> <link linkend="iddle3194" preference="0"><emphasis role="strong">memory</emphasis>, barriers</link>.</seealso></indexterm><indexterm id="iddle2444" significance="normal"><?indexkey G?><?primarykey gate?><primary><emphasis role="strong">gate</emphasis></primary><seealso> <link linkend="iddle3321" preference="0"><emphasis role="strong">notification</emphasis>, conditional</link>.</seealso></indexterm><indexterm id="iddle2445" significance="normal"><?indexkey G?><?primarykey gate?><primary><emphasis role="strong">gate</emphasis></primary><seealso> <link linkend="iddle2932" preference="0"><emphasis role="strong">latch(es)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2882" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey PARALLEL ITERATIVE ALGORITHMS?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>parallel iterative algorithms</secondary></indexterm><indexterm id="iddle2883" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey PARALLEL ITERATIVE ALGORITHMS?><?tertiarykey BARRIER MANAGEMENT OF?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>parallel iterative algorithms</secondary><tertiary>barrier management of</tertiary></indexterm><indexterm id="iddle2937" significance="normal"><?indexkey L?><?primarykey latch(es)?><?secondarykey BARRIERS VS?><primary><emphasis role="strong">latch(es)</emphasis></primary><secondary>barriers vs</secondary></indexterm><indexterm id="iddle3284" significance="normal"><?indexkey M?><?primarykey mutexes (mutual exclusion locks)?><?secondarykey BINARY SEMAPHORE USE AS?><primary><emphasis role="strong">mutexes (mutual exclusion locks)</emphasis></primary><secondary>binary semaphore use as</secondary></indexterm><indexterm id="iddle3357" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey POOLS?><?tertiarykey BOUNDED, SEMAPHORE MANAGEMENT OF?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>pools</secondary><tertiary>bounded, semaphore management of</tertiary></indexterm><indexterm id="iddle3452" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey ITERATIVE ALGORITHMS?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>iterative algorithms</secondary></indexterm><indexterm id="iddle3453" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey ITERATIVE ALGORITHMS?><?tertiarykey BARRIER MANAGEMENT OF?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>iterative algorithms</secondary><tertiary>barrier management of</tertiary></indexterm><indexterm id="iddle3555" significance="normal"><?indexkey P?><?primarykey point(s)?><primary><emphasis role="strong">point(s)</emphasis></primary></indexterm><indexterm id="iddle3556" significance="normal"><?indexkey P?><?primarykey point(s)?><?secondarykey BARRIER?><primary><emphasis role="strong">point(s)</emphasis></primary><secondary>barrier</secondary></indexterm><indexterm id="iddle3609" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey OBJECT?><?tertiarykey BOUNDED, SEMAPHORE USE?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>object</secondary><tertiary>bounded, semaphore use</tertiary></indexterm><indexterm id="iddle4123" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey BINARY SEMAPHORES?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>binary semaphores</secondary></indexterm><indexterm id="iddle4148" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey BINARY?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>binary</secondary></indexterm><indexterm id="iddle4149" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey BINARY?><?tertiarykey MUTEX USE?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>binary</secondary><tertiary>mutex use</tertiary></indexterm><indexterm id="iddle4574" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey TYPES?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>types</secondary><see> <link linkend="iddle3194" preference="0"><emphasis role="strong">memory</emphasis>, barriers</link>.</see></indexterm><indexterm id="iddle4575" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey TYPES?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>types</secondary><see> <link linkend="iddle1208" preference="0"><emphasis role="strong">block(ing)</emphasis></link>.</see></indexterm><indexterm id="iddle4576" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey TYPES?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>types</secondary><see> <link linkend="iddle2430" preference="0"><emphasis role="strong">FutureTask</emphasis></link>.</see></indexterm><indexterm id="iddle4577" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey TYPES?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>types</secondary><see> <link linkend="iddle2932" preference="0"><emphasis role="strong">latch(es)</emphasis></link>.</see></indexterm><indexterm id="iddle4578" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey TYPES?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>types</secondary><see> <link linkend="iddle4145" preference="0"><emphasis role="strong">semaphores</emphasis></link>.</see></indexterm><indexterm id="iddle4890" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey BARRIER HANDLING BASED ON?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>barrier handling based on</secondary></indexterm>of a counting semaphore is a binary semaphore, a <literal>Semaphore</literal> with an initial count of one. A binary semaphore can be used as a <emphasis>mutex</emphasis> with nonreentrant locking semantics; whoever holds the sole permit holds the mutex.</para>
<para>Semaphores are useful for implementing resource pools such as database connection pools. While it is easy to construct a fixed-sized pool that fails if you request a resource from an empty pool, what you really want is to <emphasis>block</emphasis> if the pool is empty and unblock when it becomes nonempty again. If you initialize a <literal>Semaphore</literal> to the pool size, <literal>acquire</literal> a permit before trying to fetch a resource from the pool, and <literal>release</literal> the permit after putting a resource back in the pool, <literal>acquire</literal> blocks until the pool becomes nonempty. This technique is used in the bounded buffer class in <link linkend="ch12" preference="0">Chapter 12</link>. (An easier way to construct a blocking object pool would be to use a <literal>BlockingQueue</literal> to hold the pooled resources.)</para>
<para>Similarly, you can use a <literal>Semaphore</literal> to turn any collection into a blocking bounded collection, as illustrated by <literal>BoundedHashSet</literal> in <link linkend="ch05list14" preference="0">Listing 5.14</link>. The semaphore is initialized to the desired maximum size of the collection. The <literal>add</literal> operation acquires a permit before adding the item into the underlying collection. If the underlying <literal>add</literal> operation does not actually add anything, it releases the permit immediately. Similarly, a successful <literal>remove</literal> operation releases a permit, enabling more elements to be added. The underlying <literal>Set</literal> implementation knows nothing about the bound; this is handled by <literal>BoundedHashSet</literal>.</para>
</section>
<section id="ch05lev2sec13" label="5.5.4" xreflabel="5.5.4">
<title id="ch05lev2sec13__title">Barriers</title>
<para>We have seen how latches can facilitate starting a group of related activities or waiting for a group of related activities to complete. Latches are single-use objects; once a latch enters the terminal state, it cannot be reset.</para>
<para><emphasis>Barriers</emphasis> are similar to latches in that they block a group of threads until some event has occurred [CPJ 4.4.3]. The key difference is that with a barrier, all the threads must come together at a barrier point <emphasis>at the same time</emphasis> in order to proceed. Latches are for waiting for <emphasis>events</emphasis>; barriers are for waiting for <emphasis>other threads</emphasis>. A barrier implements the protocol some families use to rendezvous during a day at the mall: “Everyone meet at McDonald’s at 6:00; once you get there, stay there until everyone shows up, and then we’ll figure out what we’re doing next.”</para>
<para><literal>CyclicBarrier</literal> allows a fixed number of parties to rendezvous repeatedly at a <emphasis>barrier point</emphasis> and is useful in parallel iterative algorithms that break down a problem into a fixed number of independent subproblems. Threads call <literal>await</literal> when they reach the barrier point, and <literal>await</literal> blocks until <emphasis>all</emphasis> the threads have reached the barrier point. If all threads meet at the barrier point, the barrier has been successfully passed, in which case all threads are released and the barrier is reset so it can be used again. If a call to <literal>await</literal> times out or a thread blocked in <literal>await</literal> is interrupted, then the barrier is considered <emphasis>broken</emphasis> and all outstanding calls to <literal>await</literal> terminate with <literal>BrokenBarrierException</literal>. If the barrier is successfully passed, <literal>await</literal> returns a unique arrival index for each thread, which can be used to “elect” a leader that takes some special action in the next iteration. <literal>CyclicBar</literal> <?docpage num="101"?><indexterm id="iddle2091" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BOUNDEDHASHSET?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BoundedHashSet</literal></secondary></indexterm><indexterm id="iddle4138" significance="normal"><?indexkey S?><?primarykey Semaphore?><?secondarykey EXAMPLE USE?><primary><emphasis role="strong">Semaphore</emphasis></primary><secondary>example use</secondary></indexterm><indexterm id="iddle4213" significance="normal"><?indexkey S?><?primarykey set(s)?><?secondarykey BOUNDEDHASHSET EXAMPLE?><primary><emphasis role="strong">set(s)</emphasis></primary><secondary><literal>BoundedHashSet</literal> example</secondary></indexterm><indexterm id="iddle1128" significance="normal"><?indexkey A?><?primarykey asymmetric two-party tasks?><primary><emphasis role="strong">asymmetric two-party tasks</emphasis></primary></indexterm><indexterm id="iddle1129" significance="normal"><?indexkey A?><?primarykey asymmetric two-party tasks?><?secondarykey EXCHANGER MANAGEMENT OF?><primary><emphasis role="strong">asymmetric two-party tasks</emphasis></primary><secondary><literal>Exchanger</literal> management of</secondary></indexterm><indexterm id="iddle1288" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey RESULT?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>result</secondary></indexterm><indexterm id="iddle1289" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey RESULT?><?tertiarykey BUILDING?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>result</secondary><tertiary>building</tertiary></indexterm><indexterm id="iddle1328" significance="normal"><?indexkey C?><?primarykey cellular automata?><primary><emphasis role="strong">cellular automata</emphasis></primary></indexterm><indexterm id="iddle1329" significance="normal"><?indexkey C?><?primarykey cellular automata?><?secondarykey BARRIER USE FOR COMPUTATION OF?><primary><emphasis role="strong">cellular automata</emphasis></primary><secondary>barrier use for computation of</secondary></indexterm><indexterm id="iddle1444" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1994" significance="normal"><?indexkey E?><?primarykey efficiency?><?secondarykey RESULT CACHE, BUILDING?><primary><emphasis role="strong">efficiency</emphasis></primary><secondary>result cache, building</secondary></indexterm><indexterm id="iddle2239" significance="normal"><?indexkey E?><?primarykey Exchanger?><?secondarykey AS TWO-PARTY BARRIER?><primary><emphasis role="strong">Exchanger</emphasis></primary><secondary>as two-party barrier</secondary></indexterm><indexterm id="iddle2961" significance="normal"><?indexkey L?><?primarykey Life cellular automata game?><primary><emphasis role="strong">Life cellular automata game</emphasis></primary></indexterm><indexterm id="iddle2962" significance="normal"><?indexkey L?><?primarykey Life cellular automata game?><?secondarykey BARRIER USE FOR COMPUTATION OF?><primary><emphasis role="strong">Life cellular automata game</emphasis></primary><secondary>barrier use for computation of</secondary></indexterm><indexterm id="iddle3465" significance="normal"><?indexkey P?><?primarykey partitioning?><primary><emphasis role="strong">partitioning</emphasis></primary></indexterm><indexterm id="iddle3466" significance="normal"><?indexkey P?><?primarykey partitioning?><?secondarykey AS PARALLELIZING STRATEGY?><primary><emphasis role="strong">partitioning</emphasis></primary><secondary>as parallelizing strategy</secondary></indexterm><indexterm id="iddle3979" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey CACHE?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>cache</secondary></indexterm><indexterm id="iddle3980" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey CACHE?><?tertiarykey BUILDING?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>cache</secondary><tertiary>building</tertiary></indexterm><indexterm id="iddle4080" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey RESULT CACHE?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>result cache</secondary></indexterm><indexterm id="iddle4081" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey RESULT CACHE?><?tertiarykey BUILDING?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>result cache</secondary><tertiary>building</tertiary></indexterm><indexterm id="iddle4288" significance="normal"><?indexkey S?><?primarykey simulations?><primary><emphasis role="strong">simulations</emphasis></primary></indexterm><indexterm id="iddle4289" significance="normal"><?indexkey S?><?primarykey simulations?><?secondarykey BARRIER USE IN?><primary><emphasis role="strong">simulations</emphasis></primary><secondary>barrier use in</secondary></indexterm><indexterm id="iddle4478" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey PARALLELIZATION?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>parallelization</secondary></indexterm><indexterm id="iddle4479" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey PARALLELIZATION?><?tertiarykey PARTITIONING?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>parallelization</secondary><tertiary>partitioning</tertiary></indexterm><indexterm id="iddle4661" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey TWO-PARTY?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>two-party</secondary></indexterm><indexterm id="iddle4662" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey TWO-PARTY?><?tertiarykey EXCHANGER MANAGEMENT OF?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>two-party</secondary><tertiary><literal>Exchanger</literal> management of</tertiary></indexterm><literal>rier</literal> also lets you pass a <emphasis>barrier action</emphasis> to the constructor; this is a <literal>Runnable</literal> that is executed (in one of the subtask threads) when the barrier is successfully passed but before the blocked threads are released.</para>
<example id="ch05list14" label="5.14" role="Listing" xreflabel="5.14" condition="100">
<?docpage num="100"?>
<title id="ch05list14__title">Using <literal>Semaphore</literal> to Bound a Collection.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class BoundedHashSet&lt;T&gt; {
    private final Set&lt;T&gt; set;
    private final Semaphore sem;

    public BoundedHashSet(int bound) {
        this.set = Collections.synchronizedSet(new HashSet&lt;T&gt;());
        sem = new Semaphore(bound);
    }

    public boolean add(T o) throws InterruptedException {
        sem.acquire();
        boolean wasAdded = false;
        try {
            wasAdded = set.add(o);
            return wasAdded;
        }
        finally {
            if (!wasAdded)
                sem.release();
        }
    }

    public boolean remove(Object o) {
        boolean wasRemoved = set.remove(o);
        if (wasRemoved)
            sem.release();
        return wasRemoved;
    }
}
</programlisting>
</example>
<para>Barriers are often used in simulations, where the work to calculate one step can be done in parallel but all the work associated with a given step must complete before advancing to the next step. For example, in <emphasis>n</emphasis>-body particle simulations, each step calculates an update to the position of each particle based on the locations and other attributes of the other particles. Waiting on a barrier between each update ensures that all updates for step <emphasis>k</emphasis> have completed before moving on to step <emphasis>k</emphasis> + 1.</para>
<para><literal>CellularAutomata</literal> in <link linkend="ch05list15" preference="0">Listing 5.15</link> demonstrates using a barrier to compute a cellular automata simulation, such as Conway’s Life game (<link linkend="biblio01_012" preference="0">Gardner, 1970</link>). When parallelizing a simulation, it is generally impractical to assign a separate thread to each element (in the case of Life, a cell); this would require too many threads, and the overhead of coordinating them would dwarf the computation. Instead, it makes sense to <emphasis>partition</emphasis> the problem into a number of subparts, let each thread solve a subpart, and then merge the results. <literal>CellularAutomata</literal> partitions the board into <emphasis>N</emphasis><subscript><emphasis>cpu</emphasis></subscript> parts, where <emphasis>N</emphasis><subscript><emphasis>cpu</emphasis></subscript> is the number of CPUs available, and assigns each part to a thread. <footnote id="ch05fn05" label="5"><para>For computational problems like this that do no I/O and access no shared data, <emphasis>Ncpu</emphasis> or <emphasis>Ncpu</emphasis> + 1 threads yield optimal throughput; more threads do not help, and may in fact degrade performance as the threads compete for CPU and memory resources.</para></footnote> At each step, the worker threads calculate new values for all the cells in their part of the board. When all worker threads have reached the barrier, the barrier action commits the new values to the data model. After the barrier action runs, the worker threads are released to compute the next step of the calculation, which includes consulting an <literal>isDone</literal> method to determine whether further iterations are required.</para>
<para>Another form of barrier is <literal>Exchanger</literal>, a two-party barrier in which the parties exchange data at the barrier point [CPJ 3.4.3]. Exchangers are useful when the parties perform asymmetric activities, for example when one thread fills a buffer with data and the other thread consumes the data from the buffer; these threads could use an <literal>Exchanger</literal> to meet and exchange a full buffer for an empty one. When two threads exchange objects via an <literal>Exchanger</literal>, the exchange constitutes a safe publication of both objects to the other party.</para>
<para>The timing of the exchange depends on the responsiveness requirements of the application. The simplest approach is that the filling task exchanges when the buffer is full, and the emptying task exchanges when the buffer is empty; this minimizes the number of exchanges but can delay processing of some data if the arrival rate of new data is unpredictable. Another approach would be that the filler exchanges when the buffer is full, but also when the buffer is partially filled and a certain amount of time has elapsed.</para>
</section>
</section>
<section id="ch05lev1sec6" condition="101" label="5.6" xreflabel="5.6"><?docpage num="101"?><?docpage num="102"?>
<title id="ch05lev1sec6__title">Building an Efficient, Scalable Result Cache</title>
<para>Nearly every server application uses some form of caching. Reusing the results of a previous computation can reduce latency and increase throughput, at the cost <?docpage num="103"?><indexterm id="iddle1742" significance="normal"><?indexkey C?><?primarykey CyclicBarrier?><?secondarykey PARALLEL ITERATIVE ALGORITHM USE?><primary><emphasis role="strong">CyclicBarrier</emphasis></primary><secondary>parallel iterative algorithm use</secondary></indexterm><indexterm id="iddle2097" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CELLULARAUTOMATA?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>CellularAutomata</literal></secondary></indexterm><indexterm id="iddle1459" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey CACHE IMPLEMENTATION ISSUES?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>cache implementation issues</secondary></indexterm><indexterm id="iddle1734" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey WRAPPERS?><primary><emphasis role="strong">creation</emphasis></primary><secondary>wrappers</secondary></indexterm><indexterm id="iddle1735" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey WRAPPERS?><?tertiarykey DURING MEMOIZATION?><primary><emphasis role="strong">creation</emphasis></primary><secondary>wrappers</secondary><tertiary>during memoization</tertiary></indexterm><indexterm id="iddle2098" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey COMPUTABLE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Computable</literal></secondary></indexterm><indexterm id="iddle2113" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey EXPENSIVEFUNCTION?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ExpensiveFunction</literal></secondary></indexterm><indexterm id="iddle2135" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MEMOIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Memoizer</literal></secondary></indexterm><indexterm id="iddle3192" significance="normal"><?indexkey M?><?primarykey memoization?><primary><emphasis role="strong">memoization</emphasis></primary><seealso> <link linkend="iddle1279" preference="0"><emphasis role="strong">cache/caching</emphasis></link>.</seealso></indexterm><indexterm id="iddle3489" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey CACHE IMPLEMENTATION ISSUES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>cache implementation issues</secondary></indexterm><indexterm id="iddle4541" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey CACHE IMPLEMENTATION ISSUES?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>cache implementation issues</secondary></indexterm>of some additional memory usage.</para>
<example id="ch05list15" label="5.15" role="Listing" xreflabel="5.15" condition="102">
<?docpage num="102"?>
<title id="ch05list15__title">Coordinating Computation in a Cellular Automaton with <literal>CyclicBarrier</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class CellularAutomata {
    private final Board mainBoard;
    private final CyclicBarrier barrier;
    private final Worker[] workers;

    public CellularAutomata(Board board) {
        this.mainBoard = board;
        int count = Runtime.getRuntime().availableProcessors();
        this.barrier = new CyclicBarrier(count,
                new Runnable() {
                    public void run() {
                        mainBoard.commitNewValues();
                    }});
        this.workers = new Worker[count];
        for (int i = 0; i &lt; count; i++)
            workers[i] = new Worker(mainBoard.getSubBoard(count, i));
    }

    private class Worker implements Runnable {
        private final Board board;

        public Worker(Board board) { this.board = board; }
        public void run() {
            while (!board.hasConverged()) {
                for (int x = 0; x &lt; board.getMaxX(); x++)
                    for (int y = 0; y &lt; board.getMaxY(); y++)
                        board.setNewValue(x, y, computeValue(x, y));
                try {
                    barrier.await();
                } catch (InterruptedException ex) {
                    return;
                } catch (BrokenBarrierException ex) {
                    return;
                }
            }
        }
    }

    public void start() {
        for (int i = 0; i &lt; workers.length; i++)
            new Thread(workers[i]).start();
        mainBoard.waitForConvergence();}
    }
}
</programlisting>
</example>
<para>Like many other frequently reinvented wheels, caching often looks simpler than it is. A naive cache implementation is likely to turn a performance bottleneck into a scalability bottleneck, even if it does improve single-threaded performance. In this section we develop an efficient and scalable result cache for a computationally expensive function. Let’s start with the obvious approach—a simple <literal>HashMap</literal>—and then look at some of its concurrency disadvantages and how to fix them.</para>
<para>The <literal>Computable&lt;A,V&gt;</literal> interface in <link linkend="ch05list16" preference="0">Listing 5.16</link> describes a function with input of type <emphasis>A</emphasis> and result of type <emphasis>V</emphasis>. <literal>ExpensiveFunction</literal>, which implements <literal>Computable</literal>, takes a long time to compute its result; we’d like to create a <literal>Computable</literal> wrapper that remembers the results of previous computations and encapsulates the caching process. (This technique is known as <emphasis>memoization</emphasis>.)</para>
<example id="ch05list16" label="5.16" role="Listing" xreflabel="5.16" condition="103">
<title id="ch05list16__title">Initial Cache Attempt Using <literal>HashMap</literal> and Synchronization.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public interface Computable&lt;A, V&gt; {
    V compute(A arg) throws InterruptedException;
}

public class ExpensiveFunction
        implements Computable&lt;String, BigInteger&gt; {
    public BigInteger compute(String arg) {
        <emphasis>// after deep thought...</emphasis>
        return new BigInteger(arg);
    }
}

public class Memoizer1&lt;A, V&gt; implements Computable&lt;A, V&gt; {
    @GuardedBy("this")
    private final Map&lt;A, V&gt; cache = new HashMap&lt;A, V&gt;();
    private final Computable&lt;A, V&gt; c;

    public Memoizer1(Computable&lt;A, V&gt; c) {
        this.c = c;
    }

    public <emphasis role="strong">synchronized</emphasis> V compute(A arg) throws InterruptedException {
        V result = cache.get(arg);
        if (result == null) {
            result = c.compute(arg);
            cache.put(arg, result);
        }
        return result;
    }
}
</programlisting>
</example>
<para><?docpage num="104"?><indexterm id="iddle1051" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey DESIGN ROLE OF REPRESENTATION?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>design role of representation</secondary></indexterm><indexterm id="iddle1285" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey IMPLEMENTATION ISSUES?><?tertiarykey SAFETY?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>implementation issues</secondary><tertiary>safety</tertiary></indexterm><indexterm id="iddle2137" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MEMOIZER2?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Memoizer2</literal></secondary></indexterm><indexterm id="iddle3866" significance="normal"><?indexkey R?><?primarykey representation?><?secondarykey ALGORITHM DESIGN ROLE?><primary><emphasis role="strong">representation</emphasis></primary><secondary>algorithm design role</secondary></indexterm><indexterm id="iddle4032" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey CACHE IMPLEMENTATION ISSUES?><primary><emphasis role="strong">safety</emphasis></primary><secondary>cache implementation issues</secondary></indexterm><literal>Memoizer1</literal> in <link linkend="ch05list16" preference="0">Listing 5.16</link> shows a first attempt: using a <literal>HashMap</literal> to store the results of previous computations. The <literal>compute</literal> method first checks whether the desired result is already cached, and returns the precomputed value if it is. Otherwise, the result is computed and cached in the <literal>HashMap</literal> before returning.</para>
<para><literal>HashMap</literal> is not thread-safe, so to ensure that two threads do not access the <literal>HashMap</literal> at the same time, <literal>Memoizer1</literal> takes the conservative approach of synchronizing the entire <literal>compute</literal> method. This ensures thread safety but has an obvious scalability problem: only one thread at a time can execute <literal>compute</literal> at all. If another thread is busy computing a result, other threads calling <literal>compute</literal> may be blocked for a long time. If multiple threads are queued up waiting to compute values not already computed, <literal>compute</literal> may actually take longer than it would have without memoization. <link linkend="ch05fig02" preference="1">Figure 5.2</link> illustrates what could happen when several threads attempt to use a function memoized with this approach. This is not the sort of performance improvement we had hoped to achieve through caching.</para>
<figure float="1" id="ch05fig02" label="5.2" xreflabel="5.2" condition="104">

<title id="ch05fig02__title">Poor Concurrency of <literal>Memoizer1</literal>.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="186" fileref="graphics/05fig02.gif" format="GIF" width="492"/></imageobject>

</mediaobject>
</figure>
<para><literal>Memoizer2</literal> in <link linkend="ch05list17" preference="0">Listing 5.17</link> improves on the awful concurrent behavior of <literal>Memoizer1</literal> by replacing the <literal>HashMap</literal> with a <literal>ConcurrentHashMap</literal>. Since <literal>ConcurrentHashMap</literal> is thread-safe, there is no need to synchronize when accessing the backing <literal>Map</literal>, thus eliminating the serialization induced by synchronizing <literal>compute</literal> in <literal>Memoizer1</literal>.</para>
<para><literal>Memoizer2</literal> certainly has better concurrent behavior than <literal>Memoizer1</literal>: multiple threads can actually use it concurrently. But it still has some defects as a cache—there is a window of vulnerability in which two threads calling <literal>compute</literal> at the same time could end up computing the same value. In the case of memoization, this is merely inefficient—the purpose of a cache is to prevent the same data from being calculated multiple times. For a more general-purpose caching mechanism, it is far worse; for an object cache that is supposed to provide once-and-only-once initialization, this vulnerability would also pose a safety risk.</para>
<para>The problem with <literal>Memoizer2</literal> is that if one thread starts an expensive computation, other threads are not aware that the computation is in progress and so may start the same computation, as illustrated in <link linkend="ch05fig03" preference="1">Figure 5.3</link>. We’d like to somehow represent the notion that “thread <emphasis>X</emphasis> is currently computing <emphasis>f</emphasis> (27)”, so that if another thread arrives looking for <emphasis>f</emphasis> (27), it knows that the most efficient way to find it is to head over to Thread <emphasis>X</emphasis>’s house, hang out there until <emphasis>X</emphasis> is finished, and <?docpage num="105"?><indexterm id="iddle2435" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey EFFICIENT AND SCALABLE CACHE IMPLEMENTATION WITH?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>efficient and scalable cache implementation with</secondary></indexterm>then ask “Hey, what did you get for <emphasis>f</emphasis> (27)?”</para>
<figure float="1" id="ch05fig03" label="5.3" xreflabel="5.3" condition="105">

<title id="ch05fig03__title">Two Threads Computing the Same Value When Using <literal>Memoizer2</literal>.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="115" fileref="graphics/05fig03.gif" format="GIF" width="491"/></imageobject>

</mediaobject>
</figure>
<example id="ch05list17" label="5.17" role="Listing" xreflabel="5.17" condition="105">
<title id="ch05list17__title">Replacing <literal>HashMap</literal> with <literal>ConcurrentHashMap</literal>.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class Memoizer2&lt;A, V&gt; implements Computable&lt;A, V&gt; {
    private final Map&lt;A, V&gt; cache = <emphasis role="strong">new ConcurrentHashMap&lt;A, V&gt;();</emphasis>
    private final Computable&lt;A, V&gt; c;

    public Memoizer2(Computable&lt;A, V&gt; c) { this.c = c; }

    public V compute(A arg) throws InterruptedException {
        V result = cache.get(arg);
        if (result == null) {
            result = c.compute(arg);
            cache.put(arg, result);
        }
        return result;
    }
}
</programlisting>
</example>
<para>We’ve already seen a class that does almost exactly this: <literal>FutureTask</literal>. <literal>FutureTask</literal> represents a computational process that may or may not already have completed. <literal>FutureTask.get</literal> returns the result of the computation immediately if it is available; otherwise it blocks until the result has been computed and then returns it.</para>
<para><literal>Memoizer3</literal> in <link linkend="ch05list18" preference="0">Listing 5.18</link> redefines the backing <literal>Map</literal> for the value cache as a <literal>ConcurrentHashMap&lt;A,Future&lt;V&gt;&gt;</literal> instead of a <literal>ConcurrentHashMap&lt;A,V&gt;</literal>. <literal>Memoizer3</literal> first checks to see if the appropriate calculation has been started (as opposed to finished, as in <literal>Memoizer2</literal>). If not, it creates a <literal>FutureTask</literal>, registers it in the <literal>Map</literal>, and starts the computation; otherwise it waits for the result of the existing computation. The result might be available immediately or might be in the process of being computed—but this is transparent to the caller of <literal>Future.get</literal>.</para>
<para>The <literal>Memoizer3</literal> implementation is almost perfect: it exhibits very good concurrency (mostly derived from the excellent concurrency of <literal>ConcurrentHashMap</literal>), the result is returned efficiently if it is already known, and if the computation is in progress by another thread, newly arriving threads wait patiently for the result. It has only one defect—there is still a small window of vulnerability in which <?docpage num="106"?><indexterm id="iddle1159" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey IN CACHE IMPLEMENTATION DESIGN?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>in cache implementation design</secondary></indexterm><indexterm id="iddle1283" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey IMPLEMENTATION ISSUES?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>implementation issues</secondary></indexterm><indexterm id="iddle1284" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey IMPLEMENTATION ISSUES?><?tertiarykey ATOMIC/ATOMICITY?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>implementation issues</secondary><tertiary>atomic/atomicity</tertiary></indexterm><indexterm id="iddle1424" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey IN CACHE IMPLEMENTATION?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>in cache implementation</secondary></indexterm><indexterm id="iddle2138" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MEMOIZER3?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Memoizer3</literal></secondary></indexterm>two threads might compute the same value. This window is far smaller than in <literal>Memoizer2</literal>, but because the <literal>if</literal> block in <literal>compute</literal> is still a nonatomic check-thenact sequence, it is possible for two threads to call <literal>compute</literal> with the same value at roughly the same time, both see that the cache does not contain the desired value, and both start the computation. This unlucky timing is illustrated in <link linkend="ch05fig04" preference="1">Figure 5.4</link>.</para>
<figure float="1" id="ch05fig04" label="5.4" xreflabel="5.4" condition="107">
<?docpage num="107"?>
<title id="ch05fig04__title">Unlucky Timing that could Cause <literal>Memoizer3</literal> to Calculate the Same Value Twice.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="115" fileref="graphics/05fig04.gif" format="GIF" width="500"/></imageobject>

</mediaobject>
</figure>
<example id="ch05list18" label="5.18" role="Listing" xreflabel="5.18" condition="106">
<title id="ch05list18__title">Memoizing Wrapper Using <literal>FutureTask</literal>.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class Memoizer3&lt;A, V&gt; implements Computable&lt;A, V&gt; {
    private final Map&lt;A, Future&lt;V&gt;&gt; cache
            = <emphasis role="strong">new ConcurrentHashMap&lt;A, Future&lt;V&gt;&gt;();</emphasis>
    private final Computable&lt;A, V&gt; c;

    public Memoizer3(Computable&lt;A, V&gt; c) { this.c = c; }

    public V compute(final A arg) throws InterruptedException {
        Future&lt;V&gt; f = cache.get(arg);
        if (f == null) {
            Callable&lt;V&gt; eval = new Callable&lt;V&gt;() {
                public V call() throws InterruptedException {
                    return c.compute(arg);
                }
            };
            FutureTask&lt;V&gt; ft = new FutureTask&lt;V&gt;(eval);
            f = ft;
            cache.put(arg, ft);
            <emphasis role="strong">ft.run();</emphasis> <emphasis>// call to c.compute happens here</emphasis>
        }
        try {
            return <emphasis role="strong">f.get();</emphasis>
        } catch (ExecutionException e) {
            throw launderThrowable(e.getCause());
        }
    }
}
</programlisting>
</example>
<para><literal>Memoizer3</literal> is vulnerable to this problem because a compound action (put-if-absent) is performed on the backing map that cannot be made atomic using locking. <literal>Memoizer</literal> in <link linkend="ch05list19" preference="0">Listing 5.19</link> takes advantage of the atomic <literal>putIfAbsent</literal> method of <literal>ConcurrentMap</literal>, closing the window of vulnerability in <literal>Memoizer3</literal>.</para>
<para>Caching a <literal>Future</literal> instead of a value creates the possibility of <emphasis>cache pollution</emphasis>: if a computation is cancelled or fails, future attempts to compute the result will also indicate cancellation or failure. To avoid this, <literal>Memoizer</literal> removes the <literal>Future</literal> from the cache if it detects that the computation was cancelled; it might also be desirable to remove the <literal>Future</literal> upon detecting a <literal>RuntimeException</literal> if the computation might succeed on a future attempt. <literal>Memoizer</literal> also does not address <?docpage num="107"?>cache expiration, but this could be accomplished by using a subclass of <literal>FutureTask</literal> that associates an expiration time with each result and periodically scanning the cache for expired entries. (Similarly, it does not address cache eviction, where old entries are removed to make room for new ones so that the cache does not consume too much memory.)</para>
<para>With our concurrent cache implementation complete, we can now add real caching to the factorizing servlet from <link linkend="ch02" preference="0">Chapter 2</link>, as promised. <literal>Factorizer</literal> in <link linkend="ch05list20" preference="0">Listing 5.20</link> uses <literal>Memoizer</literal> to cache previously computed values efficiently and scalably.</para>

<para><?docpage num="108"?></para><example id="ch05list19" label="5.19" role="Listing" xreflabel="5.19" condition="108">

<title id="ch05list19__title"><indexterm id="iddle2136" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MEMOIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Memoizer</literal></secondary></indexterm><indexterm id="iddle2437" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey EXAMPLE USE?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>example use</secondary></indexterm>Final Implementation of <literal>Memoizer</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class Memoizer&lt;A, V&gt; implements Computable&lt;A, V&gt; {
    private final ConcurrentMap&lt;A, Future&lt;V&gt;&gt; cache
        = new ConcurrentHashMap&lt;A, Future&lt;V&gt;&gt;();
    private final Computable&lt;A, V&gt; c;

    public Memoizer(Computable&lt;A, V&gt; c) { this.c = c; }

    public V compute(final A arg) throws InterruptedException {
        while (true) {
            Future&lt;V&gt; f = cache.get(arg);
            if (f == null) {
                Callable&lt;V&gt; eval = new Callable&lt;V&gt;() {
                    public V call() throws InterruptedException {
                        return c.compute(arg);
                    }
                };
                FutureTask&lt;V&gt; ft = new FutureTask&lt;V&gt;(eval);
                f = cache.<emphasis role="strong">putIfAbsent(arg, ft);</emphasis>
                if (f == null) { f = ft; ft.run(); }
            }
            try {
                return f.get();
            } catch (CancellationException e) {
                cache.remove(arg, f);
            } catch (ExecutionException e) {
                throw launderThrowable(e.getCause());
            }
        }
    }
}
</programlisting>
</example>

<para><?docpage num="109"?></para><example id="ch05list20" label="5.20" role="Listing" xreflabel="5.20" condition="109">

<title id="ch05list20__title"><indexterm id="iddle2114" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey FACTORIZER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Factorizer</literal></secondary></indexterm>Factorizing Servlet that Caches Results Using <literal>Memoizer</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class Factorizer implements Servlet {
    private final Computable&lt;BigInteger, BigInteger[]&gt; c =
        new Computable&lt;BigInteger, BigInteger[]&gt;() {
            public BigInteger[] compute(BigInteger arg) {
                return factor(arg);
            }
        };
    private final Computable&lt;BigInteger, BigInteger[]&gt; cache
        = new Memoizer&lt;BigInteger, BigInteger[]&gt;(c);

    public void service(ServletRequest req,
                        ServletResponse resp) {
        try {
            BigInteger i = extractFromRequest(req);
            encodeIntoResponse(resp, cache.compute(i));
        } catch (InterruptedException e) {
            encodeError(resp, "factorization interrupted");
        }
    }
}
</programlisting>
</example>
</section>
<section id="ch05lev1sec7" condition="110" label="" xreflabel="">
<?docpage num="110"?>
<title id="ch05lev1sec7__title">Summary of Part I</title>
<para><indexterm id="iddle1024" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey MUTABLE STATE?><primary><emphasis role="strong">access</emphasis></primary><secondary>mutable state</secondary></indexterm><indexterm id="iddle1025" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey MUTABLE STATE?><?tertiarykey IMPORTANCE OF COORDINATING?><primary><emphasis role="strong">access</emphasis></primary><secondary>mutable state</secondary><tertiary>importance of coordinating</tertiary></indexterm><indexterm id="iddle1415" significance="normal"><?indexkey C?><?primarykey compound actions?><?secondarykey CONCURRENCY DESIGN RULES ROLE?><primary><emphasis role="strong">compound actions</emphasis></primary><secondary>concurrency design rules role</secondary></indexterm><indexterm id="iddle1464" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey DESIGN RULES?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>design rules</secondary></indexterm><indexterm id="iddle1657" significance="normal"><?indexkey C?><?primarykey coordination?><?secondarykey MUTABLE STATE ACCESS?><primary><emphasis role="strong">coordination</emphasis></primary><secondary>mutable state access</secondary></indexterm><indexterm id="iddle1658" significance="normal"><?indexkey C?><?primarykey coordination?><?secondarykey MUTABLE STATE ACCESS?><?tertiarykey IMPORTANCE OF?><primary><emphasis role="strong">coordination</emphasis></primary><secondary>mutable state access</secondary><tertiary>importance of</tertiary></indexterm><indexterm id="iddle1898" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey CONCURRENCY DESIGN RULES?><primary><emphasis role="strong">design</emphasis></primary><secondary>concurrency design rules</secondary></indexterm><indexterm id="iddle1961" significance="normal"><?indexkey D?><?primarykey documentation?><?secondarykey CONCURRENCY DESIGN RULES ROLE?><primary><emphasis role="strong">documentation</emphasis></primary><secondary>concurrency design rules role</secondary></indexterm><indexterm id="iddle2009" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey CONCURRENCY DESIGN RULES ROLE?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>concurrency design rules role</secondary></indexterm><indexterm id="iddle2352" significance="normal"><?indexkey F?><?primarykey final?><?secondarykey CONCURRENCY DESIGN RULES ROLE?><primary><emphasis role="strong">final</emphasis></primary><secondary>concurrency design rules role</secondary></indexterm><indexterm id="iddle2505" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey CONCURRENCY DESIGN RULES?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>concurrency design rules</secondary></indexterm><indexterm id="iddle2707" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><?secondarykey CONCURRENCY DESIGN RULES ROLE?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><secondary>concurrency design rules role</secondary></indexterm><indexterm id="iddle2847" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey CONCURRENCY DESIGN RULES ROLE?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>concurrency design rules role</secondary></indexterm><indexterm id="iddle3074" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONCURRENCY DESIGN RULES ROLE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>concurrency design rules role</secondary></indexterm><indexterm id="iddle4410" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey MUTABLE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>mutable</secondary></indexterm><indexterm id="iddle4411" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey MUTABLE?><?tertiarykey COORDINATING ACCESS TO?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>mutable</secondary><tertiary>coordinating access to</tertiary></indexterm>We’ve covered a lot of material so far! The following “concurrency cheat sheet” summarizes the main concepts and rules presented in <link linkend="part01" preference="0">Part I</link>.</para>
<sidebar float="1" id="ch05sb04" condition="110"><title/>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para><emphasis>It’s the mutable state, stupid.</emphasis> <footnote id="ch05fn06" label="1"><para>During the 1992 U.S. presidential election, electoral strategist James Carville hung a sign in Bill Clinton’s campaign headquarters reading “The economy, stupid”, to keep the campaign on message.</para></footnote></para>
<para>All concurrency issues boil down to coordinating access to mutable state. The less mutable state, the easier it is to ensure thread safety.</para></listitem>
<listitem><para><emphasis>Make fields final unless they need to be mutable.</emphasis></para></listitem>
<listitem><para><emphasis>Immutable objects are automatically thread-safe.</emphasis></para>
<para>Immutable objects simplify concurrent programming tremendously. They are simpler and safer, and can be shared freely without locking or defensive copying.</para></listitem>
<listitem><para><emphasis>Encapsulation makes it practical to manage the complexity.</emphasis></para>
<para>You could write a thread-safe program with all data stored in global variables, but why would you want to? Encapsulating data within objects makes it easier to preserve their invariants; encapsulating synchronization within objects makes it easier to comply with their synchronization policy.</para></listitem>
<listitem><para><emphasis>Guard each mutable variable with a lock.</emphasis></para></listitem>
<listitem><para><emphasis>Guard all variables in an invariant with the same lock.</emphasis></para></listitem>
<listitem><para><emphasis>Hold locks for the duration of compound actions.</emphasis></para></listitem>
<listitem><para><emphasis>A program that accesses a mutable variable from multiple threads without synchronization is a broken program.</emphasis></para></listitem>
<listitem><para><emphasis>Don’t rely on clever reasoning about why you don’t need to synchronize.</emphasis></para></listitem>
<listitem><para><emphasis>Include thread safety in the design process—or explicitly document that your class is not thread-safe.</emphasis></para></listitem>
<listitem><para><emphasis>Document your synchronization policy.</emphasis></para></listitem>
</itemizedlist>
</sidebar>
</section>

</chapter>

</part>

<part id="part02" label="II" xreflabel="II" condition="111">
<?docpage num="111"?><?docpage num="112"?>
<title id="part02__title">Structuring Concurrent Applications</title>
<chapter id="ch06" label="6" xreflabel="6" condition="113">
<?docpage num="113"?>
<title id="ch06__title">Task Execution</title>


<para><indexterm id="iddle1042" significance="normal"><?indexkey A?><?primarykey activity(s)?><primary><emphasis role="strong">activity(s)</emphasis></primary><seealso> <link linkend="iddle1134" preference="0"><emphasis role="strong">asynchrony/asynchronous</emphasis>, tasks</link>.</seealso></indexterm><indexterm id="iddle1045" significance="normal"><?indexkey A?><?primarykey activity(s)?><?secondarykey TASKS AS REPRESENTATION OF?><primary><emphasis role="strong">activity(s)</emphasis></primary><secondary>tasks as representation of</secondary></indexterm><indexterm id="iddle1112" significance="normal"><?indexkey A?><?primarykey application(s)?><?secondarykey PARALLELIZING?><primary><emphasis role="strong">application(s)</emphasis></primary><secondary>parallelizing</secondary></indexterm><indexterm id="iddle1113" significance="normal"><?indexkey A?><?primarykey application(s)?><?secondarykey PARALLELIZING?><?tertiarykey TASK DECOMPOSITION?><primary><emphasis role="strong">application(s)</emphasis></primary><secondary>parallelizing</secondary><tertiary>task decomposition</tertiary></indexterm><indexterm id="iddle1198" significance="normal"><?indexkey B?><?primarykey behavior?><primary><emphasis role="strong">behavior</emphasis></primary><seealso> <link linkend="iddle3864" preference="0"><emphasis role="strong">representation</emphasis>, activities</link>.</seealso></indexterm><indexterm id="iddle1199" significance="normal"><?indexkey B?><?primarykey behavior?><primary><emphasis role="strong">behavior</emphasis></primary><seealso> <link linkend="iddle1134" preference="0"><emphasis role="strong">asynchrony/asynchronous</emphasis>, tasks</link>.</seealso></indexterm><indexterm id="iddle1255" significance="normal"><?indexkey B?><?primarykey boundaries?><?secondarykey TASK?><primary><emphasis role="strong">boundaries</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle1357" significance="normal"><?indexkey C?><?primarykey client(s)?><?secondarykey REQUESTS?><primary><emphasis role="strong">client(s)</emphasis></primary><secondary>requests</secondary></indexterm><indexterm id="iddle1358" significance="normal"><?indexkey C?><?primarykey client(s)?><?secondarykey REQUESTS?><?tertiarykey AS NATURAL TASK BOUNDARY?><primary><emphasis role="strong">client(s)</emphasis></primary><secondary>requests</secondary><tertiary>as natural task boundary</tertiary></indexterm><indexterm id="iddle1455" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey AND TASK INDEPENDENCE?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>and task independence</secondary></indexterm><indexterm id="iddle1841" significance="normal"><?indexkey D?><?primarykey decomposition?><?secondarykey TASKS-RELATED?><primary><emphasis role="strong">decomposition</emphasis></primary><secondary>tasks-related</secondary></indexterm><indexterm id="iddle1847" significance="normal"><?indexkey D?><?primarykey decoupling?><?secondarykey OF ACTIVITIES?><?tertiarykey TASK DECOMPOSITION AS REPRESENTATION OF?><primary><emphasis role="strong">decoupling</emphasis></primary><secondary>of activities</secondary><tertiary>task decomposition as representation of</tertiary></indexterm><indexterm id="iddle1880" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey STATE?><?tertiarykey TASK FREEDOM FROM, IMPORTANCE OF?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>state</secondary><tertiary>task freedom from, importance of</tertiary></indexterm><indexterm id="iddle1884" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey TASK FREEDOM FROM?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>task freedom from</secondary></indexterm><indexterm id="iddle1885" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey TASK FREEDOM FROM?><?tertiarykey IMPORTANCE?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>task freedom from</secondary><tertiary>importance</tertiary></indexterm><indexterm id="iddle1925" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PROGRAM?><primary><emphasis role="strong">design</emphasis></primary><secondary>program</secondary></indexterm><indexterm id="iddle1926" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PROGRAM?><?tertiarykey AND TASK DECOMPOSITION?><primary><emphasis role="strong">design</emphasis></primary><secondary>program</secondary><tertiary>and task decomposition</tertiary></indexterm><indexterm id="iddle2249" significance="normal"><?indexkey E?><?primarykey execution?><?secondarykey TASK?><primary><emphasis role="strong">execution</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle2307" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey GRACEFUL DEGRADATION?><primary><emphasis role="strong">failure</emphasis></primary><secondary>graceful degradation</secondary></indexterm><indexterm id="iddle2308" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey GRACEFUL DEGRADATION?><?tertiarykey TASK DESIGN IMPORTANCE?><primary><emphasis role="strong">failure</emphasis></primary><secondary>graceful degradation</secondary><tertiary>task design importance</tertiary></indexterm><indexterm id="iddle2381" significance="normal"><?indexkey F?><?primarykey flexibility?><?secondarykey RESOURCE MANAGEMENT?><?tertiarykey TASK DESIGN GUIDELINES FOR?><primary><emphasis role="strong">flexibility</emphasis></primary><secondary>resource management</secondary><tertiary>task design guidelines for</tertiary></indexterm><indexterm id="iddle2382" significance="normal"><?indexkey F?><?primarykey flexibility?><?secondarykey TASK DESIGN ROLE?><primary><emphasis role="strong">flexibility</emphasis></primary><secondary>task design role</secondary></indexterm><indexterm id="iddle2461" significance="normal"><?indexkey G?><?primarykey graceful?><?secondarykey DEGRADATION?><?tertiarykey TASK DESIGN IMPORTANCE?><primary><emphasis role="strong">graceful</emphasis></primary><secondary>degradation</secondary><tertiary>task design importance</tertiary></indexterm><indexterm id="iddle2731" significance="normal"><?indexkey I?><?primarykey independent/independence?><?secondarykey TASK?><primary><emphasis role="strong">independent/independence</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle2732" significance="normal"><?indexkey I?><?primarykey independent/independence?><?secondarykey TASK?><?tertiarykey CONCURRENCY ADVANTAGES?><primary><emphasis role="strong">independent/independence</emphasis></primary><secondary>task</secondary><tertiary>concurrency advantages</tertiary></indexterm><indexterm id="iddle3458" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey TASK-RELATED DECOMPOSITION?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>task-related decomposition</secondary></indexterm><indexterm id="iddle3583" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey EXECUTION?><?tertiarykey TASK, APPLICATION PERFORMANCE IMPORTANCE?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>execution</secondary><tertiary>task, application performance importance</tertiary></indexterm><indexterm id="iddle3864" significance="normal"><?indexkey R?><?primarykey representation?><?secondarykey ACTIVITIES?><primary><emphasis role="strong">representation</emphasis></primary><secondary>activities</secondary></indexterm><indexterm id="iddle3865" significance="normal"><?indexkey R?><?primarykey representation?><?secondarykey ACTIVITIES?><?tertiarykey TASKS USE FOR?><primary><emphasis role="strong">representation</emphasis></primary><secondary>activities</secondary><tertiary>tasks use for</tertiary></indexterm><indexterm id="iddle3967" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey SERVER APPLICATIONS?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>server applications</secondary></indexterm><indexterm id="iddle3968" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey SERVER APPLICATIONS?><?tertiarykey IMPORTANCE OF?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>server applications</secondary><tertiary>importance of</tertiary></indexterm><indexterm id="iddle3983" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey DEPENDENCIES?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>dependencies</secondary></indexterm><indexterm id="iddle3984" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey DEPENDENCIES?><?tertiarykey TASK FREEDOM FROM, IMPORTANCE OF?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>dependencies</secondary><tertiary>task freedom from, importance of</tertiary></indexterm><indexterm id="iddle4191" significance="normal"><?indexkey S?><?primarykey server?><?secondarykey APPLICATIONS?><?tertiarykey DESIGN ISSUES?><primary><emphasis role="strong">server</emphasis></primary><secondary>applications</secondary><tertiary>design issues</tertiary></indexterm><indexterm id="iddle4274" significance="normal"><?indexkey S?><?primarykey side-effects?><?secondarykey FREEDOM FROM?><primary><emphasis role="strong">side-effects</emphasis></primary><secondary>freedom from</secondary></indexterm><indexterm id="iddle4275" significance="normal"><?indexkey S?><?primarykey side-effects?><?secondarykey FREEDOM FROM?><?tertiarykey IMPORTANCE FOR TASK INDEPENDENCE?><primary><emphasis role="strong">side-effects</emphasis></primary><secondary>freedom from</secondary><tertiary>importance for task independence</tertiary></indexterm><indexterm id="iddle4317" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey TASK?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle4318" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey TASK?><?tertiarykey APPROPRIATE?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>task</secondary><tertiary>appropriate</tertiary></indexterm><indexterm id="iddle4394" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey DEPENDENT?><?tertiarykey TASK FREEDOM FROM, IMPORTANCE OF?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>dependent</secondary><tertiary>task freedom from, importance of</tertiary></indexterm><indexterm id="iddle4601" significance="normal"><?indexkey T?><?primarykey task(s)?><primary><emphasis role="strong">task(s)</emphasis></primary><seealso> <link linkend="iddle3864" preference="0"><emphasis role="strong">representation</emphasis>, activities</link>.</seealso></indexterm><indexterm id="iddle4602" significance="normal"><?indexkey T?><?primarykey task(s)?><primary><emphasis role="strong">task(s)</emphasis></primary><seealso> <link linkend="iddle2059" preference="0"><emphasis role="strong">event(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle4603" significance="normal"><?indexkey T?><?primarykey task(s)?><primary><emphasis role="strong">task(s)</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle4606" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey BOUNDARIES?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>boundaries</secondary></indexterm><indexterm id="iddle4618" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey EXECUTION?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>execution</secondary></indexterm><indexterm id="iddle4619" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey EXECUTION?><?tertiarykey IN THREADS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>execution</secondary><tertiary>in threads</tertiary></indexterm><indexterm id="iddle4622" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey EXECUTION?><?tertiarykey POLICIES, APPLICATION PERFORMANCE IMPORTANCE?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>execution</secondary><tertiary>policies, application performance importance</tertiary></indexterm><indexterm id="iddle4829" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey TASK?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle4830" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey TASK?><?tertiarykey EXECUTION IN?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>task</secondary><tertiary>execution in</tertiary></indexterm><indexterm id="iddle4874" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey SERVER APPLICATION?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>server application</secondary></indexterm><indexterm id="iddle4875" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey SERVER APPLICATION?><?tertiarykey IMPORTANCE OF?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>server application</secondary><tertiary>importance of</tertiary></indexterm><indexterm id="iddle5165" significance="normal"><?indexkey W?><?primarykey work?><?secondarykey TASKS AS REPRESENTATION OF?><primary><emphasis role="strong">work</emphasis></primary><secondary>tasks as representation of</secondary></indexterm>Most concurrent applications are organized around the execution of <emphasis>tasks</emphasis>: abstract, discrete units of work. Dividing the work of an application into tasks simplifies program organization, facilitates error recovery by providing natural transaction boundaries, and promotes concurrency by providing a natural structure for parallelizing work.</para>



<section id="ch06lev1sec1" condition="113" label="6.1" xreflabel="6.1"><?docpage num="113"?>
<title id="ch06lev1sec1__title">Executing Tasks in Threads</title>
<para>The first step in organizing a program around task execution is identifying sensible <emphasis>task boundaries</emphasis>. Ideally, tasks are <emphasis>independent</emphasis> activities: work that doesn’t depend on the state, result, or side effects of other tasks. Independence facilitates concurrency, as independent tasks can be executed in parallel if there are adequate processing resources. For greater flexibility in scheduling and load balancing tasks, each task should also represent a small fraction of your application’s processing capacity.</para>
<para>Server applications should exhibit both <emphasis>good throughput</emphasis> and <emphasis>good responsiveness</emphasis> under normal load. Application providers want applications to support as many users as possible, so as to reduce provisioning costs per user; users want to get their response quickly. Further, applications should exhibit <emphasis>graceful degradation</emphasis> as they become overloaded, rather than simply falling over under heavy load. Choosing good task boundaries, coupled with a sensible <emphasis>task execution policy</emphasis> (see <link linkend="ch06lev2sec5" preference="0">Section 6.2.2</link>), can help achieve these goals.</para>
<para>Most server applications offer a natural choice of task boundary: individual client requests. Web servers, mail servers, file servers, EJB containers, and database servers all accept requests via network connections from remote clients. Using individual requests as task boundaries usually offers both independence and appropriate task sizing. For example, the result of submitting a message to a mail server is not affected by the other messages being processed at the same time, and handling a single message usually requires a very small percentage of the server’s total capacity.</para>
<section id="ch06lev2sec1" condition="114" label="6.1.1" xreflabel="6.1.1">
<?docpage num="114"?>
<title id="ch06lev2sec1__title">Executing Tasks Sequentially</title>
<para><indexterm id="iddle2180" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SINGLETHREADWEBSERVER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SingleThreadWebServer</literal></secondary></indexterm><indexterm id="iddle2251" significance="normal"><?indexkey E?><?primarykey execution?><?secondarykey TASK?><?tertiarykey SEQUENTIAL?><primary><emphasis role="strong">execution</emphasis></primary><secondary>task</secondary><tertiary>sequential</tertiary></indexterm><indexterm id="iddle2488" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey FRAMEWORKS?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>frameworks</secondary></indexterm><indexterm id="iddle2489" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey FRAMEWORKS?><?tertiarykey AS SINGLE-THREADED TASK EXECUTION EXAMPLE?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>frameworks</secondary><tertiary>as single-threaded task execution example</tertiary></indexterm><indexterm id="iddle2679" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey SERVER APPLICATIONS?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>server applications</secondary></indexterm><indexterm id="iddle2680" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey SERVER APPLICATIONS?><?tertiarykey TASK EXECUTION IMPLICATIONS?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>server applications</secondary><tertiary>task execution implications</tertiary></indexterm><indexterm id="iddle3589" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SEQUENTIAL?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>sequential</secondary></indexterm><indexterm id="iddle3590" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SEQUENTIAL?><?tertiarykey TASK EXECUTION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>sequential</secondary><tertiary>task execution</tertiary></indexterm><indexterm id="iddle3596" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey TASK SCHEDULING?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>task scheduling</secondary></indexterm><indexterm id="iddle3597" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey TASK SCHEDULING?><?tertiarykey SEQUENTIAL?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>task scheduling</secondary><tertiary>sequential</tertiary></indexterm><indexterm id="iddle3926" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey SINGLE-THREADED TASK EXECUTION DISADVANTAGES?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>single-threaded task execution disadvantages</tertiary></indexterm><indexterm id="iddle3969" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey SERVER APPLICATIONS?><?tertiarykey SINGLE-THREADED EXECUTION DISADVANTAGES?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>server applications</secondary><tertiary>single-threaded execution disadvantages</tertiary></indexterm><indexterm id="iddle4096" significance="normal"><?indexkey S?><?primarykey scheduling?><?secondarykey TASKS?><primary><emphasis role="strong">scheduling</emphasis></primary><secondary>tasks</secondary></indexterm><indexterm id="iddle4097" significance="normal"><?indexkey S?><?primarykey scheduling?><?secondarykey TASKS?><?tertiarykey SEQUENTIAL POLICY?><primary><emphasis role="strong">scheduling</emphasis></primary><secondary>tasks</secondary><tertiary>sequential policy</tertiary></indexterm><indexterm id="iddle4163" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey EXECUTION?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>execution</secondary></indexterm><indexterm id="iddle4164" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey EXECUTION?><?tertiarykey OF TASKS?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>execution</secondary><tertiary>of tasks</tertiary></indexterm><indexterm id="iddle4169" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey TASK EXECUTION POLICY?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>task execution policy</secondary></indexterm><indexterm id="iddle4301" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><?secondarykey TASK EXECUTION?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><secondary>task execution</secondary></indexterm><indexterm id="iddle4302" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><?secondarykey TASK EXECUTION?><?tertiarykey DISADVANTAGES OF?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><secondary>task execution</secondary><tertiary>disadvantages of</tertiary></indexterm><indexterm id="iddle4623" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey EXECUTION?><?tertiarykey SEQUENTIAL?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>execution</secondary><tertiary>sequential</tertiary></indexterm><indexterm id="iddle4820" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SINGLE?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>single</secondary></indexterm><indexterm id="iddle4821" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SINGLE?><?tertiarykey SEQUENTIAL TASK EXECUTION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>single</secondary><tertiary>sequential task execution</tertiary></indexterm><indexterm id="iddle4876" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey SERVER APPLICATIONS?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>server applications</secondary></indexterm><indexterm id="iddle4877" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey SERVER APPLICATIONS?><?tertiarykey SINGLE-THREADED TASK EXECUTION DISADVANTAGES?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>server applications</secondary><tertiary>single-threaded task execution disadvantages</tertiary></indexterm>There are a number of possible policies for scheduling tasks within an application, some of which exploit the potential for concurrency better than others. The simplest is to execute tasks sequentially in a single thread. <literal>SingleThreadWeb-Server</literal> in <link linkend="ch06list01" preference="0">Listing 6.1</link> processes its tasks—HTTP requests arriving on port 80—sequentially. The details of the request processing aren’t important; we’re interested in characterizing the concurrency of various scheduling policies.</para>
<example id="ch06list01" label="6.1" role="Listing" xreflabel="6.1" condition="114">
<title id="ch06list01__title">Sequential Web Server.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">class SingleThreadWebServer {
    public static void main(String[] args) throws IOException {
        ServerSocket socket = new ServerSocket(80);
        while (true) {
            Socket connection = socket.accept();
            handleRequest(connection);
        }
    }
}
</programlisting>
</example>
<para><literal>SingleThreadedWebServer</literal> is simple and theoretically correct, but would perform poorly in production because it can handle only one request at a time. The main thread alternates between accepting connections and processing the associated request. While the server is handling a request, new connections must wait until it finishes the current request and calls <literal>accept</literal> again. This might work if request processing were so fast that <literal>handleRequest</literal> effectively returned immediately, but this doesn’t describe any web server in the real world.</para>
<para>Processing a web request involves a mix of computation and I/O. The server must perform socket I/O to read the request and write the response, which can block due to network congestion or connectivity problems. It may also perform file I/O or make database requests, which can also block. In a single-threaded server, blocking not only delays completing the current request, but prevents pending requests from being processed at all. If one request blocks for an unusually long time, users might think the server is unavailable because it appears unresponsive. At the same time, resource utilization is poor, since the CPU sits idle while the single thread waits for its I/O to complete.</para>
<para>In server applications, sequential processing rarely provides either good throughput or good responsiveness. There are exceptions—such as when tasks are few and long-lived, or when the server serves a single client that makes only a single request at a time—but most server applications do not work this way.<footnote id="ch06fn01" label="1"><para>In some situations, sequential processing may offer a simplicity or safety advantage; most GUI frameworks process tasks sequentially using a single thread. We return to the sequential model in <link linkend="ch09" preference="0">Chapter 9</link>.</para></footnote></para>
</section>
<section id="ch06lev2sec2" condition="115" label="6.1.2" xreflabel="6.1.2">
<?docpage num="115"?>
<title id="ch06lev2sec2__title">Explicitly Creating Threads for Tasks</title>
<para><indexterm id="iddle1730" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey THREAD?><?tertiarykey EXPLICITLY, FOR TASKS?><primary><emphasis role="strong">creation</emphasis></primary><secondary>thread</secondary><tertiary>explicitly, for tasks</tertiary></indexterm><indexterm id="iddle2203" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey THREADPERTASKWEBSERVER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ThreadPerTaskWebServer</literal></secondary></indexterm><indexterm id="iddle3459" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey THREAD-PER-TASK POLICY?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>thread-per-task policy</secondary></indexterm><indexterm id="iddle3600" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey TASK SCHEDULING?><?tertiarykey THREAD-PER-TASK?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>task scheduling</secondary><tertiary>thread-per-task</tertiary></indexterm><indexterm id="iddle4098" significance="normal"><?indexkey S?><?primarykey scheduling?><?secondarykey TASKS?><?tertiarykey THREAD-PER-TASK POLICY?><primary><emphasis role="strong">scheduling</emphasis></primary><secondary>tasks</secondary><tertiary>thread-per-task policy</tertiary></indexterm><indexterm id="iddle4624" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey EXPLICIT THREAD CREATION FOR?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>explicit thread creation for</secondary></indexterm><indexterm id="iddle4650" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey SCHEDULING?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>scheduling</secondary></indexterm><indexterm id="iddle4651" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey SCHEDULING?><?tertiarykey THREAD-PER-TASK POLICY?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>scheduling</secondary><tertiary>thread-per-task policy</tertiary></indexterm><indexterm id="iddle4764" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CREATION?><?tertiarykey EXPLICIT CREATION FOR TASKS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>creation</secondary><tertiary>explicit creation for tasks</tertiary></indexterm><indexterm id="iddle4831" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey TASK?><?tertiarykey SCHEDULING, THREAD-PER-TASK POLICY?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>task</secondary><tertiary>scheduling, thread-per-task policy</tertiary></indexterm>A more responsive approach is to create a new thread for servicing each request, as shown in <literal>ThreadPerTaskWebServer</literal> in <link linkend="ch06list02" preference="0">Listing 6.2</link>.</para>
<example id="ch06list02" label="6.2" role="Listing" xreflabel="6.2" condition="115">
<title id="ch06list02__title">Web Server that Starts a New Thread for Each Request.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">class ThreadPerTaskWebServer {
    public static void main(String[] args) throws IOException {
        ServerSocket socket = new ServerSocket(80);
        while (true) {
            <emphasis role="strong">final</emphasis>  Socket connection = socket.accept();
            Runnable task = new Runnable() {
                    public void run() {
                        <emphasis role="strong">handleRequest(connection);</emphasis>
                    }
                };
            <emphasis role="strong">new Thread(task).start();</emphasis>
        }
    }
}
</programlisting>
</example>
<para><literal>ThreadPerTaskWebServer</literal> is similar in structure to the single-threaded version—the main thread still alternates between accepting an incoming connection and dispatching the request. The difference is that for each connection, the main loop creates a new thread to process the request instead of processing it within the main thread. This has three main consequences:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Task processing is offloaded from the main thread, enabling the main loop to resume waiting for the next incoming connection more quickly. This enables new connections to be accepted before previous requests complete, improving responsiveness.</para></listitem>
<listitem><para>Tasks can be processed in parallel, enabling multiple requests to be serviced simultaneously. This may improve throughput if there are multiple processors, or if tasks need to block for any reason such as I/O completion, lock acquisition, or resource availability.</para></listitem>
<listitem><para>Task-handling code must be thread-safe, because it may be invoked concurrently for multiple tasks.</para></listitem>
</itemizedlist>
<para>Under light to moderate load, the thread-per-task approach is an improvement over sequential execution. As long as the request arrival rate does not exceed the server’s capacity to handle requests, this approach offers better responsiveness and throughput.</para>
</section>
<section id="ch06lev2sec3" condition="116" label="6.1.3" xreflabel="6.1.3">
<?docpage num="116"?>
<title id="ch06lev2sec3__title">Disadvantages of Unbounded Thread Creation</title>
<para><indexterm id="iddle1125" significance="normal"><?indexkey A?><?primarykey arrays?><primary><emphasis role="strong">arrays</emphasis></primary><seealso> <link linkend="iddle1460" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, collections</link>.</seealso></indexterm><indexterm id="iddle1126" significance="normal"><?indexkey A?><?primarykey arrays?><primary><emphasis role="strong">arrays</emphasis></primary><seealso> <link linkend="iddle4229" preference="0"><emphasis role="strong">shared/sharing</emphasis>, data structures</link>.</seealso></indexterm><indexterm id="iddle1563" significance="normal"><?indexkey C?><?primarykey constraints?><?secondarykey THREAD CREATION?><primary><emphasis role="strong">constraints</emphasis></primary><secondary>thread creation</secondary></indexterm><indexterm id="iddle1564" significance="normal"><?indexkey C?><?primarykey constraints?><?secondarykey THREAD CREATION?><?tertiarykey IMPORTANCE OF?><primary><emphasis role="strong">constraints</emphasis></primary><secondary>thread creation</secondary><tertiary>importance of</tertiary></indexterm><indexterm id="iddle1732" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey THREAD?><?tertiarykey UNBOUNDED, DISADVANTAGES?><primary><emphasis role="strong">creation</emphasis></primary><secondary>thread</secondary><tertiary>unbounded, disadvantages</tertiary></indexterm><indexterm id="iddle1765" significance="normal"><?indexkey D?><?primarykey data structure(s)?><primary><emphasis role="strong">data structure(s)</emphasis></primary><seealso> <link linkend="iddle1460" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, collections</link>.</seealso></indexterm><indexterm id="iddle1766" significance="normal"><?indexkey D?><?primarykey data structure(s)?><primary><emphasis role="strong">data structure(s)</emphasis></primary><seealso> <link linkend="iddle1646" preference="0"><emphasis role="strong">cooperation/cooperating</emphasis>, objects</link>.</seealso></indexterm><indexterm id="iddle1767" significance="normal"><?indexkey D?><?primarykey data structure(s)?><primary><emphasis role="strong">data structure(s)</emphasis></primary><seealso> <link linkend="iddle1222" preference="0"><emphasis role="strong">block(ing)</emphasis>, queues, and thread pool management</link>.</seealso></indexterm><indexterm id="iddle1768" significance="normal"><?indexkey D?><?primarykey data structure(s)?><primary><emphasis role="strong">data structure(s)</emphasis></primary><seealso> <link linkend="iddle4353" preference="0"><emphasis role="strong">stack(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1769" significance="normal"><?indexkey D?><?primarykey data structure(s)?><primary><emphasis role="strong">data structure(s)</emphasis></primary><seealso> <link linkend="iddle4964" preference="0"><emphasis role="strong">tree(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1836" significance="normal"><?indexkey D?><?primarykey debugging?><?secondarykey UNBOUNDED THREAD CREATION RISKS?><primary><emphasis role="strong">debugging</emphasis></primary><secondary>unbounded thread creation risks</secondary></indexterm><indexterm id="iddle2981" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey THREAD?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle2982" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey THREAD?><?tertiarykey PERFORMANCE IMPACT?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>thread</secondary><tertiary>performance impact</tertiary></indexterm><indexterm id="iddle3199" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey DEPLETION?><?tertiarykey THREAD-PER-TASK POLICY ISSUE?><primary><emphasis role="strong">memory</emphasis></primary><secondary>depletion</secondary><tertiary>thread-per-task policy issue</tertiary></indexterm><indexterm id="iddle3420" significance="normal"><?indexkey O?><?primarykey OutOfMemoryError?><primary><emphasis role="strong">OutOfMemoryError</emphasis></primary></indexterm><indexterm id="iddle3421" significance="normal"><?indexkey O?><?primarykey OutOfMemoryError?><?secondarykey UNBOUNDED THREAD CREATION RISK?><primary><emphasis role="strong">OutOfMemoryError</emphasis></primary><secondary>unbounded thread creation risk</secondary></indexterm><indexterm id="iddle3491" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey COSTS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>costs</secondary></indexterm><indexterm id="iddle3492" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey COSTS?><?tertiarykey THREAD-PER-TASK POLICY?><primary><emphasis role="strong">performance</emphasis></primary><secondary>costs</secondary><tertiary>thread-per-task policy</tertiary></indexterm><indexterm id="iddle3749" significance="normal"><?indexkey Q?><?primarykey queue(s)?><primary><emphasis role="strong">queue(s)</emphasis></primary><seealso> <link linkend="iddle4229" preference="0"><emphasis role="strong">shared/sharing</emphasis>, data structures</link>.</seealso></indexterm><indexterm id="iddle3910" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey DEPLETION?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>depletion</secondary></indexterm><indexterm id="iddle3911" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey DEPLETION?><?tertiarykey THREAD-PER-TASK POLICY ISSUE?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>depletion</secondary><tertiary>thread-per-task policy issue</tertiary></indexterm><indexterm id="iddle3931" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey THREAD-PER-TASK POLICY DISADVANTAGES?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>thread-per-task policy disadvantages</tertiary></indexterm><indexterm id="iddle4353" significance="normal"><?indexkey S?><?primarykey stack(s)?><primary><emphasis role="strong">stack(s)</emphasis></primary></indexterm><indexterm id="iddle4354" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey ADDRESS SPACE?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>address space</secondary></indexterm><indexterm id="iddle4355" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey ADDRESS SPACE?><?tertiarykey THREAD CREATION CONSTRAINT?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>address space</secondary><tertiary>thread creation constraint</tertiary></indexterm><indexterm id="iddle4765" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CREATION?><?tertiarykey UNBOUNDED, DISADVANTAGES?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>creation</secondary><tertiary>unbounded, disadvantages</tertiary></indexterm><indexterm id="iddle47861" significance="normal"><?indexkey T?><?primarykey thread(s)?><primary><emphasis role="strong">thread(s)</emphasis></primary></indexterm><indexterm id="iddle4786" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey LIFECYCLE?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>lifecycle</secondary></indexterm><indexterm id="iddle4787" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey LIFECYCLE?><?tertiarykey PERFORMANCE IMPACT?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>lifecycle</secondary><tertiary>performance impact</tertiary></indexterm><indexterm id="iddle4832" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey TASK?><?tertiarykey SCHEDULING, THREAD-PER-TASK POLICY DISADVANTAGES?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>task</secondary><tertiary>scheduling, thread-per-task policy disadvantages</tertiary></indexterm><indexterm id="iddle4838" significance="normal"><?indexkey T?><?primarykey thread-local?><primary><emphasis role="strong">thread-local</emphasis></primary><seealso> <link linkend="iddle4353" preference="0"><emphasis role="strong">stack(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle4997" significance="normal"><?indexkey U?><?primarykey unbounded?><?secondarykey THREAD CREATION?><primary><emphasis role="strong">unbounded</emphasis></primary><secondary>thread creation</secondary></indexterm><indexterm id="iddle4998" significance="normal"><?indexkey U?><?primarykey unbounded?><?secondarykey THREAD CREATION?><?tertiarykey DISADVANTAGES OF?><primary><emphasis role="strong">unbounded</emphasis></primary><secondary>thread creation</secondary><tertiary>disadvantages of</tertiary></indexterm><indexterm id="iddle5154" significance="normal"><?indexkey W?><?primarykey within-thread usage?><primary><emphasis role="strong">within-thread usage</emphasis></primary><see> <link linkend="iddle4353" preference="0"><emphasis role="strong">stack(s)</emphasis></link>.</see></indexterm>For production use, however, the thread-per-task approach has some practical drawbacks, especially when a large number of threads may be created:</para>
<formalpara><title><emphasis role="strong"><?design?>Thread lifecycle overhead.</emphasis></title><para>Thread creation and teardown are not free. The actual overhead varies across platforms, but thread creation takes time, introducing latency into request processing, and requires some processing activity by the JVM and OS. If requests are frequent and lightweight, as in most server applications, creating a new thread for each request can consume significant computing resources.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Resource consumption.</emphasis></title><para>Active threads consume system resources, especially memory. When there are more runnable threads than available processors, threads sit idle. Having many idle threads can tie up a lot of memory, putting pressure on the garbage collector, and having many threads competing for the CPUs can impose other performance costs as well. If you have enough threads to keep all the CPUs busy, creating more threads won’t help and may even hurt.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Stability.</emphasis></title><para>There is a limit on how many threads can be created. The limit varies by platform and is affected by factors including JVM invocation parameters, the requested stack size in the <literal>Thread</literal> constructor, and limits on threads placed by the underlying operating system.<footnote id="ch06fn02" label="2"><para>On 32-bit machines, a major limiting factor is address space for thread stacks. Each thread maintains two execution stacks, one for Java code and one for native code. Typical JVM defaults yield a combined stack size of around half a megabyte. (You can change this with the <literal>-Xss</literal> JVM flag or through the <literal>Thread</literal> constructor.) If you divide the per-thread stack size into 2<superscript>32</superscript>, you get a limit of a few thousands or tens of thousands of threads. Other factors, such as OS limitations, may impose stricter limits.</para></footnote> When you hit this limit, the most likely result is an <literal>OutOfMemoryError</literal>. Trying to recover from such an error is very risky; it is far easier to structure your program to avoid hitting this limit.</para></formalpara>
<para>Up to a certain point, more threads can improve throughput, but beyond that point creating more threads just slows down your application, and creating one thread too many can cause your entire application to crash horribly. The way to stay out of danger is to place some bound on how many threads your application creates, and to test your application thoroughly to ensure that, even when this bound is reached, it does not run out of resources.</para>
<para>The problem with the thread-per-task approach is that nothing places any limit on the number of threads created except the rate at which remote users can throw HTTP requests at it. Like other concurrency hazards, unbounded thread creation may <emphasis>appear</emphasis> to work just fine during prototyping and development, with problems surfacing only when the application is deployed and under heavy load. So a malicious user, or enough ordinary users, can make your web server crash if the traffic load ever reaches a certain threshold. For a server application that is supposed to provide high availability and graceful degradation under load, this is a serious failing.</para>
</section>
</section>
<section id="ch06lev1sec2" condition="117" label="6.2" xreflabel="6.2">
<?docpage num="117"?>
<title id="ch06lev1sec2__title">The Executor Framework</title>
<para><indexterm id="iddle1134" significance="normal"><?indexkey A?><?primarykey asynchrony/asynchronous?><?secondarykey TASKS?><primary><emphasis role="strong">asynchrony/asynchronous</emphasis></primary><secondary>tasks</secondary></indexterm><indexterm id="iddle1135" significance="normal"><?indexkey A?><?primarykey asynchrony/asynchronous?><?secondarykey TASKS?><?tertiarykey EXECUTION, EXECUTOR FRAMEWORK USE?><primary><emphasis role="strong">asynchrony/asynchronous</emphasis></primary><secondary>tasks</secondary><tertiary>execution, <literal>Executor</literal> framework use</tertiary></indexterm><indexterm id="iddle1849" significance="normal"><?indexkey D?><?primarykey decoupling?><?secondarykey TASK SUBMISSION FROM EXECUTION?><primary><emphasis role="strong">decoupling</emphasis></primary><secondary>task submission from execution</secondary></indexterm><indexterm id="iddle1850" significance="normal"><?indexkey D?><?primarykey decoupling?><?secondarykey TASK SUBMISSION FROM EXECUTION?><?tertiarykey AND EXECUTOR FRAMEWORK?><primary><emphasis role="strong">decoupling</emphasis></primary><secondary>task submission from execution</secondary><tertiary>and <literal>Executor</literal> framework</tertiary></indexterm><indexterm id="iddle1922" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PRODUCER-CONSUMER PATTERN?><primary><emphasis role="strong">design</emphasis></primary><secondary>producer-consumer pattern</secondary></indexterm><indexterm id="iddle1923" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PRODUCER-CONSUMER PATTERN?><?tertiarykey DECOUPLING ADVANTAGES?><primary><emphasis role="strong">design</emphasis></primary><secondary>producer-consumer pattern</secondary><tertiary>decoupling advantages</tertiary></indexterm><indexterm id="iddle1924" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PRODUCER-CONSUMER PATTERN?><?tertiarykey EXECUTOR FRAMEWORK USE?><primary><emphasis role="strong">design</emphasis></primary><secondary>producer-consumer pattern</secondary><tertiary><literal>Executor</literal> framework use</tertiary></indexterm><indexterm id="iddle2254" significance="normal"><?indexkey E?><?primarykey Executor framework?><primary><emphasis role="strong">Executor framework</emphasis></primary></indexterm><indexterm id="iddle2255" significance="normal"><?indexkey E?><?primarykey Executor framework?><primary><emphasis role="strong">Executor framework</emphasis></primary></indexterm><indexterm id="iddle2761" significance="normal"><?indexkey I?><?primarykey instrumentation?><?secondarykey SUPPORT?><primary><emphasis role="strong">instrumentation</emphasis></primary><secondary>support</secondary></indexterm><indexterm id="iddle2762" significance="normal"><?indexkey I?><?primarykey instrumentation?><?secondarykey SUPPORT?><?tertiarykey EXECUTOR FRAMEWORK USE?><primary><emphasis role="strong">instrumentation</emphasis></primary><secondary>support</secondary><tertiary><literal>Executor</literal> framework use</tertiary></indexterm><indexterm id="iddle2976" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey SUPPORT?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>support</secondary></indexterm><indexterm id="iddle2977" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey SUPPORT?><?tertiarykey EXECUTOR FRAMEWORK USE?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>support</secondary><tertiary><literal>Executor</literal> framework use</tertiary></indexterm><indexterm id="iddle3598" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey TASK SCHEDULING?><?tertiarykey THREAD POOLS?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>task scheduling</secondary><tertiary>thread pools</tertiary></indexterm><indexterm id="iddle3623" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey AS THREAD RESOURCE MANAGEMENT MECHANISM?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>as thread resource management mechanism</tertiary></indexterm><indexterm id="iddle3685" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey EXECUTOR FRAMEWORK USE?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary><literal>Executor</literal> framework use</secondary></indexterm><indexterm id="iddle3921" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey EXECUTOR FRAMEWORK USE?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary><literal>Executor</literal> framework use</tertiary></indexterm><indexterm id="iddle3928" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey THREAD POOLS?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>thread pools</tertiary></indexterm><indexterm id="iddle4797" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey AS THREAD RESOURCE MANAGEMENT MECHANISM?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>as thread resource management mechanism</tertiary></indexterm>Tasks are logical units of work, and threads are a mechanism by which tasks can run asynchronously. We’ve examined two policies for executing tasks using threads—execute tasks sequentially in a single thread, and execute each task in its own thread. Both have serious limitations: the sequential approach suffers from poor responsiveness and throughput, and the thread-per-task approach suffers from poor resource management.</para>
<para>In <link linkend="ch05" preference="0">Chapter 5</link>, we saw how to use <emphasis>bounded queues</emphasis> to prevent an overloaded application from running out of memory. <emphasis>Thread pools</emphasis> offer the same benefit for thread management, and <literal>java.util.concurrent</literal> provides a flexible thread pool implementation as part of the <literal>Executor</literal> framework. The primary abstraction for task execution in the Java class libraries is <emphasis>not</emphasis> <literal>Thread</literal>, but <literal>Executor</literal>, shown in <link linkend="ch06list03" preference="0">Listing 6.3</link>.</para>
<example id="ch06list03" label="6.3" role="Listing" xreflabel="6.3" condition="117">
<title id="ch06list03__title"><literal>Executor</literal> Interface.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface Executor {
    void execute(Runnable command);
}
</programlisting>
</example>
<para><literal>Executor</literal> may be a simple interface, but it forms the basis for a flexible and powerful framework for asynchronous task execution that supports a wide variety of task execution policies. It provides a standard means of decoupling <emphasis>task submission</emphasis> from <emphasis>task execution</emphasis>, describing tasks with <literal>Runnable</literal>. The <literal>Executor</literal> implementations also provide lifecycle support and hooks for adding statistics gathering, application management, and monitoring.</para>
<para><literal>Executor</literal> is based on the producer-consumer pattern, where activities that submit tasks are the producers (producing units of work to be done) and the threads that execute tasks are the consumers (consuming those units of work). <emphasis>Using an <literal>Executor</literal> is usually the easiest path to implementing a producer-consumer design in your application.</emphasis></para>
<section id="ch06lev2sec4" label="6.2.1" xreflabel="6.2.1">
<title id="ch06lev2sec4__title">Example: Web Server Using Executor</title>
<para>Building a web server with an <literal>Executor</literal> is easy. <literal>TaskExecutionWebServer</literal> in <link linkend="ch06list04" preference="0">Listing 6.4</link> replaces the hard-coded thread creation with an <literal>Executor</literal>. In this case, we use one of the standard <literal>Executor</literal> implementations, a fixed-size thread pool with 100 threads.</para>
<para>In <literal>TaskExecutionWebServer</literal>, submission of the request-handling task is decoupled from its execution using an <literal>Executor</literal>, and its behavior can be changed merely by substituting a different <literal>Executor</literal> implementation. Changing <literal>Executor</literal> implementations or configuration is far less invasive than changing the way tasks are submitted; <literal>Executor</literal> configuration is generally a one-time event and can easily be exposed for deployment-time configuration, whereas task submission code tends to be strewn throughout the program and harder to expose.</para>

<para><?docpage num="118"?></para><example id="ch06list04" label="6.4" role="Listing" xreflabel="6.4" condition="118">

<title id="ch06list04__title">Web Server Using a Thread Pool.</title>
<programlisting format="linespecific" linenumbering="unnumbered">class TaskExecutionWebServer {
    private static final int NTHREADS = 100;
    <emphasis role="strong">private static final Executor exec</emphasis>
        <emphasis role="strong">= Executors.newFixedThreadPool(NTHREADS);</emphasis>

    public static void main(String[] args) throws IOException {
        ServerSocket socket = new ServerSocket(80);
        while (true) {
            final Socket connection = socket.accept();
            Runnable task = new Runnable() {
                public void run() {
                    handleRequest(connection);
                }
            };
            <emphasis role="strong">exec.execute(task);</emphasis>
        }
    }
}
</programlisting>
</example>
<para><indexterm id="iddle2193" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey TASKEXECUTIONWEBSERVER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>TaskExecutionWebServer</literal></secondary></indexterm><indexterm id="iddle2202" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey THREADPERTASKEXECUTOR?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ThreadPerTaskExecutor</literal></secondary></indexterm><indexterm id="iddle2250" significance="normal"><?indexkey E?><?primarykey execution?><?secondarykey TASK?><?tertiarykey POLICIES?><primary><emphasis role="strong">execution</emphasis></primary><secondary>task</secondary><tertiary>policies</tertiary></indexterm><indexterm id="iddle3582" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey EXECUTION?><?tertiarykey TASK?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>execution</secondary><tertiary>task</tertiary></indexterm><indexterm id="iddle4620" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey EXECUTION?><?tertiarykey POLICIES?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>execution</secondary><tertiary>policies</tertiary></indexterm>We can easily modify <literal>TaskExecutionWebServer</literal> to behave like <literal>ThreadPer-TaskWebServer</literal> by substituting an <literal>Executor</literal> that creates a new thread for each request. Writing such an <literal>Executor</literal> is trivial, as shown in <literal>ThreadPerTaskExecutor</literal> in <link linkend="ch06list05" preference="0">Listing 6.5</link>.</para>
<example id="ch06list05" label="6.5" role="Listing" xreflabel="6.5" condition="118">
<title id="ch06list05__title"><literal>Executor</literal> that Starts a New Thread for Each Task.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class ThreadPerTaskExecutor implements Executor {
    public void execute(Runnable r) {
        <emphasis role="strong">new Thread(r).start();</emphasis>
    };
}
</programlisting>
</example>
<para>Similarly, it is also easy to write an <literal>Executor</literal> that would make <literal>TaskExecutionWebServer</literal> behave like the single-threaded version, executing each task synchronously before returning from <literal>execute</literal>, as shown in <literal>WithinThreadExecutor</literal> in <link linkend="ch06list06" preference="0">Listing 6.6</link>.</para>
</section>
<section id="ch06lev2sec5" label="6.2.2" xreflabel="6.2.2">
<title id="ch06lev2sec5__title">Execution Policies</title>
<para>The value of decoupling submission from execution is that it lets you easily specify, and subsequently change without great difficulty, the <emphasis>execution policy</emphasis> for a given class of tasks. An execution policy specifies the “what, where, when, and how” of task execution, including:</para>

<para><?docpage num="119"?></para><example id="ch06list06" label="6.6" role="Listing" xreflabel="6.6" condition="119">

<title id="ch06list06__title"><literal>Executor</literal> that Executes Tasks Synchronously in the Calling Thread.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class WithinThreadExecutor implements Executor {
    public void execute(Runnable r) {
        r.run();
    };
}
</programlisting>
</example>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para><indexterm id="iddle1597" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey RESOURCE?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>resource</secondary></indexterm><indexterm id="iddle1598" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey RESOURCE?><?tertiarykey AND TASK EXECUTION POLICY?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>resource</secondary><tertiary>and task execution policy</tertiary></indexterm><indexterm id="iddle2219" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey WITHINTHREADEXECUTOR?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>WithinThreadExecutor</literal></secondary></indexterm><indexterm id="iddle2375" significance="normal"><?indexkey F?><?primarykey flexibility?><?secondarykey DECOUPLING TASK SUBMISSION FROM EXECUTION, ADVANTAGES FOR?><primary><emphasis role="strong">flexibility</emphasis></primary><secondary>decoupling task submission from execution, advantages for</secondary></indexterm><indexterm id="iddle2460" significance="normal"><?indexkey G?><?primarykey graceful?><?secondarykey DEGRADATION?><?tertiarykey LIMITING TASK COUNT?><primary><emphasis role="strong">graceful</emphasis></primary><secondary>degradation</secondary><tertiary>limiting task count</tertiary></indexterm><indexterm id="iddle2524" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey EXECUTION POLICY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>execution policy</secondary></indexterm><indexterm id="iddle2525" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey EXECUTION POLICY?><?tertiarykey DESIGN?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>execution policy</secondary><tertiary>design</tertiary></indexterm><indexterm id="iddle3486" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey AND RESOURCE MANAGEMENT?><primary><emphasis role="strong">performance</emphasis></primary><secondary>and resource management</secondary></indexterm><indexterm id="iddle3619" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle3625" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey COMBINED WITH WORK QUEUES, IN EXECUTOR FRAMEWORK?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>combined with work queues, in <literal>Executor</literal> framework</tertiary></indexterm><indexterm id="iddle3746" significance="normal"><?indexkey Q?><?primarykey quality of service?><?secondarykey REQUIREMENTS?><primary><emphasis role="strong">quality of service</emphasis></primary><secondary>requirements</secondary></indexterm><indexterm id="iddle3747" significance="normal"><?indexkey Q?><?primarykey quality of service?><?secondarykey REQUIREMENTS?><?tertiarykey AND TASK EXECUTION POLICY?><primary><emphasis role="strong">quality of service</emphasis></primary><secondary>requirements</secondary><tertiary>and task execution policy</tertiary></indexterm><indexterm id="iddle3775" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey WORK?><?tertiarykey IN THREAD POOLS?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>work</secondary><tertiary>in thread pools</tertiary></indexterm><indexterm id="iddle3895" significance="normal"><?indexkey R?><?primarykey resource exhaustion, preventing?><?secondarykey EXECUTION POLICY AS TOOL FOR?><primary><emphasis role="strong">resource exhaustion, preventing</emphasis></primary><secondary>execution policy as tool for</secondary></indexterm><indexterm id="iddle3920" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey EXECUTION POLICY AS TOOL FOR?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>execution policy as tool for</tertiary></indexterm><indexterm id="iddle4792" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary></indexterm><indexterm id="iddle4794" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey AND WORK QUEUES?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>and work queues</tertiary></indexterm><indexterm id="iddle5159" significance="normal"><?indexkey W?><?primarykey work?><?secondarykey QUEUES?><?tertiarykey IN EXECUTOR FRAMEWORK USE?><primary><emphasis role="strong">work</emphasis></primary><secondary>queues</secondary><tertiary>in <literal>Executor</literal> framework use</tertiary></indexterm>In what thread will tasks be executed?</para></listitem>
<listitem><para>In what order should tasks be executed (FIFO, LIFO, priority order)?</para></listitem>
<listitem><para>How many tasks may execute concurrently?</para></listitem>
<listitem><para>How many tasks may be queued pending execution?</para></listitem>
<listitem><para>If a task has to be rejected because the system is overloaded, which task should be selected as the victim, and how should the application be notified?</para></listitem>
<listitem><para>What actions should be taken before or after executing a task?</para></listitem>
</itemizedlist>
<para>Execution policies are a resource management tool, and the optimal policy depends on the available computing resources and your quality-of-service requirements. By limiting the number of concurrent tasks, you can ensure that the application does not fail due to resource exhaustion or suffer performance problems due to contention for scarce resources.<footnote id="ch06fn03" label="3"><para>This is analogous to one of the roles of a transaction monitor in an enterprise application: it can throttle the rate at which transactions are allowed to proceed so as not to exhaust or overstress limited resources.</para></footnote> Separating the specification of execution policy from task submission makes it practical to select an execution policy at deployment time that is matched to the available hardware.</para>
<sidebar float="1" id="ch06sb01" condition="119"><title/>
<para>Whenever you see code of the form:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">new Thread(runnable).start()
</programlisting>
</informalexample>
<para>and you think you might at some point want a more flexible execution policy, seriously consider replacing it with the use of an <literal>Executor</literal>.</para>
</sidebar>
</section>
<section id="ch06lev2sec6" label="6.2.3" xreflabel="6.2.3">
<title id="ch06lev2sec6__title">Thread Pools</title>
<para>A thread pool, as its name suggests, manages a homogeneous pool of worker threads. A thread pool is tightly bound to a <emphasis>work queue</emphasis> holding tasks waiting to be executed. Worker threads have a simple life: request the next task from the work queue, execute it, and go back to waiting for another task.</para>
<para><?docpage num="120"?><indexterm id="iddle1733" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey THREAD POOLS?><primary><emphasis role="strong">creation</emphasis></primary><secondary>thread pools</secondary></indexterm><indexterm id="iddle2267" significance="normal"><?indexkey E?><?primarykey Executors?><primary><emphasis role="strong">Executors</emphasis></primary></indexterm><indexterm id="iddle2268" significance="normal"><?indexkey E?><?primarykey Executors?><?secondarykey FACTORY METHODS?><primary><emphasis role="strong">Executors</emphasis></primary><secondary>factory methods</secondary></indexterm><indexterm id="iddle2269" significance="normal"><?indexkey E?><?primarykey Executors?><?secondarykey FACTORY METHODS?><?tertiarykey THREAD POOL CREATION WITH?><primary><emphasis role="strong">Executors</emphasis></primary><secondary>factory methods</secondary><tertiary>thread pool creation with</tertiary></indexterm><indexterm id="iddle2297" significance="normal"><?indexkey F?><?primarykey factory(s)?><?secondarykey METHODS?><?tertiarykey THREAD POOL CREATION WITH?><primary><emphasis role="strong">factory(s)</emphasis></primary><secondary>methods</secondary><tertiary>thread pool creation with</tertiary></indexterm><indexterm id="iddle3572" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey APPLICATION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>application</secondary></indexterm><indexterm id="iddle3573" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey APPLICATION?><?tertiarykey THREAD POOL ADVANTAGES?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>application</secondary><tertiary>thread pool advantages</tertiary></indexterm><indexterm id="iddle3628" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey CREATING?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>creating</tertiary></indexterm><indexterm id="iddle4009" significance="normal"><?indexkey R?><?primarykey robustness?><?secondarykey THREAD POOL ADVANTAGES?><primary><emphasis role="strong">robustness</emphasis></primary><secondary>thread pool advantages</secondary></indexterm><indexterm id="iddle4799" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey CREATING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>creating</tertiary></indexterm>Executing tasks in pool threads has a number of advantages over the thread-per-task approach. Reusing an existing thread instead of creating a new one amortizes thread creation and teardown costs over multiple requests. As an added bonus, since the worker thread often already exists at the time the request arrives, the latency associated with thread creation does not delay task execution, thus improving responsiveness. By properly tuning the size of the thread pool, you can have enough threads to keep the processors busy while not having so many that your application runs out of memory or thrashes due to competition among threads for resources.</para>
<para>The class library provides a flexible thread pool implementation along with some useful predefined configurations. You can create a thread pool by calling one of the static factory methods in <literal>Executors</literal>:</para>
<formalpara><title><emphasis role="strong"><?design?>newFixedThreadPool.</emphasis></title><para>A fixed-size thread pool creates threads as tasks are submitted, up to the maximum pool size, and then attempts to keep the pool size constant (adding new threads if a thread dies due to an unexpected <literal>Exception</literal>).</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>newCachedThreadPool.</emphasis></title><para>A cached thread pool has more flexibility to reap idle threads when the current size of the pool exceeds the demand for processing, and to add new threads when demand increases, but places no bounds on the size of the pool.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>newSingleThreadExecutor.</emphasis></title><para>A single-threaded executor creates a single worker thread to process tasks, replacing it if it dies unexpectedly. Tasks are guaranteed to be processed sequentially according to the order imposed by the task queue (FIFO, LIFO, priority order).<footnote id="ch06fn04" label="4"><para>Single-threaded executors also provide sufficient internal synchronization to guarantee that any memory writes made by tasks are visible to subsequent tasks; this means that objects can be safely confined to the “task thread” even though that thread may be replaced with another from time to time.</para></footnote></para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>newScheduledThreadPool.</emphasis></title><para>A fixed-size thread pool that supports delayed and periodic task execution, similar to <literal>Timer</literal>. (See <link linkend="ch06lev2sec8" preference="0">Section 6.2.5</link>.)</para></formalpara>
<para>The <literal>newFixedThreadPool</literal> and <literal>newCachedThreadPool</literal> factories return instances of the general-purpose <literal>ThreadPoolExecutor</literal>, which can also be used directly to construct more specialized executors. We discuss thread pool configuration options in depth in <link linkend="ch08" preference="0">Chapter 8</link>.</para>
<para>The web server in <literal>TaskExecutionWebServer</literal> uses an <literal>Executor</literal> with a bounded pool of worker threads. Submitting a task with <literal>execute</literal> adds the task to the work queue, and the worker threads repeatedly dequeue tasks from the work queue and execute them.</para>
<para>Switching from a thread-per-task policy to a pool-based policy has a big effect on application stability: the web server will no longer fail under heavy load.<footnote id="ch06fn05" label="5"><para>While the server may not fail due to the creation of too many threads, if the task arrival rate exceeds the task service rate for long enough it is still possible (just harder) to run out of memory because of the growing queue of <literal>Runnable</literal>s awaiting execution. This can be addressed within the <literal>Executor</literal> framework by using a bounded work queue—see <link linkend="ch08lev2sec4" preference="0">Section 8.3.2</link>.</para></footnote> <?docpage num="121"?><indexterm id="iddle2274" significance="normal"><?indexkey E?><?primarykey ExecutorService?><?secondarykey LIFECYCLE METHODS?><primary><emphasis role="strong">ExecutorService</emphasis></primary><secondary>lifecycle methods</secondary></indexterm><indexterm id="iddle2275" significance="normal"><?indexkey E?><?primarykey ExecutorService?><?secondarykey LIFECYCLE METHODS?><primary><emphasis role="strong">ExecutorService</emphasis></primary><secondary>lifecycle methods</secondary></indexterm><indexterm id="iddle2456" significance="normal"><?indexkey G?><?primarykey graceful?><primary><emphasis role="strong">graceful</emphasis></primary></indexterm><indexterm id="iddle2457" significance="normal"><?indexkey G?><?primarykey graceful?><?secondarykey DEGRADATION?><primary><emphasis role="strong">graceful</emphasis></primary><secondary>degradation</secondary></indexterm><indexterm id="iddle2458" significance="normal"><?indexkey G?><?primarykey graceful?><?secondarykey DEGRADATION?><?tertiarykey AND EXECUTION POLICY?><primary><emphasis role="strong">graceful</emphasis></primary><secondary>degradation</secondary><tertiary>and execution policy</tertiary></indexterm><indexterm id="iddle2758" significance="normal"><?indexkey I?><?primarykey instrumentation?><?secondarykey POTENTIAL?><primary><emphasis role="strong">instrumentation</emphasis></primary><secondary>potential</secondary></indexterm><indexterm id="iddle2759" significance="normal"><?indexkey I?><?primarykey instrumentation?><?secondarykey POTENTIAL?><?tertiarykey AS EXECUTION POLICY ADVANTAGE?><primary><emphasis role="strong">instrumentation</emphasis></primary><secondary>potential</secondary><tertiary>as execution policy advantage</tertiary></indexterm><indexterm id="iddle2973" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey EXECUTOR?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary><literal>Executor</literal></secondary></indexterm><indexterm id="iddle2974" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey EXECUTOR?><?tertiarykey IMPLEMENTATIONS?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary><literal>Executor</literal></secondary><tertiary>implementations</tertiary></indexterm><indexterm id="iddle3599" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey TASK SCHEDULING?><?tertiarykey THREAD POOLS ADVANTAGES OVER THREAD-PER-TASK?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>task scheduling</secondary><tertiary>thread pools advantages over thread-per-task</tertiary></indexterm><indexterm id="iddle3825" significance="normal"><?indexkey R?><?primarykey rejected execution handler?><primary><emphasis role="strong">rejected execution handler</emphasis></primary></indexterm><indexterm id="iddle3826" significance="normal"><?indexkey R?><?primarykey rejected execution handler?><?secondarykey EXECUTORSERVICE POST-TERMINATION TASK HANDLING?><primary><emphasis role="strong">rejected execution handler</emphasis></primary><secondary>ExecutorService post-termination task handling</secondary></indexterm><indexterm id="iddle3929" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey THREAD POOLS, ADVANTAGES?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>thread pools, advantages</tertiary></indexterm><indexterm id="iddle4017" significance="normal"><?indexkey R?><?primarykey running?><primary><emphasis role="strong">running</emphasis></primary></indexterm><indexterm id="iddle4018" significance="normal"><?indexkey R?><?primarykey running?><?secondarykey EXECUTORSERVICE STATE?><primary><emphasis role="strong">running</emphasis></primary><secondary><literal>ExecutorService</literal> state</secondary></indexterm><indexterm id="iddle4252" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey EXECUTORSERVICE STATE?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary><literal>ExecutorService</literal> state</secondary></indexterm><indexterm id="iddle4267" significance="normal"><?indexkey S?><?primarykey shutdown?><primary><emphasis role="strong">shutdown</emphasis></primary></indexterm><indexterm id="iddle4269" significance="normal"><?indexkey S?><?primarykey shutdownNow?><primary><emphasis role="strong">shutdownNow</emphasis></primary></indexterm><indexterm id="iddle4400" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey LIFECYLE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>lifecyle</secondary></indexterm><indexterm id="iddle4401" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey LIFECYLE?><?tertiarykey EXECUTORSERVICE METHODS?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>lifecyle</secondary><tertiary><literal>ExecutorService</literal> methods</tertiary></indexterm><indexterm id="iddle4635" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey LIFECYCLE?><?tertiarykey EXECUTORSERVICE METHODS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>lifecycle</secondary><tertiary><literal>ExecutorService</literal> methods</tertiary></indexterm><indexterm id="iddle4641" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey POST-TERMINATION HANDLING?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>post-termination handling</secondary></indexterm><indexterm id="iddle4672" significance="normal"><?indexkey T?><?primarykey terminated?><primary><emphasis role="strong">terminated</emphasis></primary></indexterm><indexterm id="iddle4673" significance="normal"><?indexkey T?><?primarykey terminated?><?secondarykey EXECUTORSERVICE STATE?><primary><emphasis role="strong">terminated</emphasis></primary><secondary><literal>ExecutorService</literal> state</secondary></indexterm>It also degrades more gracefully, since it does not create thousands of threads that compete for limited CPU and memory resources. And using an <literal>Executor</literal> opens the door to all sorts of additional opportunities for tuning, management, monitoring, logging, error reporting, and other possibilities that would have been far more difficult to add without a task execution framework.</para>
</section>
<section id="ch06lev2sec7" label="6.2.4" xreflabel="6.2.4">
<title id="ch06lev2sec7__title">Executor Lifecycle</title>
<para>We’ve seen how to create an <literal>Executor</literal> but not how to shut one down. An <literal>Executor</literal> implementation is likely to create threads for processing tasks. But the JVM can’t exit until all the (nondaemon) threads have terminated, so failing to shut down an <literal>Executor</literal> could prevent the JVM from exiting.</para>
<para>Because an <literal>Executor</literal> processes tasks asynchronously, at any given time the state of previously submitted tasks is not immediately obvious. Some may have completed, some may be currently running, and others may be queued awaiting execution. In shutting down an application, there is a spectrum from graceful shutdown (finish what you’ve started but don’t accept any new work) to abrupt shutdown (turn off the power to the machine room), and various points in between. Since <literal>Executor</literal>s provide a service to applications, they should be able to be shut down as well, both gracefully and abruptly, and feed back information to the application about the status of tasks that were affected by the shutdown.</para>
<para>To address the issue of execution service lifecycle, the <literal>ExecutorService</literal> interface extends <literal>Executor</literal>, adding a number of methods for lifecycle management (as well as some convenience methods for task submission). The lifecycle management methods of <literal>ExecutorService</literal> are shown in <link linkend="ch06list07" preference="0">Listing 6.7</link>.</para>
<example id="ch06list07" label="6.7" role="Listing" xreflabel="6.7" condition="121">
<title id="ch06list07__title">Lifecycle Methods in <literal>ExecutorService</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface ExecutorService extends Executor {
    void shutdown();
    List&lt;Runnable&gt; shutdownNow();
    boolean isShutdown();
    boolean isTerminated();
    boolean awaitTermination(long timeout, TimeUnit unit)
        throws InterruptedException;
    //  ... <emphasis>additional convenience methods for task submission</emphasis>
}
</programlisting>
</example>
<para>The lifecycle implied by <literal>ExecutorService</literal> has three states—<emphasis>running</emphasis>, <emphasis>shutting down</emphasis>, and <emphasis>terminated</emphasis>. <literal>ExecutorService</literal>s are initially created in the <emphasis>running</emphasis> state. The <literal>shutdown</literal> method initiates a graceful shutdown: no new tasks are accepted but previously submitted tasks are allowed to complete—including those that have not yet begun execution. The <literal>shutdownNow</literal> method initiates an abrupt shutdown: it attempts to cancel outstanding tasks and does not start any tasks that are queued but not begun.</para>
<para>Tasks submitted to an <literal>ExecutorService</literal> after it has been shut down are handled by the <emphasis>rejected execution handler</emphasis> (see <link linkend="ch08lev2sec5" preference="0">Section 8.3.3</link>), which might silently discard <?docpage num="122"?><indexterm id="iddle2128" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey LIFECYCLEWEBSERVER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>LifecycleWebServer</literal></secondary></indexterm><indexterm id="iddle3830" significance="normal"><?indexkey R?><?primarykey RejectedExecutionException?><?secondarykey POST-TERMINATION TASK HANDLING?><primary><emphasis role="strong">RejectedExecutionException</emphasis></primary><secondary>post-termination task handling</secondary></indexterm><indexterm id="iddle4265" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey SUPPORT?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>support</secondary></indexterm><indexterm id="iddle4266" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey SUPPORT?><?tertiarykey LIFECYCLEWEBSERVER EXAMPLE?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>support</secondary><tertiary><literal>LifecycleWebServer</literal> example</tertiary></indexterm>the task or might cause <literal>execute</literal> to throw the unchecked <literal>RejectedExecutionException</literal>. Once all tasks have completed, the <literal>ExecutorService</literal> transitions to the <emphasis>terminated</emphasis> state. You can wait for an <literal>ExecutorService</literal> to reach the terminated state with <literal>awaitTermination</literal>, or poll for whether it has yet terminated with <literal>isTerminated</literal>. It is common to follow <literal>shutdown</literal> immediately by <literal>awaitTermination</literal>, creating the effect of synchronously shutting down the <literal>ExecutorService</literal>.(<literal>Executor</literal> shutdown and task cancellation are covered in more detail in <link linkend="ch07" preference="0">Chapter 7</link>.)</para>
<para><literal>LifecycleWebServer</literal> in <link linkend="ch06list08" preference="0">Listing 6.8</link> extends our web server with lifecycle support. It can be shut down in two ways: programmatically by calling <literal>stop</literal>, and through a client request by sending the web server a specially formatted HTTP request.</para>
<example id="ch06list08" label="6.8" role="Listing" xreflabel="6.8" condition="122">
<title id="ch06list08__title">Web Server with Shutdown Support.</title>
<programlisting format="linespecific" linenumbering="unnumbered">class LifecycleWebServer {
    private final ExecutorService exec = ...;

    public void start() throws IOException {
        ServerSocket socket = new ServerSocket(80);
        while (!exec.isShutdown()) {
            try {
                final Socket conn = socket.accept();
                exec.execute(new Runnable() {
                    public void run() { handleRequest(conn); }
                });
            } catch (RejectedExecutionException e) {
                if (!exec.isShutdown())
                    log("task submission rejected", e);
            }
        }
    }

    public void stop() { exec.shutdown(); }

    void handleRequest(Socket connection) {
        Request req = readRequest(connection);
        if (isShutdownRequest(req))
            stop();
        else
            dispatchRequest(req);
    }
}
</programlisting>
</example>
</section>
<section id="ch06lev2sec8" condition="123" label="6.2.5" xreflabel="6.2.5">
<?docpage num="123"?>
<title id="ch06lev2sec8__title">Delayed and Periodic Tasks</title>
<para><indexterm id="iddle1089" significance="normal"><?indexkey A?><?primarykey analysis?><?secondarykey FOR EXPLOITABLE PARALLELISM?><primary><emphasis role="strong">analysis</emphasis></primary><secondary>for exploitable parallelism</secondary></indexterm><indexterm id="iddle1256" significance="normal"><?indexkey B?><?primarykey boundaries?><?secondarykey TASK?><?tertiarykey ANALYSIS FOR PARALLELISM?><primary><emphasis role="strong">boundaries</emphasis></primary><secondary>task</secondary><tertiary>analysis for parallelism</tertiary></indexterm><indexterm id="iddle1852" significance="normal"><?indexkey D?><?primarykey delayed tasks?><?secondarykey HANDLING OF?><primary><emphasis role="strong">delayed tasks</emphasis></primary><secondary>handling of</secondary></indexterm><indexterm id="iddle1853" significance="normal"><?indexkey D?><?primarykey DelayQueue?><primary><emphasis role="strong"><literal>DelayQueue</literal></emphasis></primary></indexterm><indexterm id="iddle1854" significance="normal"><?indexkey D?><?primarykey DelayQueue?><?secondarykey TIME MANAGEMENT?><primary><emphasis role="strong"><literal>DelayQueue</literal></emphasis></primary><secondary>time management</secondary></indexterm><indexterm id="iddle1913" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PARALLELISM?><primary><emphasis role="strong">design</emphasis></primary><secondary>parallelism</secondary></indexterm><indexterm id="iddle1914" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PARALLELISM?><?tertiarykey APPLICATION ANALYSIS FOR?><primary><emphasis role="strong">design</emphasis></primary><secondary>parallelism</secondary><tertiary>application analysis for</tertiary></indexterm><indexterm id="iddle2234" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey TIMER DISADVANTAGES?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary><literal>Timer</literal> disadvantages</secondary></indexterm><indexterm id="iddle2248" significance="normal"><?indexkey E?><?primarykey execution?><?secondarykey POLICIES?><?tertiarykey PARALLELISM ANALYSIS FOR?><primary><emphasis role="strong">execution</emphasis></primary><secondary>policies</secondary><tertiary>parallelism analysis for</tertiary></indexterm><indexterm id="iddle2563" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey PARALLELISM ANALYSIS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>parallelism analysis</secondary></indexterm><indexterm id="iddle2954" significance="normal"><?indexkey L?><?primarykey leakage?><?secondarykey THREAD?><?tertiarykey TIMER PROBLEMS WITH?><primary><emphasis role="strong">leakage</emphasis></primary><secondary>thread</secondary><tertiary><literal>Timer</literal> problems with</tertiary></indexterm><indexterm id="iddle3450" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey APPLICATION ANALYSIS?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>application analysis</secondary></indexterm><indexterm id="iddle3581" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey EXECUTION?><?tertiarykey PARALLELISM ANALYSIS FOR?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>execution</secondary><tertiary>parallelism analysis for</tertiary></indexterm><indexterm id="iddle4090" significance="normal"><?indexkey S?><?primarykey ScheduledThreadPoolExecutor?><primary><emphasis role="strong">ScheduledThreadPoolExecutor</emphasis></primary></indexterm><indexterm id="iddle4091" significance="normal"><?indexkey S?><?primarykey ScheduledThreadPoolExecutor?><?secondarykey AS TIMER REPLACEMENT?><primary><emphasis role="strong">ScheduledThreadPoolExecutor</emphasis></primary><secondary>as <literal>Timer</literal> replacement</secondary></indexterm><indexterm id="iddle4296" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><?secondarykey AS TIMER RESTRICTION?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><secondary>as <literal>Timer</literal> restriction</secondary></indexterm><indexterm id="iddle4607" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey BOUNDARIES?><?tertiarykey PARALLELISM ANALYSIS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>boundaries</secondary><tertiary>parallelism analysis</tertiary></indexterm><indexterm id="iddle4659" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey TIMED?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>timed</secondary></indexterm><indexterm id="iddle4660" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey TIMED?><?tertiarykey HANDLING OF?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>timed</secondary><tertiary>handling of</tertiary></indexterm><indexterm id="iddle4784" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey LEAKAGE?><?tertiarykey TIMER PROBLEMS WITH?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>leakage</secondary><tertiary><literal>Timer</literal> problems with</tertiary></indexterm><indexterm id="iddle4886" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey %?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>-based task</secondary></indexterm><indexterm id="iddle4887" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey %?><?tertiarykey HANDLING?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>-based task</secondary><tertiary>handling</tertiary></indexterm><indexterm id="iddle4916" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey PERIODIC TASKS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>periodic tasks</secondary></indexterm><indexterm id="iddle4917" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey PERIODIC TASKS?><?tertiarykey HANDLING OF?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>periodic tasks</secondary><tertiary>handling of</tertiary></indexterm><indexterm id="iddle4920" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey RELATIVE VS. ABSOLUTE?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>relative vs. absolute</secondary></indexterm><indexterm id="iddle4921" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey RELATIVE VS. ABSOLUTE?><?tertiarykey CLASS CHOICES BASED ON?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>relative vs. absolute</secondary><tertiary>class choices based on</tertiary></indexterm><indexterm id="iddle4932" significance="normal"><?indexkey T?><?primarykey Timer?><primary><emphasis role="strong">Timer</emphasis></primary></indexterm><indexterm id="iddle4933" significance="normal"><?indexkey T?><?primarykey Timer?><?secondarykey TASK-HANDLING ISSUES?><primary><emphasis role="strong">Timer</emphasis></primary><secondary>task-handling issues</secondary></indexterm>The <literal>Timer</literal> facility manages the execution of deferred (“run this task in 100 ms”) and periodic (“run this task every 10 ms”) tasks. However, <literal>Timer</literal> has some drawbacks, and <literal>ScheduledThreadPoolExecutor</literal> should be thought of as its replacement.<footnote id="ch06fn06" label="6"><para><literal>Timer</literal> does have support for scheduling based on absolute, not relative time, so that tasks can be sensitive to changes in the system clock; <literal>ScheduledThreadPoolExecutor</literal> supports only relative time.</para></footnote> You can construct a <literal>ScheduledThreadPoolExecutor</literal> through its constructor or through the <literal>newScheduledThreadPool</literal> factory.</para>
<para>A <literal>Timer</literal> creates only a single thread for executing timer tasks. If a timer task takes too long to run, the timing accuracy of other <literal>TimerTask</literal>s can suffer. If a recurring <literal>TimerTask</literal> is scheduled to run every 10 ms and another <literal>Timer-Task</literal> takes 40 ms to run, the recurring task either (depending on whether it was scheduled at fixed rate or fixed delay) gets called four times in rapid succession after the long-running task completes, or “misses” four invocations completely. Scheduled thread pools address this limitation by letting you provide multiple threads for executing deferred and periodic tasks.</para>
<para>Another problem with <literal>Timer</literal> is that it behaves poorly if a <literal>TimerTask</literal> throws an unchecked exception. The <literal>Timer</literal> thread doesn’t catch the exception, so an unchecked exception thrown from a <literal>TimerTask</literal> terminates the timer thread. <literal>Timer</literal> also doesn’t resurrect the thread in this situation; instead, it erroneously assumes the entire <literal>Timer</literal> was cancelled. In this case, <literal>TimerTask</literal>s that are already scheduled but not yet executed are never run, and new tasks cannot be scheduled. (This problem, called “thread leakage” is described in <link linkend="ch07lev1sec3" preference="0">Section 7.3</link>, along with techniques for avoiding it.)</para>
<para><literal>OutOfTime</literal> in <link linkend="ch06list09" preference="0">Listing 6.9</link> illustrates how a <literal>Timer</literal> can become confused in this manner and, as confusion loves company, how the <literal>Timer</literal> shares its confusion with the next hapless caller that tries to submit a <literal>TimerTask</literal>. You might expect the program to run for six seconds and exit, but what actually happens is that it terminates after one second with an <literal>IllegalStateException</literal> whose message text is “Timer already cancelled”. <literal>ScheduledThreadPoolExecutor</literal> deals properly with ill-behaved tasks; there is little reason to use <literal>Timer</literal> in Java 5.0 or later.</para>
<para>If you need to build your own scheduling service, you may still be able to take advantage of the library by using a <literal>DelayQueue</literal>, a <literal>BlockingQueue</literal> implementation that provides the scheduling functionality of <literal>ScheduledThreadPoolExecutor</literal>. A <literal>DelayQueue</literal> manages a collection of <literal>Delayed</literal> objects. A <literal>Delayed</literal> has a delay time associated with it: <literal>DelayQueue</literal> lets you <literal>take</literal> an element only if its delay has expired. Objects are returned from a <literal>DelayQueue</literal> ordered by the time associated with their delay.</para>
</section>
</section>
<section id="ch06lev1sec3" condition="123" label="6.3" xreflabel="6.3"><?docpage num="123"?>
<title id="ch06lev1sec3__title">Finding Exploitable Parallelism</title>
<para>The <literal>Executor</literal> framework makes it easy to specify an execution policy, but in order to use an <literal>Executor</literal>, you have to be able to describe your task as a <literal>Runnable</literal>. In most server applications, there is an obvious task boundary: a single client request. But sometimes good task boundaries are not quite so obvious, as <?docpage num="124"?><indexterm id="iddle1445" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1710" significance="normal"><?indexkey C?><?primarykey CPU utilization?><?secondarykey AND SEQUENTIAL EXECUTION?><primary><emphasis role="strong">CPU utilization</emphasis></primary><secondary>and sequential execution</secondary></indexterm><indexterm id="iddle2151" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey OUTOFTIME?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>OutOfTime</literal></secondary></indexterm><indexterm id="iddle2678" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey SEQUENTIAL EXECUTION LIMITATIONS?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>sequential execution limitations</secondary></indexterm><indexterm id="iddle3446" significance="normal"><?indexkey P?><?primarykey page renderer examples?><?secondarykey PARALLELISM ANALYSIS?><primary><emphasis role="strong">page renderer examples</emphasis></primary><secondary>parallelism analysis</secondary></indexterm><indexterm id="iddle3447" significance="normal"><?indexkey P?><?primarykey page renderer examples?><?secondarykey SEQUENTIAL EXECUTION?><primary><emphasis role="strong">page renderer examples</emphasis></primary><secondary>sequential execution</secondary></indexterm><indexterm id="iddle3966" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey SEQUENTIAL EXECUTION LIMITATIONS?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>sequential execution limitations</secondary></indexterm><indexterm id="iddle4167" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey PAGE RENDERER EXAMPLE?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>page renderer example</secondary></indexterm><indexterm id="iddle5036" significance="normal"><?indexkey U?><?primarykey utilization?><?secondarykey CPU?><?tertiarykey SEQUENTIAL EXECUTION LIMITATIONS?><primary><emphasis role="strong">utilization</emphasis></primary><secondary>CPU</secondary><tertiary>sequential execution limitations</tertiary></indexterm>in many desktop applications. There may also be exploitable parallelism within a single client request in server applications, as is sometimes the case in database servers. (For a further discussion of the competing design forces in choosing task boundaries, see [CPJ 4.4.1.1].)</para>
<example id="ch06list09" label="6.9" role="Listing" xreflabel="6.9" condition="124">
<title id="ch06list09__title">Class Illustrating Confusing <literal>Timer</literal> Behavior.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class OutOfTime {
    public static void main(String[] args) throws Exception {
        Timer timer = new Timer();
        timer.schedule(new ThrowTask(), 1);
        SECONDS.sleep(1);
        timer.schedule(new ThrowTask(), 1);
        SECONDS.sleep(5);
    }

    static class ThrowTask extends TimerTask {
        public void run() { throw new RuntimeException(); }
    }
}
</programlisting>
</example>
<para>In this section we develop several versions of a component that admit varying degrees of concurrency. Our sample component is the page-rendering portion of a browser application, which takes a page of HTML and renders it into an image buffer. To keep it simple, we assume that the HTML consists only of marked up text interspersed with image elements with pre-specified dimensions and URLs.</para>
<section id="ch06lev2sec9" label="6.3.1" xreflabel="6.3.1">
<title id="ch06lev2sec9__title">Example: Sequential Page Renderer</title>
<para>The simplest approach is to process the HTML document sequentially. As text markup is encountered, render it into the image buffer; as image references are encountered, fetch the image over the network and draw it into the image buffer as well. This is easy to implement and requires touching each element of the input only once (it doesn’t even require buffering the document), but is likely to annoy the user, who may have to wait a long time before all the text is rendered.</para>
<para>A less annoying but still sequential approach involves rendering the text elements first, leaving rectangular placeholders for the images, and after completing the initial pass on the document, going back and downloading the images and drawing them into the associated placeholder. This approach is shown in <literal>SingleThreadRenderer</literal> in <link linkend="ch06list10" preference="0">Listing 6.10</link>.</para>
<para>Downloading an image mostly involves waiting for I/O to complete, and during this time the CPU does little work. So the sequential approach may underutilize the CPU, and also makes the user wait longer than necessary to see the finished page. We can achieve better utilization and responsiveness by breaking the problem into independent tasks that can execute concurrently.</para>

<para><?docpage num="125"?></para><example id="ch06list10" label="6.10" role="Listing" xreflabel="6.10" condition="125">

<title id="ch06list10__title">Rendering Page Elements Sequentially.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class SingleThreadRenderer {
    void renderPage(CharSequence source) {
        renderText(source);
        List&lt;ImageData&gt; imageData = new ArrayList&lt;ImageData&gt;();
        for (ImageInfo imageInfo : scanForImageInfo(source))
            imageData.add(imageInfo.downloadImage());
        for (ImageData data : imageData)
            renderImage(data);
    }
}
</programlisting>
</example>
</section>
<section id="ch06lev2sec10" label="6.3.2" xreflabel="6.3.2">
<title id="ch06lev2sec10__title">Result-bearing Tasks: <literal>Callable</literal> and <literal>Future</literal></title>
<para><indexterm id="iddle1292" significance="normal"><?indexkey C?><?primarykey Callable?><?secondarykey RESULTS HANDLING CAPABILITIES?><primary><emphasis role="strong">Callable</emphasis></primary><secondary>results handling capabilities</secondary></indexterm><indexterm id="iddle1315" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey TASK?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle1316" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey TASK?><?tertiarykey EXECUTOR HANDLING?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>task</secondary><tertiary><literal>Executor</literal> handling</tertiary></indexterm><indexterm id="iddle1432" significance="normal"><?indexkey C?><?primarykey computation?><?secondarykey DEFERRED?><primary><emphasis role="strong">computation</emphasis></primary><secondary>deferred</secondary></indexterm><indexterm id="iddle1433" significance="normal"><?indexkey C?><?primarykey computation?><?secondarykey DEFERRED?><?tertiarykey DESIGN ISSUES?><primary><emphasis role="strong">computation</emphasis></primary><secondary>deferred</secondary><tertiary>design issues</tertiary></indexterm><indexterm id="iddle1927" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey RESULT-BEARING TASKS?><primary><emphasis role="strong">design</emphasis></primary><secondary>result-bearing tasks</secondary></indexterm><indexterm id="iddle1928" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey RESULT-BEARING TASKS?><?tertiarykey REPRESENTATION ISSUES?><primary><emphasis role="strong">design</emphasis></primary><secondary>result-bearing tasks</secondary><tertiary>representation issues</tertiary></indexterm><indexterm id="iddle2179" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SINGLETHREADRENDERER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SingleThreadRenderer</literal></secondary></indexterm><indexterm id="iddle2229" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey HANDLING?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>handling</secondary></indexterm><indexterm id="iddle2230" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey HANDLING?><?tertiarykey RUNNABLE LIMITATIONS?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>handling</secondary><tertiary>Runnable limitations</tertiary></indexterm><indexterm id="iddle2425" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey RESULTS HANDLING CAPABILITIES?><primary><emphasis role="strong">Future</emphasis></primary><secondary>results handling capabilities</secondary></indexterm><indexterm id="iddle2427" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey TASK LIFECYCLE REPRESENTATION BY?><primary><emphasis role="strong">Future</emphasis></primary><secondary>task lifecycle representation by</secondary></indexterm><indexterm id="iddle2978" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey TASK?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle2979" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey TASK?><?tertiarykey AND FUTURE?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>task</secondary><tertiary>and <literal>Future</literal></tertiary></indexterm><indexterm id="iddle2980" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey TASK?><?tertiarykey EXECUTOR PHASES?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>task</secondary><tertiary><literal>Executor</literal> phases</tertiary></indexterm><indexterm id="iddle3867" significance="normal"><?indexkey R?><?primarykey representation?><?secondarykey RESULT-BEARING TASKS?><primary><emphasis role="strong">representation</emphasis></primary><secondary>result-bearing tasks</secondary></indexterm><indexterm id="iddle3868" significance="normal"><?indexkey R?><?primarykey representation?><?secondarykey TASK?><primary><emphasis role="strong">representation</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle3869" significance="normal"><?indexkey R?><?primarykey representation?><?secondarykey TASK?><?tertiarykey LIFECYCLE, FUTURE USE FOR?><primary><emphasis role="strong">representation</emphasis></primary><secondary>task</secondary><tertiary>lifecycle, <literal>Future</literal> use for</tertiary></indexterm><indexterm id="iddle3870" significance="normal"><?indexkey R?><?primarykey representation?><?secondarykey TASK?><?tertiarykey RUNNABLE USE FOR?><primary><emphasis role="strong">representation</emphasis></primary><secondary>task</secondary><tertiary><literal>Runnable</literal> use for</tertiary></indexterm><indexterm id="iddle3981" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey CALLABLE HANDLING OF?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary><literal>Callable</literal> handling of</secondary></indexterm><indexterm id="iddle3985" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey FUTURE HANDLING OF?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary><literal>Future</literal> handling of</secondary></indexterm><indexterm id="iddle3991" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey NON-VALUE-RETURNING TASKS?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>non-value-returning tasks</secondary></indexterm><indexterm id="iddle3992" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey RUNNABLE LIMITATIONS?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary><literal>Runnable</literal> limitations</secondary></indexterm><indexterm id="iddle3995" significance="normal"><?indexkey R?><?primarykey return values?><primary><emphasis role="strong">return values</emphasis></primary></indexterm><indexterm id="iddle3996" significance="normal"><?indexkey R?><?primarykey return values?><?secondarykey RUNNABLE LIMITATIONS?><primary><emphasis role="strong">return values</emphasis></primary><secondary><literal>Runnable</literal> limitations</secondary></indexterm><indexterm id="iddle4016" significance="normal"><?indexkey R?><?primarykey Runnable?><?secondarykey TASK REPRESENTATION LIMITATIONS?><primary><emphasis role="strong">Runnable</emphasis></primary><secondary>task representation limitations</secondary></indexterm><indexterm id="iddle4633" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey LIFECYCLE?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>lifecycle</secondary></indexterm><indexterm id="iddle4634" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey LIFECYCLE?><?tertiarykey EXECUTOR PHASES?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>lifecycle</secondary><tertiary><literal>Executor</literal> phases</tertiary></indexterm><indexterm id="iddle4636" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey LIFECYCLE?><?tertiarykey REPRESENTING WITH FUTURE?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>lifecycle</secondary><tertiary>representing with <literal>Future</literal></tertiary></indexterm><indexterm id="iddle4645" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey REPRESENTATION?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>representation</secondary></indexterm><indexterm id="iddle4646" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey REPRESENTATION?><?tertiarykey RUNNABLE USE FOR?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>representation</secondary><tertiary><literal>Runnable</literal> use for</tertiary></indexterm><indexterm id="iddle4897" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey DEFERRED COMPUTATIONS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>deferred computations</secondary></indexterm><indexterm id="iddle4898" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey DEFERRED COMPUTATIONS?><?tertiarykey DESIGN ISSUES?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>deferred computations</secondary><tertiary>design issues</tertiary></indexterm><indexterm id="iddle5114" significance="normal"><?indexkey V?><?primarykey Void?><primary><emphasis role="strong">Void</emphasis></primary></indexterm><indexterm id="iddle5115" significance="normal"><?indexkey V?><?primarykey Void?><?secondarykey NON-VALUE-RETURNING TASKS USE?><primary><emphasis role="strong">Void</emphasis></primary><secondary>non-value-returning tasks use</secondary></indexterm>The <literal>Executor</literal> framework uses <literal>Runnable</literal> as its basic task representation. <literal>Runnable</literal> is a fairly limiting abstraction; <literal>run</literal> cannot return a value or throw checked exceptions, although it can have side effects such as writing to a log file or placing a result in a shared data structure.</para>
<para>Many tasks are effectively deferred computations—executing a database query, fetching a resource over the network, or computing a complicated function. For these types of tasks, <literal>Callable</literal> is a better abstraction: it expects that the main entry point, <literal>call</literal>, will return a value and anticipates that it might throw an exception.<footnote id="ch06fn07" label="7"><para>To express a non-value-returning task with <literal>Callable</literal>, use <literal>Callable&lt;Void&gt;</literal>.</para></footnote> <literal>Executors</literal> includes several utility methods for wrapping other types of tasks, including <literal>Runnable</literal> and <literal>java.security.PrivilegedAction</literal>, with a <literal>Callable</literal>.</para>
<para><literal>Runnable</literal> and <literal>Callable</literal> describe abstract computational tasks. Tasks are usually finite: they have a clear starting point and they eventually terminate. The lifecycle of a task executed by an <literal>Executor</literal> has four phases: <emphasis>created</emphasis>, <emphasis>submitted</emphasis>, <emphasis>started</emphasis>, and <emphasis>completed</emphasis>. Since tasks can take a long time to run, we also want to be able to cancel a task. In the <literal>Executor</literal> framework, tasks that have been submitted but not yet started can always be cancelled, and tasks that have started can sometimes be cancelled if they are responsive to interruption. Cancelling a task that has already completed has no effect. (Cancellation is covered in greater detail in <link linkend="ch07" preference="0">Chapter 7</link>.)</para>
<para><literal>Future</literal> represents the lifecycle of a task and provides methods to test whether the task has completed or been cancelled, retrieve its result, and cancel the task. <literal>Callable</literal> and <literal>Future</literal> are shown in <link linkend="ch06list11" preference="0">Listing 6.11</link>. Implicit in the specification of <literal>Future</literal> is that task lifecycle can only move forwards, not backwards—just like the <literal>ExecutorService</literal> lifecycle. Once a task is completed, it stays in that state forever.</para>
<para>The behavior of <literal>get</literal> varies depending on the task state (not yet started, running, completed). It returns immediately or throws an <literal>Exception</literal> if the task has already completed, but if not it blocks until the task completes. If the task completes by throwing an exception, <literal>get</literal> rethrows it wrapped in an <literal>ExecutionException</literal>; <?docpage num="126"?><indexterm id="iddle1012" significance="normal"><?indexkey A?><?primarykey AbstractExecutorService?><primary><emphasis role="strong">AbstractExecutorService</emphasis></primary></indexterm><indexterm id="iddle1013" significance="normal"><?indexkey A?><?primarykey AbstractExecutorService?><?secondarykey TASK REPRESENTATION USE?><primary><emphasis role="strong">AbstractExecutorService</emphasis></primary><secondary>task representation use</secondary></indexterm><indexterm id="iddle1290" significance="normal"><?indexkey C?><?primarykey Callable?><primary><emphasis role="strong">Callable</emphasis></primary></indexterm><indexterm id="iddle2419" significance="normal"><?indexkey F?><?primarykey Future?><primary><emphasis role="strong">Future</emphasis></primary></indexterm><indexterm id="iddle2428" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey TASK REPRESENTATION?><primary><emphasis role="strong">Future</emphasis></primary><secondary>task representation</secondary></indexterm><indexterm id="iddle2429" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey TASK REPRESENTATION?><?tertiarykey IMPLEMENTATION STRATEGIES?><primary><emphasis role="strong">Future</emphasis></primary><secondary>task representation</secondary><tertiary>implementation strategies</tertiary></indexterm><indexterm id="iddle2440" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey TASK REPRESENTATION USE?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>task representation use</secondary></indexterm><indexterm id="iddle3298" significance="normal"><?indexkey N?><?primarykey newTaskFor?><primary><emphasis role="strong">newTaskFor</emphasis></primary></indexterm><indexterm id="iddle3729" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey SAFE?><?tertiarykey IN TASK CREATION?><primary><emphasis role="strong">publication</emphasis></primary><secondary>safe</secondary><tertiary>in task creation</tertiary></indexterm><indexterm id="iddle3871" significance="normal"><?indexkey R?><?primarykey representation?><?secondarykey TASK?><?tertiarykey WITH FUTURE?><primary><emphasis role="strong">representation</emphasis></primary><secondary>task</secondary><tertiary>with <literal>Future</literal></tertiary></indexterm><indexterm id="iddle4040" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey PUBLICATION?><?tertiarykey IN TASK CREATION?><primary><emphasis role="strong">safety</emphasis></primary><secondary>publication</secondary><tertiary>in task creation</tertiary></indexterm><indexterm id="iddle4647" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey REPRESENTATION?><?tertiarykey WITH FUTURE?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>representation</secondary><tertiary>with <literal>Future</literal></tertiary></indexterm><indexterm id="iddle4858" significance="normal"><?indexkey T?><?primarykey ThreadPoolExecutor?><?secondarykey NEWTASKFOR?><primary><emphasis role="strong">ThreadPoolExecutor</emphasis></primary><secondary><literal>newTaskFor</literal></secondary></indexterm>if it was cancelled, <literal>get</literal> throws <literal>CancellationException</literal>. If <literal>get</literal> throws <literal>ExecutionException</literal>, the underlying exception can be retrieved with <literal>getCause</literal>.</para>
<example id="ch06list11" label="6.11" role="Listing" xreflabel="6.11" condition="126">
<title id="ch06list11__title"><literal>Callable</literal> and <literal>Future</literal> Interfaces.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface Callable&lt;V&gt; {
    V call() throws Exception;
}

public interface Future&lt;V&gt; {
    boolean cancel(boolean mayInterruptIfRunning);
    boolean isCancelled();
    boolean isDone();
    V get() throws InterruptedException, ExecutionException,
                   CancellationException;
    V get(long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException,
               CancellationException, TimeoutException;
}
</programlisting>
</example>
<para>There are several ways to create a <literal>Future</literal> to describe a task. The <literal>submit</literal> methods in <literal>ExecutorService</literal> all return a <literal>Future</literal>, so that you can submit a <literal>Runnable</literal> or a <literal>Callable</literal> to an executor and get back a <literal>Future</literal> that can be used to retrieve the result or cancel the task. You can also explicitly instantiate a <literal>FutureTask</literal> for a given <literal>Runnable</literal> or <literal>Callable</literal>. (Because <literal>FutureTask</literal> implements <literal>Runnable</literal>, it can be submitted to an <literal>Executor</literal> for execution or executed directly by calling its <literal>run</literal> method.)</para>
<para>As of Java 6, <literal>ExecutorService</literal> implementations can override <literal>newTaskFor</literal> in <literal>AbstractExecutorService</literal> to control instantiation of the <literal>Future</literal> corresponding to a submitted <literal>Callable</literal> or <literal>Runnable</literal>. The default implementation just creates a new <literal>FutureTask</literal>, as shown in <link linkend="ch06list12" preference="0">Listing 6.12</link>.</para>
<example id="ch06list12" label="6.12" role="Listing" xreflabel="6.12" condition="126">
<title id="ch06list12__title">Default Implementation of <literal>newTaskFor</literal> in <literal>ThreadPoolExecutor</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; task) {
    return new FutureTask&lt;T&gt;(task);
}
</programlisting>
</example>
<para>Submitting a <literal>Runnable</literal> or <literal>Callable</literal> to an <literal>Executor</literal> constitutes a safe publication (see <link linkend="ch03lev1sec5" preference="0">Section 3.5</link>) of the <literal>Runnable</literal> or <literal>Callable</literal> from the submitting thread to the thread that will eventually execute the task. Similarly, setting the result value for a <literal>Future</literal> constitutes a safe publication of the result from the thread in which it was computed to any thread that retrieves it via <literal>get</literal>.</para>
</section>
<section id="ch06lev2sec11" condition="127" label="6.3.3" xreflabel="6.3.3">
<?docpage num="127"?><?docpage num="128"?>
<title id="ch06lev2sec11__title">Example: Page Renderer with Future</title>
<para><indexterm id="iddle2635" significance="normal"><?indexkey H?><?primarykey heterogeneous tasks?><primary><emphasis role="strong">heterogeneous tasks</emphasis></primary></indexterm><indexterm id="iddle2636" significance="normal"><?indexkey H?><?primarykey heterogeneous tasks?><?secondarykey PARALLELIZATION LIMITATIONS?><primary><emphasis role="strong">heterogeneous tasks</emphasis></primary><secondary>parallelization limitations</secondary></indexterm><indexterm id="iddle3445" significance="normal"><?indexkey P?><?primarykey page renderer examples?><?secondarykey HETEROGENOUS TASK PARTITIONING?><primary><emphasis role="strong">page renderer examples</emphasis></primary><secondary>heterogenous task partitioning</secondary></indexterm><indexterm id="iddle3451" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey HETEROGENEOUS TASKS?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>heterogeneous tasks</secondary></indexterm><indexterm id="iddle3484" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey AND HETEROGENEOUS TASKS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>and heterogeneous tasks</secondary></indexterm><indexterm id="iddle4067" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey HETEROGENEOUS TASK ISSUES?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>heterogeneous task issues</secondary></indexterm><indexterm id="iddle4312" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey HETEROGENEOUS TASKS?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>heterogeneous tasks</secondary></indexterm><indexterm id="iddle4628" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey HETEROGENEOUS TASKS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>heterogeneous tasks</secondary></indexterm><indexterm id="iddle4629" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey HETEROGENEOUS TASKS?><?tertiarykey PARALLELIZATION LIMITATIONS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>heterogeneous tasks</secondary><tertiary>parallelization limitations</tertiary></indexterm>As a first step towards making the page renderer more concurrent, let’s divide it into two tasks, one that renders the text and one that downloads all the images. (Because one task is largely CPU-bound and the other is largely I/O-bound, this approach may yield improvements even on single-CPU systems.)</para>
<para><literal>Callable</literal> and <literal>Future</literal> can help us express the interaction between these cooperating tasks. In <literal>FutureRenderer</literal> in <link linkend="ch06list13" preference="0">Listing 6.13</link>, we create a <literal>Callable</literal> to download all the images, and submit it to an <literal>ExecutorService</literal>. This returns a <literal>Future</literal> describing the task’s execution; when the main task gets to the point where it needs the images, it waits for the result by calling <literal>Future.get</literal>. Ifwe’re lucky, the results will already be ready by the time we ask; otherwise, at least we got a head start on downloading the images.</para>
<para>The state-dependent nature of <literal>get</literal> means that the caller need not be aware of the state of the task, and the safe publication properties of task submission and result retrieval make this approach thread-safe. The exception handling code surrounding <literal>Future.get</literal> deals with two possible problems: that the task encountered an <literal>Exception</literal>, or the thread calling <literal>get</literal> was interrupted before the results were available. (See <link linkend="ch05lev2sec11" preference="0">Sections 5.5.2</link> and <link linkend="ch05lev1sec4" preference="0">5.4</link>.)</para>
<para><literal>FutureRenderer</literal> allows the text to be rendered concurrently with downloading the image data. When all the images are downloaded, they are rendered onto the page. This is an improvement in that the user sees a result quickly and it exploits some parallelism, but we can do considerably better. There is no need for users to wait for <emphasis>all</emphasis> the images to be downloaded; they would probably prefer to see individual images drawn as they become available.</para>
</section>
<section id="ch06lev2sec12" label="6.3.4" xreflabel="6.3.4">
<title id="ch06lev2sec12__title">Limitations of Parallelizing Heterogeneous Tasks</title>
<para>In the last example, we tried to execute two different types of tasks in parallel—downloading the images and rendering the page. But obtaining significant performance improvements by trying to parallelize sequential heterogeneous tasks can be tricky.</para>
<para>Two people can divide the work of cleaning the dinner dishes fairly effectively: one person washes while the other dries. However, assigning a different type of task to each worker does not scale well; if several more people show up, it is not obvious how they can help without getting in the way or significantly restructuring the division of labor. Without finding finer-grained parallelism among similar tasks, this approach will yield diminishing returns.</para>
<para>A further problem with dividing heterogeneous tasks among multiple workers is that the tasks may have disparate sizes. If you divide tasks <emphasis>A</emphasis> and <emphasis>B</emphasis> between two workers but <emphasis>A</emphasis> takes ten times as long as <emphasis>B</emphasis>, you’ve only speeded up the total process by 9%. Finally, dividing a task among multiple workers always involves some amount of coordination overhead; for the division to be worthwhile, this overhead must be more than compensated by productivity improvements due to parallelism.</para>
<para><literal>FutureRenderer</literal> uses two tasks: one for rendering text and one for downloading the images. If rendering the text is much faster than downloading the images, <?docpage num="129"?><indexterm id="iddle1225" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey QUEUES?><?tertiarykey EXECUTOR FUNCTIONALITY COMBINED WITH?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>queues</secondary><tertiary><literal>Executor</literal> functionality combined with</tertiary></indexterm><indexterm id="iddle1400" significance="normal"><?indexkey C?><?primarykey completion?><?secondarykey SERVICE?><primary><emphasis role="strong">completion</emphasis></primary><secondary>service</secondary></indexterm><indexterm id="iddle1401" significance="normal"><?indexkey C?><?primarykey completion?><?secondarykey SERVICE?><?tertiarykey FUTURE?><primary><emphasis role="strong">completion</emphasis></primary><secondary>service</secondary><tertiary><literal>Future</literal></tertiary></indexterm><indexterm id="iddle1405" significance="normal"><?indexkey C?><?primarykey CompletionService?><primary><emphasis role="strong">CompletionService</emphasis></primary></indexterm><indexterm id="iddle1406" significance="normal"><?indexkey C?><?primarykey CompletionService?><?secondarykey IN PAGE RENDERING EXAMPLE?><primary><emphasis role="strong">CompletionService</emphasis></primary><secondary>in page rendering example</secondary></indexterm><indexterm id="iddle2165" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey QUEUEINGFUTURE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>QueueingFuture</literal></secondary></indexterm><indexterm id="iddle2238" significance="normal"><?indexkey E?><?primarykey Exchanger?><primary><emphasis role="strong">Exchanger</emphasis></primary><seealso> <link linkend="iddle1579" preference="0"><emphasis role="strong">consumers</emphasis>, producer-consumer pattern</link>.</seealso></indexterm><indexterm id="iddle2265" significance="normal"><?indexkey E?><?primarykey ExecutorCompletionService?><primary><emphasis role="strong">ExecutorCompletionService</emphasis></primary></indexterm><indexterm id="iddle2266" significance="normal"><?indexkey E?><?primarykey ExecutorCompletionService?><?secondarykey IN PAGE RENDERING EXAMPLE?><primary><emphasis role="strong">ExecutorCompletionService</emphasis></primary><secondary>in page rendering example</secondary></indexterm><indexterm id="iddle2643" significance="normal"><?indexkey H?><?primarykey homogeneous tasks?><primary><emphasis role="strong">homogeneous tasks</emphasis></primary></indexterm><indexterm id="iddle2644" significance="normal"><?indexkey H?><?primarykey homogeneous tasks?><?secondarykey PARALLELISM ADVANTAGES?><primary><emphasis role="strong">homogeneous tasks</emphasis></primary><secondary>parallelism advantages</secondary></indexterm><indexterm id="iddle3678" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary></indexterm><indexterm id="iddle3679" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey AND EXECUTOR FUNCTIONALITY?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>and <literal>Executor</literal> functionality</secondary></indexterm><indexterm id="iddle3680" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey AND EXECUTOR FUNCTIONALITY?><?tertiarykey IN COMPLETIONSERVICE?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>and <literal>Executor</literal> functionality</secondary><tertiary>in <literal>CompletionService</literal></tertiary></indexterm><indexterm id="iddle3753" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey BLOCKING?><?tertiarykey COMPLETIONSERVICE AS?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>blocking</secondary><tertiary><literal>CompletionService</literal> as</tertiary></indexterm><indexterm id="iddle4630" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey HETEROGENEOUS TASKS?><?tertiarykey PARALLELIZATION LIMITATIONS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>heterogeneous tasks</secondary><tertiary>parallelization limitations</tertiary></indexterm><indexterm id="iddle4631" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey HOMOGENEOUS TASKS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>homogeneous tasks</secondary></indexterm><indexterm id="iddle4632" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey HOMOGENEOUS TASKS?><?tertiarykey PARALLELISM ADVANTAGES?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>homogeneous tasks</secondary><tertiary>parallelism advantages</tertiary></indexterm><indexterm id="iddle4639" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey PARALLELIZATION OF?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>parallelization of</secondary></indexterm><indexterm id="iddle4640" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey PARALLELIZATION OF?><?tertiarykey HOMOGENEOUS VS. HETEROGENEOUS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>parallelization of</secondary><tertiary>homogeneous vs. heterogeneous</tertiary></indexterm>as is entirely possible, the resulting performance is not much different from the sequential version, but the code is a lot more complicated. And the best we can do with two threads is speed things up by a factor of two. Thus, trying to increase concurrency by parallelizing heterogeneous activities can be a lot of work, and there is a limit to how much additional concurrency you can get out of it. (See <link linkend="ch11lev2sec9" preference="0">Sections 11.4.2</link> and <link linkend="ch11lev2sec10" preference="0">11.4.3</link> for another example of the same phenomenon.)</para>
<example id="ch06list13" label="6.13" role="Listing" xreflabel="6.13" condition="128">
<?docpage num="128"?>
<title id="ch06list13__title">Waiting for Image Download with <literal>Future</literal>.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class FutureRenderer {
    private final ExecutorService executor = ...;

    void renderPage(CharSequence source) {
        final List&lt;ImageInfo&gt; imageInfos = scanForImageInfo(source);
        Callable&lt;List&lt;ImageData&gt;&gt; task =
                new Callable&lt;List&lt;ImageData&gt;&gt;() {
                    public List&lt;ImageData&gt; call() {
                        List&lt;ImageData&gt; result
                                = new ArrayList&lt;ImageData&gt;();
                        for (ImageInfo imageInfo : imageInfos)
                            result.add(imageInfo.downloadImage());
                        return result;
                    }
                };

        Future&lt;List&lt;ImageData&gt;&gt; future =  <emphasis role="strong">executor.submit(task);</emphasis>
        renderText(source);

        try {
            List&lt;ImageData&gt; imageData =  <emphasis role="strong">future.get();</emphasis>
            for (ImageData data : imageData)
                renderImage(data);
        } catch (InterruptedException e) {
            // <emphasis>Re-assert the thread's interrupted status</emphasis>
            Thread.currentThread().interrupt();
            // <emphasis>We don't need the result, so cancel the task too</emphasis>
            future.cancel(true);
        } catch (ExecutionException e) {
            throw launderThrowable(e.getCause());
        }
    }
}
</programlisting>
</example>
<sidebar float="1" id="ch06sb02" condition="129"><title/>
<para><indexterm id="iddle2116" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey FUTURERENDERER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>FutureRenderer</literal></secondary></indexterm>The real performance payoff of dividing a program’s workload into tasks comes when there are a large number of independent, <emphasis>homogeneous</emphasis> tasks that can be processed concurrently.</para>
</sidebar>
</section>
<section id="ch06lev2sec13" label="6.3.5" xreflabel="6.3.5">
<title id="ch06lev2sec13__title"><literal>CompletionService</literal>: Executor Meets <literal>BlockingQueue</literal></title>
<para>If you have a batch of computations to submit to an <literal>Executor</literal> and you want to retrieve their results as they become available, you could retain the <literal>Future</literal> associated with each task and repeatedly poll for completion by calling <literal>get</literal> with a timeout of zero. This is possible, but tedious. Fortunately there is a better way: a <emphasis>completion service</emphasis>.</para>
<para><literal>CompletionService</literal> combines the functionality of an <literal>Executor</literal> and a <literal>BlockingQueue</literal>. You can submit <literal>Callable</literal> tasks to it for execution and use the queuelike methods <literal>take</literal> and <literal>poll</literal> to retrieve completed results, packaged as <literal>Future</literal>s, as they become available. <literal>ExecutorCompletionService</literal> implements <literal>CompletionService</literal>, delegating the computation to an <literal>Executor</literal>.</para>
<para>The implementation of <literal>ExecutorCompletionService</literal> is quite straightforward. The constructor creates a <literal>BlockingQueue</literal> to hold the completed results. <literal>Future-Task</literal> has a <literal>done</literal> method that is called when the computation completes. When a task is submitted, it is wrapped with a <literal>QueueingFuture</literal>, a subclass of <literal>FutureTask</literal> that overrides <literal>done</literal> to place the result on the <literal>BlockingQueue</literal>, as shown in <link linkend="ch06list14" preference="0">Listing 6.14</link>. The <literal>take</literal> and <literal>poll</literal> methods delegate to the <literal>BlockingQueue</literal>, blocking if results are not yet available.</para>
<example id="ch06list14" label="6.14" role="Listing" xreflabel="6.14" condition="129">
<title id="ch06list14__title"><literal>QueueingFuture</literal> Class Used By <literal>ExecutorCompletionService</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">private class QueueingFuture&lt;V&gt; extends FutureTask&lt;V&gt; {
    QueueingFuture(Callable&lt;V&gt; c) { super(c); }
    QueueingFuture(Runnable t, V r) { super(t, r); }

    protected void done() {
        completionQueue.add(this);
    }
}
</programlisting>
</example>
</section>
<section id="ch06lev2sec14" condition="130" label="6.3.6" xreflabel="6.3.6">
<?docpage num="130"?>
<title id="ch06lev2sec14__title">Example: Page Renderer with <literal>CompletionService</literal></title>
<para><indexterm id="iddle2169" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey RENDERER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Renderer</literal></secondary></indexterm><indexterm id="iddle3517" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey PAGE RENDERER EXAMPLE WITH COMPLETIONSERVICE?><primary><emphasis role="strong">performance</emphasis></primary><secondary>page renderer example with <literal>CompletionService</literal></secondary></indexterm><indexterm id="iddle3518" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey PAGE RENDERER EXAMPLE WITH COMPLETIONSERVICE?><?tertiarykey IMPROVEMENTS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>page renderer example with <literal>CompletionService</literal></secondary><tertiary>improvements</tertiary></indexterm><indexterm id="iddle3958" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey PAGE RENDERER EXAMPLE WITH COMPLETIONSERVICE?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>page renderer example with <literal>CompletionService</literal></secondary></indexterm><indexterm id="iddle3959" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey PAGE RENDERER EXAMPLE WITH COMPLETIONSERVICE?><?tertiarykey IMPROVEMENTS?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>page renderer example with <literal>CompletionService</literal></secondary><tertiary>improvements</tertiary></indexterm><indexterm id="iddle4241" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey STRATEGIES?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>strategies</secondary></indexterm><indexterm id="iddle4242" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey STRATEGIES?><?tertiarykey EXECUTORCOMPLETIONSERVICE USE?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>strategies</secondary><tertiary><literal>ExecutorCompletionService</literal> use</tertiary></indexterm>We can use a <literal>CompletionService</literal> to improve the performance of the page renderer in two ways: shorter total runtime and improved responsiveness. We can create a separate task for downloading <emphasis>each</emphasis> image and execute them in a thread pool, turning the sequential download into a parallel one: this reduces the amount of time to download all the images. And by fetching results from the <literal>CompletionService</literal> and rendering each image as soon as it is available, we can give the user a more dynamic and responsive user interface. This implementation is shown in <literal>Renderer</literal> in <link linkend="ch06list15" preference="0">Listing 6.15</link>.</para>
<example id="ch06list15" label="6.15" role="Listing" xreflabel="6.15" condition="130">
<title id="ch06list15__title">Using <literal>CompletionService</literal> to Render Page Elements as they Become Available.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class Renderer {
    private final ExecutorService executor;

    Renderer(ExecutorService executor) { this.executor = executor; }

    void renderPage(CharSequence source) {
        List&lt;ImageInfo&gt; info = scanForImageInfo(source);
        CompletionService&lt;ImageData&gt; completionService =
            new ExecutorCompletionService&lt;ImageData&gt;(executor);
        for (final ImageInfo imageInfo : info)
            <emphasis role="strong">completionService.submit</emphasis>(new Callable&lt;ImageData&gt;() {
                 public ImageData call() {
                     return imageInfo.downloadImage();
                 }
            });

        renderText(source);

        try {
            for (int t = 0, n =  info.size(); t &lt; n;  t++) {
                Future&lt;ImageData&gt; f = <emphasis role="strong">completionService.take();</emphasis>
                ImageData imageData = f.get();
                renderImage(imageData);
            }
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        } catch (ExecutionException e) {
            throw launderThrowable(e.getCause());
        }
    }
}
</programlisting>
</example>
<para>Multiple <literal>ExecutorCompletionService</literal>s can share a single <literal>Executor</literal>, so it is <?docpage num="131"?><indexterm id="iddle1317" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey TASK?><?tertiarykey IN TIMED TASK HANDLING?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>task</secondary><tertiary>in timed task handling</tertiary></indexterm><indexterm id="iddle1934" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey TIMED TASKS?><primary><emphasis role="strong">design</emphasis></primary><secondary>timed tasks</secondary></indexterm><indexterm id="iddle3633" significance="normal"><?indexkey P?><?primarykey portal?><primary><emphasis role="strong">portal</emphasis></primary></indexterm><indexterm id="iddle3634" significance="normal"><?indexkey P?><?primarykey portal?><?secondarykey TIMED TASK EXAMPLE?><primary><emphasis role="strong">portal</emphasis></primary><secondary>timed task example</secondary></indexterm><indexterm id="iddle3933" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey TIMED TASK HANDLING?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>timed task handling</tertiary></indexterm><indexterm id="iddle4888" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey %?><?tertiarykey MANAGEMENT DESIGN ISSUES?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>-based task</secondary><tertiary>management design issues</tertiary></indexterm><indexterm id="iddle4929" significance="normal"><?indexkey T?><?primarykey TimeoutException?><primary><emphasis role="strong">TimeoutException</emphasis></primary></indexterm><indexterm id="iddle4930" significance="normal"><?indexkey T?><?primarykey TimeoutException?><?secondarykey IN TIMED TASKS?><primary><emphasis role="strong">TimeoutException</emphasis></primary><secondary>in timed tasks</secondary></indexterm><indexterm id="iddle4962" significance="normal"><?indexkey T?><?primarykey travel reservations portal example?><primary><emphasis role="strong">travel reservations portal example</emphasis></primary></indexterm><indexterm id="iddle4963" significance="normal"><?indexkey T?><?primarykey travel reservations portal example?><?secondarykey AS TIMED TASK EXAMPLE?><primary><emphasis role="strong">travel reservations portal example</emphasis></primary><secondary>as timed task example</secondary></indexterm>perfectly sensible to create an <literal>ExecutorCompletionService</literal> that is private to a particular computation while sharing a common <literal>Executor</literal>. When used in this way, a <literal>CompletionService</literal> acts as a handle for a batch of computations in much the same way that a <literal>Future</literal> acts as a handle for a single computation. By remembering how many tasks were submitted to the <literal>CompletionService</literal> and counting how many completed results are retrieved, you can know when all the results for a given batch have been retrieved, even if you use a shared <literal>Executor</literal>.</para>
</section>
<section id="ch06lev2sec15" label="6.3.7" xreflabel="6.3.7">
<title id="ch06lev2sec15__title">Placing Time Limits on Tasks</title>
<para>Sometimes, if an activity does not complete within a certain amount of time, the result is no longer needed and the activity can be abandoned. For example, a web application may fetch its advertisements from an external ad server, but if the ad is not available within two seconds, it instead displays a default advertisement so that ad unavailability does not undermine the site’s responsiveness requirements. Similarly, a portal site may fetch data in parallel from multiple data sources, but may be willing to wait only a certain amount of time for data to be available before rendering the page without it.</para>
<para>The primary challenge in executing tasks within a time budget is making sure that you don’t wait longer than the time budget to get an answer or find out that one is not forthcoming. The timed version of <literal>Future.get</literal> supports this requirement: it returns as soon as the result is ready, but throws <literal>TimeoutException</literal> if the result is not ready within the timeout period.</para>
<para>A secondary problem when using timed tasks is to stop them when they run out of time, so they do not waste computing resources by continuing to compute a result that will not be used. This can be accomplished by having the task strictly manage its own time budget and abort if it runs out of time, or by cancelling the task if the timeout expires. Again, <literal>Future</literal> can help; if a timed <literal>get</literal> completes with a <literal>TimeoutException</literal>, you can cancel the task through the <literal>Future</literal>. If the task is written to be cancellable (see <link linkend="ch07" preference="0">Chapter 7</link>), it can be terminated early so as not to consume excessive resources. This technique is used in <link linkend="ch06list13" preference="0">Listings 6.13</link> and <link linkend="ch06list16" preference="0">6.16</link>.</para>
<para><link linkend="ch06list16" preference="0">Listing 6.16</link> shows a typical application of a timed <literal>Future.get</literal>. It generates a composite web page that contains the requested content plus an advertisement fetched from an ad server. It submits the ad-fetching task to an executor, computes the rest of the page content, and then waits for the ad until its time budget runs out.<footnote id="ch06fn08" label="8"><para>The timeout passed to <literal>get</literal> is computed by subtracting the current time from the deadline; this may in fact yield a negative number, but all the timed methods in <literal>java.util.concurrent</literal> treat negative timeouts as zero, so no extra code is needed to deal with this case.</para></footnote> If the <literal>get</literal> times out, it cancels<footnote id="ch06fn09" label="9"><para>The <literal>true</literal> parameter to <literal>Future.cancel</literal> means that the task thread can be interrupted if the task is currently running; see <link linkend="ch07" preference="0">Chapter 7</link>.</para></footnote> the ad-fetching task and uses a default advertisement instead.</para>
</section>
<section id="ch06lev2sec16" label="6.3.8" xreflabel="6.3.8">
<title id="ch06lev2sec16__title">Example: A Travel Reservations Portal</title>
<para>The time-budgeting approach in the previous section can be easily generalized to an arbitrary number of tasks. Consider a travel reservation portal: the user enters <?docpage num="132"?>travel dates and requirements and the portal fetches and displays bids from a number of airlines, hotels or car rental companies. Depending on the company, fetching a bid might involve invoking a web service, consulting a database, performing an EDI transaction, or some other mechanism. Rather than have the response time for the page be driven by the slowest response, it may be preferable to present only the information available within a given time budget. For providers that do not respond in time, the page could either omit them completely or display a placeholder such as “Did not hear from Air Java in time.”</para>
<example id="ch06list16" label="6.16" role="Listing" xreflabel="6.16" condition="132">
<title id="ch06list16__title">Fetching an Advertisement with a Time Budget.</title>
<programlisting format="linespecific" linenumbering="unnumbered">Page renderPageWithAd() throws InterruptedException {
    long endNanos = System.nanoTime() + TIME_BUDGET;
    Future&lt;Ad&gt; f = exec.submit(new FetchAdTask());
    // <emphasis>Render the page while waiting for the ad</emphasis>
    Page page = renderPageBody();
    Ad ad;
    try {
        // <emphasis>Only wait for the remaining time budget</emphasis>
        long timeLeft = endNanos - System.nanoTime();
        ad = f.get(timeLeft, NANOSECONDS);
    } catch (ExecutionException e) {
        ad = DEFAULT_AD;
    } catch (TimeoutException e) {
        ad = DEFAULT_AD;
        f.cancel(true);
    }
    page.setAd(ad);
    return page;
}
</programlisting>
</example>
<para>Fetching a bid from one company is independent of fetching bids from another, so fetching a single bid is a sensible task boundary that allows bid retrieval to proceed concurrently. It would be easy enough to create <emphasis>n</emphasis> tasks, submit them to a thread pool, retain the <literal>Future</literal>s, and use a timed <literal>get</literal> to fetch each result sequentially via its <literal>Future</literal>, but there is an even easierway—<literal>invokeAll</literal>.</para>
<para><link linkend="ch06list17" preference="0">Listing 6.17</link> uses the timed version of <literal>invokeAll</literal> to submit multiple tasks to an <literal>ExecutorService</literal> and retrieve the results. The <literal>invokeAll</literal> method takes a collection of tasks and returns a collection of <literal>Future</literal>s. The two collections have identical structures; <literal>invokeAll</literal> adds the <literal>Future</literal>s to the returned collection in the order imposed by the task collection’s iterator, thus allowing the caller to associate a <literal>Future</literal> with the <literal>Callable</literal> it represents. The timed version of <literal>invokeAll</literal> will return when all the tasks have completed, the calling thread is interrupted, or the timeout expires. Any tasks that are not complete when the timeout expires are cancelled. On return from <literal>invokeAll</literal>, each task will have either completed normally or been cancelled; the client code can call <literal>get</literal> or <literal>isCancelled</literal> to find <?docpage num="133"?><indexterm id="iddle4889" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey %?><?tertiarykey MANAGEMENT DESIGN ISSUES?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>-based task</secondary><tertiary>management design issues</tertiary></indexterm>out which.</para>
</section>
</section>



<section id="ch06lev1sec4" condition="133" label="" xreflabel=""><?docpage num="133"?>
<title id="ch06lev1sec4__title">Summary</title>
<para>Structuring applications around the execution of <emphasis>tasks</emphasis> can simplify development and facilitate concurrency. The <literal>Executor</literal> framework permits you to decouple task submission from execution policy and supports a rich variety of execution policies; whenever you find yourself creating threads to perform tasks, consider using an <literal>Executor</literal> instead. To maximize the benefit of decomposing an application into tasks, you must identify sensible task boundaries. In some applications, the obvious task boundaries work well, whereas in others some analysis may be required to uncover finer-grained exploitable parallelism.</para>

<para><?docpage num="134"?></para><example id="ch06list17" label="6.17" role="Listing" xreflabel="6.17" condition="134">

<title id="ch06list17__title">Requesting Travel Quotes Under a Time Budget.</title>
<programlisting format="linespecific" linenumbering="unnumbered">private class QuoteTask implements Callable&lt;TravelQuote&gt; {
    private final TravelCompany company;
    private final TravelInfo travelInfo;
    ...
    public TravelQuote call() throws Exception {
        return company.solicitQuote(travelInfo);
    }
}

public List&lt;TravelQuote&gt; getRankedTravelQuotes(
        TravelInfo travelInfo, Set&lt;TravelCompany&gt; companies,
        Comparator&lt;TravelQuote&gt; ranking, long time, TimeUnit unit)
        throws InterruptedException {
    List&lt;QuoteTask&gt; tasks = new ArrayList&lt;QuoteTask&gt;();
    for (TravelCompany company : companies)
        tasks.add(new QuoteTask(company, travelInfo));

    List&lt;Future&lt;TravelQuote&gt;&gt; futures =
        <emphasis role="strong">exec.invokeAll(tasks, time, unit);</emphasis>

    List&lt;TravelQuote&gt; quotes =
        new ArrayList&lt;TravelQuote&gt;(tasks.size());
    Iterator&lt;QuoteTask&gt; taskIter = tasks.iterator();
    for (Future&lt;TravelQuote&gt; f : futures) {
        QuoteTask task = taskIter.next();
        try {
            quotes.add(f.get());
        } catch (ExecutionException e) {
            quotes.add(task.getFailureQuote(e.getCause()));
        } catch (CancellationException e) {
            quotes.add(task.getTimeoutQuote(e));
        }
    }

    Collections.sort(quotes, ranking);
    return quotes;
}
</programlisting>
</example>
</section>

</chapter>

<chapter id="ch07" label="7" xreflabel="7" condition="135">
<?docpage num="135"?>
<title id="ch07__title">Cancellation and Shutdown</title>


<para><indexterm id="iddle1043" significance="normal"><?indexkey A?><?primarykey activity(s)?><?secondarykey CANCELLATION?><primary><emphasis role="strong">activity(s)</emphasis></primary><secondary>cancellation</secondary></indexterm><indexterm id="iddle1044" significance="normal"><?indexkey A?><?primarykey activity(s)?><?secondarykey CANCELLATION?><primary><emphasis role="strong">activity(s)</emphasis></primary><secondary>cancellation</secondary></indexterm><indexterm id="iddle1296" significance="normal"><?indexkey C?><?primarykey cancellation?><primary><emphasis role="strong">cancellation</emphasis></primary><seealso> <link linkend="iddle3584" preference="0"><emphasis role="strong">policy(s)</emphasis>, interruption</link>.</seealso></indexterm><indexterm id="iddle1297" significance="normal"><?indexkey C?><?primarykey cancellation?><primary><emphasis role="strong">cancellation</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle1298" significance="normal"><?indexkey C?><?primarykey cancellation?><primary><emphasis role="strong">cancellation</emphasis></primary><seealso> <link linkend="iddle1114" preference="0"><emphasis role="strong">application(s)</emphasis>, shutdown</link>.</seealso></indexterm><indexterm id="iddle1299" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey ACTIVITY?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>activity</secondary></indexterm><indexterm id="iddle1314" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey SHUTDOWN AND?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>shutdown and</secondary></indexterm><indexterm id="iddle1351" significance="normal"><?indexkey C?><?primarykey cleanup?><primary><emphasis role="strong">cleanup</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle1354" significance="normal"><?indexkey C?><?primarykey cleanup?><?secondarykey IN END-OF-LIFECYCLE PROCESSING?><primary><emphasis role="strong">cleanup</emphasis></primary><secondary>in end-of-lifecycle processing</secondary></indexterm><indexterm id="iddle1565" significance="normal"><?indexkey C?><?primarykey construction/constructors?><primary><emphasis role="strong">construction/constructors</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle1643" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey END-OF-LIFECYCLE MECHANISMS?><?tertiarykey INTERRUPTION AS?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>end-of-lifecycle mechanisms</secondary><tertiary>interruption as</tertiary></indexterm><indexterm id="iddle2034" significance="normal"><?indexkey E?><?primarykey end-of-lifecycle?><?secondarykey MANAGEMENT TECHNIQUES?><primary><emphasis role="strong">end-of-lifecycle</emphasis></primary><secondary>management techniques</secondary></indexterm><indexterm id="iddle2309" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey MANAGEMENT TECHNIQUES?><primary><emphasis role="strong">failure</emphasis></primary><secondary>management techniques</secondary></indexterm><indexterm id="iddle2735" significance="normal"><?indexkey I?><?primarykey initialization?><primary><emphasis role="strong">initialization</emphasis></primary><seealso> <link linkend="iddle1565" preference="0"><emphasis role="strong">construction/constructors</emphasis></link>.</seealso></indexterm><indexterm id="iddle2796" significance="normal"><?indexkey I?><?primarykey interruption(s)?><primary><emphasis role="strong">interruption(s)</emphasis></primary></indexterm><indexterm id="iddle2811" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey PREEMPTIVE?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>preemptive</secondary></indexterm><indexterm id="iddle2812" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey PREEMPTIVE?><?tertiarykey DEPRECATION REASONS?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>preemptive</secondary><tertiary>deprecation reasons</tertiary></indexterm><indexterm id="iddle2963" significance="normal"><?indexkey L?><?primarykey lifecycle?><primary><emphasis role="strong">lifecycle</emphasis></primary><seealso> <link linkend="iddle1043" preference="0"><emphasis role="strong">activity(s)</emphasis>, cancellation</link>.</seealso></indexterm><indexterm id="iddle2964" significance="normal"><?indexkey L?><?primarykey lifecycle?><primary><emphasis role="strong">lifecycle</emphasis></primary><seealso> <link linkend="iddle2646" preference="0"><emphasis role="strong">hooks</emphasis>, completion</link>.</seealso></indexterm><indexterm id="iddle2965" significance="normal"><?indexkey L?><?primarykey lifecycle?><primary><emphasis role="strong">lifecycle</emphasis></primary><seealso> <link linkend="iddle1565" preference="0"><emphasis role="strong">construction/constructors</emphasis></link>.</seealso></indexterm><indexterm id="iddle2966" significance="normal"><?indexkey L?><?primarykey lifecycle?><primary><emphasis role="strong">lifecycle</emphasis></primary><seealso> <link linkend="iddle2973" preference="0"><emphasis role="strong">lifecycle</emphasis>, <literal>Executor</literal></link>.</seealso></indexterm><indexterm id="iddle2967" significance="normal"><?indexkey L?><?primarykey lifecycle?><primary><emphasis role="strong">lifecycle</emphasis></primary><seealso> <link linkend="iddle3584" preference="0"><emphasis role="strong">policy(s)</emphasis>, interruption</link>.</seealso></indexterm><indexterm id="iddle2968" significance="normal"><?indexkey L?><?primarykey lifecycle?><primary><emphasis role="strong">lifecycle</emphasis></primary><seealso> <link linkend="iddle1114" preference="0"><emphasis role="strong">application(s)</emphasis>, shutdown</link>.</seealso></indexterm><indexterm id="iddle2969" significance="normal"><?indexkey L?><?primarykey lifecycle?><primary><emphasis role="strong">lifecycle</emphasis></primary><seealso> <link linkend="iddle4835" preference="0"><emphasis role="strong">thread(s)</emphasis>, termination</link>.</seealso></indexterm><indexterm id="iddle2970" significance="normal"><?indexkey L?><?primarykey lifecycle?><primary><emphasis role="strong">lifecycle</emphasis></primary><seealso> <link linkend="iddle2603" preference="0"><emphasis role="strong">guidelines</emphasis>, threads</link>.</seealso></indexterm><indexterm id="iddle2971" significance="normal"><?indexkey L?><?primarykey lifecycle?><primary><emphasis role="strong">lifecycle</emphasis></primary><seealso> <link linkend="iddle48911" preference="0"><emphasis role="strong">time/timing</emphasis></link>.</seealso></indexterm><indexterm id="iddle2975" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey MANAGEMENT STRATEGIES?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>management strategies</secondary></indexterm><indexterm id="iddle3650" significance="normal"><?indexkey P?><?primarykey preemptive interruption?><primary><emphasis role="strong">preemptive interruption</emphasis></primary></indexterm><indexterm id="iddle3651" significance="normal"><?indexkey P?><?primarykey preemptive interruption?><?secondarykey DEPRECATION REASONS?><primary><emphasis role="strong">preemptive interruption</emphasis></primary><secondary>deprecation reasons</secondary></indexterm><indexterm id="iddle3798" significance="normal"><?indexkey R?><?primarykey reaping?><primary><emphasis role="strong">reaping</emphasis></primary><see> <link linkend="iddle4835" preference="0"><emphasis role="strong">thread(s)</emphasis>, termination</link>.</see></indexterm><indexterm id="iddle4246" significance="normal"><?indexkey S?><?primarykey shutdown?><primary><emphasis role="strong">shutdown</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle4251" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey CANCELLATION AND?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>cancellation and</secondary></indexterm><indexterm id="iddle4467" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey END-OF-LIFECYCLE MANAGEMENT?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>end-of-lifecycle management</secondary></indexterm><indexterm id="iddle4514" significance="normal"><?indexkey S?><?primarykey suspension, thread?><?secondarykey THREAD.SUSPEND, DEPRECATION REASONS?><primary><emphasis role="strong">suspension, thread</emphasis></primary><secondary><literal>Thread.suspend</literal>, deprecation reasons</secondary></indexterm><indexterm id="iddle4609" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey CANCELLATION?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>cancellation</secondary></indexterm><indexterm id="iddle4674" significance="normal"><?indexkey T?><?primarykey termination?><primary><emphasis role="strong">termination</emphasis></primary><seealso> <link linkend="iddle1043" preference="0"><emphasis role="strong">activity(s)</emphasis>, cancellation</link>.</seealso></indexterm><indexterm id="iddle4675" significance="normal"><?indexkey T?><?primarykey termination?><primary><emphasis role="strong">termination</emphasis></primary><seealso> <link linkend="iddle3584" preference="0"><emphasis role="strong">policy(s)</emphasis>, interruption</link>.</seealso></indexterm><indexterm id="iddle4676" significance="normal"><?indexkey T?><?primarykey termination?><primary><emphasis role="strong">termination</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle4684" significance="normal"><?indexkey T?><?primarykey termination?><?secondarykey THREAD?><?tertiarykey REASONS FOR DEPRECATION OF?><primary><emphasis role="strong">termination</emphasis></primary><secondary>thread</secondary><tertiary>reasons for deprecation of</tertiary></indexterm><indexterm id="iddle4775" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey FORCED TERMINATION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>forced termination</secondary></indexterm><indexterm id="iddle4776" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey FORCED TERMINATION?><?tertiarykey REASONS FOR DEPRECATION OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>forced termination</secondary><tertiary>reasons for deprecation of</tertiary></indexterm><indexterm id="iddle4828" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SUSPENSION?><?tertiarykey THREAD.SUSPEND, DEPRECATION REASONS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>suspension</secondary><tertiary><literal>Thread.suspend</literal>, deprecation reasons</tertiary></indexterm><indexterm id="iddle4841" significance="normal"><?indexkey T?><?primarykey Thread.stop?><primary><emphasis role="strong">Thread.stop</emphasis></primary></indexterm><indexterm id="iddle4842" significance="normal"><?indexkey T?><?primarykey Thread.stop?><?secondarykey DEPRECATION REASONS?><primary><emphasis role="strong">Thread.stop</emphasis></primary><secondary>deprecation reasons</secondary></indexterm><indexterm id="iddle4843" significance="normal"><?indexkey T?><?primarykey Thread.suspend?><primary><emphasis role="strong">Thread.suspend</emphasis></primary></indexterm><indexterm id="iddle4844" significance="normal"><?indexkey T?><?primarykey Thread.suspend?><?secondarykey DEPRECATION REASONS?><primary><emphasis role="strong">Thread.suspend</emphasis></primary><secondary>deprecation reasons</secondary></indexterm><indexterm id="iddle5014" significance="normal"><?indexkey U?><?primarykey updating?><primary><emphasis role="strong">updating</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm>It is easy to start tasks and threads. Most of the time we allow them to decide when to stop by letting them run to completion. Sometimes, however, we want to stop tasks or threads earlier than they would on their own, perhaps because the user cancelled an operation or the application needs to shut down quickly.</para>
<para>Getting tasks and threads to stop safely, quickly, and reliably is not always easy. Java does not provide any mechanism for safely forcing a thread to stop what it is doing.<footnote id="ch07fn01" label="1"><para>The deprecated <literal>Thread.stop</literal> and <literal>suspend</literal> methods were an attempt to provide such a mechanism, but were quickly realized to be seriously flawed and should be avoided. See <literal><ulink url="http://java.sun.com/j2se/1.5.0/docs/guide/misc/threadPrimitiveDeprecation.html">http://java.sun.com/j2se/1.5.0/docs/guide/misc/threadPrimitiveDeprecation.html</ulink></literal> for an explanation of the problems with these methods.</para></footnote> Instead, it provides <emphasis>interruption</emphasis>, a cooperative mechanism that lets one thread ask another to stop what it is doing.</para>
<para>The cooperative approach is required because we rarely want a task, thread, or service to stop <emphasis>immediately</emphasis>, since that could leave shared data structures in an inconsistent state. Instead, tasks and services can be coded so that, when requested, they clean up any work currently in progress and <emphasis>then</emphasis> terminate. This provides greater flexibility, since the task code itself is usually better able to assess the cleanup required than is the code requesting cancellation.</para>
<para>End-of-lifecycle issues can complicate the design and implementation of tasks, services, and applications, and this important element of program design is too often ignored. Dealing well with failure, shutdown, and cancellation is one of the characteristics that distinguishes a well-behaved application from one that merely works. This chapter addresses mechanisms for cancellation and interruption, and how to code tasks and services to be responsive to cancellation requests.</para>



<section id="ch07lev1sec1" condition="135" label="7.1" xreflabel="7.1"><?docpage num="135"?>
<title id="ch07lev1sec1__title">Task Cancellation</title>
<para>An activity is <emphasis>cancellable</emphasis> if external code can move it to completion before its normal completion. There are a number of reasons why you might want to cancel an activity:</para>
<itemizedlist mark="none" spacing="normal">
<listitem><formalpara><?docpage num="136"?><title><emphasis role="strong"><?design?>User-requested cancellation.</emphasis></title><para><indexterm id="iddle1114" significance="normal"><?indexkey A?><?primarykey application(s)?><?secondarykey SHUTDOWN?><primary><emphasis role="strong">application(s)</emphasis></primary><secondary>shutdown</secondary></indexterm><indexterm id="iddle1115" significance="normal"><?indexkey A?><?primarykey application(s)?><?secondarykey SHUTDOWN?><?tertiarykey AND TASK CANCELLATION?><primary><emphasis role="strong">application(s)</emphasis></primary><secondary>shutdown</secondary><tertiary>and task cancellation</tertiary></indexterm><indexterm id="iddle1310" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey POLICY?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>policy</secondary></indexterm><indexterm id="iddle1313" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey REASONS FOR?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>reasons for</secondary></indexterm><indexterm id="iddle2041" significance="normal"><?indexkey E?><?primarykey error(s)?><primary><emphasis role="strong">error(s)</emphasis></primary></indexterm><indexterm id="iddle2042" significance="normal"><?indexkey E?><?primarykey error(s)?><?secondarykey AS CANCELLATION REASON?><primary><emphasis role="strong">error(s)</emphasis></primary><secondary>as cancellation reason</secondary></indexterm><indexterm id="iddle2060" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey AS CANCELLATION REASON?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>as cancellation reason</secondary></indexterm><indexterm id="iddle2221" significance="normal"><?indexkey E?><?primarykey exceptions?><primary><emphasis role="strong">exceptions</emphasis></primary><seealso> <link linkend="iddle3324" preference="0"><emphasis role="strong">notification</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle2222" significance="normal"><?indexkey E?><?primarykey exceptions?><primary><emphasis role="strong">exceptions</emphasis></primary><seealso> <link linkend="iddle3584" preference="0"><emphasis role="strong">policy(s)</emphasis>, interruption</link>.</seealso></indexterm><indexterm id="iddle2223" significance="normal"><?indexkey E?><?primarykey exceptions?><primary><emphasis role="strong">exceptions</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle2276" significance="normal"><?indexkey E?><?primarykey exhaustion?><primary><emphasis role="strong">exhaustion</emphasis></primary><see> <link linkend="iddle3021" preference="0"><emphasis role="strong">liveness</emphasis>, failure</link>.</see></indexterm><indexterm id="iddle2277" significance="normal"><?indexkey E?><?primarykey exhaustion?><primary><emphasis role="strong">exhaustion</emphasis></primary><see> <link linkend="iddle3914" preference="0"><emphasis role="strong">resource(s)</emphasis>, leakage</link>.</see></indexterm><indexterm id="iddle2278" significance="normal"><?indexkey E?><?primarykey exhaustion?><primary><emphasis role="strong">exhaustion</emphasis></primary><see> <link linkend="iddle2276" preference="0"><emphasis role="strong">exhaustion</emphasis></link>.</see></indexterm><indexterm id="iddle2301" significance="normal"><?indexkey F?><?primarykey failure?><primary><emphasis role="strong">failure</emphasis></primary><seealso> <link linkend="iddle3167" preference="0"><emphasis role="strong">logging</emphasis>, exceptions</link>.</seealso></indexterm><indexterm id="iddle2302" significance="normal"><?indexkey F?><?primarykey failure?><primary><emphasis role="strong">failure</emphasis></primary><seealso> <link linkend="iddle3015" preference="0"><emphasis role="strong">liveness</emphasis></link>.</seealso></indexterm><indexterm id="iddle2303" significance="normal"><?indexkey F?><?primarykey failure?><primary><emphasis role="strong">failure</emphasis></primary><seealso> <link linkend="iddle1810" preference="0"><emphasis role="strong">deadlock(s)</emphasis>, recovery</link>.</seealso></indexterm><indexterm id="iddle2304" significance="normal"><?indexkey F?><?primarykey failure?><primary><emphasis role="strong">failure</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle2369" significance="normal"><?indexkey F?><?primarykey flag(s)?><?secondarykey CANCELLATION REQUEST?><primary><emphasis role="strong">flag(s)</emphasis></primary><secondary>cancellation request</secondary></indexterm><indexterm id="iddle2370" significance="normal"><?indexkey F?><?primarykey flag(s)?><?secondarykey CANCELLATION REQUEST?><?tertiarykey AS CANCELLATION MECHANISM?><primary><emphasis role="strong">flag(s)</emphasis></primary><secondary>cancellation request</secondary><tertiary>as cancellation mechanism</tertiary></indexterm><indexterm id="iddle3574" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey CANCELLATION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>cancellation</secondary></indexterm><indexterm id="iddle3988" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey IRRELEVANCY?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>irrelevancy</secondary></indexterm><indexterm id="iddle3989" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey IRRELEVANCY?><?tertiarykey AS CANCELLATION REASON?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>irrelevancy</secondary><tertiary>as cancellation reason</tertiary></indexterm><indexterm id="iddle4196" significance="normal"><?indexkey S?><?primarykey service(s)?><?secondarykey SHUTDOWN?><primary><emphasis role="strong">service(s)</emphasis></primary><secondary>shutdown</secondary></indexterm><indexterm id="iddle4197" significance="normal"><?indexkey S?><?primarykey service(s)?><?secondarykey SHUTDOWN?><?tertiarykey AS CANCELLATION REASON?><primary><emphasis role="strong">service(s)</emphasis></primary><secondary>shutdown</secondary><tertiary>as cancellation reason</tertiary></indexterm><indexterm id="iddle4250" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey AS CANCELLATION REASON?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>as cancellation reason</secondary></indexterm><indexterm id="iddle4610" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey CANCELLATION?><?tertiarykey POLICY?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>cancellation</secondary><tertiary>policy</tertiary></indexterm><indexterm id="iddle4612" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey COMPLETION?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>completion</secondary></indexterm><indexterm id="iddle4613" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey COMPLETION?><?tertiarykey AS CANCELLATION REASON?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>completion</secondary><tertiary>as cancellation reason</tertiary></indexterm><indexterm id="iddle4891" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey CONSTRAINTS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>constraints</secondary></indexterm><indexterm id="iddle4892" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey CONSTRAINTS?><?tertiarykey AS CANCELLATION REASON?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>constraints</secondary><tertiary>as cancellation reason</tertiary></indexterm><indexterm id="iddle4977" significance="normal"><?indexkey T?><?primarykey try-catch block?><primary><emphasis role="strong">try-catch block</emphasis></primary><seealso> <link linkend="iddle3167" preference="0"><emphasis role="strong">logging</emphasis>, exceptions</link>.</seealso></indexterm><indexterm id="iddle4979" significance="normal"><?indexkey T?><?primarykey try-finally block?><primary><emphasis role="strong">try-finally block</emphasis></primary><seealso> <link linkend="iddle3167" preference="0"><emphasis role="strong">logging</emphasis>, exceptions</link>.</seealso></indexterm><indexterm id="iddle5003" significance="normal"><?indexkey U?><?primarykey unchecked exceptions?><primary><emphasis role="strong">unchecked exceptions</emphasis></primary><seealso> <link linkend="iddle3167" preference="0"><emphasis role="strong">logging</emphasis>, exceptions</link>.</seealso></indexterm><indexterm id="iddle5024" significance="normal"><?indexkey U?><?primarykey user?><?secondarykey CANCELLATION REQUEST?><primary><emphasis role="strong">user</emphasis></primary><secondary>cancellation request</secondary></indexterm><indexterm id="iddle5025" significance="normal"><?indexkey U?><?primarykey user?><?secondarykey CANCELLATION REQUEST?><?tertiarykey AS CANCELLATION REASON?><primary><emphasis role="strong">user</emphasis></primary><secondary>cancellation request</secondary><tertiary>as cancellation reason</tertiary></indexterm><indexterm id="iddle5116" significance="normal"><?indexkey V?><?primarykey volatile?><primary><emphasis role="strong">volatile</emphasis></primary></indexterm><indexterm id="iddle5117" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey CANCELLATION FLAG USE?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>cancellation flag use</secondary></indexterm>The user clicked on the “cancel” button in a GUI application, or requested cancellation through a management interface such as JMX (Java Management Extensions).</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Time-limited activities.</emphasis></title><para>An application searches a problem space for a finite amount of time and chooses the best solution found within that time. When the timer expires, any tasks still searching are cancelled.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Application events.</emphasis></title><para>An application searches a problem space by decomposing it so that different tasks search different regions of the problem space. When one task finds a solution, all other tasks still searching are cancelled.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Errors.</emphasis></title><para>A web crawler searches for relevant pages, storing pages or summary data to disk. When a crawler task encounters an error (for example, the disk is full), other crawling tasks are cancelled, possibly recording their current state so that they can be restarted later.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Shutdown.</emphasis></title><para>When an application or service is shut down, something must be done about work that is currently being processed or queued for processing. In a graceful shutdown, tasks currently in progress might be allowed to complete; in a more immediate shutdown, currently executing tasks might be cancelled.</para></formalpara></listitem>
</itemizedlist>
<para role="continued">There is no safe way to preemptively stop a thread in Java, and therefore no safe way to preemptively stop a task. There are only cooperative mechanisms, by which the task and the code requesting cancellation follow an agreed-upon protocol.</para>
<para>One such cooperative mechanism is setting a “cancellation requested” flag that the task checks periodically; if it finds the flag set, the task terminates early. <literal>PrimeGenerator</literal> in <link linkend="ch07list01" preference="0">Listing 7.1</link>, which enumerates prime numbers until it is cancelled, illustrates this technique. The <literal>cancel</literal> method sets the <literal>cancelled</literal> flag, and the main loop polls this flag before searching for the next prime number. (For this to work reliably, <literal>cancelled</literal> must be <literal>volatile</literal>.)</para>
<para><link linkend="ch07list02" preference="0">Listing 7.2</link> shows a sample use of this class that lets the prime generator run for one second before cancelling it. The generator won’t necessarily stop after exactly one second, since there may be some delay between the time that cancellation is requested and the time that the <literal>run</literal> loop next checks for cancellation. The <literal>cancel</literal> method is called from a <literal>finally</literal> block to ensure that the prime generator is cancelled even if the the call to <literal>sleep</literal> is interrupted. If <literal>cancel</literal> were not called, the prime-seeking thread would run forever, consuming CPU cycles and preventing the JVM from exiting.</para>
<para>A task that wants to be cancellable must have a <emphasis>cancellation policy</emphasis> that specifies the “how”, “when”, and “what” of cancellation—how other code can request cancellation, when the task checks whether cancellation has been requested, and what actions the task takes in response to a cancellation request.</para>
<para>Consider the real-world example of stopping payment on a check. Banks have rules about how to submit a stop-payment request, what responsiveness guarantees it makes in processing such requests, and what procedures it follows when <?docpage num="137"?><?docpage num="138"?><indexterm id="iddle1214" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey INTERRUPTION HANDLING METHODS?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>interruption handling methods</secondary></indexterm><indexterm id="iddle1223" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey QUEUES?><?tertiarykey CANCELLATION, PROBLEMS?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>queues</secondary><tertiary>cancellation, problems</tertiary></indexterm><indexterm id="iddle1304" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey INTERRUPTION RELATIONSHIP TO?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>interruption relationship to</secondary></indexterm><indexterm id="iddle2371" significance="normal"><?indexkey F?><?primarykey flag(s)?><?secondarykey INTERRUPTED STATUS?><primary><emphasis role="strong">flag(s)</emphasis></primary><secondary>interrupted status</secondary></indexterm><indexterm id="iddle2394" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey ISSUES AND CAUSES?><?tertiarykey INTERRUPTION USE FOR NONSTANDARD PURPOSES?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>issues and causes</secondary><tertiary>interruption use for nonstandard purposes</tertiary></indexterm><indexterm id="iddle2538" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INTERRUPTION HANDLING?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>interruption handling</secondary></indexterm><indexterm id="iddle2539" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INTERRUPTION HANDLING?><?tertiarykey CANCELLATION RELATIONSHIP?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>interruption handling</secondary><tertiary>cancellation relationship</tertiary></indexterm><indexterm id="iddle2785" significance="normal"><?indexkey I?><?primarykey InterruptedException?><?secondarykey INTERRUPTION API?><primary><emphasis role="strong">InterruptedException</emphasis></primary><secondary>interruption API</secondary></indexterm><indexterm id="iddle2797" significance="normal"><?indexkey I?><?primarykey interruption(s)?><primary><emphasis role="strong">interruption(s)</emphasis></primary></indexterm><indexterm id="iddle2820" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey THREAD?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle3751" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey BLOCKING?><?tertiarykey CANCELLATION, PROBLEMS?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>blocking</secondary><tertiary>cancellation, problems</tertiary></indexterm><indexterm id="iddle4448" significance="normal"><?indexkey S?><?primarykey status?><?secondarykey INTERRUPTED?><primary><emphasis role="strong">status</emphasis></primary><secondary>interrupted</secondary></indexterm><indexterm id="iddle4725" significance="normal"><?indexkey T?><?primarykey Thread?><?secondarykey INTERRUPTION METHODS?><primary><emphasis role="strong">Thread</emphasis></primary><secondary>interruption methods</secondary></indexterm><indexterm id="iddle4779" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey INTERRUPTION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>interruption</secondary></indexterm><indexterm id="iddle4781" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey INTERRUPTION?><?tertiarykey STATUS FLAG?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>interruption</secondary><tertiary>status flag</tertiary></indexterm><indexterm id="iddle2157" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PRIMEGENERATOR?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>PrimeGenerator</literal></secondary></indexterm>payment is actually stopped (such as notifying the other bank involved in the transaction and assessing a fee against the payor’s account). Taken together, these procedures and guarantees comprise the cancellation policy for check payment.</para>
<example id="ch07list01" label="7.1" role="Listing" xreflabel="7.1" condition="138">
<?docpage num="138"?>
<title id="ch07list01__title">Using a <literal>Volatile</literal> Field to Hold Cancellation State.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class PrimeGenerator implements Runnable {
     @GuardedBy("this")
     private final List&lt;BigInteger&gt; primes
             = new ArrayList&lt;BigInteger&gt;();
     private  <emphasis role="strong">volatile</emphasis> boolean <emphasis role="strong">cancelled;</emphasis>

     public void run() {
         BigInteger p = BigInteger.ONE;
         while (<emphasis role="strong">!cancelled</emphasis> ) {
             p = p.nextProbablePrime();
             synchronized (this) {
                 primes.add(p);
             }
         }
     }

     public void cancel() { <emphasis role="strong">cancelled = true;</emphasis>  }

     public synchronized List&lt;BigInteger&gt; get() {
         return new ArrayList&lt;BigInteger&gt;(primes);
     }
}
</programlisting>
</example>
<example id="ch07list02" label="7.2" role="Listing" xreflabel="7.2" condition="138">
<?docpage num="138"?>
<title id="ch07list02__title">Generating a Second’s Worth of Prime Numbers.</title>
<programlisting format="linespecific" linenumbering="unnumbered">List&lt;BigInteger&gt; aSecondOfPrimes() throws InterruptedException {
    PrimeGenerator generator = new PrimeGenerator();
    new Thread(generator).start();
    try {
        SECONDS.sleep(1);
    } finally {
        generator.cancel();
    }
    return generator.get();
}
</programlisting>
</example>
<para><literal>PrimeGenerator</literal> uses a simple cancellation policy: client code requests cancellation by calling <literal>cancel</literal>, <literal>PrimeGenerator</literal> checks for cancellation once per prime found and exits when it detects cancellation has been requested.</para>
<section id="ch07lev2sec1" label="7.1.1" xreflabel="7.1.1">
<title id="ch07lev2sec1__title">Interruption</title>
<para>The cancellation mechanism in <literal>PrimeGenerator</literal> will eventually cause the primeseeking task to exit, but it might take a while. If, however, a task that uses this approach calls a blocking method such as <literal>BlockingQueue.put</literal>, we could have a more serious problem—the task might never check the cancellation flag and therefore might never terminate.</para>
<para><literal>BrokenPrimeProducer</literal> in <link linkend="ch07list03" preference="0">Listing 7.3</link> illustrates this problem. The producer thread generates primes and places them on a blocking queue. If the producer gets ahead of the consumer, the queue will fill up and <literal>put</literal> will block. What happens if the consumer tries to cancel the producer task while it is blocked in <literal>put</literal>? It can call <literal>cancel</literal> which will set the <literal>cancelled</literal> flag—but the producer will never check the flag because it will never emerge from the blocking <literal>put</literal> (because the consumer has stopped retrieving primes from the queue).</para>
<para>As we hinted in <link linkend="ch05" preference="0">Chapter 5</link>, certain blocking library methods support <emphasis>interruption</emphasis>. Thread interruption is a cooperative mechanism for a thread to signal another thread that it should, at its convenience and if it feels like it, stop what it is doing and do something else.</para>
<sidebar float="1" id="ch07sb01" condition="137"><title/>
<para>There is nothing in the API or language specification that ties interruption to any specific cancellation semantics, but in practice, using interruption for anything but cancellation is fragile and difficult to sustain in larger applications.</para>
</sidebar>
<para>Each thread has a boolean <emphasis>interrupted status</emphasis>; interrupting a thread sets its interrupted status to true. <literal>Thread</literal> contains methods for interrupting a thread and querying the interrupted status of a thread, as shown in <link linkend="ch07list04" preference="0">Listing 7.4</link>. The <literal>interrupt</literal> method interrupts the target thread, and <literal>isInterrupted</literal> returns the interrupted status of the target thread. The poorly named static <literal>interrupted</literal> method <emphasis>clears</emphasis> the interrupted status of the current thread and returns its previous value; this is the only way to clear the interrupted status.</para>
<para>Blocking library methods like <literal>Thread.sleep</literal> and <literal>Object.wait</literal> try to detect when a thread has been interrupted and return early. They respond to interruption by clearing the interrupted status and throwing <literal>InterruptedException</literal>, indicating that the blocking operation completed early due to interruption. The JVM makes no guarantees on how quickly a blocking method will detect interruption, but in practice this happens reasonably quickly.</para>

<para><?docpage num="139"?></para><example id="ch07list03" label="7.3" role="Listing" xreflabel="7.3" condition="139">

<title id="ch07list03__title"><indexterm id="iddle2092" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BROKENPRIMEPRODUCER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BrokenPrimeProducer</literal></secondary></indexterm><indexterm id="iddle4726" significance="normal"><?indexkey T?><?primarykey Thread?><?secondarykey INTERRUPTION METHODS?><primary><emphasis role="strong">Thread</emphasis></primary><secondary>interruption methods</secondary></indexterm>Unreliable Cancellation that can Leave Producers Stuck in a Blocking Operation. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">class BrokenPrimeProducer extends Thread {
    private final BlockingQueue&lt;BigInteger&gt; queue;
    private volatile boolean cancelled = false;

    BrokenPrimeProducer(BlockingQueue&lt;BigInteger&gt; queue) {
        this.queue = queue;
    }

    public void run() {
        try {
            BigInteger p = BigInteger.ONE;
            while (<emphasis role="strong">!cancelled)</emphasis>
                queue.put(p = p.nextProbablePrime());
        } catch (InterruptedException consumed) { }
    }

    public void cancel() { <emphasis role="strong">cancelled = true;</emphasis>  }
}

void consumePrimes() throws InterruptedException {
    BlockingQueue&lt;BigInteger&gt; primes = ...;
    BrokenPrimeProducer producer = new BrokenPrimeProducer(primes);
    producer.start();
    try {
        while (needMorePrimes())
            consume(primes.take());
    } finally {
        producer.cancel();
    }
}
</programlisting>
</example>
<example id="ch07list04" label="7.4" role="Listing" xreflabel="7.4" condition="139">
<title id="ch07list04__title">Interruption Methods in <literal>Thread</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class Thread {
    public void interrupt() { ... }
    public boolean isInterrupted() { ... }
    public static boolean interrupted() { ... }
    ...
}
</programlisting>
</example>
<para><?docpage num="140"?><indexterm id="iddle1224" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey QUEUES?><?tertiarykey CANCELLATION, SOLUTIONS?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>queues</secondary><tertiary>cancellation, solutions</tertiary></indexterm><indexterm id="iddle1309" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey POINTS?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>points</secondary></indexterm><indexterm id="iddle1312" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey POLICY?><?tertiarykey INTERRUPTION ADVANTAGES AS IMPLEMENTATION STRATEGY?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>policy</secondary><tertiary>interruption advantages as implementation strategy</tertiary></indexterm><indexterm id="iddle1848" significance="normal"><?indexkey D?><?primarykey decoupling?><?secondarykey OF INTERRUPT NOTIFICATION FROM HANDLING IN THREAD INTERRUPTION HANDLING METHODS?><primary><emphasis role="strong">decoupling</emphasis></primary><secondary>of interrupt notification from handling in <literal>Thread</literal> interruption handling methods</secondary></indexterm><indexterm id="iddle2781" significance="normal"><?indexkey I?><?primarykey interrupted (Thread)?><primary><emphasis role="strong">interrupted (Thread)</emphasis></primary></indexterm><indexterm id="iddle2782" significance="normal"><?indexkey I?><?primarykey interrupted (Thread)?><?secondarykey USAGE PRECAUTIONS?><primary><emphasis role="strong">interrupted (Thread)</emphasis></primary><secondary>usage precautions</secondary></indexterm><indexterm id="iddle2813" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey REQUEST?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>request</secondary></indexterm><indexterm id="iddle2814" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey REQUEST?><?tertiarykey STRATEGIES FOR HANDLING?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>request</secondary><tertiary>strategies for handling</tertiary></indexterm><indexterm id="iddle2818" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey SWALLOWING?><?tertiarykey BAD CONSEQUENCES OF?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>swallowing</secondary><tertiary>bad consequences of</tertiary></indexterm><indexterm id="iddle3557" significance="normal"><?indexkey P?><?primarykey point(s)?><?secondarykey CANCELLATION?><primary><emphasis role="strong">point(s)</emphasis></primary><secondary>cancellation</secondary></indexterm><indexterm id="iddle3576" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey CANCELLATION?><?tertiarykey INTERRUPTION ADVANTAGES AS IMPLEMENTATION STRATEGY?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>cancellation</secondary><tertiary>interruption advantages as implementation strategy</tertiary></indexterm><indexterm id="iddle3752" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey BLOCKING?><?tertiarykey CANCELLATION, SOLUTIONS?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>blocking</secondary><tertiary>cancellation, solutions</tertiary></indexterm><indexterm id="iddle3873" significance="normal"><?indexkey R?><?primarykey request?><primary><emphasis role="strong">request</emphasis></primary></indexterm><indexterm id="iddle3874" significance="normal"><?indexkey R?><?primarykey request?><?secondarykey INTERRUPT?><primary><emphasis role="strong">request</emphasis></primary><secondary>interrupt</secondary></indexterm><indexterm id="iddle3875" significance="normal"><?indexkey R?><?primarykey request?><?secondarykey INTERRUPT?><?tertiarykey STRATEGIES FOR HANDLING?><primary><emphasis role="strong">request</emphasis></primary><secondary>interrupt</secondary><tertiary>strategies for handling</tertiary></indexterm><indexterm id="iddle4470" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey INTERRUPTION HANDLING?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>interruption handling</secondary></indexterm><indexterm id="iddle4517" significance="normal"><?indexkey S?><?primarykey swallowing interrupts?><?secondarykey BAD CONSEQUENCES OF?><primary><emphasis role="strong">swallowing interrupts</emphasis></primary><secondary>bad consequences of</secondary></indexterm><indexterm id="iddle4727" significance="normal"><?indexkey T?><?primarykey Thread?><?secondarykey INTERRUPTION METHODS?><?tertiarykey USAGE PRECAUTIONS?><primary><emphasis role="strong">Thread</emphasis></primary><secondary>interruption methods</secondary><tertiary>usage precautions</tertiary></indexterm>If a thread is interrupted when it is <emphasis>not</emphasis> blocked, its interrupted status is set, and it is up to the activity being cancelled to poll the interrupted status to detect interruption. In this way interruption is “sticky”—if it doesn’t trigger an <literal>InterruptedException</literal>, evidence of interruption persists until someone deliberately clears the interrupted status.</para>
<sidebar float="1" id="ch07sb02" condition="140"><title/>
<para>Calling <literal>interrupt</literal> does not necessarily stop the target thread from doing what it is doing; it merely delivers the message that interruption has been requested.</para>
</sidebar>
<para>A good way to think about interruption is that it does not actually interrupt a running thread; it just <emphasis>requests</emphasis> that the thread interrupt itself at the next convenient opportunity. (These opportunities are called <emphasis>cancellation points</emphasis>.) Some methods, such as <literal>wait</literal>, <literal>sleep</literal>, and <literal>join</literal>, take such requests seriously, throwing an exception when they receive an interrupt request or encounter an already set interrupt status upon entry. Well behaved methods may totally ignore such requests so long as they leave the interruption request in place so that calling code can do something with it. Poorly behaved methods swallow the interrupt request, thus denying code further up the call stack the opportunity to act on it.</para>
<para>The static <literal>interrupted</literal> method should be used with caution, because it clears the current thread’s interrupted status. If you call <literal>interrupted</literal> and it returns <literal>true</literal>, unless you are planning to swallow the interruption, you should do something with it—either throw <literal>InterruptedException</literal> or restore the interrupted status by calling <literal>interrupt</literal> again, as in <link linkend="ch05list10" preference="0">Listing 5.10</link> on page <link linkend="ch05list10" preference="0" role="pageref">94</link>.</para>
<para><literal>BrokenPrimeProducer</literal> illustrates how custom cancellation mechanisms do not always interact well with blocking library methods. If you code your tasks to be responsive to interruption, you can use interruption as your cancellation mechanism and take advantage of the interruption support provided by many library classes.</para>
<sidebar float="1" id="ch07sb03" condition="140"><title/>
<para>Interruption is usually the most sensible way to implement cancellation.</para>
</sidebar>
<para><literal>BrokenPrimeProducer</literal> can be easily fixed (and simplified) by using interruption instead of a boolean flag to request cancellation, as shown in <link linkend="ch07list05" preference="0">Listing 7.5</link>. There are two points in each loop iteration where interruption may be detected: in the blocking <literal>put</literal> call, and by explicitly polling the interrupted status in the loop header. The explicit test is not strictly necessary here because of the blocking <literal>put</literal> call, but it makes <literal>PrimeProducer</literal> more responsive to interruption because it checks for interruption <emphasis>before</emphasis> starting the lengthy task of searching for a prime, rather than after. When calls to interruptible blocking methods are not frequent enough to deliver the desired responsiveness, explicitly testing the interrupted status can help.</para>

<para><?docpage num="141"?></para><example id="ch07list05" label="7.5" role="Listing" xreflabel="7.5" condition="141">

<title id="ch07list05__title">Using Interruption for Cancellation.</title>
<programlisting format="linespecific" linenumbering="unnumbered">class PrimeProducer extends Thread {
    private final BlockingQueue&lt;BigInteger&gt; queue;

    PrimeProducer(BlockingQueue&lt;BigInteger&gt; queue) {
        this.queue = queue;
    }

    public void run() {
        try {
            BigInteger p = BigInteger.ONE;
            while (<emphasis role="strong">!Thread.currentThread().isInterrupted())</emphasis>
                queue.put(p = p.nextProbablePrime());
        } catch (InterruptedException consumed) {
            <emphasis>/*  Allow thread to exit  */</emphasis>
        }
    }
    public void cancel() { interrupt(); }
}
</programlisting>
</example>
</section>
<section id="ch07lev2sec2" label="7.1.2" xreflabel="7.1.2">
<title id="ch07lev2sec2__title">Interruption Policies</title>
<para><indexterm id="iddle1311" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey POLICY?><?tertiarykey AND THREAD INTERRUPTION POLICY?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>policy</secondary><tertiary>and thread interruption policy</tertiary></indexterm><indexterm id="iddle2158" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PRIMEPRODUCER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>PrimeProducer</literal></secondary></indexterm><indexterm id="iddle2809" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey POLICIES?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>policies</secondary></indexterm><indexterm id="iddle2810" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey POLICIES?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>policies</secondary></indexterm><indexterm id="iddle3575" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey CANCELLATION?><?tertiarykey FOR TASKS, THREAD INTERRUPTION POLICY RELATIONSHIP TO?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>cancellation</secondary><tertiary>for tasks, thread interruption policy relationship to</tertiary></indexterm><indexterm id="iddle3584" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey INTERRUPTION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>interruption</secondary></indexterm><indexterm id="iddle3585" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey INTERRUPTION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>interruption</secondary></indexterm><indexterm id="iddle4611" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey CANCELLATION?><?tertiarykey THREAD INTERRUPTION POLICY RELATIONSHIP TO?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>cancellation</secondary><tertiary>thread interruption policy relationship to</tertiary></indexterm><indexterm id="iddle4657" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey THREAD(S) VS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>thread(s) vs</secondary></indexterm><indexterm id="iddle4658" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey THREAD(S) VS?><?tertiarykey INTERRUPTION HANDLING?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>thread(s) vs</secondary><tertiary>interruption handling</tertiary></indexterm><indexterm id="iddle4833" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey TASK?><?tertiarykey VS. INTERRUPTION HANDLING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>task</secondary><tertiary>vs. interruption handling</tertiary></indexterm>Just as tasks should have a cancellation policy, threads should have an <emphasis>interruption policy</emphasis>. An interruption policy determines how a thread interprets an interruption request—what it does (if anything) when one is detected, what units of work are considered atomic with respect to interruption, and how quickly it reacts to interruption.</para>
<para>The most sensible interruption policy is some form of thread-level or servicelevel cancellation: exit as quickly as practical, cleaning up if necessary, and possibly notifying some owning entity that the thread is exiting. It is possible to establish other interruption policies, such as pausing or resuming a service, but threads or thread pools with nonstandard interruption policies may need to be restricted to tasks that have been written with an awareness of the policy.</para>
<para>It is important to distinguish between how <emphasis>tasks</emphasis> and <emphasis>threads</emphasis> should react to interruption. A single interrupt request may havemore than one desired recipient—interrupting a worker thread in a thread pool can mean both “cancel the current task” and “shut down the worker thread”.</para>
<para>Tasks do not execute in threads they own; they borrow threads owned by a service such as a thread pool. Code that doesn’t own the thread (for a thread pool, any code outside of the thread pool implementation) should be careful to preserve the interrupted status so that the owning code can eventually act on it, even if the “guest” code acts on the interruption as well. (If you are house-sitting for someone, you don’t throw out the mail that comes while they’re away—you save it and let them deal with it when they get back, even if you do read their magazines.)</para>
<para><?docpage num="142"?><indexterm id="iddle1352" significance="normal"><?indexkey C?><?primarykey cleanup?><?secondarykey AND INTERRUPTION HANDLING?><primary><emphasis role="strong">cleanup</emphasis></primary><secondary>and interruption handling</secondary></indexterm><indexterm id="iddle1353" significance="normal"><?indexkey C?><?primarykey cleanup?><?secondarykey AND INTERRUPTION HANDLING?><?tertiarykey PROTECTING DATA INTEGRITY?><primary><emphasis role="strong">cleanup</emphasis></primary><secondary>and interruption handling</secondary><tertiary>protecting data integrity</tertiary></indexterm><indexterm id="iddle1684" significance="normal"><?indexkey C?><?primarykey corruption?><?secondarykey DATA?><primary><emphasis role="strong">corruption</emphasis></primary><secondary>data</secondary></indexterm><indexterm id="iddle1685" significance="normal"><?indexkey C?><?primarykey corruption?><?secondarykey DATA?><?tertiarykey AND INTERRUPTION HANDLING?><primary><emphasis role="strong">corruption</emphasis></primary><secondary>data</secondary><tertiary>and interruption handling</tertiary></indexterm><indexterm id="iddle1775" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey PROTECTION?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>protection</secondary></indexterm><indexterm id="iddle1776" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey PROTECTION?><?tertiarykey AND INTERRUPTION HANDLING?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>protection</secondary><tertiary>and interruption handling</tertiary></indexterm><indexterm id="iddle2378" significance="normal"><?indexkey F?><?primarykey flexibility?><?secondarykey INTERRUPTION POLICY?><primary><emphasis role="strong">flexibility</emphasis></primary><secondary>interruption policy</secondary></indexterm><indexterm id="iddle2540" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INTERRUPTION HANDLING?><?tertiarykey IMPORTANCE OF INTERRUPTION POLICY KNOWLEDGE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>interruption handling</secondary><tertiary>importance of interruption policy knowledge</tertiary></indexterm><indexterm id="iddle2783" significance="normal"><?indexkey I?><?primarykey InterruptedException?><primary><emphasis role="strong">InterruptedException</emphasis></primary></indexterm><indexterm id="iddle2784" significance="normal"><?indexkey I?><?primarykey InterruptedException?><?secondarykey FLEXIBLE INTERRUPTION POLICY ADVANTAGES?><primary><emphasis role="strong">InterruptedException</emphasis></primary><secondary>flexible interruption policy advantages</secondary></indexterm><indexterm id="iddle2801" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey INTERRUPTION RESPONSE STRATEGY?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>interruption response strategy</secondary></indexterm><indexterm id="iddle2802" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey INTERRUPTION RESPONSE STRATEGY?><?tertiarykey EXCEPTION PROPAGATION?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>interruption response strategy</secondary><tertiary>exception propagation</tertiary></indexterm><indexterm id="iddle2803" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey INTERRUPTION RESPONSE STRATEGY?><?tertiarykey STATUS RESTORATION?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>interruption response strategy</secondary><tertiary>status restoration</tertiary></indexterm><indexterm id="iddle2815" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey RESPONDING TO?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>responding to</secondary></indexterm><indexterm id="iddle3701" significance="normal"><?indexkey P?><?primarykey propagation?><primary><emphasis role="strong">propagation</emphasis></primary></indexterm><indexterm id="iddle3702" significance="normal"><?indexkey P?><?primarykey propagation?><?secondarykey OF INTERRUPTION EXCEPTION?><primary><emphasis role="strong">propagation</emphasis></primary><secondary>of interruption exception</secondary></indexterm><indexterm id="iddle3953" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey INTERRUPTION POLICY?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>interruption policy</secondary></indexterm><indexterm id="iddle3954" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey INTERRUPTION POLICY?><?tertiarykey INTERRUPTEDEXCEPTION ADVANTAGES?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>interruption policy</secondary><tertiary><literal>InterruptedException</literal> advantages</tertiary></indexterm><indexterm id="iddle3975" significance="normal"><?indexkey R?><?primarykey restoring interruption status?><primary><emphasis role="strong">restoring interruption status</emphasis></primary></indexterm><indexterm id="iddle4008" significance="normal"><?indexkey R?><?primarykey robustness?><?secondarykey INTERRUPTEDEXCEPTION ADVANTAGES?><primary><emphasis role="strong">robustness</emphasis></primary><secondary><literal>InterruptedException</literal> advantages</secondary></indexterm><indexterm id="iddle4471" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey INTERRUPTION HANDLING?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>interruption handling</secondary></indexterm>This is why most blocking library methods simply throw <literal>InterruptedException</literal> in response to an interrupt. They will never execute in a thread they own, so they implement the most reasonable cancellation policy for task or library code: get out of the way as quickly as possible and communicate the interruption back to the caller so that code higher up on the call stack can take further action.</para>
<para>A task needn’t necessarily drop everything when it detects an interruption request—it can choose to postpone it until a more opportune time by remembering that it was interrupted, finishing the task it was performing, and <emphasis>then</emphasis> throwing <literal>InterruptedException</literal> or otherwise indicating interruption. This technique can protect data structures from corruption when an activity is interrupted in the middle of an update.</para>
<para>A task should not assume anything about the interruption policy of its executing thread unless it is explicitly designed to run within a service that has a specific interruption policy. Whether a task interprets interruption as cancellation or takes some other action on interruption, it should take care to preserve the executing thread’s interruption status. If it is not simply going to propagate <literal>InterruptedException</literal> to its caller, it should restore the interruption status after catching <literal>InterruptedException</literal>:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">Thread.currentThread().interrupt();
</programlisting>
</informalexample>
<para role="continued">Just as task code should not make assumptions about what interruption means to its executing thread, cancellation code should not make assumptions about the interruption policy of arbitrary threads. A thread should be interrupted only by its owner; the owner can encapsulate knowledge of the thread’s interruption policy in an appropriate cancellation mechanism such as a shutdown method.</para>
<sidebar float="1" id="ch07sb04" condition="142"><title/>
<para>Because each thread has its own interruption policy, you should not interrupt a thread unless you know what interruption means to that thread.</para>
</sidebar>
<para>Critics have derided the Java interruption facility because it does not provide a preemptive interruption capability and yet forces developers to handle <literal>InterruptedException</literal>. However, the ability to postpone an interruption request enables developers to craft flexible interruption policies that balance responsiveness and robustness as appropriate for the application.</para>
</section>
<section id="ch07lev2sec3" label="7.1.3" xreflabel="7.1.3">
<title id="ch07lev2sec3__title">Responding to Interruption</title>
<para>As mentioned in <link linkend="ch05lev1sec4" preference="0">Section 5.4</link>, when you call an interruptible blocking method such as <literal>Thread.sleep</literal> or <literal>BlockingQueue.put</literal>, there are two practical strategies for handling <literal>InterruptedException</literal>:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Propagate the exception (possibly after some task-specific cleanup), making your method an interruptible blocking method, too; or</para></listitem>
<listitem><para>Restore the interruption status so that code higher up on the call stack can deal with it.</para></listitem>
</itemizedlist>
<para role="continued"><?docpage num="143"?><indexterm id="iddle1215" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey METHODS?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>methods</secondary></indexterm><indexterm id="iddle1216" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey METHODS?><?tertiarykey AND INTERRUPTION?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>methods</secondary><tertiary>and interruption</tertiary></indexterm><indexterm id="iddle1992" significance="normal"><?indexkey E?><?primarykey efficiency?><?secondarykey RESPONSIVENESS VS?><primary><emphasis role="strong">efficiency</emphasis></primary><secondary>responsiveness vs</secondary></indexterm><indexterm id="iddle1993" significance="normal"><?indexkey E?><?primarykey efficiency?><?secondarykey RESPONSIVENESS VS?><?tertiarykey POLLING FREQUENCY?><primary><emphasis role="strong">efficiency</emphasis></primary><secondary>responsiveness vs</secondary><tertiary>polling frequency</tertiary></indexterm><indexterm id="iddle2542" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INTERRUPTION HANDLING?><?tertiarykey INTERRUPT SWALLOWING PRECAUTIONS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>interruption handling</secondary><tertiary>interrupt swallowing precautions</tertiary></indexterm><indexterm id="iddle2786" significance="normal"><?indexkey I?><?primarykey InterruptedException?><?secondarykey PROPAGATION OF?><primary><emphasis role="strong">InterruptedException</emphasis></primary><secondary>propagation of</secondary></indexterm><indexterm id="iddle2805" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey NON-CANCELLATION USES FOR?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>non-cancellation uses for</secondary></indexterm><indexterm id="iddle2819" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey SWALLOWING?><?tertiarykey WHEN PERMITTED?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>swallowing</secondary><tertiary>when permitted</tertiary></indexterm><indexterm id="iddle3174" significance="normal"><?indexkey L?><?primarykey loops/looping?><primary><emphasis role="strong">loops/looping</emphasis></primary></indexterm><indexterm id="iddle3175" significance="normal"><?indexkey L?><?primarykey loops/looping?><?secondarykey AND INTERRUPTION?><primary><emphasis role="strong">loops/looping</emphasis></primary><secondary>and interruption</secondary></indexterm><indexterm id="iddle3604" significance="normal"><?indexkey P?><?primarykey polling?><?secondarykey FOR INTERRUPTION?><primary><emphasis role="strong">polling</emphasis></primary><secondary>for interruption</secondary></indexterm><indexterm id="iddle3951" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey EFFICIENCY VS?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>efficiency vs</secondary></indexterm><indexterm id="iddle3952" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey EFFICIENCY VS?><?tertiarykey POLLING FREQUENCY?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>efficiency vs</secondary><tertiary>polling frequency</tertiary></indexterm><indexterm id="iddle4014" significance="normal"><?indexkey R?><?primarykey Runnable?><primary><emphasis role="strong">Runnable</emphasis></primary></indexterm><indexterm id="iddle4015" significance="normal"><?indexkey R?><?primarykey Runnable?><?secondarykey HANDLING EXCEPTIONS IN?><primary><emphasis role="strong">Runnable</emphasis></primary><secondary>handling exceptions in</secondary></indexterm><indexterm id="iddle4518" significance="normal"><?indexkey S?><?primarykey swallowing interrupts?><?secondarykey WHEN PERMITTED?><primary><emphasis role="strong">swallowing interrupts</emphasis></primary><secondary>when permitted</secondary></indexterm>Propagating <literal>InterruptedException</literal> can be as easy as adding <literal>InterruptedException</literal> to the <literal>throws</literal> clause, as shown by <literal>getNextTask</literal> in <link linkend="ch07list06" preference="0">Listing 7.6</link>.</para>
<example id="ch07list06" label="7.6" role="Listing" xreflabel="7.6" condition="143">
<title id="ch07list06__title">Propagating <literal>InterruptedException</literal> to Callers.</title>
<programlisting format="linespecific" linenumbering="unnumbered">BlockingQueue&lt;Task&gt; queue;
...
public Task getNextTask() throws InterruptedException {
    return queue.take();
}
</programlisting>
</example>
<para>If you don’t want to or cannot propagate <literal>InterruptedException</literal> (perhaps because your task is defined by a <literal>Runnable</literal>), you need to find another way to preserve the interruption request. The standard way to do this is to restore the interrupted status by calling <literal>interrupt</literal> again. What you should <emphasis>not</emphasis> do is swallow the <literal>InterruptedException</literal> by catching it and doing nothing in the <literal>catch</literal> block, unless your code is actually implementing the interruption policy for a thread. <literal>PrimeProducer</literal> swallows the interrupt, but does so with the knowledge that the thread is about to terminate and that therefore there is no code higher up on the call stack that needs to know about the interruption. Most code does not know what thread it will run in and so should preserve the interrupted status.</para>
<sidebar float="1" id="ch07sb05" condition="143"><title/>
<para>Only code that implements a thread’s interruption policy may swallow an interruption request. General-purpose task and library code should never swallow interruption requests.</para>
</sidebar>
<para>Activities that do not support cancellation but still call interruptible blocking methods will have to call them in a loop, retrying when interruption is detected. In this case, they should save the interruption status locally and restore it just before returning, as shown in <link linkend="ch07list07" preference="0">Listing 7.7</link>, rather than immediately upon catching <literal>InterruptedException</literal>. Setting the interrupted status too early could result in an infinite loop, because most interruptible blocking methods check the interrupted status on entry and throw <literal>InterruptedException</literal> immediately if it is set. (Interruptible methods usually poll for interruption before blocking or doing any significant work, so as to be as responsive to interruption as possible.)</para>
<para>If your code does not call interruptible blocking methods, it can still be made responsive to interruption by polling the current thread’s interrupted status throughout the task code. Choosing a polling frequency is a tradeoff between efficiency and responsiveness. If you have high responsiveness requirements, you cannot call potentially long-running methods that are not themselves responsive to interruption, potentially restricting your options for calling library code.</para>
<para>Cancellation can involve state other than the interruption status; interruption can be used to get the thread’s attention, and information stored elsewhere by the interrupting thread can be used to provide further instructions for the interrupted thread. (Be sure to use synchronization when accessing that information.)</para>

<para><?docpage num="144"?></para><example id="ch07list07" label="7.7" role="Listing" xreflabel="7.7" condition="144">

<title id="ch07list07__title">Noncancelable Task that Restores Interruption Before Exit.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public Task getNextTask(BlockingQueue&lt;Taskgt; queue) {
    boolean interrupted = false;
    try {
        while (true) {
            try {
                return queue.take();
            } catch (InterruptedException e) {
                interrupted = true;
                <emphasis>// fall through and retry</emphasis>
            }
        }
    } finally {
        if (interrupted)
            Thread.currentThread().interrupt();
    }
}
</programlisting>
</example>
<para><indexterm id="iddle4894" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey CONSTRAINTS?><?tertiarykey INTERRUPTION HANDLING?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>constraints</secondary><tertiary>interruption handling</tertiary></indexterm>For example, when a worker thread owned by a <literal>ThreadPoolExecutor</literal> detects interruption, it checks whether the pool is being shut down. If so, it performs some pool cleanup before terminating; otherwise it may create a new thread to restore the thread pool to the desired size.</para>
</section>
<section id="ch07lev2sec4" label="7.1.4" xreflabel="7.1.4">
<title id="ch07lev2sec4__title">Example: Timed Run</title>
<para>Many problems can take forever to solve (e.g., enumerate all the prime numbers); for others, the answer might be found reasonably quickly but also might take forever. Being able to say “spend up to ten minutes looking for the answer” or “enumerate all the answers you can in ten minutes” can be useful in these situations.</para>
<para>The <literal>aSecondOfPrimes</literal> method in <link linkend="ch07list02" preference="0">Listing 7.2</link> starts a <literal>PrimeGenerator</literal> and interrupts it after a second. While the <literal>PrimeGenerator</literal> might take somewhat longer than a second to stop, it will eventually notice the interrupt and stop, allowing the thread to terminate. But another aspect of executing a task is that you want to find out if the task throws an exception. If <literal>PrimeGenerator</literal> throws an unchecked exception before the timeout expires, it will probably go unnoticed, since the prime generator runs in a separate thread that does not explicitly handle exceptions.</para>
<para><link linkend="ch07list08" preference="0">Listing 7.8</link> shows an attempt at running an arbitrary <literal>Runnable</literal> for a given amount of time. It runs the task in the calling thread and schedules a cancellation task to interrupt it after a given time interval. This addresses the problem of unchecked exceptions thrown from the task, since they can then be caught by the caller of <literal>timedRun</literal>.</para>
<para>This is an appealingly simple approach, but it violates the rules: you should know a thread’s interruption policy before interrupting it. Since <literal>timedRun</literal> can be called from an arbitrary thread, it cannot know the calling thread’s interruption <?docpage num="145"?><indexterm id="iddle1301" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey FUTURE USE?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary><literal>Future</literal> use</secondary></indexterm><indexterm id="iddle2173" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SCHEDULEDEXECUTORSERVICE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ScheduledExecutorService</literal></secondary></indexterm><indexterm id="iddle2422" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey CANCELLATION?><?tertiarykey STRATEGY USING?><primary><emphasis role="strong">Future</emphasis></primary><secondary>cancellation</secondary><tertiary>strategy using</tertiary></indexterm><indexterm id="iddle2541" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INTERRUPTION HANDLING?><?tertiarykey IMPORTANCE OF INTERRUPTION POLICY KNOWLEDGE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>interruption handling</secondary><tertiary>importance of interruption policy knowledge</tertiary></indexterm><indexterm id="iddle2909" significance="normal"><?indexkey J?><?primarykey join (Thread)?><primary><emphasis role="strong">join (Thread)</emphasis></primary></indexterm><indexterm id="iddle2910" significance="normal"><?indexkey J?><?primarykey join (Thread)?><?secondarykey TIMED?><primary><emphasis role="strong">join (Thread)</emphasis></primary><secondary>timed</secondary></indexterm><indexterm id="iddle2911" significance="normal"><?indexkey J?><?primarykey join (Thread)?><?secondarykey TIMED?><?tertiarykey PROBLEMS WITH?><primary><emphasis role="strong">join (Thread)</emphasis></primary><secondary>timed</secondary><tertiary>problems with</tertiary></indexterm><indexterm id="iddle4457" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey CANCELLATION?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>cancellation</secondary></indexterm><indexterm id="iddle4458" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey CANCELLATION?><?tertiarykey FUTURE USE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>cancellation</secondary><tertiary>Future use</tertiary></indexterm><indexterm id="iddle4720" significance="normal"><?indexkey T?><?primarykey Thread?><primary><emphasis role="strong">Thread</emphasis></primary></indexterm><indexterm id="iddle4721" significance="normal"><?indexkey T?><?primarykey Thread?><?secondarykey JOIN?><primary><emphasis role="strong">Thread</emphasis></primary><secondary><literal>join</literal></secondary></indexterm><indexterm id="iddle4722" significance="normal"><?indexkey T?><?primarykey Thread?><?secondarykey JOIN?><?tertiarykey TIMED, PROBLEMS WITH?><primary><emphasis role="strong">Thread</emphasis></primary><secondary><literal>join</literal></secondary><tertiary>timed, problems with</tertiary></indexterm>policy. If the task completes before the timeout, the cancellation task that interrupts the thread in which <literal>timedRun</literal> was called could go off <emphasis>after</emphasis> <literal>timedRun</literal> has returned to its caller. We don’t know what code will be running when that happens, but the result won’t be good. (It is possible but surprisingly tricky to eliminate this risk by using the <literal>ScheduledFuture</literal> returned by <literal>schedule</literal> to cancel the cancellation task.)</para>
<example id="ch07list08" label="7.8" role="Listing" xreflabel="7.8" condition="145">
<title id="ch07list08__title">Scheduling an Interrupt on a Borrowed Thread. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">private static final ScheduledExecutorService cancelExec = ...;

public static void timedRun(Runnable r,
                           long timeout, TimeUnit unit) {
    final Thread taskThread = Thread.currentThread();
    cancelExec.schedule(new Runnable() {
        public void run() { <emphasis role="strong">taskThread.interrupt();</emphasis> }
    }, timeout, unit);
    <emphasis role="strong">r.run();</emphasis>
}
</programlisting>
</example>
<para>Further, if the task is not responsive to interruption, <literal>timedRun</literal> will not return until the task finishes, which may be long after the desired timeout (or even not at all). A timed run service that doesn’t return after the specified time is likely to be irritating to its callers.</para>
<para><link linkend="ch07list09" preference="0">Listing 7.9</link> addresses the exception-handling problem of <literal>aSecondOfPrimes</literal> and the problems with the previous attempt. The thread created to run the task can have its own execution policy, and even if the task doesn’t respond to the interrupt, the timed run method can still return to its caller. After starting the task thread, <literal>timedRun</literal> executes a timed <literal>join</literal> with the newly created thread. After <literal>join</literal> returns, it checks if an exception was thrown from the task and if so, rethrows it in the thread calling <literal>timedRun</literal>. The saved <literal>Throwable</literal> is shared between the two threads, and so is declared <literal>volatile</literal> to safely publish it from the task thread to the <literal>timedRun</literal> thread.</para>
<para>This version addresses the problems in the previous examples, but because it relies on a timed <literal>join</literal>, it shares a deficiency with <literal>join</literal>: we don’t know if control was returned because the thread exited normally or because the <literal>join</literal> timed out.<footnote id="ch07fn02" label="2"><para>This is a flaw in the <literal>Thread</literal> API, because whether or not the <literal>join</literal> completes successfully has memory visibility consequences in the Java Memory Model, but <literal>join</literal> does not return a status indicating whether it was successful.</para></footnote></para>
</section>
<section id="ch07lev2sec5" label="7.1.5" xreflabel="7.1.5">
<title id="ch07lev2sec5__title">Cancellation Via <literal>Future</literal></title>
<para>We’ve already used an abstraction for managing the lifecycle of a task, dealing with exceptions, and facilitating cancellation—<literal>Future</literal>. Following the general principle that it is better to use existing library classes than to roll your own, let’s build <literal>timedRun</literal> using <literal>Future</literal> and the task execution framework.</para>

<para><?docpage num="146"?></para><example id="ch07list09" label="7.9" role="Listing" xreflabel="7.9" condition="146">

<title id="ch07list09__title">Interrupting a Task in a Dedicated Thread.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public static void timedRun(final Runnable r,
                            long timeout, TimeUnit unit)
                            throws InterruptedException {
    class RethrowableTask implements Runnable {
        private volatile Throwable t;
        public void run() {
            try { r.run(); }
            catch (Throwable t) { this.t = t; }
        }
        void rethrow() {
            if (t != null)
                throw launderThrowable(t);
        }
    }

    RethrowableTask task = new RethrowableTask();
    final Thread taskThread = new Thread(task);
    <emphasis role="strong">taskThread.start();</emphasis>
    cancelExec.schedule(new Runnable() {
        public void run() { <emphasis role="strong">taskThread.interrupt();</emphasis>  }
    }, timeout, unit);
    <emphasis role="strong">taskThread.join</emphasis>(unit.toMillis(timeout));
    task.rethrow();
}
</programlisting>
</example>
<para><indexterm id="iddle2272" significance="normal"><?indexkey E?><?primarykey ExecutorService?><?secondarykey CANCELLATION STRATEGY USING?><primary><emphasis role="strong">ExecutorService</emphasis></primary><secondary>cancellation strategy using</secondary></indexterm><indexterm id="iddle4472" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey INTERRUPTION HANDLING?><?tertiarykey FUTURE USE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>interruption handling</secondary><tertiary><literal>Future</literal> use</tertiary></indexterm><literal>ExecutorService.submit</literal> returns a <literal>Future</literal> describing the task. <literal>Future</literal> has a <literal>cancel</literal> method that takes a boolean argument, <literal>mayInterruptIfRunning</literal>, and returns a value indicating whether the cancellation attempt was successful. (This tells you only whether it was able to deliver the interruption, not whether the task detected and acted on it.) When <literal>mayInterruptIfRunning</literal> is <literal>true</literal> and the task is currently running in some thread, then that thread is interrupted. Setting this argument to <literal>false</literal> means “don’t run this task if it hasn’t started yet”, and should be used for tasks that are not designed to handle interruption.</para>
<para>Since you shouldn’t interrupt a thread unless you know its interruption policy, when is it OK to call <literal>cancel</literal> with an argument of <literal>true</literal>? The task execution threads created by the standard <literal>Executor</literal> implementations implement an interruption policy that lets tasks be cancelled using interruption, so it is safe to set <literal>mayInterruptIfRunning</literal> when cancelling tasks through their <literal>Future</literal>s when they are running in a standard <literal>Executor</literal>. You should not interrupt a pool thread directly when attempting to cancel a task, because you won’t know what task is running when the interrupt request is delivered—do this only through the task’s <literal>Future</literal>. This is yet another reason to code tasks to treat interruption as a cancellation request: then they can be cancelled through their <literal>Future</literal>s.</para>
<para><?docpage num="147"?><indexterm id="iddle1217" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey NON-INTERRUPTABLE?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>non-interruptable</secondary></indexterm><indexterm id="iddle1308" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey NON-STANDARD?><?tertiarykey REASONS AND STRATEGIES?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>non-standard</secondary><tertiary>reasons and strategies</tertiary></indexterm><indexterm id="iddle2596" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey TASK CANCELLATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>task cancellation</secondary></indexterm><indexterm id="iddle2597" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey TASK CANCELLATION?><?tertiarykey CRITERIA FOR?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>task cancellation</secondary><tertiary>criteria for</tertiary></indexterm><indexterm id="iddle2788" significance="normal"><?indexkey I?><?primarykey InterruptedException?><?secondarykey TASK CANCELLATION?><primary><emphasis role="strong">InterruptedException</emphasis></primary><secondary>task cancellation</secondary></indexterm><indexterm id="iddle2789" significance="normal"><?indexkey I?><?primarykey InterruptedException?><?secondarykey TASK CANCELLATION?><?tertiarykey CRITERIA FOR?><primary><emphasis role="strong">InterruptedException</emphasis></primary><secondary>task cancellation</secondary><tertiary>criteria for</tertiary></indexterm><indexterm id="iddle2806" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey NON-INTERRUPTABLE BLOCKING?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>non-interruptable blocking</secondary></indexterm><indexterm id="iddle2807" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey NON-INTERRUPTABLE BLOCKING?><?tertiarykey HANDLING?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>non-interruptable blocking</secondary><tertiary>handling</tertiary></indexterm><indexterm id="iddle3990" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey IRRELEVANCY?><?tertiarykey AS CANCELLATION REASON?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>irrelevancy</secondary><tertiary>as cancellation reason</tertiary></indexterm><indexterm id="iddle4931" significance="normal"><?indexkey T?><?primarykey TimeoutException?><?secondarykey TASK CANCELLATION CRITERIA?><primary><emphasis role="strong">TimeoutException</emphasis></primary><secondary>task cancellation criteria</secondary></indexterm><link linkend="ch07list10" preference="0">Listing 7.10</link> shows a version of <literal>timedRun</literal> that submits the task to an <literal>ExecutorService</literal> and retrieves the result with a timed <literal>Future.get</literal>. If <literal>get</literal> terminates with a <literal>TimeoutException</literal>, the task is cancelled via its <literal>Future</literal>. (To simplify coding, this version calls <literal>Future.cancel</literal> unconditionally in a <literal>finally</literal> block, taking advantage of the fact that cancelling a completed task has no effect.) If the underlying computation throws an exception prior to cancellation, it is rethrown from <literal>timedRun</literal>, which is the most convenient way for the caller to deal with the exception. <link linkend="ch07list10" preference="0">Listing 7.10</link> also illustrates another good practice: cancelling tasks whose result is no longer needed. (This technique was also used in <link linkend="ch06list13" preference="0">Listing 6.13</link> on page <link linkend="ch06list13" preference="0" role="pageref">128</link> and <link linkend="ch06list16" preference="0">Listing 6.16</link> on page <link linkend="ch06list16" preference="0" role="pageref">132</link>.)</para>
<example id="ch07list10" label="7.10" role="Listing" xreflabel="7.10" condition="147">
<title id="ch07list10__title">Cancelling a Task Using <literal>Future</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public static void timedRun(Runnable r,
                            long timeout, TimeUnit unit)
                            throws InterruptedException {
    <emphasis role="strong">Future&lt;?&gt; task = taskExec.submit(r);</emphasis>
    try {
        <emphasis role="strong">task.get(timeout, unit);</emphasis>
    } catch (TimeoutException e) {
        <emphasis>// task will be cancelled below</emphasis>
    } catch (ExecutionException e) {
        <emphasis>// exception thrown in task; rethrow</emphasis>
        throw launderThrowable(e.getCause());
    } finally {
        <emphasis>// Harmless if task already completed</emphasis>
        <emphasis role="strong">task.cancel(true);</emphasis>  <emphasis>// interrupt if running</emphasis>
    }
}
</programlisting>
</example>
<sidebar float="1" id="ch07sb06" condition="147"><title/>
<para>When <literal>Future.get</literal> throws <literal>InterruptedException</literal> or <literal>TimeoutException</literal> and you know that the result is no longer needed by the program, cancel the task with <literal>Future.cancel</literal>.</para>
</sidebar>
</section>
<section id="ch07lev2sec6" label="7.1.6" xreflabel="7.1.6">
<title id="ch07lev2sec6__title">Dealing with Non-interruptible Blocking</title>
<para>Many blocking library methods respond to interruption by returning early and throwing <literal>InterruptedException</literal>, which makes it easier to build tasks that are responsive to cancellation. However, not all blocking methods or blocking mechanisms are responsive to interruption; if a thread is blocked performing synchronous socket I/O or waiting to acquire an intrinsic lock, interruption has no effect other than setting the thread’s interrupted status. We can sometimes convince threads blocked in noninterruptible activities to stop by means similar to interruption, but this requires greater awareness of why the thread is blocked.</para>
<formalpara><?docpage num="148"?><?docpage num="149"?><title><emphasis role="strong"><?design?>Synchronous socket I/O in java.io.</emphasis></title><para><indexterm id="iddle1132" significance="normal"><?indexkey A?><?primarykey asynchrony/asynchronous?><?secondarykey I/O, AND NON-INTERRUPTABLE BLOCKING?><primary><emphasis role="strong">asynchrony/asynchronous</emphasis></primary><secondary>I/O, and non-interruptable blocking</secondary></indexterm><indexterm id="iddle1306" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey NON-STANDARD?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>non-standard</secondary></indexterm><indexterm id="iddle1307" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey NON-STANDARD?><?tertiarykey ENCAPSULATION OF?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>non-standard</secondary><tertiary>encapsulation of</tertiary></indexterm><indexterm id="iddle2016" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey NON-STANDARD CANCELLATION?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>non-standard cancellation</secondary></indexterm><indexterm id="iddle2282" significance="normal"><?indexkey E?><?primarykey explicit locks?><?secondarykey INTERRUPTION DURING ACQUISITION?><primary><emphasis role="strong">explicit locks</emphasis></primary><secondary>interruption during acquisition</secondary></indexterm><indexterm id="iddle2294" significance="normal"><?indexkey F?><?primarykey factory(s)?><?secondarykey METHODS?><?tertiarykey NEWTASKFOR?><primary><emphasis role="strong">factory(s)</emphasis></primary><secondary>methods</secondary><tertiary><literal>newTaskFor</literal></tertiary></indexterm><indexterm id="iddle2424" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey ENCAPSULATION OF NON-STANDARD CANCELLATION USE?><primary><emphasis role="strong">Future</emphasis></primary><secondary>encapsulation of non-standard cancellation use</secondary></indexterm><indexterm id="iddle2672" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey ASYNCHRONOUS?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>asynchronous</secondary></indexterm><indexterm id="iddle2673" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey ASYNCHRONOUS?><?tertiarykey NON-INTERRUPTABLE BLOCKING?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>asynchronous</secondary><tertiary>non-interruptable blocking</tertiary></indexterm><indexterm id="iddle2681" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey SYNCHRONOUS?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>synchronous</secondary></indexterm><indexterm id="iddle2682" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey SYNCHRONOUS?><?tertiarykey NON-INTERRUPTABLE BLOCKING?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>synchronous</secondary><tertiary>non-interruptable blocking</tertiary></indexterm><indexterm id="iddle2808" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey NON-INTERRUPTABLE BLOCKING?><?tertiarykey REASONS FOR?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>non-interruptable blocking</secondary><tertiary>reasons for</tertiary></indexterm><indexterm id="iddle2832" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><?secondarykey ACQUISITION, NON-INTERRUPTABLE BLOCKING REASON?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><secondary>acquisition, non-interruptable blocking reason</secondary></indexterm><indexterm id="iddle2902" significance="normal"><?indexkey J?><?primarykey java.nio package?><primary><emphasis role="strong">java.nio package</emphasis></primary></indexterm><indexterm id="iddle2903" significance="normal"><?indexkey J?><?primarykey java.nio package?><?secondarykey SYNCHRONOUS I/O?><primary><emphasis role="strong">java.nio package</emphasis></primary><secondary>synchronous I/O</secondary></indexterm><indexterm id="iddle2904" significance="normal"><?indexkey J?><?primarykey java.nio package?><?secondarykey SYNCHRONOUS I/O?><?tertiarykey NON-INTERRUPTABLE BLOCKING?><primary><emphasis role="strong">java.nio package</emphasis></primary><secondary>synchronous I/O</secondary><tertiary>non-interruptable blocking</tertiary></indexterm><indexterm id="iddle3042" significance="normal"><?indexkey L?><?primarykey Lock?><?secondarykey INTERRUPTIBLE ACQUISITION?><primary><emphasis role="strong">Lock</emphasis></primary><secondary>interruptible acquisition</secondary></indexterm><indexterm id="iddle3053" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><?tertiarykey INTRINSIC, NON-INTERRUPTABLE BLOCKING REASON?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary><tertiary>intrinsic, non-interruptable blocking reason</tertiary></indexterm><indexterm id="iddle3100" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey EXPLICIT?><?tertiarykey INTERRUPTION DURING LOCK ACQUISITION USE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>explicit</secondary><tertiary>interruption during lock acquisition use</tertiary></indexterm><indexterm id="iddle3108" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><?tertiarykey ACQUISITION, NON-INTERRUPTABLE BLOCKING REASON?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary><tertiary>acquisition, non-interruptable blocking reason</tertiary></indexterm><indexterm id="iddle3299" significance="normal"><?indexkey N?><?primarykey newTaskFor?><?secondarykey ENCAPSULATING NON-STANDARD CANCELLATION?><primary><emphasis role="strong">newTaskFor</emphasis></primary><secondary>encapsulating non-standard cancellation</secondary></indexterm><indexterm id="iddle4118" significance="normal"><?indexkey S?><?primarykey Selector?><primary><emphasis role="strong">Selector</emphasis></primary></indexterm><indexterm id="iddle4119" significance="normal"><?indexkey S?><?primarykey Selector?><?secondarykey NON-INTERRUPTABLE BLOCKING?><primary><emphasis role="strong">Selector</emphasis></primary><secondary>non-interruptable blocking</secondary></indexterm><indexterm id="iddle4325" significance="normal"><?indexkey S?><?primarykey sockets?><?secondarykey SYNCHRONOUS I/O?><primary><emphasis role="strong">sockets</emphasis></primary><secondary>synchronous I/O</secondary></indexterm><indexterm id="iddle4326" significance="normal"><?indexkey S?><?primarykey sockets?><?secondarykey SYNCHRONOUS I/O?><?tertiarykey NON-INTERRUPTABLE BLOCKING REASON?><primary><emphasis role="strong">sockets</emphasis></primary><secondary>synchronous I/O</secondary><tertiary>non-interruptable blocking reason</tertiary></indexterm><indexterm id="iddle4595" significance="normal"><?indexkey S?><?primarykey synchronous I/O?><primary><emphasis role="strong">synchronous I/O</emphasis></primary></indexterm><indexterm id="iddle4596" significance="normal"><?indexkey S?><?primarykey synchronous I/O?><?secondarykey NON-INTERRUPTABLE BLOCKING?><primary><emphasis role="strong">synchronous I/O</emphasis></primary><secondary>non-interruptable blocking</secondary></indexterm><indexterm id="iddle4859" significance="normal"><?indexkey T?><?primarykey ThreadPoolExecutor?><?secondarykey NEWTASKFOR?><primary><emphasis role="strong">ThreadPoolExecutor</emphasis></primary><secondary><literal>newTaskFor</literal></secondary></indexterm>The common form of blocking I/O in server applications is reading or writing to a socket. Unfortunately, the <literal>read</literal> and <literal>write</literal> methods in <literal>InputStream</literal> and <literal>OutputStream</literal> are not responsive to interruption, but closing the underlying socket makes any threads blocked in <literal>read</literal> or <literal>write</literal> throw a <literal>SocketException</literal>.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Synchronous I/O in java.nio.</emphasis></title><para>Interrupting a thread waiting on an <literal>InterruptibleChannel</literal> causes it to throw <literal>ClosedByInterruptException</literal> and close the channel (and also causes all other threads blocked on the channel to throw <literal>ClosedByInterruptException</literal>). Closing an <literal>InterruptibleChannel</literal> causes threads blocked on channel operations to throw <literal>AsynchronousCloseException</literal>. Most standard <literal>Channel</literal>s implement <literal>InterruptibleChannel</literal>.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Asynchronous I/O with Selector.</emphasis></title><para>If a thread is blocked in <literal>Selector.select</literal> (in <literal>java.nio.channels</literal>), calling close or <literal>wakeup</literal> causes it to return prematurely.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Lock acquisition.</emphasis></title><para>If a thread is blocked waiting for an intrinsic lock, there is nothing you can do to stop it short of ensuring that it eventually acquires the lock and makes enough progress that you can get its attention some other way. However, the explicit <literal>Lock</literal> classes offer the <literal>lockInterruptibly</literal> method, which allows you to wait for a lock and still be responsive to interrupts—see <link linkend="ch13" preference="0">Chapter 13</link>.</para></formalpara>
<para><literal>ReaderThread</literal> in <link linkend="ch07list11" preference="0">Listing 7.11</link> shows a technique for encapsulating nonstandard cancellation. <literal>ReaderThread</literal> manages a single socket connection, reading synchronously from the socket and passing any data received to <literal>processBuffer</literal>. To facilitate terminating a user connection or shutting down the server, <literal>ReaderThread</literal> overrides <literal>interrupt</literal> to both deliver a standard interrupt and close the underlying socket; thus interrupting a <literal>ReaderThread</literal> makes it stop what it is doing whether it is blocked in <literal>read</literal> or in an interruptible blocking method.</para>
</section>
<section id="ch07lev2sec7" label="7.1.7" xreflabel="7.1.7">
<title id="ch07lev2sec7__title">Encapsulating Nonstandard Cancellation with <literal>newTaskFor</literal></title>
<para>The technique used in <literal>ReaderThread</literal> to encapsulate nonstandard cancellation can be refined using the <literal>newTaskFor</literal> hook added to <literal>ThreadPoolExecutor</literal> in Java 6. When a <literal>Callable</literal> is submitted to an <literal>ExecutorService</literal>, <literal>submit</literal> returns a <literal>Future</literal> that can be used to cancel the task. The <literal>newTaskFor</literal> hook is a factory method that creates the <literal>Future</literal> representing the task. It returns a <literal>RunnableFuture</literal>, an interface that extends both <literal>Future</literal> and <literal>Runnable</literal> (and is implemented by <literal>FutureTask</literal>).</para>
<para>Customizing the task <literal>Future</literal> allows you to override <literal>Future.cancel</literal>. Custom cancellation code can perform logging or gather statistics on cancellation, and can also be used to cancel activities that are not responsive to interruption. <literal>ReaderThread</literal> encapsulates cancellation of socket-using threads by overriding <literal>interrupt</literal>; the same can be done for tasks by overriding <literal>Future.cancel</literal>.</para>
<para><literal>CancellableTask</literal> in <link linkend="ch07list12" preference="0">Listing 7.12</link> defines a <literal>CancellableTask</literal> interface that extends <literal>Callable</literal> and adds a <literal>cancel</literal> method and a <literal>newTask</literal> factory method for <?docpage num="150"?><indexterm id="iddle2166" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey READERTHREAD?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ReaderThread</literal></secondary></indexterm><indexterm id="iddle1364" significance="normal"><?indexkey C?><?primarykey client-side locking?><?secondarykey STREAM CLASS MANAGEMENT?><primary><emphasis role="strong">client-side locking</emphasis></primary><secondary>stream class management</secondary></indexterm><indexterm id="iddle2030" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey THREAD OWNERSHIP?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>thread ownership</secondary></indexterm><indexterm id="iddle2605" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey THREADS?><?tertiarykey HANDLING ENCAPSULATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>threads</secondary><tertiary>handling encapsulation</tertiary></indexterm><indexterm id="iddle2606" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey THREADS?><?tertiarykey LIFECYCLE METHODS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>threads</secondary><tertiary>lifecycle methods</tertiary></indexterm><indexterm id="iddle2772" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey LOGGING OUTPUT?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>logging output</secondary></indexterm><indexterm id="iddle2773" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey LOGGING OUTPUT?><?tertiarykey AND CLIENT-SIDE LOCKING?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>logging output</secondary><tertiary>and client-side locking</tertiary></indexterm><indexterm id="iddle2822" significance="normal"><?indexkey I?><?primarykey intransitivity?><primary><emphasis role="strong">intransitivity</emphasis></primary></indexterm><indexterm id="iddle2823" significance="normal"><?indexkey I?><?primarykey intransitivity?><?secondarykey ENCAPSULATION CHARACTERIZED BY?><primary><emphasis role="strong">intransitivity</emphasis></primary><secondary>encapsulation characterized by</secondary></indexterm><indexterm id="iddle2983" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey THREAD?><?tertiarykey THREAD-BASED SERVICE MANAGEMENT?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>thread</secondary><tertiary>thread-based service management</tertiary></indexterm><indexterm id="iddle3069" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CLIENT-SIDE?><?tertiarykey STREAM CLASS MANAGEMENT?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>client-side</secondary><tertiary>stream class management</tertiary></indexterm><indexterm id="iddle3169" significance="normal"><?indexkey L?><?primarykey logging?><?secondarykey SERVICE?><primary><emphasis role="strong">logging</emphasis></primary><secondary>service</secondary></indexterm><indexterm id="iddle3170" significance="normal"><?indexkey L?><?primarykey logging?><?secondarykey SERVICE?><?tertiarykey AS EXAMPLE OF STOPPING A THREADBASED SERVICE?><primary><emphasis role="strong">logging</emphasis></primary><secondary>service</secondary><tertiary>as example of stopping a threadbased service</tertiary></indexterm><indexterm id="iddle3443" significance="normal"><?indexkey O?><?primarykey ownership?><?secondarykey THREAD?><primary><emphasis role="strong">ownership</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle3872" significance="normal"><?indexkey R?><?primarykey representation?><?secondarykey THREAD?><primary><emphasis role="strong">representation</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle4194" significance="normal"><?indexkey S?><?primarykey service(s)?><?secondarykey LOGGING?><primary><emphasis role="strong">service(s)</emphasis></primary><secondary>logging</secondary></indexterm><indexterm id="iddle4195" significance="normal"><?indexkey S?><?primarykey service(s)?><?secondarykey LOGGING?><?tertiarykey AS THREAD-BASED SERVICE EXAMPLE?><primary><emphasis role="strong">service(s)</emphasis></primary><secondary>logging</secondary><tertiary>as thread-based service example</tertiary></indexterm><indexterm id="iddle4198" significance="normal"><?indexkey S?><?primarykey service(s)?><?secondarykey THREAD-BASED?><primary><emphasis role="strong">service(s)</emphasis></primary><secondary>thread-based</secondary></indexterm><indexterm id="iddle4199" significance="normal"><?indexkey S?><?primarykey service(s)?><?secondarykey THREAD-BASED?><?tertiarykey STOPPING?><primary><emphasis role="strong">service(s)</emphasis></primary><secondary>thread-based</secondary><tertiary>stopping</tertiary></indexterm><indexterm id="iddle4258" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey OF THREAD-BASED SERVICES?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>of thread-based services</secondary></indexterm><indexterm id="iddle4262" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey STRATEGIES?><?tertiarykey LOGGING SERVICE EXAMPLE?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>strategies</secondary><tertiary>logging service example</tertiary></indexterm><indexterm id="iddle4487" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey SHUTDOWN?><?tertiarykey LOGGING SERVICE EXAMPLE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>shutdown</secondary><tertiary>logging service example</tertiary></indexterm><indexterm id="iddle4493" significance="normal"><?indexkey S?><?primarykey stream classes?><primary><emphasis role="strong">stream classes</emphasis></primary></indexterm><indexterm id="iddle4494" significance="normal"><?indexkey S?><?primarykey stream classes?><?secondarykey CLIENT-SIDE LOCKING WITH?><primary><emphasis role="strong">stream classes</emphasis></primary><secondary>client-side locking with</secondary></indexterm><indexterm id="iddle4495" significance="normal"><?indexkey S?><?primarykey stream classes?><?secondarykey THREAD SAFETY?><primary><emphasis role="strong">stream classes</emphasis></primary><secondary>thread safety</secondary></indexterm><indexterm id="iddle4788" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey LIFECYCLE?><?tertiarykey THREAD-BASED SERVICE MANAGEMENT?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>lifecycle</secondary><tertiary>thread-based service management</tertiary></indexterm><indexterm id="iddle4791" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey OWNERSHIP?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>ownership</secondary></indexterm><indexterm id="iddle4816" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SERVICES THAT OWN?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>services that own</secondary></indexterm><indexterm id="iddle4817" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SERVICES THAT OWN?><?tertiarykey STOPPING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>services that own</secondary><tertiary>stopping</tertiary></indexterm>constructing a <literal>RunnableFuture</literal>. <literal>CancellingExecutor</literal> extends <literal>ThreadPoolExecutor</literal>, and overrides <literal>newTaskFor</literal> to let a <literal>CancellableTask</literal> create its own <literal>Future</literal>.</para>
<example id="ch07list11" label="7.11" role="Listing" xreflabel="7.11" condition="149">
<?docpage num="149"?>
<title id="ch07list11__title">Encapsulating Nonstandard Cancellation in a <literal>Thread</literal> by Overriding <literal>Interrupt</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class ReaderThread extends Thread {
    private final Socket socket;
    private final InputStream in;

    public ReaderThread(Socket socket) throws IOException {
        this.socket = socket;
        this.in = socket.getInputStream();
    }

    public void  <emphasis role="strong">interrupt()</emphasis>  {
        try {
            socket.close();
        }
        catch (IOException ignored) { }
        finally {
            <emphasis role="strong">super.interrupt();</emphasis>
        }
    }

    public void run() {
        try {
            byte[] buf = new byte[BUFSZ];
            while (true) {
                int count = in.read(buf);
                if (count &lt; 0)
                    break;
                else if (count &gt; 0)
                    processBuffer(buf, count);
            }
        } catch (IOException e) { <emphasis>/*  Allow thread to exit  */</emphasis>  }
    }
}
</programlisting>
</example>
<para><literal>SocketUsingTask</literal> implements <literal>CancellableTask</literal> and defines <literal>Future.cancel</literal> to close the socket as well as call <literal>super.cancel</literal>. If a <literal>SocketUsingTask</literal> is cancelled through its <literal>Future</literal>, the socket is closed <emphasis>and</emphasis> the executing thread is interrupted. This increases the task’s responsiveness to cancellation: not only can it safely call interruptible blocking methods while remaining responsive to cancellation, but it can also call blocking socket I/O methods.</para>
</section>
</section>
<section id="ch07lev1sec2" condition="150" label="7.2" xreflabel="7.2"><?docpage num="150"?><?docpage num="151"?>
<title id="ch07lev1sec2__title">Stopping a Thread-based Service</title>
<para>Applications commonly create services that own threads, such as thread pools, and the lifetime of these services is usually longer than that of the method that creates them. If the application is to shut down gracefully, the threads owned by these services need to be terminated. Since there is no preemptive way to stop a thread, they must instead be persuaded to shut down on their own.</para>
<para>Sensible encapsulation practices dictate that you should not manipulate a thread—interrupt it, modify its priority, etc.—unless you own it. The thread API has no formal concept of thread ownership: a thread is represented with a <literal>Thread</literal> object that can be freely shared like any other object. However, it makes sense to think of a thread as having an owner, and this is usually the class that created the thread. So a thread pool owns its worker threads, and if those threads need to be interrupted, the thread pool should take care of it.</para>
<para>As with any other encapsulated object, thread ownership is not transitive: the application may own the service and the service may own the worker threads, but the application doesn’t own the worker threads and therefore should not attempt to stop them directly. Instead, the service should provide <emphasis>lifecycle methods</emphasis> for shutting itself down that also shut down the owned threads; then the application can shut down the service, and the service can shut down the threads. <literal>ExecutorService</literal> provides the <literal>shutdown</literal> and <literal>shutdownNow</literal> methods; other thread-owning services should provide a similar shutdown mechanism.</para>
<sidebar float="1" id="ch07sb07" condition="150"><title/>
<para>Provide lifecycle methods whenever a thread-owning service has a lifetime longer than that of the method that created it.</para>
</sidebar>
<section id="ch07lev2sec8" label="7.2.1" xreflabel="7.2.1">
<title id="ch07lev2sec8__title">Example: A Logging Service</title>
<para>Most server applications use logging, which can be as simple as inserting <literal>println</literal> statements into the code. Stream classes like <literal>PrintWriter</literal> are thread-safe, so this simple approach would require no explicit synchronization.<footnote id="ch07fn03" label="3"><para>If you are logging multiple lines as part of a single log message, you may need to use additional client-side locking to prevent undesirable interleaving of output from multiple threads. If two threads logged multiline stack traces to the same stream with one <literal>println</literal> call per line, the results would be interleaved unpredictably, and could easily look like one large but meaningless stack trace.</para></footnote> However, as <?docpage num="152"?><indexterm id="iddle2094" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CANCELLABLETASK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>CancellableTask</literal></secondary></indexterm><indexterm id="iddle2183" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SOCKETUSINGTASK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SocketUsingTask</literal></secondary></indexterm><indexterm id="iddle2438" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey EXAMPLE USE?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>example use</secondary></indexterm><indexterm id="iddle2134" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey LOGWRITER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>LogWriter</literal></secondary></indexterm><indexterm id="iddle2921" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey SERVICE SHUTDOWN ISSUES?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>service shutdown issues</secondary></indexterm>we’ll see in <link linkend="ch11lev1sec6" preference="0">Section 11.6</link>, inline logging can have some performance costs in highvolume applications. Another alternative is have the <literal>log</literal> call queue the log message for processing by another thread.</para>
<example id="ch07list12" label="7.12" role="Listing" xreflabel="7.12" condition="151">
<?docpage num="151"?>
<title id="ch07list12__title">Encapsulating Nonstandard Cancellation in a Task with <literal>Newtaskfor</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface CancellableTask&lt;T&gt; extends Callable&lt;T&gt; {
    void cancel();
    RunnableFuture&lt;T&gt; newTask();
}

@ThreadSafe
public class CancellingExecutor extends ThreadPoolExecutor {
    ...
    protected&lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) {
        if (callable instanceof CancellableTask)
            return ((CancellableTask&lt;T&gt;) callable).newTask();
        else
            return super.newTaskFor(callable);
    }
}

public abstract class SocketUsingTask&lt;T&gt;
        implements CancellableTask&lt;T&gt; {
    @GuardedBy("this") private Socket socket;

    protected synchronized void setSocket(Socket s) { socket = s; }

    public synchronized void cancel() {
        try {
            if (socket != null)
                socket.close();
        } catch (IOException ignored) { }
    }

    public RunnableFuture&lt;T&gt; newTask() {
        return new FutureTask&lt;T&gt;(this) {
            public boolean cancel(boolean mayInterruptIfRunning) {
                try {
                    SocketUsingTask.this.cancel();
                } finally {
                    return super.cancel(mayInterruptIfRunning);
                }
            }
        };
    }
}
</programlisting>
</example>
<para><literal>LogWriter</literal> in <link linkend="ch07list13" preference="0">Listing 7.13</link> shows a simple logging service in which the logging activity is moved to a separate logger thread. Instead of having the thread that produces the message write it directly to the output stream, <literal>LogWriter</literal> hands it off to the logger thread via a <literal>BlockingQueue</literal> and the logger thread writes it out. This is a multiple-producer, single-consumer design: any activity calling <literal>log</literal> is acting as a producer, and the background logger thread is the consumer. If the logger thread falls behind, the <literal>BlockingQueue</literal> eventually blocks the producers until the logger thread catches up.</para>
<example id="ch07list13" label="7.13" role="Listing" xreflabel="7.13" condition="152">
<title id="ch07list13__title">Producer-Consumer Logging Service with No Shutdown Support.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class LogWriter {
    private final BlockingQueue&lt;String&gt; queue;
    private final LoggerThread logger;

    public LogWriter(Writer writer) {
        this.queue = new LinkedBlockingQueue&lt;String&gt;(CAPACITY);
        this.logger = new LoggerThread(writer);
    }

    public void start() { logger.start(); }

    public void log(String msg) throws InterruptedException {
        queue.put(msg);
    }

    private class LoggerThread extends Thread {
        private final PrintWriter writer;
        ...
        public void run() {
            try {
                while (true)
                   writer.println(queue.take());
            } catch(InterruptedException ignored) {
            } finally {
                writer.close();
            }
        }
    }
}
</programlisting>
</example>
<para>For a service like <literal>LogWriter</literal> to be useful in production, we need a way to terminate the logger thread so it does not prevent the JVM from shutting down <?docpage num="153"?><indexterm id="iddle1011" significance="normal"><?indexkey A?><?primarykey abrupt shutdown?><?secondarykey VS. GRACEFUL SHUTDOWN?><primary><emphasis role="strong">abrupt shutdown</emphasis></primary><secondary>vs. graceful shutdown</secondary></indexterm><indexterm id="iddle1153" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey AND SERVICE SHUTDOWN?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>and service shutdown</secondary></indexterm><indexterm id="iddle1336" significance="normal"><?indexkey C?><?primarykey check-then-act operation?><?secondarykey SERVICE SHUTDOWN ISSUE?><primary><emphasis role="strong">check-then-act operation</emphasis></primary><secondary>service shutdown issue</secondary></indexterm><indexterm id="iddle2132" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey LOGSERVICE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>LogService</literal></secondary></indexterm><indexterm id="iddle2270" significance="normal"><?indexkey E?><?primarykey ExecutorService?><primary><emphasis role="strong">ExecutorService</emphasis></primary></indexterm><indexterm id="iddle2271" significance="normal"><?indexkey E?><?primarykey ExecutorService?><?secondarykey AND SERVICE SHUTDOWN?><primary><emphasis role="strong">ExecutorService</emphasis></primary><secondary>and service shutdown</secondary></indexterm><indexterm id="iddle2462" significance="normal"><?indexkey G?><?primarykey graceful?><?secondarykey SHUTDOWN?><primary><emphasis role="strong">graceful</emphasis></primary><secondary>shutdown</secondary></indexterm><indexterm id="iddle2463" significance="normal"><?indexkey G?><?primarykey graceful?><?secondarykey SHUTDOWN?><?tertiarykey VS. ABRUPT SHUTDOWN?><primary><emphasis role="strong">graceful</emphasis></primary><secondary>shutdown</secondary><tertiary>vs. abrupt shutdown</tertiary></indexterm><indexterm id="iddle3782" significance="normal"><?indexkey R?><?primarykey race conditions?><?secondarykey AVOIDANCE?><?tertiarykey IN THREAD-BASED SERVICE SHUTDOWN?><primary><emphasis role="strong">race conditions</emphasis></primary><secondary>avoidance</secondary><tertiary>in thread-based service shutdown</tertiary></indexterm><indexterm id="iddle3964" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey SAFETY VS?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>safety vs</secondary></indexterm><indexterm id="iddle3965" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey SAFETY VS?><?tertiarykey GRACEFUL VS. ABRUPT SHUTDOWN?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>safety vs</secondary><tertiary>graceful vs. abrupt shutdown</tertiary></indexterm><indexterm id="iddle4042" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey RESPONSIVENESS VS?><primary><emphasis role="strong">safety</emphasis></primary><secondary>responsiveness vs</secondary></indexterm><indexterm id="iddle4043" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey RESPONSIVENESS VS?><?tertiarykey AS GRACEFUL VS. ABRUPT SHUTDOWN?><primary><emphasis role="strong">safety</emphasis></primary><secondary>responsiveness vs</secondary><tertiary>as graceful vs. abrupt shutdown</tertiary></indexterm><indexterm id="iddle4253" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey GRACEFUL VS. ABRUPT TRADEOFFS?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>graceful vs. abrupt tradeoffs</secondary></indexterm><indexterm id="iddle4268" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey LOGGING SERVICE SHUTDOWN ALTERNATIVES?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>logging service shutdown alternatives</secondary></indexterm><indexterm id="iddle4271" significance="normal"><?indexkey S?><?primarykey shutdownNow?><?secondarykey LOGGING SERVICE SHUTDOWN ALTERNATIVES?><primary><emphasis role="strong">shutdownNow</emphasis></primary><secondary>logging service shutdown alternatives</secondary></indexterm>normally. Stopping the logger thread is easy enough, since it repeatedly calls <literal>take</literal>, which is responsive to interruption; if the logger thread is modified to exit on catching <literal>InterruptedException</literal>, then interrupting the logger thread stops the service.</para>
<para>However, simply making the logger thread exit is not a very satisfying shutdown mechanism. Such an abrupt shutdown discards log messages that might be waiting to be written to the log, but, more importantly, threads blocked in <literal>log</literal> because the queue is full <emphasis>will never become unblocked</emphasis>. Cancelling a producerconsumer activity requires cancelling both the producers and the consumers. Interrupting the logger thread deals with the consumer, but because the producers in this case are not dedicated threads, cancelling them is harder.</para>
<para>Another approach to shutting down <literal>LogWriter</literal> would be to set a “shutdown requested” flag to prevent further messages from being submitted, as shown in <link linkend="ch07list14" preference="0">Listing 7.14</link>. The consumer could then drain the queue upon being notified that shutdown has been requested, writing out any pending messages and unblocking any producers blocked in <literal>log</literal>. However, this approach has race conditions that make it unreliable. The implementation of <literal>log</literal> is a check-then-act sequence: producers could observe that the service has not yet been shut down but still queue messages after the shutdown, again with the risk that the producer might get blocked in <literal>log</literal> and never become unblocked. There are tricks that reduce the likelihood of this (like having the consumer wait several seconds before declaring the queue drained), but these do not change the fundamental problem, merely the likelihood that it will cause a failure.</para>
<example id="ch07list14" label="7.14" role="Listing" xreflabel="7.14" condition="153">
<title id="ch07list14__title">Unreliable Way to Add Shutdown Support to the Logging Service.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public void log(String msg) throws InterruptedException {
    if (!shutdownRequested)
        queue.put(msg);
    else
        throw new IllegalStateException("logger is shut down");
}
</programlisting>
</example>
<para>The way to provide reliable shutdown for <literal>LogWriter</literal> is to fix the race condition, which means making the submission of a new log message atomic. But we don’t want to hold a lock while trying to enqueue the message, since <literal>put</literal> could block. Instead, we can atomically check for shutdown and conditionally increment a counter to “reserve” the right to submit a message, as shown in <literal>LogService</literal> in <link linkend="ch07list15" preference="0">Listing 7.15</link>.</para>
</section>
<section id="ch07lev2sec9" label="7.2.2" xreflabel="7.2.2">
<title id="ch07lev2sec9__title"><literal>ExecutorService</literal> Shutdown</title>
<para>In <link linkend="ch06lev2sec7" preference="0">Section 6.2.4</link>, we saw that <literal>ExecutorService</literal> offers two ways to shut down: graceful shutdown with <literal>shutdown</literal>, and abrupt shutdown with <literal>shutdownNow</literal>. In an abrupt shutdown, <literal>shutdownNow</literal> returns the list of tasks that had not yet started after attempting to cancel all actively executing tasks.</para>

<para><?docpage num="154"?></para><example id="ch07list15" label="7.15" role="Listing" xreflabel="7.15" condition="154">

<title id="ch07list15__title">Adding Reliable Cancellation to <literal>LogWriter</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class LogService {
    private final BlockingQueue&lt;String&gt; queue;
    private final LoggerThread loggerThread;
    private final PrintWriter writer;
    @GuardedBy("this") private boolean isShutdown;
    @GuardedBy("this") private int reservations;

    public void start() { loggerThread.start(); }

    public void stop() {
        synchronized (this) { isShutdown = true; }
        loggerThread.interrupt();
    }

    public void log(String msg) throws InterruptedException {
        synchronized (this) {
            if (isShutdown)
                throw new IllegalStateException(...);
            ++reservations;
        }
        queue.put(msg);
    }

    private class LoggerThread extends Thread {
        public void run() {
            try {
                while (true) {
                    try {
                        synchronized (LogService.this) {
                            if (isShutdown &amp;&amp; reservations == 0)
                                break;
                        }
                        String msg = queue.take();
                        synchronized (LogService.this) {
                            --reservations;
                        }
                        writer.println(msg);
                    } catch (InterruptedException e) { <emphasis>/*  retry  */</emphasis> }
                }
            } finally {
                writer.close();
            }
        }
    }
}
</programlisting>
</example>
<para><?docpage num="155"?><indexterm id="iddle2133" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey LOGSERVICE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>LogService</literal></secondary></indexterm><indexterm id="iddle2018" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey OF LIFECYCLE METHODS?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>of lifecycle methods</secondary></indexterm><indexterm id="iddle2972" significance="normal"><?indexkey L?><?primarykey lifecycle?><?secondarykey ENCAPSULATION?><primary><emphasis role="strong">lifecycle</emphasis></primary><secondary>encapsulation</secondary></indexterm><indexterm id="iddle3560" significance="normal"><?indexkey P?><?primarykey poison?><?secondarykey PILL?><primary><emphasis role="strong">poison</emphasis></primary><secondary>pill</secondary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle3561" significance="normal"><?indexkey P?><?primarykey poison?><?secondarykey PILL?><primary><emphasis role="strong">poison</emphasis></primary><secondary>pill</secondary><seealso> <link linkend="iddle1114" preference="0"><emphasis role="strong">application(s)</emphasis>, shutdown</link>.</seealso></indexterm><indexterm id="iddle3562" significance="normal"><?indexkey P?><?primarykey poison?><?secondarykey PILL?><primary><emphasis role="strong">poison</emphasis></primary><secondary>pill</secondary></indexterm><indexterm id="iddle3566" significance="normal"><?indexkey P?><?primarykey poison?><?secondarykey PILL?><?tertiarykey UNBOUNDED QUEUE SHUTDOWN WITH?><primary><emphasis role="strong">poison</emphasis></primary><secondary>pill</secondary><tertiary>unbounded queue shutdown with</tertiary></indexterm><indexterm id="iddle4260" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey STRATEGIES?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>strategies</secondary></indexterm><indexterm id="iddle4261" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey STRATEGIES?><?tertiarykey LIFECYCLE METHOD ENCAPSULATION?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>strategies</secondary><tertiary>lifecycle method encapsulation</tertiary></indexterm><indexterm id="iddle4263" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey STRATEGIES?><?tertiarykey LOGGING SERVICE EXAMPLE?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>strategies</secondary><tertiary>logging service example</tertiary></indexterm><indexterm id="iddle4485" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey SHUTDOWN?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>shutdown</secondary></indexterm><indexterm id="iddle4486" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey SHUTDOWN?><?tertiarykey LIFECYCLE METHOD ENCAPSULATION?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>shutdown</secondary><tertiary>lifecycle method encapsulation</tertiary></indexterm><indexterm id="iddle4489" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey SHUTDOWN?><?tertiarykey POISON PILL?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>shutdown</secondary><tertiary>poison pill</tertiary></indexterm><indexterm id="iddle4995" significance="normal"><?indexkey U?><?primarykey unbounded?><?secondarykey QUEUES?><?tertiarykey POISON PILL SHUTDOWN USE?><primary><emphasis role="strong">unbounded</emphasis></primary><secondary>queues</secondary><tertiary>poison pill shutdown use</tertiary></indexterm>The two different termination options offer a tradeoff between safety and responsiveness: abrupt termination is faster but riskier because tasks may be interrupted in the middle of execution, and normal termination is slower but safer because the <literal>ExecutorService</literal> does not shut down until all queued tasks are processed. Other thread-owning services should consider providing a similar choice of shutdown modes.</para>
<para>Simple programs can get away with starting and shutting down a global <literal>ExecutorService</literal> from <literal>main</literal>. More sophisticated programs are likely to encapsulate an <literal>ExecutorService</literal> behind a higher-level service that provides its own lifecycle methods, such as the variant of <literal>LogService</literal> in <link linkend="ch07list16" preference="0">Listing 7.16</link> that delegates to an <literal>ExecutorService</literal> instead of managing its own threads. Encapsulating an <literal>ExecutorService</literal> extends the ownership chain from application to service to thread by adding another link; each member of the chain manages the lifecycle of the services or threads it owns.</para>
<example id="ch07list16" label="7.16" role="Listing" xreflabel="7.16" condition="155">
<title id="ch07list16__title">Logging Service that Uses an <literal>ExecutorService</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class LogService {
    private final ExecutorService exec = newSingleThreadExecutor();
    ...
    public void start() { }

    public void stop() throws InterruptedException {
        try {
            <emphasis role="strong">exec.shutdown();</emphasis>
            <emphasis role="strong">exec.awaitTermination(TIMEOUT, UNIT);</emphasis>
        } finally {
            writer.close();
        }
    }
    public void log(String msg) {
        try {
            exec.execute(new WriteTask(msg));
        } catch (RejectedExecutionException ignored) { }
    }
}
</programlisting>
</example>
</section>
<section id="ch07lev2sec10" label="7.2.3" xreflabel="7.2.3">
<title id="ch07lev2sec10__title">Poison Pills</title>
<para>Another way to convince a producer-consumer service to shut down is with a <emphasis>poison pill</emphasis>: a recognizable object placed on the queue that means “when you get this, stop.” With a FIFO queue, poison pills ensure that consumers finish the work on their queue before shutting down, since any work submitted prior to submitting the poison pill will be retrieved before the pill; producers should not submit any work after putting a poison pill on the queue. <literal>IndexingService</literal> in <link linkend="ch07list17" preference="0">Listings 7.17</link>, <link linkend="ch07list18" preference="0">7.18</link>, and <link linkend="ch07list19" preference="0">7.19</link> shows a single-producer, single-consumer version of <?docpage num="156"?><?docpage num="157"?><indexterm id="iddle2125" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey INDEXINGSERVICE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>IndexingService</literal></secondary></indexterm><indexterm id="iddle3565" significance="normal"><?indexkey P?><?primarykey poison?><?secondarykey PILL?><?tertiarykey INDEXINGSERVICE?><primary><emphasis role="strong">poison</emphasis></primary><secondary>pill</secondary><tertiary><literal>IndexingService</literal></tertiary></indexterm><indexterm id="iddle3770" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey UNBOUNDED?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>unbounded</secondary></indexterm><indexterm id="iddle3771" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey UNBOUNDED?><?tertiarykey POISON PILL SHUTDOWN?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>unbounded</secondary><tertiary>poison pill shutdown</tertiary></indexterm><indexterm id="iddle4264" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey STRATEGIES?><?tertiarykey ONE-SHOT EXECUTION SERVICE EXAMPLE?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>strategies</secondary><tertiary>one-shot execution service example</tertiary></indexterm><indexterm id="iddle4488" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey SHUTDOWN?><?tertiarykey ONE-SHOT EXECUTION SERVICE EXAMPLE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>shutdown</secondary><tertiary>one-shot execution service example</tertiary></indexterm>the desktop search example from <link linkend="ch05list08" preference="0">Listing 5.8</link> on page <link linkend="ch05list08" preference="0" role="pageref">91</link> that uses a poison pill to shut down the service.</para>
<example id="ch07list17" label="7.17" role="Listing" xreflabel="7.17" condition="156">
<title id="ch07list17__title">Shutdown with Poison Pill.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class IndexingService {
    <emphasis role="strong">private static final File POISON = new File("");</emphasis>
    private final IndexerThread consumer = new IndexerThread();
    private final CrawlerThread producer = new CrawlerThread();
    private final BlockingQueue&lt;File&gt; queue;
    private final FileFilter fileFilter;
    private final File root;

    class CrawlerThread extends Thread { <emphasis>/* Listing 7.18 */</emphasis> }
    class IndexerThread extends Thread { <emphasis>/* Listing 7.19 */</emphasis> }

    public void start() {
        producer.start();
        consumer.start();
    }

    public void stop() { producer.interrupt(); }

    public void awaitTermination() throws InterruptedException {
        consumer.join();
    }
}
</programlisting>
</example>
<para>Poison pills work only when the number of producers and consumers is known. The approach in <literal>IndexingService</literal> can be extended tomultiple producers by having each producer place a pill on the queue and having the consumer stop only when it receives <emphasis>N<subscript>producers</subscript></emphasis> pills. It can be extended to multiple consumers by having each producer place <emphasis>N<subscript>consumers</subscript></emphasis> pills on the queue, though this can get unwieldy with large numbers of producers and consumers. Poison pills work reliably only with unbounded queues.</para>
</section>
<section id="ch07lev2sec11" label="7.2.4" xreflabel="7.2.4">
<title id="ch07lev2sec11__title">Example: A One-shot Execution Service</title>
<para>If a method needs to process a batch of tasks and does not return until all the tasks are finished, it can simplify service lifecycle management by using a private <literal>Executor</literal> whose lifetime is bounded by that method. (The <literal>invokeAll</literal> and <literal>invokeAny</literal> methods can often be useful in such situations.)</para>
<para>The <literal>checkMail</literal> method in <link linkend="ch07list20" preference="0">Listing 7.20</link> checks for new mail in parallel on a number of hosts. It creates a private executor and submits a task for each host: it then shuts down the executor and waits for termination, which occurs when all <?docpage num="158"?><indexterm id="iddle2106" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CRAWLERTHREAD?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>CrawlerThread</literal></secondary></indexterm><indexterm id="iddle2124" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey INDEXERTHREAD?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>IndexerThread</literal></secondary></indexterm><indexterm id="iddle3563" significance="normal"><?indexkey P?><?primarykey poison?><?secondarykey PILL?><?tertiarykey CRAWLERTHREAD?><primary><emphasis role="strong">poison</emphasis></primary><secondary>pill</secondary><tertiary><literal>CrawlerThread</literal></tertiary></indexterm><indexterm id="iddle3564" significance="normal"><?indexkey P?><?primarykey poison?><?secondarykey PILL?><?tertiarykey INDEXERTHREAD?><primary><emphasis role="strong">poison</emphasis></primary><secondary>pill</secondary><tertiary><literal>IndexerThread</literal></tertiary></indexterm><indexterm id="iddle1008" significance="normal"><?indexkey A?><?primarykey abrupt shutdown?><primary><emphasis role="strong">abrupt shutdown</emphasis></primary></indexterm><indexterm id="iddle1009" significance="normal"><?indexkey A?><?primarykey abrupt shutdown?><?secondarykey LIMITATIONS?><primary><emphasis role="strong">abrupt shutdown</emphasis></primary><secondary>limitations</secondary></indexterm><indexterm id="iddle1337" significance="normal"><?indexkey C?><?primarykey checkpoint?><primary><emphasis role="strong">checkpoint</emphasis></primary></indexterm><indexterm id="iddle1338" significance="normal"><?indexkey C?><?primarykey checkpoint?><?secondarykey STATE?><primary><emphasis role="strong">checkpoint</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle1339" significance="normal"><?indexkey C?><?primarykey checkpoint?><?secondarykey STATE?><?tertiarykey SHUTDOWN ISSUES?><primary><emphasis role="strong">checkpoint</emphasis></primary><secondary>state</secondary><tertiary>shutdown issues</tertiary></indexterm><indexterm id="iddle2273" significance="normal"><?indexkey E?><?primarykey ExecutorService?><?secondarykey CHECKMAIL EXAMPLE?><primary><emphasis role="strong">ExecutorService</emphasis></primary><secondary>checkMail example</secondary></indexterm><indexterm id="iddle2355" significance="normal"><?indexkey F?><?primarykey final?><?secondarykey VOLATILE VS?><primary><emphasis role="strong">final</emphasis></primary><secondary><literal>volatile</literal> vs</secondary></indexterm><indexterm id="iddle2760" significance="normal"><?indexkey I?><?primarykey instrumentation?><?secondarykey SERVICE SHUTDOWN USE?><primary><emphasis role="strong">instrumentation</emphasis></primary><secondary>service shutdown use</secondary></indexterm><indexterm id="iddle4249" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey ABRUPT?><?tertiarykey LIMITATIONS?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>abrupt</secondary><tertiary>limitations</tertiary></indexterm><indexterm id="iddle4270" significance="normal"><?indexkey S?><?primarykey shutdownNow?><?secondarykey LIMITATIONS?><primary><emphasis role="strong">shutdownNow</emphasis></primary><secondary>limitations</secondary></indexterm><indexterm id="iddle4426" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey TASK?><?tertiarykey INTERMEDIATE, SHUTDOWN ISSUES?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>task</secondary><tertiary>intermediate, shutdown issues</tertiary></indexterm><indexterm id="iddle4449" significance="normal"><?indexkey S?><?primarykey status?><?secondarykey THREAD?><primary><emphasis role="strong">status</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle4450" significance="normal"><?indexkey S?><?primarykey status?><?secondarykey THREAD?><?tertiarykey SHUTDOWN ISSUES?><primary><emphasis role="strong">status</emphasis></primary><secondary>thread</secondary><tertiary>shutdown issues</tertiary></indexterm><indexterm id="iddle4656" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey STATE?><?tertiarykey INTERMEDIATE, SHUTDOWN ISSUES?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>state</secondary><tertiary>intermediate, shutdown issues</tertiary></indexterm><indexterm id="iddle4780" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey INTERRUPTION?><?tertiarykey SHUTDOWN ISSUES?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>interruption</secondary><tertiary>shutdown issues</tertiary></indexterm><indexterm id="iddle5118" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey FINAL VS?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>final vs</secondary></indexterm>the mail-checking tasks have completed.<footnote id="ch07fn04" label="4"><para>The reason an <literal>AtomicBoolean</literal> is used instead of a <literal>volatile boolean</literal> is that in order to access the <literal>hasNewMail</literal> flag from the inner <literal>Runnable</literal>, it would have to be <literal>final</literal>, which would preclude modifying it.</para></footnote></para>
<example id="ch07list18" label="7.18" role="Listing" xreflabel="7.18" condition="157">
<?docpage num="157"?>
<title id="ch07list18__title">Producer Thread for <literal>IndexingService</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class CrawlerThread extends Thread {
    public void run() {
        try {
            <emphasis role="strong">crawl(root);</emphasis>
        } catch (InterruptedException e) { <emphasis>/*  fall through  */</emphasis>  }
        finally {
            while (true) {
                try {
                    <emphasis role="strong">queue.put(POISON);</emphasis>
                    break;
                } catch (InterruptedException e1) { <emphasis>/*  retry  */</emphasis> }
            }
        }
    }

    private void crawl(File root) throws InterruptedException {
        ...
    }
}
</programlisting>
</example>
<example id="ch07list19" label="7.19" role="Listing" xreflabel="7.19" condition="157">
<?docpage num="157"?>
<title id="ch07list19__title">Consumer Thread for <literal>IndexingService</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class IndexerThread extends Thread {
    public void run() {
        try {
            while (true) {
                File file = queue.take();
                <emphasis role="strong">if (file == POISON)</emphasis>
                   <emphasis role="strong">break;</emphasis>
                else
                   indexFile(file);
            }
        } catch (InterruptedException consumed) { }
    }
}
</programlisting>
</example>
<example id="ch07list20" label="7.20" role="Listing" xreflabel="7.20" condition="158">
<title id="ch07list20__title">Using a Private <literal>Executor</literal> Whose Lifetime is Bounded by a Method Call.</title>
<programlisting format="linespecific" linenumbering="unnumbered">boolean checkMail(Set&lt;String&gt; hosts, long timeout, TimeUnit unit)
        throws InterruptedException {
    ExecutorService exec = Executors.newCachedThreadPool();
    final AtomicBoolean hasNewMail = new AtomicBoolean(false);
    try {
        for (final String host : hosts)
            exec.execute(new Runnable() {
                public void run() {
                   if (checkMail(host))
                       hasNewMail.set(true);
                }
            });
    } finally {
        exec.shutdown();
        exec.awaitTermination(timeout, unit);
    }
    return hasNewMail.get();
}
</programlisting>
</example>
</section>
<section id="ch07lev2sec12" label="7.2.5" xreflabel="7.2.5">
<title id="ch07lev2sec12__title">Limitations of <literal>Shutdownnow</literal></title>
<para>When an <literal>ExecutorService</literal> is shut down abruptly with <literal>shutdownNow</literal>, it attempts to cancel the tasks currently in progress and returns a list of tasks that were submitted but never started so that they can be logged or saved for later processing.<footnote id="ch07fn05" label="5"><para>The <literal>Runnable</literal> objects returned by <literal>shutdownNow</literal> might not be the same objects that were submitted to the <literal>ExecutorService</literal>: they might be <emphasis>wrapped</emphasis> instances of the submitted tasks.</para></footnote></para>
<para>However, there is no general way to find out which tasks started but did not complete. This means that there is no way of knowing the state of the tasks in progress at shutdown time unless the tasks themselves perform some sort of checkpointing. To know which tasks have not completed, you need to know not only which tasks didn’t start, but also which tasks were in progress when the executor was shut down.<footnote id="ch07fn06" label="6"><para>Unfortunately, there is no shutdown option in which tasks not yet started are returned to the caller but tasks in progress are allowed to complete; such an option would eliminate this uncertain intermediate state.</para></footnote></para>
<para><literal>TrackingExecutor</literal> in <link linkend="ch07list21" preference="0">Listing 7.21</link> shows a technique for determining which tasks were in progress at shutdown time. By encapsulating an <literal>ExecutorService</literal> and instrumenting <literal>execute</literal> (and similarly <literal>submit</literal>, not shown) to remember <?docpage num="159"?><?docpage num="160"?><indexterm id="iddle2207" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey TRACKINGEXECUTORSERVICE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>TrackingExecutorService</literal></secondary></indexterm><indexterm id="iddle5153" significance="normal"><?indexkey W?><?primarykey web crawler example?><primary><emphasis role="strong">web crawler example</emphasis></primary></indexterm>which tasks were cancelled after shutdown, <literal>TrackingExecutor</literal> can identify which tasks started but did not complete normally. After the executor terminates, <literal>getCancelledTasks</literal> returns the list of cancelled tasks. In order for this technique to work, the tasks must preserve the thread’s interrupted status when they return, which well behaved tasks will do anyway.</para>
<example id="ch07list21" label="7.21" role="Listing" xreflabel="7.21" condition="159">
<title id="ch07list21__title"><literal>ExecutorService</literal> that Keeps Track of Cancelled Tasks After Shutdown.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class TrackingExecutor extends AbstractExecutorService {
    private final ExecutorService exec;
    private final Set&lt;Runnable&gt; tasksCancelledAtShutdown =
        Collections.synchronizedSet(new HashSet&lt;Runnable&gt;());
    ...
    public List&lt;Runnable&gt; getCancelledTasks() {
        if (!exec.isTerminated())
            throw new IllegalStateException(...);
        return new ArrayList&lt;Runnable&gt;(tasksCancelledAtShutdown);
    }

    public void execute(final Runnable runnable) {
        exec.execute(new Runnable() {
            public void run() {
                try {
                    runnable.run();
                } finally {
                    if (isShutdown()
                        &amp;&amp; Thread.currentThread().isInterrupted())
                        tasksCancelledAtShutdown.add(runnable);
                }
            }
        });
    }

    <emphasis>// delegate other ExecutorService methods to exec</emphasis>
}
</programlisting>
</example>
<para><literal>WebCrawler</literal> in <link linkend="ch07list22" preference="0">Listing 7.22</link> shows an application of <literal>TrackingExecutor</literal>. The work of a web crawler is often unbounded, so if a crawler must be shut down we might want to save its state so it can be restarted later. <literal>CrawlTask</literal> provides a <literal>getPage</literal> method that identifies what page it is working on. When the crawler is shut down, both the tasks that did not start and those that were cancelled are scanned and their URLs recorded, so that page-crawling tasks for those URLs can be added to the queue when the crawler restarts.</para>
<para><literal>TrackingExecutor</literal> has an unavoidable race condition that could make it yield false positives: tasks that are identified as cancelled but actually completed. This <?docpage num="161"?><indexterm id="iddle2217" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey WEBCRAWLER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>WebCrawler</literal></secondary></indexterm><indexterm id="iddle1004" significance="normal"><?indexkey A?><?primarykey abnormal thread termination?><primary><emphasis role="strong">abnormal thread termination</emphasis></primary></indexterm><indexterm id="iddle1005" significance="normal"><?indexkey A?><?primarykey abnormal thread termination?><?secondarykey HANDLING?><primary><emphasis role="strong">abnormal thread termination</emphasis></primary><secondary>handling</secondary></indexterm><indexterm id="iddle1821" significance="normal"><?indexkey D?><?primarykey death, thread?><primary><emphasis role="strong">death, thread</emphasis></primary></indexterm><indexterm id="iddle1822" significance="normal"><?indexkey D?><?primarykey death, thread?><?secondarykey ABNORMAL, HANDLING?><primary><emphasis role="strong">death, thread</emphasis></primary><secondary>abnormal, handling</secondary></indexterm><indexterm id="iddle2152" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey OUTOFTIME?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>OutOfTime</literal></secondary></indexterm><indexterm id="iddle2236" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey UNCHECKED?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>unchecked</secondary></indexterm><indexterm id="iddle2237" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey UNCHECKED?><?tertiarykey CATCHING, DISADVANTAGES?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>unchecked</secondary><tertiary>catching, disadvantages</tertiary></indexterm><indexterm id="iddle2685" significance="normal"><?indexkey I?><?primarykey idempotence?><primary><emphasis role="strong">idempotence</emphasis></primary></indexterm><indexterm id="iddle2686" significance="normal"><?indexkey I?><?primarykey idempotence?><?secondarykey AND RACE CONDITION MITIGATION?><primary><emphasis role="strong">idempotence</emphasis></primary><secondary>and race condition mitigation</secondary></indexterm><indexterm id="iddle2953" significance="normal"><?indexkey L?><?primarykey leakage?><?secondarykey THREAD?><primary><emphasis role="strong">leakage</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle3784" significance="normal"><?indexkey R?><?primarykey race conditions?><?secondarykey IN WEB CRAWLER EXAMPLE?><primary><emphasis role="strong">race conditions</emphasis></primary><secondary>in web crawler example</secondary></indexterm><indexterm id="iddle3785" significance="normal"><?indexkey R?><?primarykey race conditions?><?secondarykey IN WEB CRAWLER EXAMPLE?><?tertiarykey IDEMPOTENCE AS MITIGATING CIRCUMSTANCE?><primary><emphasis role="strong">race conditions</emphasis></primary><secondary>in web crawler example</secondary><tertiary>idempotence as mitigating circumstance</tertiary></indexterm><indexterm id="iddle4023" significance="normal"><?indexkey R?><?primarykey RuntimeException?><primary><emphasis role="strong">RuntimeException</emphasis></primary></indexterm><indexterm id="iddle4024" significance="normal"><?indexkey R?><?primarykey RuntimeException?><?secondarykey AS THREAD DEATH CAUSE?><primary><emphasis role="strong">RuntimeException</emphasis></primary><secondary>as thread death cause</secondary></indexterm><indexterm id="iddle4026" significance="normal"><?indexkey R?><?primarykey RuntimeException?><?secondarykey CATCHING?><primary><emphasis role="strong">RuntimeException</emphasis></primary><secondary>catching</secondary></indexterm><indexterm id="iddle4027" significance="normal"><?indexkey R?><?primarykey RuntimeException?><?secondarykey CATCHING?><?tertiarykey DISADVANTAGES OF?><primary><emphasis role="strong">RuntimeException</emphasis></primary><secondary>catching</secondary><tertiary>disadvantages of</tertiary></indexterm><indexterm id="iddle4050" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey UNTRUSTED CODE BEHAVIOR?><primary><emphasis role="strong">safety</emphasis></primary><secondary>untrusted code behavior</secondary></indexterm><indexterm id="iddle4051" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey UNTRUSTED CODE BEHAVIOR?><?tertiarykey PROTECTION MECHANISMS?><primary><emphasis role="strong">safety</emphasis></primary><secondary>untrusted code behavior</secondary><tertiary>protection mechanisms</tertiary></indexterm><indexterm id="iddle4681" significance="normal"><?indexkey T?><?primarykey termination?><?secondarykey THREAD?><primary><emphasis role="strong">termination</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle4682" significance="normal"><?indexkey T?><?primarykey termination?><?secondarykey THREAD?><?tertiarykey ABNORMAL, HANDLING?><primary><emphasis role="strong">termination</emphasis></primary><secondary>thread</secondary><tertiary>abnormal, handling</tertiary></indexterm><indexterm id="iddle4744" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey ABNORMAL TERMINATION OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>abnormal termination of</secondary></indexterm><indexterm id="iddle4782" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey LEAKAGE?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>leakage</secondary></indexterm><indexterm id="iddle4978" significance="normal"><?indexkey T?><?primarykey try-catch block?><?secondarykey AS PROTECTION AGAINST UNTRUSTED CODE BEHAVIOR?><primary><emphasis role="strong">try-catch block</emphasis></primary><secondary>as protection against untrusted code behavior</secondary></indexterm><indexterm id="iddle4981" significance="normal"><?indexkey T?><?primarykey try-finally block?><?secondarykey AS PROTECTION AGAINST UNTRUSTED CODE BEHAVIOR?><primary><emphasis role="strong">try-finally block</emphasis></primary><secondary>as protection against untrusted code behavior</secondary></indexterm><indexterm id="iddle5004" significance="normal"><?indexkey U?><?primarykey unchecked exceptions?><?secondarykey CATCHING?><primary><emphasis role="strong">unchecked exceptions</emphasis></primary><secondary>catching</secondary></indexterm><indexterm id="iddle5005" significance="normal"><?indexkey U?><?primarykey unchecked exceptions?><?secondarykey CATCHING?><?tertiarykey DISADVANTAGES OF?><primary><emphasis role="strong">unchecked exceptions</emphasis></primary><secondary>catching</secondary><tertiary>disadvantages of</tertiary></indexterm><indexterm id="iddle5013" significance="normal"><?indexkey U?><?primarykey untrusted code behavior?><?secondarykey PROTECTION MECHANISMS?><primary><emphasis role="strong">untrusted code behavior</emphasis></primary><secondary>protection mechanisms</secondary></indexterm>arises because the thread pool could be shut down between when the last instruction of the task executes and when the pool records the task as complete. This is not a problem if tasks are <emphasis>idempotent</emphasis> (if performing them twice has the same effect as performing them once), as they typically are in a web crawler. Otherwise, the application retrieving the cancelled tasks must be aware of this risk and be prepared to deal with false positives.</para>
<example id="ch07list22" label="7.22" role="Listing" xreflabel="7.22" condition="160">
<?docpage num="160"?>
<title id="ch07list22__title">Using <literal>TrackingExecutorService</literal> to Save Unfinished Tasks for Later Execution.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public abstract class WebCrawler {
    private volatile TrackingExecutor exec;
    @GuardedBy("this")
    private final Set&lt;URL&gt; urlsToCrawl = new HashSet&lt;URL&gt;();
    ...
    public synchronized void start() {
        exec = new TrackingExecutor(
                Executors.newCachedThreadPool());
        for (URL url : urlsToCrawl) submitCrawlTask(url);
        urlsToCrawl.clear();
    }

    public synchronized void stop() throws InterruptedException {
        try {
            saveUncrawled(<emphasis role="strong">exec.shutdownNow()</emphasis>);
            if (<emphasis role="strong">exec.awaitTermination(TIMEOUT, UNIT)</emphasis>)
                saveUncrawled(exec.getCancelledTasks());
        } finally {
            exec = null;
        }
    }

    protected abstract List&lt;URL&gt; processPage(URL url);

    private void saveUncrawled(List&lt;Runnable&gt; uncrawled) {
        for (Runnable task : uncrawled)
            urlsToCrawl.add(((CrawlTask) task).getPage());
    }
    private void submitCrawlTask(URL u) {
        exec.execute(new CrawlTask(u));
    }
    private class CrawlTask implements Runnable {
        private final URL url;
        ...
        public void run() {
            for (URL link : processPage(url)) {
                if (Thread.currentThread().isInterrupted())
                    return;
                submitCrawlTask(link);
            }
        }
        public URL getPage() { return url; }
    }
}
</programlisting>
</example>
</section>
</section>
<section id="ch07lev1sec3" condition="161" label="7.3" xreflabel="7.3"><?docpage num="161"?>
<title id="ch07lev1sec3__title">Handling Abnormal Thread Termination</title>
<para>It is obvious when a single-threaded console application terminates due to an uncaught exception—the program stops running and produces a stack trace that is very different from typical program output. Failure of a thread in a concurrent application is not always so obvious. The stack trace may be printed on the console, but no one may be watching the console. Also, when a thread fails, the application may appear to continue to work, so its failure could go unnoticed. Fortunately, there are means of both detecting and preventing threads from “leaking” from an application.</para>
<para>The leading cause of premature thread death is <literal>RuntimeException</literal>. Because these exceptions indicate a programming error or other unrecoverable problem, they are generally not caught. Instead they propagate all the way up the stack, at which point the default behavior is to print a stack trace on the console and let the thread terminate.</para>
<para>The consequences of abnormal thread death range from benign to disastrous, depending on the thread’s role in the application. Losing a thread from a thread pool can have performance consequences, but an application that runs well with a 50-thread pool will probably run fine with a 49-thread pool too. But losing the event dispatch thread in a GUI application would be quite noticeable—the application would stop processing events and the GUI would freeze. <literal>OutOfTime</literal> on <link linkend="ch06list09" preference="0" role="pageref">124</link> showed a serious consequence of thread leakage: the service represented by the <literal>Timer</literal> is permanently out of commission.</para>
<para>Just about any code can throw a <literal>RuntimeException</literal>. Whenever you call another method, you are taking a leap of faith that it will return normally or throw one of the checked exceptions its signature declares. The less familiar you are with the code being called, the more skeptical you should be about its behavior.</para>
<para>Task-processing threads such as the worker threads in a thread pool or the Swing event dispatch thread spend their whole life calling unknown code through an abstraction barrier like <literal>Runnable</literal>, and these threads should be very skeptical that the code they call will be well behaved. It would be very bad if a service like the Swing event thread failed just because some poorly written event handler threw a <literal>NullPointerException</literal>. Accordingly, these facilities should call tasks within a <literal>try-catch</literal> block that catches unchecked exceptions, or within a <literal>try-finally</literal> block to ensure that if the thread exits abnormally the framework is informed of this and can take corrective action. This is one of the few times when you might want to consider catching <literal>RuntimeException</literal>—when you are calling unknown, untrusted code through an abstraction such as <literal>Runnable</literal>.<footnote id="ch07fn07" label="7"><para>There is some controversy over the safety of this technique; when a thread throws an unchecked <?docpage num="162"?><indexterm id="iddle2235" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey UNCAUGHT EXCEPTION HANDLER?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>uncaught exception handler</secondary></indexterm><indexterm id="iddle2315" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey THREAD?><primary><emphasis role="strong">failure</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle2316" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey THREAD?><?tertiarykey UNCAUGHT EXCEPTION HANDLERS?><primary><emphasis role="strong">failure</emphasis></primary><secondary>thread</secondary><tertiary>uncaught exception handlers</tertiary></indexterm><indexterm id="iddle2929" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey UNCAUGHT EXCEPTION HANDLING?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>uncaught exception handling</secondary></indexterm><indexterm id="iddle2955" significance="normal"><?indexkey L?><?primarykey leakage?><?secondarykey THREAD?><?tertiarykey UNCAUGHTEXCEPTIONHANDLER PREVENTION OF?><primary><emphasis role="strong">leakage</emphasis></primary><secondary>thread</secondary><tertiary><literal>UncaughtExceptionHandler</literal> prevention of</tertiary></indexterm><indexterm id="iddle4529" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey UNTRUSTED CODE PROTECTION MECHANISMS IN?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>untrusted code protection mechanisms in</secondary></indexterm><indexterm id="iddle4773" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey FAILURE?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>failure</secondary></indexterm><indexterm id="iddle4774" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey FAILURE?><?tertiarykey UNCAUGHT EXCEPTION HANDLERS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>failure</secondary><tertiary>uncaught exception handlers</tertiary></indexterm><indexterm id="iddle4785" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey LEAKAGE?><?tertiarykey UNCAUGHTEXCEPTIONHANDLER PREVENTION OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>leakage</secondary><tertiary><literal>UncaughtExceptionHandler</literal> prevention of</tertiary></indexterm><indexterm id="iddle4853" significance="normal"><?indexkey T?><?primarykey ThreadPoolExecutor?><primary><emphasis role="strong">ThreadPoolExecutor</emphasis></primary></indexterm><indexterm id="iddle4854" significance="normal"><?indexkey T?><?primarykey ThreadPoolExecutor?><?secondarykey AND UNTRUSTED CODE?><primary><emphasis role="strong">ThreadPoolExecutor</emphasis></primary><secondary>and untrusted code</secondary></indexterm><indexterm id="iddle4999" significance="normal"><?indexkey U?><?primarykey uncaught exception handlers?><primary><emphasis role="strong">uncaught exception handlers</emphasis></primary><seealso> <link linkend="iddle3167" preference="0"><emphasis role="strong">logging</emphasis>, exceptions</link>.</seealso></indexterm><indexterm id="iddle5002" significance="normal"><?indexkey U?><?primarykey UncaughtExceptionHandler?><?secondarykey THREAD LEAKAGE DETECTION?><primary><emphasis role="strong">UncaughtExceptionHandler</emphasis></primary><secondary>thread leakage detection</secondary></indexterm>exception, the entire application may possibly be compromised. But the alternative—shutting down the entire application—is usually not practical.</para></footnote></para>
<para><?docpage num="162"?><link linkend="ch07list23" preference="0">Listing 7.23</link> illustrates a way to structure a worker thread within a thread pool. If a task throws an unchecked exception, it allows the thread to die, but not before notifying the framework that the thread has died. The framework may then replace the worker thread with a new thread, or may choose not to because the thread pool is being shut down or there are already enough worker threads to meet current demand. <literal>ThreadPoolExecutor</literal> and Swing use this technique to ensure that a poorly behaved task doesn’t prevent subsequent tasks from executing. If you are writing a worker thread class that executes submitted tasks, or calling untrusted external code (such as dynamically loaded plugins), use one of these approaches to prevent a poorly written task or plugin from taking down the thread that happens to call it.</para>
<example id="ch07list23" label="7.23" role="Listing" xreflabel="7.23" condition="162">
<title id="ch07list23__title">Typical Thread-pool Worker Thread Structure.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public void run() {
    Throwable thrown = null;
    try {
        while (!isInterrupted())
            runTask(getTaskFromWorkQueue());
    } catch (Throwable e) {
        thrown = e;
    } finally {
        threadExited(this, thrown);
    }
}
</programlisting>
</example>
<section id="ch07lev2sec13" label="7.3.1" xreflabel="7.3.1">
<title id="ch07lev2sec13__title">Uncaught Exception Handlers</title>
<para>The previous section offered a proactive approach to the problem of unchecked exceptions. The Thread API also provides the <literal>UncaughtExceptionHandler</literal> facility, which lets you detect when a thread dies due to an uncaught exception. The two approaches are complementary: taken together, they provide defense-indepth against thread leakage.</para>
<para>When a thread exits due to an uncaught exception, the JVM reports this event to an application-provided <literal>UncaughtExceptionHandler</literal> (see <link linkend="ch07list24" preference="0">Listing 7.24</link>); if no handler exists, the default behavior is to print the stack trace to <literal>System.err</literal>.<footnote id="ch07fn08" label="8"><para>Before Java 5.0, the only way to control the <literal>UncaughtExceptionHandler</literal> was by subclassing <literal>ThreadGroup</literal>. In Java 5.0 and later, you can set an <literal>UncaughtExceptionHandler</literal> on a per-thread basis with <literal>Thread.setUncaughtExceptionHandler</literal>, and can also set the default <literal>UncaughtExceptionHandler</literal> with <literal>Thread.setDefaultUncaughtExceptionHandler</literal>. However, only one of these handlers is called—first the JVM looks for a per-thread handler, then for a <literal>ThreadGroup</literal> handler. The default handler implementation in <literal>ThreadGroup</literal> delegates to its parent thread group, and so on up the chain until one of the <literal>ThreadGroup</literal> handlers deals with the uncaught exception or it bubbles up to the toplevel thread group. The top-level thread group handler delegates to the default system handler (if one exists; the default is none) and otherwise prints the stack trace to the console.</para></footnote></para>

<para><?docpage num="163"?></para><example id="ch07list24" label="7.24" role="Listing" xreflabel="7.24" condition="163">

<title id="ch07list24__title"><literal>UncaughtExceptionHandler</literal> Interface.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface UncaughtExceptionHandler {
    void uncaughtException(Thread t, Throwable e);
}
</programlisting>
</example>
<para><indexterm id="iddle2208" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey UEHLOGGER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>UEHLogger</literal></secondary></indexterm><indexterm id="iddle2231" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey LOGGING?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>logging</secondary></indexterm><indexterm id="iddle2232" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey LOGGING?><?tertiarykey UEHLOGGER EXAMPLE?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>logging</secondary><tertiary><literal>UEHLogger</literal> example</tertiary></indexterm><indexterm id="iddle2241" significance="normal"><?indexkey E?><?primarykey execute?><primary><emphasis role="strong">execute</emphasis></primary></indexterm><indexterm id="iddle2242" significance="normal"><?indexkey E?><?primarykey execute?><?secondarykey SUBMIT VS., UNCAUGHT EXCEPTION HANDLING?><primary><emphasis role="strong">execute</emphasis></primary><secondary><literal>submit</literal> vs., uncaught exception handling</secondary></indexterm><indexterm id="iddle2523" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey EXCEPTION HANDLING?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>exception handling</secondary></indexterm><indexterm id="iddle3167" significance="normal"><?indexkey L?><?primarykey logging?><?secondarykey EXCEPTIONS?><primary><emphasis role="strong">logging</emphasis></primary><secondary>exceptions</secondary></indexterm><indexterm id="iddle3168" significance="normal"><?indexkey L?><?primarykey logging?><?secondarykey EXCEPTIONS?><?tertiarykey UEHLOGGER EXAMPLE?><primary><emphasis role="strong">logging</emphasis></primary><secondary>exceptions</secondary><tertiary><literal>UEHLogger</literal> example</tertiary></indexterm><indexterm id="iddle3632" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey UNCAUGHT EXCEPTION HANDLING?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>uncaught exception handling</tertiary></indexterm><indexterm id="iddle4508" significance="normal"><?indexkey S?><?primarykey submit, execute vs.?><primary><emphasis role="strong">submit, execute vs.</emphasis></primary></indexterm><indexterm id="iddle4509" significance="normal"><?indexkey S?><?primarykey submit, execute vs.?><?secondarykey UNCAUGHT EXCEPTION HANDLING?><primary><emphasis role="strong">submit, execute vs.</emphasis></primary><secondary>uncaught exception handling</secondary></indexterm><indexterm id="iddle4980" significance="normal"><?indexkey T?><?primarykey try-finally block?><?secondarykey AND UNCAUGHT EXCEPTIONS?><primary><emphasis role="strong">try-finally block</emphasis></primary><secondary>and uncaught exceptions</secondary></indexterm><indexterm id="iddle5000" significance="normal"><?indexkey U?><?primarykey UncaughtExceptionHandler?><primary><emphasis role="strong">UncaughtExceptionHandler</emphasis></primary></indexterm>What the handler should do with an uncaught exception depends on your quality-of-service requirements. The most common response is to write an error message and stack trace to the application log, as shown in <link linkend="ch07list25" preference="0">Listing 7.25</link>. Handlers can also take more direct action, such as trying to restart the thread, shutting down the application, paging an operator, or other corrective or diagnostic action.</para>
<example id="ch07list25" label="7.25" role="Listing" xreflabel="7.25" condition="163">
<title id="ch07list25__title"><literal>UncaughtExceptionHandler</literal> that Logs the Exception.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class UEHLogger implements Thread.UncaughtExceptionHandler {
    public void uncaughtException(Thread t, Throwable e) {
        Logger logger = Logger.getAnonymousLogger();
        logger.log(Level.SEVERE,
              "Thread terminated with exception: " + t.getName(),
              e);
    }
}
</programlisting>
</example>
<sidebar float="1" id="ch07sb08" condition="163"><title/>
<para>In long-running applications, always use uncaught exception handlers for all threads that at least log the exception.</para>
</sidebar>
<para>To set an <literal>UncaughtExceptionHandler</literal> for pool threads, provide a <literal>ThreadFactory</literal> to the <literal>ThreadPoolExecutor</literal> constructor. (As with all thread manipulation, only the thread’s owner should change its <literal>UncaughtExceptionHandler</literal>.) The standard thread pools allow an uncaught task exception to terminate the pool thread, but use a <literal>try-finally</literal> block to be notified when this happens so the thread can be replaced. Without an uncaught exception handler or other failure notification mechanism, tasks can appear to fail silently, which can be very confusing. If you want to be notified when a task fails due to an exception so that you can take some task-specific recovery action, either wrap the task with a <literal>Runnable</literal> or <literal>Callable</literal> that catches the exception or override the <literal>afterExecute</literal> hook in <literal>ThreadPoolExecutor</literal>.</para>
<para>Somewhat confusingly, exceptions thrown from tasks make it to the uncaught exception handler only for tasks submitted with <literal>execute</literal>; for tasks submitted with <literal>submit</literal>, <emphasis>any</emphasis> thrown exception, checked or not, is considered to be part of the task’s return status. If a task submitted with <literal>submit</literal> terminates with an exception, it is rethrown by <literal>Future.get</literal>, wrapped in an <literal>ExecutionException</literal>.</para>
</section>
</section>
<section id="ch07lev1sec4" condition="164" label="7.4" xreflabel="7.4">
<?docpage num="164"?>
<title id="ch07lev1sec4__title">JVM Shutdown</title>
<para><indexterm id="iddle1010" significance="normal"><?indexkey A?><?primarykey abrupt shutdown?><?secondarykey TRIGGERS FOR?><primary><emphasis role="strong">abrupt shutdown</emphasis></primary><secondary>triggers for</secondary></indexterm><indexterm id="iddle1355" significance="normal"><?indexkey C?><?primarykey cleanup?><?secondarykey JVM SHUTDOWN HOOKS USE FOR?><primary><emphasis role="strong">cleanup</emphasis></primary><secondary>JVM shutdown hooks use for</secondary></indexterm><indexterm id="iddle2356" significance="normal"><?indexkey F?><?primarykey finalizers?><primary><emphasis role="strong">finalizers</emphasis></primary></indexterm><indexterm id="iddle2357" significance="normal"><?indexkey F?><?primarykey finalizers?><?secondarykey JVM ORDERLY SHUTDOWN USE?><primary><emphasis role="strong">finalizers</emphasis></primary><secondary>JVM orderly shutdown use</secondary></indexterm><indexterm id="iddle2648" significance="normal"><?indexkey H?><?primarykey hooks?><?secondarykey SHUTDOWN?><primary><emphasis role="strong">hooks</emphasis></primary><secondary>shutdown</secondary></indexterm><indexterm id="iddle2649" significance="normal"><?indexkey H?><?primarykey hooks?><?secondarykey SHUTDOWN?><?tertiarykey JVM ORDERLY SHUTDOWN?><primary><emphasis role="strong">hooks</emphasis></primary><secondary>shutdown</secondary><tertiary>JVM orderly shutdown</tertiary></indexterm><indexterm id="iddle2650" significance="normal"><?indexkey H?><?primarykey hooks?><?secondarykey SINGLE SHUTDOWN?><primary><emphasis role="strong">hooks</emphasis></primary><secondary>single shutdown</secondary></indexterm><indexterm id="iddle2651" significance="normal"><?indexkey H?><?primarykey hooks?><?secondarykey SINGLE SHUTDOWN?><?tertiarykey ORDERLY SHUTDOWN STRATEGY?><primary><emphasis role="strong">hooks</emphasis></primary><secondary>single shutdown</secondary><tertiary>orderly shutdown strategy</tertiary></indexterm><indexterm id="iddle2922" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey SHUTDOWN?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>shutdown</secondary></indexterm><indexterm id="iddle2924" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey SHUTDOWN?><?tertiarykey ORDERLY SHUTDOWN?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>shutdown</secondary><tertiary>orderly shutdown</tertiary></indexterm><indexterm id="iddle3419" significance="normal"><?indexkey O?><?primarykey orderly shutdown?><primary><emphasis role="strong">orderly shutdown</emphasis></primary></indexterm><indexterm id="iddle4166" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey ORDERLY SHUTDOWN STRATEGY?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>orderly shutdown strategy</secondary></indexterm><indexterm id="iddle4247" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey ABRUPT?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>abrupt</secondary></indexterm><indexterm id="iddle4248" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey ABRUPT?><?tertiarykey JVM, TRIGGERS FOR?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>abrupt</secondary><tertiary>JVM, triggers for</tertiary></indexterm><indexterm id="iddle4254" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey HOOKS?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>hooks</secondary></indexterm><indexterm id="iddle4255" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey HOOKS?><?tertiarykey IN ORDERLY SHUTDOWN?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>hooks</secondary><tertiary>in orderly shutdown</tertiary></indexterm><indexterm id="iddle4256" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey JVM?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>JVM</secondary></indexterm><indexterm id="iddle4259" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey ORDERLY?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>orderly</secondary></indexterm><indexterm id="iddle4293" significance="normal"><?indexkey S?><?primarykey single shutdown hook?><?secondarykey ORDERLY SHUTDOWN STRATEGY?><primary><emphasis role="strong">single shutdown hook</emphasis></primary><secondary>orderly shutdown strategy</secondary></indexterm><indexterm id="iddle4731" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey AND SHUTDOWN HOOKS?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>and shutdown hooks</secondary></indexterm><indexterm id="iddle4975" significance="normal"><?indexkey T?><?primarykey trigger(ing)?><?secondarykey JVM ABRUPT SHUTDOWN?><primary><emphasis role="strong">trigger(ing)</emphasis></primary><secondary>JVM abrupt shutdown</secondary></indexterm>The JVM can shut down in either an <emphasis>orderly</emphasis> or <emphasis>abrupt</emphasis> manner. An orderly shutdown is initiated when the last “normal” (nondaemon) thread terminates, someone calls <literal>System.exit</literal>, or by other platform-specific means (such as sending a <literal>SIGINT</literal> or hitting <literal>Ctrl-C</literal>). While this is the standard and preferred way for the JVM to shut down, it can also be shut down abruptly by calling <literal>Runtime.halt</literal> or by killing the JVM process through the operating system (such as sending a <literal>SIGKILL</literal>).</para>
<section id="ch07lev2sec14" label="7.4.1" xreflabel="7.4.1">
<title id="ch07lev2sec14__title">Shutdown Hooks</title>
<para>In an orderly shutdown, the JVM first starts all registered <emphasis>shutdown hooks</emphasis>. Shutdown hooks are unstarted threads that are registered with <literal>Runtime.addShutdownHook</literal>. The JVM makes no guarantees on the order in which shutdown hooks are started. If any application threads (daemon or nondaemon) are still running at shutdown time, they continue to run concurrently with the shutdown process. When all shutdown hooks have completed, the JVM may choose to run finalizers if <literal>runFinalizersOnExit</literal> is <literal>true</literal>, and then halts. The JVM makes no attempt to stop or interrupt any application threads that are still running at shutdown time; they are abruptly terminated when the JVM eventually halts. If the shutdown hooks or finalizers don’t complete, then the orderly shutdown process “hangs” and the JVM must be shut down abruptly. In an abrupt shutdown, the JVM is not required to do anything other than halt the JVM; shutdown hooks will not run.</para>
<para>Shutdown hooks should be thread-safe: they must use synchronization when accessing shared data and should be careful to avoid deadlock, just like any other concurrent code. Further, they should not make assumptions about the state of the application (such as whether other services have shut down already or all normal threads have completed) or about why the JVM is shutting down, and must therefore be coded extremely defensively. Finally, they should exit as quickly as possible, since their existence delays JVM termination at a time when the user may be expecting the JVM to terminate quickly.</para>
<para>Shutdown hooks can be used for service or application cleanup, such as deleting temporary files or cleaning up resources that are not automatically cleaned up by the OS. <link linkend="ch07list26" preference="0">Listing 7.26</link> shows how <literal>LogService</literal> in <link linkend="ch07list16" preference="0">Listing 7.16</link> could register a shutdown hook from its <literal>start</literal> method to ensure the log file is closed on exit.</para>
<para>Because shutdown hooks all run concurrently, closing the log file could cause trouble for other shutdown hooks who want to use the logger. To avoid this problem, shutdown hooks should not rely on services that can be shut down by the application or other shutdown hooks. One way to accomplish this is to use a single shutdown hook for all services, rather than one for each service, and have it call a series of shutdown actions. This ensures that shutdown actions execute sequentially in a single thread, thus avoiding the possibility of race conditions or deadlock between shutdown actions. This technique can be used whether or not you use shutdown hooks; executing shutdown actions sequentially rather than concurrently eliminates many potential sources of failure. In applications <?docpage num="165"?><indexterm id="iddle1745" significance="normal"><?indexkey D?><?primarykey daemon threads?><primary><emphasis role="strong">daemon threads</emphasis></primary></indexterm><indexterm id="iddle2358" significance="normal"><?indexkey F?><?primarykey finalizers?><?secondarykey WARNINGS?><primary><emphasis role="strong">finalizers</emphasis></primary><secondary>warnings</secondary></indexterm><indexterm id="iddle2603" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey THREADS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>threads</secondary></indexterm><indexterm id="iddle2604" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey THREADS?><?tertiarykey DAEMON THREAD PRECAUTIONS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>threads</secondary><tertiary>daemon thread precautions</tertiary></indexterm><indexterm id="iddle2923" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey SHUTDOWN?><?tertiarykey AND DAEMON THREADS?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>shutdown</secondary><tertiary>and daemon threads</tertiary></indexterm><indexterm id="iddle3293" significance="normal"><?indexkey N?><?primarykey native code?><primary><emphasis role="strong">native code</emphasis></primary></indexterm><indexterm id="iddle3294" significance="normal"><?indexkey N?><?primarykey native code?><?secondarykey FINALIZER USE AND LIMITATIONS?><primary><emphasis role="strong">native code</emphasis></primary><secondary>finalizer use and limitations</secondary></indexterm><indexterm id="iddle3922" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey FINALIZER USE AND LIMITATIONS?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>finalizer use and limitations</tertiary></indexterm><indexterm id="iddle4257" significance="normal"><?indexkey S?><?primarykey shutdown?><?secondarykey JVM?><?tertiarykey AND DAEMON THREADS?><primary><emphasis role="strong">shutdown</emphasis></primary><secondary>JVM</secondary><tertiary>and daemon threads</tertiary></indexterm><indexterm id="iddle4766" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey DAEMON?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>daemon</secondary></indexterm>that maintain explicit dependency information among services, this technique can also ensure that shutdown actions are performed in the right order.</para>
<example id="ch07list26" label="7.26" role="Listing" xreflabel="7.26" condition="165">
<title id="ch07list26__title">Registering a Shutdown Hook to Stop the Logging Service.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public void start() {
    Runtime.getRuntime().addShutdownHook(new Thread() {
        public void run() {
            try { LogService.this.stop(); }
            catch (InterruptedException ignored) {}
        }
    });
}
</programlisting>
</example>
</section>
<section id="ch07lev2sec15" label="7.4.2" xreflabel="7.4.2">
<title id="ch07lev2sec15__title">Daemon Threads</title>
<para>Sometimes you want to create a thread that performs some helper function but you don’t want the existence of this thread to prevent the JVM from shutting down. This is what <emphasis>daemon threads</emphasis> are for.</para>
<para>Threads are divided into two types: normal threads and daemon threads. When the JVM starts up, all the threads it creates (such as garbage collector and other housekeeping threads) are daemon threads, except the main thread. When a new thread is created, it inherits the daemon status of the thread that created it, so by default any threads created by the main thread are also normal threads.</para>
<para>Normal threads and daemon threads differ only in what happens when they exit. When a thread exits, the JVM performs an inventory of running threads, and if the only threads that are left are daemon threads, it initiates an orderly shutdown. When the JVM halts, any remaining daemon threads are abandoned—<literal>finally</literal> blocks are not executed, stacks are not unwound—the JVM just exits.</para>
<para>Daemon threads should be used sparingly—few processing activities can be safely abandoned at any time with no cleanup. In particular, it is dangerous to use daemon threads for tasks that might perform any sort of I/O. Daemon threads are best saved for “housekeeping” tasks, such as a background thread that periodically removes expired entries from an in-memory cache.</para>
<sidebar float="1" id="ch07sb09" condition="165"><title/>
<para>Daemon threads are not a good substitute for properly managing the lifecycle of services within an application.</para>
</sidebar>
</section>
<section id="ch07lev2sec16" label="7.4.3" xreflabel="7.4.3">
<title id="ch07lev2sec16__title">Finalizers</title>
<para>The garbage collector does a good job of reclaiming memory resources when they are no longer needed, but some resources, such as file or socket handles, must be explicitly returned to the operating system when no longer needed. To assist in <?docpage num="166"?><indexterm id="iddle1985" significance="normal"><?indexkey E?><?primarykey Effective Java Programming Language Guide?><primary><emphasis role="strong"><emphasis>Effective Java Programming Language Guide</emphasis></emphasis></primary></indexterm><indexterm id="iddle2528" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey FINALIZER PRECAUTIONS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>finalizer precautions</secondary></indexterm><indexterm id="iddle4468" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey END-OF-LIFECYCLE MANAGEMENT?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>end-of-lifecycle management</secondary></indexterm>this, the garbage collector treats objects that have a nontrivial <literal>finalize</literal> method specially: after they are reclaimed by the collector, <literal>finalize</literal> is called so that persistent resources can be released.</para>
<para>Since finalizers can run in a thread managed by the JVM, any state accessed by a finalizer will be accessed by more than one thread and therefore must be accessed with synchronization. Finalizers offer no guarantees on when or even if they run, and they impose a significant performance cost on objects with nontrivial finalizers. They are also extremely difficult to write correctly.<footnote id="ch07fn09" label="9"><para>See (<link linkend="biblio01_006" preference="0">Boehm, 2005</link>) for some of the challenges involved in writing finalizers.</para></footnote> In most cases, the combination of <literal>finally</literal> blocks and explicit <literal>close</literal> methods does a better job of resource management than finalizers; the sole exception is when you need to manage objects that hold resources acquired by native methods. For these reasons and others, work hard to avoid writing or using classes with finalizers (other than the platform library classes) [EJ Item 6].</para>
<sidebar float="1" id="ch07sb10" condition="166"><title/>
<para>Avoid finalizers.</para>
</sidebar>
</section>
</section>



<section id="ch07lev1sec5" condition="166" label="" xreflabel=""><?docpage num="166"?>
<title id="ch07lev1sec5__title">Summary</title>
<para>End-of-lifecycle issues for tasks, threads, services, and applications can add complexity to their design and implementation. Java does not provide a preemptive mechanism for cancelling activities or terminating threads. Instead, it provides a cooperative interruption mechanism that can be used to facilitate cancellation, but it is up to you to construct protocols for cancellation and use them consistently. Using <literal>FutureTask</literal> and the <literal>Executor</literal> framework simplifies building cancellable tasks and services.</para>
</section>

</chapter>

<chapter id="ch08" label="8" xreflabel="8" condition="167">
<?docpage num="167"?>
<title id="ch08__title">Applying Thread Pools</title>


<para><indexterm id="iddle1540" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><?tertiarykey AND EXECUTION POLICY?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary><tertiary>and execution policy</tertiary></indexterm><indexterm id="iddle1707" significance="normal"><?indexkey C?><?primarykey coupling?><?secondarykey IMPLICIT?><primary><emphasis role="strong">coupling</emphasis></primary><secondary>implicit</secondary></indexterm><indexterm id="iddle1708" significance="normal"><?indexkey C?><?primarykey coupling?><?secondarykey IMPLICIT?><?tertiarykey BETWEEN TASKS AND EXECUTION POLICIES?><primary><emphasis role="strong">coupling</emphasis></primary><secondary>implicit</secondary><tertiary>between tasks and execution policies</tertiary></indexterm><indexterm id="iddle1881" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey TASK?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle1882" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey TASK?><?tertiarykey AND EXECUTION POLICY?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>task</secondary><tertiary>and execution policy</tertiary></indexterm><indexterm id="iddle1905" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey EXECUTION POLICY?><primary><emphasis role="strong">design</emphasis></primary><secondary>execution policy</secondary></indexterm><indexterm id="iddle1906" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey EXECUTION POLICY?><?tertiarykey INFLUENCING FACTORS?><primary><emphasis role="strong">design</emphasis></primary><secondary>execution policy</secondary><tertiary>influencing factors</tertiary></indexterm><indexterm id="iddle2243" significance="normal"><?indexkey E?><?primarykey execution?><primary><emphasis role="strong">execution</emphasis></primary></indexterm><indexterm id="iddle2244" significance="normal"><?indexkey E?><?primarykey execution?><?secondarykey POLICIES?><primary><emphasis role="strong">execution</emphasis></primary><secondary>policies</secondary></indexterm><indexterm id="iddle2245" significance="normal"><?indexkey E?><?primarykey execution?><?secondarykey POLICIES?><?tertiarykey DESIGN, INFLUENCING FACTORS?><primary><emphasis role="strong">execution</emphasis></primary><secondary>policies</secondary><tertiary>design, influencing factors</tertiary></indexterm><indexterm id="iddle2247" significance="normal"><?indexkey E?><?primarykey execution?><?secondarykey POLICIES?><?tertiarykey IMPLICIT COUPLINGS BETWEEN TASKS AND?><primary><emphasis role="strong">execution</emphasis></primary><secondary>policies</secondary><tertiary>implicit couplings between tasks and</tertiary></indexterm><indexterm id="iddle2260" significance="normal"><?indexkey E?><?primarykey Executor framework?><?secondarykey EXECUTION POLICY DESIGN?><primary><emphasis role="strong">Executor framework</emphasis></primary><secondary>execution policy design</secondary></indexterm><indexterm id="iddle2717" significance="normal"><?indexkey I?><?primarykey implicit coupling?><?secondarykey BETWEEN TASKS AND EXECUTION POLICIES?><primary><emphasis role="strong">implicit coupling</emphasis></primary><secondary>between tasks and execution policies</secondary></indexterm><indexterm id="iddle3577" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey EXECUTION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>execution</secondary></indexterm><indexterm id="iddle3578" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey EXECUTION?><?tertiarykey DESIGN, INFLUENCING FACTORS?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>execution</secondary><tertiary>design, influencing factors</tertiary></indexterm><indexterm id="iddle3580" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey EXECUTION?><?tertiarykey IMPLICIT COUPLINGS BETWEEN TASKS AND?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>execution</secondary><tertiary>implicit couplings between tasks and</tertiary></indexterm><indexterm id="iddle3621" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey APPLICATION?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>application</tertiary></indexterm><indexterm id="iddle4615" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey DEPENDENCIES?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>dependencies</secondary></indexterm><indexterm id="iddle4616" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey DEPENDENCIES?><?tertiarykey EXECUTION POLICY IMPLICATIONS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>dependencies</secondary><tertiary>execution policy implications</tertiary></indexterm><indexterm id="iddle4621" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey EXECUTION?><?tertiarykey POLICIES AND, IMPLICIT COUPLINGS BETWEEN?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>execution</secondary><tertiary>policies and, implicit couplings between</tertiary></indexterm><indexterm id="iddle4752" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><?tertiarykey AND EXECUTION POLICY?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><tertiary>and execution policy</tertiary></indexterm><indexterm id="iddle4795" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey APPLICATION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>application</tertiary></indexterm><link linkend="ch06" preference="0">Chapter 6</link> introduced the task execution framework, which simplifies management of task and thread lifecycles and provides a simple and flexible means for decoupling task submission from execution policy. <link linkend="ch07" preference="0">Chapter 7</link> covered some of the messy details of service lifecycle that arise from using the task execution framework in real applications. This chapter looks at advanced options for configuring and tuning thread pools, describes hazards to watch for when using the task execution framework, and offers some more advanced examples of using <literal>Executor</literal>.</para>



<section id="ch08lev1sec1" condition="167" label="8.1" xreflabel="8.1"><?docpage num="167"?>
<title id="ch08lev1sec1__title">Implicit Couplings Between Tasks and Execution Policies</title>
<para>We claimed earlier that the <literal>Executor</literal> framework decouples task submission from task execution. Like many attempts at decoupling complex processes, this was a bit of an overstatement. While the <literal>Executor</literal> framework offers substantial flexibility in specifying and modifying execution policies, not all tasks are compatible with all execution policies. Types of tasks that require specific execution policies include:</para>
<formalpara><title><emphasis role="strong"><?design?>Dependent tasks.</emphasis></title><para>The most well behaved tasks are <emphasis>independent</emphasis>: those that do not depend on the timing, results, or side effects of other tasks. When executing independent tasks in a thread pool, you can freely vary the pool size and configuration without affecting anything but performance. On the other hand, when you submit tasks that depend on other tasks to a thread pool, you implicitly create constraints on the execution policy that must be carefully managed to avoid liveness problems (see <link linkend="ch08lev2sec1" preference="0">Section 8.1.1</link>).</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Tasks that exploit thread confinement.</emphasis></title><para>Single-threaded executors make stronger promises about concurrency than do arbitrary thread pools. They guarantee that tasks are not executed concurrently, which allows you to relax the thread safety of task code. Objects can be confined to the task thread, thus enabling tasks designed to run in that thread to access those objects without synchronization, even if those resources are not thread-safe. This forms an implicit coupling between the task and the execution policy—the tasks require <?docpage num="168"?><indexterm id="iddle1818" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey THREAD STARVATION?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>thread starvation</secondary></indexterm><indexterm id="iddle1883" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey TASK?><?tertiarykey THREAD STARVATION DEADLOCK?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>task</secondary><tertiary>thread starvation deadlock</tertiary></indexterm><indexterm id="iddle1963" significance="normal"><?indexkey D?><?primarykey documentation?><?secondarykey IMPORTANCE?><primary><emphasis role="strong">documentation</emphasis></primary><secondary>importance</secondary></indexterm><indexterm id="iddle1964" significance="normal"><?indexkey D?><?primarykey documentation?><?secondarykey IMPORTANCE?><?tertiarykey FOR SPECIAL EXECUTION POLICY REQUIREMENTS?><primary><emphasis role="strong">documentation</emphasis></primary><secondary>importance</secondary><tertiary>for special execution policy requirements</tertiary></indexterm><indexterm id="iddle2493" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey RESPONSE-TIME SENSITIVITY?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>response-time sensitivity</secondary></indexterm><indexterm id="iddle2494" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey RESPONSE-TIME SENSITIVITY?><?tertiarykey AND EXECUTION POLICY?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>response-time sensitivity</secondary><tertiary>and execution policy</tertiary></indexterm><indexterm id="iddle2526" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey EXECUTION POLICY?><?tertiarykey SPECIAL CASE IMPLICATIONS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>execution policy</secondary><tertiary>special case implications</tertiary></indexterm><indexterm id="iddle3942" significance="normal"><?indexkey R?><?primarykey response-time-senstive tasks?><primary><emphasis role="strong">response-time-senstive tasks</emphasis></primary></indexterm><indexterm id="iddle3943" significance="normal"><?indexkey R?><?primarykey response-time-senstive tasks?><?secondarykey EXECUTION POLICY IMPLICATIONS?><primary><emphasis role="strong">response-time-senstive tasks</emphasis></primary><secondary>execution policy implications</secondary></indexterm><indexterm id="iddle4375" significance="normal"><?indexkey S?><?primarykey starvation?><?secondarykey THREAD STARVATION DEADLOCK?><primary><emphasis role="strong">starvation</emphasis></primary><secondary>thread starvation deadlock</secondary></indexterm><indexterm id="iddle4608" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey BOUNDARIES?><?tertiarykey USING THREADLOCAL IN?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>boundaries</secondary><tertiary>using <literal>ThreadLocal</literal> in</tertiary></indexterm><indexterm id="iddle4617" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey DEPENDENCIES?><?tertiarykey THREAD STARVATION DEADLOCK RISKS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>dependencies</secondary><tertiary>thread starvation deadlock risks</tertiary></indexterm><indexterm id="iddle4648" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey RESPONSE-TIME SENSITIVITY?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>response-time sensitivity</secondary></indexterm><indexterm id="iddle4649" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey RESPONSE-TIME SENSITIVITY?><?tertiarykey ANDEXECUTION POLICY?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>response-time sensitivity</secondary><tertiary>andexecution policy</tertiary></indexterm><indexterm id="iddle4824" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey STARVATION DEADLOCK?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>starvation deadlock</secondary></indexterm><indexterm id="iddle4850" significance="normal"><?indexkey T?><?primarykey ThreadLocal?><?secondarykey AND EXECUTION POLICY?><primary><emphasis role="strong">ThreadLocal</emphasis></primary><secondary>and execution policy</secondary></indexterm><indexterm id="iddle4922" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey RESPONSE?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>response</secondary></indexterm><indexterm id="iddle4923" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey RESPONSE?><?tertiarykey TASK SENSITIVITY TO, EXECUTION POLICY IMPLICATIONS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>response</secondary><tertiary>task sensitivity to, execution policy implications</tertiary></indexterm>their executor to be single-threaded.<footnote id="ch08fn01" label="1"><para>The requirement is not quite this strong; it would be enough to ensure only that tasks not execute concurrently and provide enough synchronization so that the memory effects of one task are guaranteed to be visible to the next task—which is precisely the guarantee offered by <literal>newSingle-ThreadExecutor</literal>.</para></footnote> In this case, if you changed the <literal>Executor</literal> from a single-threaded one to a thread pool, thread safety could be lost.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Response-time-sensitive tasks.</emphasis></title><para>GUI applications are sensitive to response time: users are annoyed at long delays between a button click and the corresponding visual feedback. Submitting a long-running task to a single-threaded executor, or submitting several long-running tasks to a thread pool with a small number of threads, may impair the responsiveness of the service managed by that <literal>Executor</literal>.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Tasks that use <literal>ThreadLocal</literal>.</emphasis></title><para><literal>ThreadLocal</literal> allows each thread to have its own private “version” of a variable. However, executors are free to reuse threads as they see fit. The standard <literal>Executor</literal> implementations may reap idle threads when demand is low and add new ones when demand is high, and also replace a worker thread with a fresh one if an unchecked exception is thrown from a task. <literal>ThreadLocal</literal> makes sense to use in pool threads only if the thread-local value has a lifetime that is bounded by that of a task; <literal>Thread-Local</literal> should not be used in pool threads to communicate values between tasks.</para></formalpara>
<para role="continued">Thread pools work best when tasks are <emphasis>homogeneous</emphasis> and <emphasis>independent</emphasis>. Mixing long-running and short-running tasks risks “clogging” the pool unless it is very large; submitting tasks that depend on other tasks risks deadlock unless the pool is unbounded. Fortunately, requests in typical network-based server applications—web servers, mail servers, file servers—usually meet these guidelines.</para>
<sidebar float="1" id="ch08sb01" condition="168"><title/>
<para>Some tasks have characteristics that require or preclude a specific execution policy. Tasks that depend on other tasks require that the thread pool be large enough that tasks are never queued or rejected; tasks that exploit thread confinement require sequential execution. Document these requirements so that future maintainers do not undermine safety or liveness by substituting an incompatible execution policy.</para>
</sidebar>
<section id="ch08lev2sec1" label="8.1.1" xreflabel="8.1.1">
<title id="ch08lev2sec1__title">Thread Starvation Deadlock</title>
<para>If tasks that depend on other tasks execute in a thread pool, they can deadlock. In a single-threaded executor, a task that submits another task to the same executor and waits for its result will always deadlock. The second task sits on the work queue until the first task completes, but the first will not complete because it is <?docpage num="169"?><indexterm id="iddle1475" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey PREVENTION?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>prevention</secondary><seealso> <link linkend="iddle2263" preference="0"><emphasis role="strong">Executor framework</emphasis>, single-threaded</link>.</seealso></indexterm><indexterm id="iddle1817" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey THREAD STARVATION?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>thread starvation</secondary></indexterm><indexterm id="iddle2200" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey THREADDEADLOCK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ThreadDeadlock</literal></secondary></indexterm><indexterm id="iddle2263" significance="normal"><?indexkey E?><?primarykey Executor framework?><?secondarykey SINGLE-THREADED?><primary><emphasis role="strong">Executor framework</emphasis></primary><secondary>single-threaded</secondary></indexterm><indexterm id="iddle2264" significance="normal"><?indexkey E?><?primarykey Executor framework?><?secondarykey SINGLE-THREADED?><?tertiarykey DEADLOCK EXAMPLE?><primary><emphasis role="strong">Executor framework</emphasis></primary><secondary>single-threaded</secondary><tertiary>deadlock example</tertiary></indexterm><indexterm id="iddle2517" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey DEADLOCK AVOIDANCE?><?tertiarykey THREAD STARVATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>deadlock avoidance</secondary><tertiary>thread starvation</tertiary></indexterm><indexterm id="iddle4374" significance="normal"><?indexkey S?><?primarykey starvation?><?secondarykey THREAD STARVATION DEADLOCK?><primary><emphasis role="strong">starvation</emphasis></primary><secondary>thread starvation deadlock</secondary></indexterm><indexterm id="iddle4823" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey STARVATION DEADLOCK?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>starvation deadlock</secondary></indexterm>waiting for the result of the second task. The same thing can happen in larger thread pools if all threads are executing tasks that are blocked waiting for other tasks still on the work queue. This is called <emphasis>thread starvation deadlock</emphasis>, and can occur whenever a pool task initiates an unbounded blocking wait for some resource or condition that can succeed only through the action of another pool task, such as waiting for the return value or side effect of another task, unless you can guarantee that the pool is large enough.</para>
<para><literal>ThreadDeadlock</literal> in <link linkend="ch08list01" preference="0">Listing 8.1</link> illustrates thread starvation deadlock. <literal>Render-PageTask</literal> submits two additional tasks to the <literal>Executor</literal> to fetch the page header and footer, renders the page body, waits for the results of the header and footer tasks, and then combines the header, body, and footer into the finished page. With a single-threaded executor, <literal>ThreadDeadlock</literal> will always deadlock. Similarly, tasks coordinating amongst themselves with a barrier could also cause thread starvation deadlock if the pool is not big enough.</para>
<sidebar float="1" id="ch08sb02" condition="169"><title/>
<para>Whenever you submit to an <literal>Executor</literal> tasks that are not independent, be aware of the possibility of thread starvation deadlock, and document any pool sizing or configuration constraints in the code or configuration file where the <literal>Executor</literal> is configured.</para>
</sidebar>
<para>In addition to any explicit bounds on the size of a thread pool, there may also be implicit limits because of constraints on other resources. If your application uses a JDBC connection pool with ten connections and each task needs a database connection, it is as if your thread pool only has ten threads because tasks in excess of ten will block waiting for a connection.</para>
<example id="ch08list01" label="8.1" role="Listing" xreflabel="8.1" condition="169">
<title id="ch08list01__title">Task that Deadlocks in a Single-threaded <literal>Executor</literal>. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class ThreadDeadlock {
    ExecutorService exec = Executors.newSingleThreadExecutor();

    public class RenderPageTask implements Callable&lt;String&gt; {
        public String call() throws Exception {
            Future&lt;String&gt; header, footer;
            header = exec.submit(new LoadFileTask("header.html"));
            footer = exec.submit(new LoadFileTask("footer.html"));
            String page = renderBody();
            // <emphasis>Will deadlock -- task waiting for result of subtask</emphasis>
            return <emphasis role="strong">header.get()</emphasis> + page + <emphasis role="strong">footer.get();</emphasis>
        }
    }
}
</programlisting>
</example>
</section>
<section id="ch08lev2sec2" condition="170" label="8.1.2" xreflabel="8.1.2">
<?docpage num="170"?>
<title id="ch08lev2sec2__title">Long-running Tasks</title>
<para><indexterm id="iddle1220" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey OPERATIONS?><?tertiarykey THREAD POOL SIZE IMPACT?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>operations</secondary><tertiary>thread pool size impact</tertiary></indexterm><indexterm id="iddle1234" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey WAITS?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>waits</secondary></indexterm><indexterm id="iddle1235" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey WAITS?><?tertiarykey TIMED VS. UNBOUNDED?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>waits</secondary><tertiary>timed vs. unbounded</tertiary></indexterm><indexterm id="iddle1431" significance="normal"><?indexkey C?><?primarykey computation?><?secondarykey COMPUTE-INTENSIVE CODE?><?tertiarykey THREAD POOL SIZE IMPACT?><primary><emphasis role="strong">computation</emphasis></primary><secondary>compute-intensive code</secondary><tertiary>thread pool size impact</tertiary></indexterm><indexterm id="iddle1932" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey THREAD POOL SIZE?><primary><emphasis role="strong">design</emphasis></primary><secondary>thread pool size</secondary></indexterm><indexterm id="iddle1933" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey THREAD POOL SIZE?><?tertiarykey RELEVANT FACTORS FOR?><primary><emphasis role="strong">design</emphasis></primary><secondary>thread pool size</secondary><tertiary>relevant factors for</tertiary></indexterm><indexterm id="iddle2676" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey OPERATIONS?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>operations</secondary></indexterm><indexterm id="iddle2677" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey OPERATIONS?><?tertiarykey THREAD POOL SIZE IMPACT?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>operations</secondary><tertiary>thread pool size impact</tertiary></indexterm><indexterm id="iddle2763" significance="normal"><?indexkey I?><?primarykey instrumentation?><?secondarykey THREAD POOL SIZE REQUIREMENTS DETERMINATION USE OF?><primary><emphasis role="strong">instrumentation</emphasis></primary><secondary>thread pool size requirements determination use of</secondary></indexterm><indexterm id="iddle3540" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey THREAD POOL?><primary><emphasis role="strong">performance</emphasis></primary><secondary>thread pool</secondary></indexterm><indexterm id="iddle3541" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey THREAD POOL?><?tertiarykey SIZE IMPACT?><primary><emphasis role="strong">performance</emphasis></primary><secondary>thread pool</secondary><tertiary>size impact</tertiary></indexterm><indexterm id="iddle3631" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey SIZING?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>sizing</tertiary></indexterm><indexterm id="iddle3897" significance="normal"><?indexkey R?><?primarykey resource exhaustion, preventing?><?secondarykey THREAD POOL SIZING RISKS?><primary><emphasis role="strong">resource exhaustion, preventing</emphasis></primary><secondary>thread pool sizing risks</secondary></indexterm><indexterm id="iddle3924" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey LONG-RUNNING TASK HANDLING?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>long-running task handling</tertiary></indexterm><indexterm id="iddle3955" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey LONG-RUNNING TASKS?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>long-running tasks</secondary></indexterm><indexterm id="iddle3956" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey LONG-RUNNING TASKS?><?tertiarykey HANDLING?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>long-running tasks</secondary><tertiary>handling</tertiary></indexterm><indexterm id="iddle4319" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey THREAD POOLS?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>thread pools</secondary></indexterm><indexterm id="iddle4637" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey LONG-RUNNING?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>long-running</secondary></indexterm><indexterm id="iddle4638" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey LONG-RUNNING?><?tertiarykey RESPONSIVENESS PROBLEMS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>long-running</secondary><tertiary>responsiveness problems</tertiary></indexterm><indexterm id="iddle4803" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey SIZING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>sizing</tertiary></indexterm><indexterm id="iddle4910" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey LONG-RUNNING TASKS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>long-running tasks</secondary></indexterm><indexterm id="iddle4911" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey LONG-RUNNING TASKS?><?tertiarykey RESPONSIVENESS PROBLEM HANDLING?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>long-running tasks</secondary><tertiary>responsiveness problem handling</tertiary></indexterm><indexterm id="iddle4991" significance="normal"><?indexkey U?><?primarykey unbounded?><?secondarykey BLOCKING WAITS?><primary><emphasis role="strong">unbounded</emphasis></primary><secondary>blocking waits</secondary></indexterm><indexterm id="iddle4992" significance="normal"><?indexkey U?><?primarykey unbounded?><?secondarykey BLOCKING WAITS?><?tertiarykey TIMED VS., IN LONG-RUNNING TASK MANAGEMENT?><primary><emphasis role="strong">unbounded</emphasis></primary><secondary>blocking waits</secondary><tertiary>timed vs., in long-running task management</tertiary></indexterm><indexterm id="iddle5129" significance="normal"><?indexkey W?><?primarykey wait(s)?><primary><emphasis role="strong">wait(s)</emphasis></primary></indexterm><indexterm id="iddle5130" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey BLOCKING?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>blocking</secondary></indexterm><indexterm id="iddle5131" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey BLOCKING?><?tertiarykey TIMED VS. UNBOUNDED?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>blocking</secondary><tertiary>timed vs. unbounded</tertiary></indexterm>Thread pools can have responsiveness problems if tasks can block for extended periods of time, even if deadlock is not a possibility. A thread pool can become clogged with long-running tasks, increasing the service time even for short tasks. If the pool size is too small relative to the expected steady-state number of longrunning tasks, eventually all the pool threads will be running long-running tasks and responsiveness will suffer.</para>
<para>One technique that can mitigate the ill effects of long-running tasks is for tasks to use timed resource waits instead of unbounded waits. Most blocking methods in the plaform libraries come in both untimed and timed versions, such as <literal>Thread.join</literal>, <literal>BlockingQueue.put</literal>, <literal>CountDownLatch.await</literal>, and <literal>Selector.select</literal>. If the wait times out, you can mark the task as failed and abort it or requeue it for execution later. This guarantees that each task eventually makes progress towards either successful or failed completion, freeing up threads for tasks that might complete more quickly. If a thread pool is frequently full of blocked tasks, this may also be a sign that the pool is too small.</para>
</section>
</section>
<section id="ch08lev1sec2" condition="170" label="8.2" xreflabel="8.2"><?docpage num="170"?>
<title id="ch08lev1sec2__title">Sizing Thread Pools</title>
<para>The ideal size for a thread pool depends on the types of tasks that will be submitted and the characteristics of the deployment system. Thread pool sizes should rarely be hard-coded; instead pool sizes should be provided by a configuration mechanism or computed dynamically by consulting <literal>Runtime.availableProcessors</literal>.</para>
<para>Sizing thread pools is not an exact science, but fortunately you need only avoid the extremes of “too big” and “too small”. If a thread pool is too big, then threads compete for scarce CPU and memory resources, resulting in higher memory usage and possible resource exhaustion. If it is too small, throughput suffers as processors go unused despite available work.</para>
<para>To size a thread pool properly, you need to understand your computing environment, your resource budget, and the nature of your tasks. How many processors does the deployment system have? How much memory? Do tasks perform mostly computation, I/O, or some combination? Do they require a scarce resource, such as a JDBC connection? If you have different categories of tasks with very different behaviors, consider using multiple thread pools so each can be tuned according to its workload.</para>
<para>For compute-intensive tasks, an <emphasis>N<subscript>cpu</subscript></emphasis>-processor system usually achieves optimum utilization with a thread pool of <emphasis>N<subscript>cpu</subscript></emphasis> +1 threads. (Even compute-intensive threads occasionally take a page fault or pause for some other reason, so an “extra” runnable thread prevents CPU cycles from going unused when this happens.) For tasks that also include I/O or other blocking operations, you want a larger pool, since not all of the threads will be schedulable at all times. In order to size the pool properly, you must estimate the ratio of waiting time to compute time for your tasks; this estimate need not be precise and can be obtained through pro-filing or instrumentation. Alternatively, the size of the thread pool can be tuned <?docpage num="171"?><indexterm id="iddle1525" significance="normal"><?indexkey C?><?primarykey configuration?><primary><emphasis role="strong">configuration</emphasis></primary></indexterm><indexterm id="iddle1526" significance="normal"><?indexkey C?><?primarykey configuration?><?secondarykey OF THREADPOOLEXECUTOR?><primary><emphasis role="strong">configuration</emphasis></primary><secondary>of <literal>ThreadPoolExecutor</literal></secondary></indexterm><indexterm id="iddle1672" significance="normal"><?indexkey C?><?primarykey core pool size parameter?><primary><emphasis role="strong">core pool size parameter</emphasis></primary></indexterm><indexterm id="iddle1673" significance="normal"><?indexkey C?><?primarykey core pool size parameter?><?secondarykey THREAD CREATION IMPACT?><primary><emphasis role="strong">core pool size parameter</emphasis></primary><secondary>thread creation impact</secondary></indexterm><indexterm id="iddle1729" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey THREAD?><primary><emphasis role="strong">creation</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle1784" significance="normal"><?indexkey D?><?primarykey database(s)?><?secondarykey THREAD POOL SIZE IMPACT?><primary><emphasis role="strong">database(s)</emphasis></primary><secondary>thread pool size impact</secondary></indexterm><indexterm id="iddle1950" significance="normal"><?indexkey D?><?primarykey destruction?><primary><emphasis role="strong">destruction</emphasis></primary><see> <link linkend="iddle4834" preference="0"><emphasis role="strong">thread(s)</emphasis>, teardown</link>.</see></indexterm><indexterm id="iddle2246" significance="normal"><?indexkey E?><?primarykey execution?><?secondarykey POLICIES?><?tertiarykey EXECUTORS FACTORY METHODS?><primary><emphasis role="strong">execution</emphasis></primary><secondary>policies</secondary><tertiary><literal>Executors</literal> factory methods</tertiary></indexterm><indexterm id="iddle2296" significance="normal"><?indexkey F?><?primarykey factory(s)?><?secondarykey METHODS?><?tertiarykey SYNCHRONIZED COLLECTIONS?><primary><emphasis role="strong">factory(s)</emphasis></primary><secondary>methods</secondary><tertiary>synchronized collections</tertiary></indexterm><indexterm id="iddle3208" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey THREAD POOL SIZE IMPACT?><primary><emphasis role="strong">memory</emphasis></primary><secondary>thread pool size impact</secondary></indexterm><indexterm id="iddle3542" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey THREAD POOL?><?tertiarykey TUNING?><primary><emphasis role="strong">performance</emphasis></primary><secondary>thread pool</secondary><tertiary>tuning</tertiary></indexterm><indexterm id="iddle3579" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey EXECUTION?><?tertiarykey EXECUTORS, FOR THREADPOOLEXECUTOR CONFIGURATION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>execution</secondary><tertiary><literal>Executors</literal>, for <literal>ThreadPoolExecutor</literal> configuration</tertiary></indexterm><indexterm id="iddle3614" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey RESOURCE?><?tertiarykey THREAD POOL SIZE IMPACT?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>resource</secondary><tertiary>thread pool size impact</tertiary></indexterm><indexterm id="iddle3615" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey SIZE?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>size</secondary></indexterm><indexterm id="iddle3616" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey SIZE?><?tertiarykey CORE?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>size</secondary><tertiary>core</tertiary></indexterm><indexterm id="iddle3630" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey FACTORY METHODS FOR?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>factory methods for</tertiary></indexterm><indexterm id="iddle3930" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey THREAD POOLS, TUNING?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>thread pools, tuning</tertiary></indexterm><indexterm id="iddle3938" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey POOLS?><?tertiarykey THREAD POOL SIZE IMPACT?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>pools</secondary><tertiary>thread pool size impact</tertiary></indexterm><indexterm id="iddle3971" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey THREAD?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle3972" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey THREAD?><?tertiarykey POOL TUNING, THREADPOOLEXECUTOR USE?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>thread</secondary><tertiary>pool tuning, <literal>ThreadPoolExecutor</literal> use</tertiary></indexterm><indexterm id="iddle4307" significance="normal"><?indexkey S?><?primarykey size(ing)?><primary><emphasis role="strong">size(ing)</emphasis></primary><seealso> <link linkend="iddle1525" preference="0"><emphasis role="strong">configuration</emphasis></link>.</seealso></indexterm><indexterm id="iddle4308" significance="normal"><?indexkey S?><?primarykey size(ing)?><primary><emphasis role="strong">size(ing)</emphasis></primary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle4313" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey POOL?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>pool</secondary></indexterm><indexterm id="iddle4314" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey POOL?><?tertiarykey CORE?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>pool</secondary><tertiary>core</tertiary></indexterm><indexterm id="iddle4665" significance="normal"><?indexkey T?><?primarykey teardown?><primary><emphasis role="strong">teardown</emphasis></primary></indexterm><indexterm id="iddle4666" significance="normal"><?indexkey T?><?primarykey teardown?><?secondarykey THREAD?><primary><emphasis role="strong">teardown</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle4763" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CREATION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>creation</secondary></indexterm><indexterm id="iddle4801" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey FACTORY METHODS FOR?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>factory methods for</tertiary></indexterm><indexterm id="iddle4834" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey TEARDOWN?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>teardown</secondary></indexterm><indexterm id="iddle4855" significance="normal"><?indexkey T?><?primarykey ThreadPoolExecutor?><?secondarykey CONFIGURATION OF?><primary><emphasis role="strong">ThreadPoolExecutor</emphasis></primary><secondary>configuration of</secondary></indexterm><indexterm id="iddle4987" significance="normal"><?indexkey T?><?primarykey tuning?><?secondarykey THREAD POOLS?><primary><emphasis role="strong">tuning</emphasis></primary><secondary>thread pools</secondary></indexterm> by running the application using several different pool sizes under a benchmark load and observing the level of CPU utilization.</para>
<para>Given these definitions:</para>
<mediaobject float="0">
<imageobject>
<imagedata depth="101" fileref="graphics/171equ01.gif" format="GIF" width="400"/></imageobject>

</mediaobject>
<para role="continued">The optimal pool size for keeping the processors at the desired utilization is:</para>
<mediaobject float="0">
<imageobject>
<imagedata depth="50" fileref="graphics/171equ02.gif" format="GIF" width="300"/></imageobject>

</mediaobject>
<para role="continued">You can determine the number of CPUs using <literal>Runtime</literal>:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">int N_CPUS = Runtime.getRuntime().availableProcessors();
</programlisting>
</informalexample>
<para role="continued">Of course, CPU cycles are not the only resource you might want to manage using thread pools. Other resources that can contribute to sizing constraints are memory, file handles, socket handles, and database connections. Calculating pool size constraints for these types of resources is easier: just add up how much of that resource each task requires and divide that into the total quantity available. The result will be an upper bound on the pool size.</para>
<para>When tasks require a pooled resource such as database connections, thread pool size and resource pool size affect each other. If each task requires a connection, the effective size of the thread pool is limited by the connection pool size. Similarly, when the only consumers of connections are pool tasks, the effective size of the connection pool is limited by the thread pool size.</para>
</section>
<section id="ch08lev1sec3" condition="171" label="8.3" xreflabel="8.3"><?docpage num="171"?>
<title id="ch08lev1sec3__title">Configuring <literal>ThreadPoolExecutor</literal></title>
<para><literal>ThreadPoolExecutor</literal> provides the base implementation for the executors returned by the <literal>newCachedThreadPool</literal>, <literal>newFixedThreadPool</literal>, and <literal>newScheduled-ThreadExecutor</literal> factories in <literal>Executors</literal>. <literal>ThreadPoolExecutor</literal> is a flexible, robust pool implementation that allows a variety of customizations.</para>
<para>If the default execution policy does not meet your needs, you can instantiate a <literal>ThreadPoolExecutor</literal> through its constructor and customize it as you see fit; you can consult the source code for <literal>Executors</literal> to see the execution policies for the default configurations and use them as a starting point. <literal>ThreadPoolExecutor</literal> has several constructors, the most general of which is shown in <link linkend="ch08list02" preference="0">Listing 8.2</link>.</para>
<section id="ch08lev2sec3" label="8.3.1" xreflabel="8.3.1">
<title id="ch08lev2sec3__title">Thread Creation and Teardown</title>
<para>The core pool size, maximum pool size, and keep-alive time govern thread creation and teardown. The core size is the target size; the implementation attempts to maintain the pool at this size even when there are no tasks to execute,<footnote id="ch08fn02" label="2"><para>Whena <literal>ThreadPoolExecutor</literal> is initially created, the core threads are not started immediately but instead as tasks are submitted, unless you call <literal>prestartAllCoreThreads</literal>.</para></footnote> and will <?docpage num="172"?><indexterm id="iddle1251" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey QUEUES?><?tertiarykey THREAD POOL USE?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>queues</secondary><tertiary>thread pool use</tertiary></indexterm><indexterm id="iddle1476" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey PREVENTION?><?tertiarykey SINGLE-THREADED EXECUTOR USE?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>prevention</secondary><tertiary>single-threaded executor use</tertiary></indexterm><indexterm id="iddle1574" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey THREADPOOLEXECUTOR?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary><literal>ThreadPoolExecutor</literal></secondary></indexterm><indexterm id="iddle1674" significance="normal"><?indexkey C?><?primarykey core pool size parameter?><?secondarykey THREAD CREATION IMPACT?><primary><emphasis role="strong">core pool size parameter</emphasis></primary><secondary>thread creation impact</secondary></indexterm><indexterm id="iddle2926" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey THREAD TIMEOUT INTERACTION?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>thread timeout interaction</secondary></indexterm><indexterm id="iddle2927" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey THREAD TIMEOUT INTERACTION?><?tertiarykey AND CORE POOL SIZE?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>thread timeout interaction</secondary><tertiary>and core pool size</tertiary></indexterm><indexterm id="iddle2930" significance="normal"><?indexkey K?><?primarykey keep-alive time?><primary><emphasis role="strong">keep-alive time</emphasis></primary></indexterm><indexterm id="iddle2931" significance="normal"><?indexkey K?><?primarykey keep-alive time?><?secondarykey THREAD TERMINATION IMPACT?><primary><emphasis role="strong">keep-alive time</emphasis></primary><secondary>thread termination impact</secondary></indexterm><indexterm id="iddle3182" significance="normal"><?indexkey M?><?primarykey maximum pool size parameter?><primary><emphasis role="strong">maximum pool size parameter</emphasis></primary></indexterm><indexterm id="iddle3617" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey SIZE?><?tertiarykey CORE?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>size</secondary><tertiary>core</tertiary></indexterm><indexterm id="iddle3618" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey SIZE?><?tertiarykey MAXIMUM?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>size</secondary><tertiary>maximum</tertiary></indexterm><indexterm id="iddle3627" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey CONFIGURING TASK QUEUE?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>configuring task queue</tertiary></indexterm><indexterm id="iddle3768" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey TASK?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle3769" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey TASK?><?tertiarykey THREAD POOL USE OF?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>task</secondary><tertiary>thread pool use of</tertiary></indexterm><indexterm id="iddle3932" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey THREADS, KEEP-ALIVE TIME IMPACT ON?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>threads, keep-alive time impact on</tertiary></indexterm><indexterm id="iddle4303" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><?secondarykey TASK EXECUTION?><?tertiarykey EXECUTOR USE, CONCURRENCY PREVENTION?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><secondary>task execution</secondary><tertiary>executor use, concurrency prevention</tertiary></indexterm><indexterm id="iddle4315" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey POOL?><?tertiarykey CORE?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>pool</secondary><tertiary>core</tertiary></indexterm><indexterm id="iddle4316" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey POOL?><?tertiarykey MAXIMUM?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>pool</secondary><tertiary>maximum</tertiary></indexterm><indexterm id="iddle4642" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey QUEUES?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>queues</secondary></indexterm><indexterm id="iddle4643" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey QUEUES?><?tertiarykey MANAGEMENT, THREAD POOL CONFIGURATION ISSUES?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>queues</secondary><tertiary>management, thread pool configuration issues</tertiary></indexterm><indexterm id="iddle4644" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey QUEUES?><?tertiarykey THREAD POOL USE OF?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>queues</secondary><tertiary>thread pool use of</tertiary></indexterm><indexterm id="iddle4683" significance="normal"><?indexkey T?><?primarykey termination?><?secondarykey THREAD?><?tertiarykey KEEP-ALIVE TIME IMPACT ON?><primary><emphasis role="strong">termination</emphasis></primary><secondary>thread</secondary><tertiary>keep-alive time impact on</tertiary></indexterm><indexterm id="iddle4804" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey TASK QUEUE CONFIGURATION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>task queue configuration</tertiary></indexterm><indexterm id="iddle4835" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey TERMINATION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>termination</secondary></indexterm><indexterm id="iddle4836" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey TERMINATION?><?tertiarykey KEEP-ALIVE TIME IMPACT ON?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>termination</secondary><tertiary>keep-alive time impact on</tertiary></indexterm><indexterm id="iddle4856" significance="normal"><?indexkey T?><?primarykey ThreadPoolExecutor?><?secondarykey CONSTRUCTOR?><primary><emphasis role="strong">ThreadPoolExecutor</emphasis></primary><secondary>constructor</secondary></indexterm><indexterm id="iddle4903" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey KEEP-ALIVE?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>keep-alive</secondary></indexterm><indexterm id="iddle4904" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey KEEP-ALIVE?><?tertiarykey THREAD TERMINATION IMPACT?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>keep-alive</secondary><tertiary>thread termination impact</tertiary></indexterm><indexterm id="iddle4925" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey THREAD TIMEOUT?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>thread timeout</secondary></indexterm><indexterm id="iddle4926" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey THREAD TIMEOUT?><?tertiarykey CORE POOL SIZE PARAMETER IMPACT ON?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>thread timeout</secondary><tertiary>core pool size parameter impact on</tertiary></indexterm>not create more threads than this unless the work queue is full.<footnote id="ch08fn03" label="3"><para>Developers are sometimes tempted to set the core size to zero so that the worker threads will eventually be torn down and therefore won’t prevent the JVM from exiting, but this can cause some strange-seeming behavior in thread pools that don’t use a <literal>SynchronousQueue</literal> for their work queue (as <literal>newCachedThreadPool</literal> does). If the pool is already at the core size, <literal>ThreadPoolExecutor</literal> creates a new thread only if the work queue is full. So tasks submitted to a thread pool with a work queue that has any capacity and a core size of zero will not execute until the queue fills up, which is usually not what is desired. In Java 6, <literal>allowCoreThreadTimeOut</literal> allows you to request that all pool threads be able to time out; enable this feature with a core size of zero if you want a bounded thread pool with a bounded work queue but still have all the threads torn down when there is no work to do.</para></footnote> The maximum pool size is the upper bound on how many pool threads can be active at once. A thread that has been idle for longer than the keep-alive time becomes a candidate for reaping and can be terminated if the current pool size exceeds the core size.</para>
<example id="ch08list02" label="8.2" role="Listing" xreflabel="8.2" condition="172">
<title id="ch08list02__title">General Constructor for <literal>ThreadPoolExecutor</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue&lt;Runnable&gt; workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) { ... }
</programlisting>
</example>
<para>By tuning the core pool size and keep-alive times, you can encourage the pool to reclaim resources used by otherwise idle threads, making them available for more useful work. (Like everything else, this is a tradeoff: reaping idle threads incurs additional latency due to thread creation if threads must later be created when demand increases.)</para>
<para>The <literal>newFixedThreadPool</literal> factory sets both the core pool size and the maximum pool size to the requested pool size, creating the effect of infinite timeout; the <literal>newCachedThreadPool</literal> factory sets the maximum pool size to <literal>Integer.MAX_VALUE</literal> and the core pool size to zero with a timeout of one minute, creating the effect of an infinitely expandable thread pool that will contract again when demand decreases. Other combinations are possible using the explicit <literal>ThreadPool-Executor</literal> constructor.</para>
</section>
<section id="ch08lev2sec4" label="8.3.2" xreflabel="8.3.2">
<title id="ch08lev2sec4__title">Managing Queued Tasks</title>
<para>Bounded thread pools limit the number of tasks that can be executed concurrently. (The single-threaded executors are a notable special case: they guarantee that no tasks will execute concurrently, offering the possibility of achieving thread safety through thread confinement.)</para>
<para>We saw in <link linkend="ch06lev2sec2" preference="0">Section 6.1.2</link> how unbounded thread creation could lead to instability, and addressed this problem by using a fixed-sized thread pool instead of creating a new thread for every request. However, this is only a partial solution; it is still possible for the application to run out of resources under heavy load, just harder. If the arrival rate for new requests exceeds the rate at which they can be <?docpage num="173"?><indexterm id="iddle1222" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey QUEUES?><?tertiarykey AND THREAD POOL MANAGEMENT?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>queues</secondary><tertiary>and thread pool management</tertiary></indexterm><indexterm id="iddle1239" significance="normal"><?indexkey B?><?primarykey BlockingQueue?><?secondarykey THREAD POOL USE OF?><primary><emphasis role="strong">BlockingQueue</emphasis></primary><secondary>thread pool use of</secondary></indexterm><indexterm id="iddle1252" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey QUEUES?><?tertiarykey THREAD POOL USE OF?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>queues</secondary><tertiary>thread pool use of</tertiary></indexterm><indexterm id="iddle2383" significance="normal"><?indexkey F?><?primarykey flow control?><primary><emphasis role="strong">flow control</emphasis></primary></indexterm><indexterm id="iddle2384" significance="normal"><?indexkey F?><?primarykey flow control?><?secondarykey COMMUNICATION NETWORKS, THREAD POOL COMPARISON?><primary><emphasis role="strong">flow control</emphasis></primary><secondary>communication networks, thread pool comparison</secondary></indexterm><indexterm id="iddle2989" significance="normal"><?indexkey L?><?primarykey linked lists?><?secondarykey LINKEDBLOCKINGQUEUE?><?tertiarykey THREAD POOL USE OF?><primary><emphasis role="strong">linked lists</emphasis></primary><secondary><literal>LinkedBlockingQueue</literal></secondary><tertiary>thread pool use of</tertiary></indexterm><indexterm id="iddle3196" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey DEPLETION?><primary><emphasis role="strong">memory</emphasis></primary><secondary>depletion</secondary></indexterm><indexterm id="iddle3197" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey DEPLETION?><?tertiarykey AVOIDING REQUEST OVERLOAD?><primary><emphasis role="strong">memory</emphasis></primary><secondary>depletion</secondary><tertiary>avoiding request overload</tertiary></indexterm><indexterm id="iddle3664" significance="normal"><?indexkey P?><?primarykey PriorityBlockingQueue?><?secondarykey THREAD POOL USE OF?><primary><emphasis role="strong">PriorityBlockingQueue</emphasis></primary><secondary>thread pool use of</secondary></indexterm><indexterm id="iddle3767" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey SYNCHRONOUS?><?tertiarykey THREAD POOL USE OF?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>synchronous</secondary><tertiary>thread pool use of</tertiary></indexterm><indexterm id="iddle3893" significance="normal"><?indexkey R?><?primarykey resource exhaustion, preventing?><primary><emphasis role="strong">resource exhaustion, preventing</emphasis></primary></indexterm><indexterm id="iddle3894" significance="normal"><?indexkey R?><?primarykey resource exhaustion, preventing?><?secondarykey BOUNDED QUEUE USE?><primary><emphasis role="strong">resource exhaustion, preventing</emphasis></primary><secondary>bounded queue use</secondary></indexterm><indexterm id="iddle3973" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey THREAD?><?tertiarykey REQUEST OVERLOAD IMPACT?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>thread</secondary><tertiary>request overload impact</tertiary></indexterm><indexterm id="iddle4599" significance="normal"><?indexkey S?><?primarykey SynchronousQueue?><?secondarykey THREAD POOL USE OF?><primary><emphasis role="strong">SynchronousQueue</emphasis></primary><secondary>thread pool use of</secondary></indexterm><indexterm id="iddle4864" significance="normal"><?indexkey T?><?primarykey throttling?><?secondarykey AS OVERLOAD MANAGEMENT MECHANISM?><primary><emphasis role="strong">throttling</emphasis></primary><secondary>as overload management mechanism</secondary></indexterm><indexterm id="iddle4996" significance="normal"><?indexkey U?><?primarykey unbounded?><?secondarykey QUEUES?><?tertiarykey THREAD POOL USE OF?><primary><emphasis role="strong">unbounded</emphasis></primary><secondary>queues</secondary><tertiary>thread pool use of</tertiary></indexterm><indexterm id="iddle5160" significance="normal"><?indexkey W?><?primarykey work?><?secondarykey QUEUES?><?tertiarykey THREAD POOL INTERACTION, SIZE TUNING REQUIREMENTS?><primary><emphasis role="strong">work</emphasis></primary><secondary>queues</secondary><tertiary>thread pool interaction, size tuning requirements</tertiary></indexterm>handled, requests will still queue up. With a thread pool, they wait in a queue of <literal>Runnable</literal>s managed by the <literal>Executor</literal> instead of queueing up as threads contending for the CPU. Representing a waiting task with a <literal>Runnable</literal> and a list node is certainly a lot cheaper than with a thread, but the risk of resource exhaustion still remains if clients can throw requests at the server faster than it can handle them.</para>
<para>Requests often arrive in bursts even when the average request rate is fairly stable. Queues can help smooth out transient bursts of tasks, but if tasks continue to arrive too quickly you will eventually have to throttle the arrival rate to avoid running out of memory.<footnote id="ch08fn04" label="4"><para>This is analogous to flow control in communications networks: you may be willing to buffer a certain amount of data, but eventually you need to find a way to get the other side to stop sending you data, or throw the excess data on the floor and hope the sender retransmits it when you’re not so busy.</para></footnote> Even before you run out of memory, response time will get progressively worse as the task queue grows.</para>
<para><literal>ThreadPoolExecutor</literal> allows you to supply a <literal>BlockingQueue</literal> to hold tasks awaiting execution. There are three basic approaches to task queueing: unbounded queue, bounded queue, and synchronous handoff. The choice of queue interacts with other configuration parameters such as pool size.</para>
<para>The default for <literal>newFixedThreadPool</literal> and <literal>newSingleThreadExecutor</literal> is to use an unbounded <literal>LinkedBlockingQueue</literal>. Tasks will queue up if all worker threads are busy, but the queue could grow without bound if the tasks keep arriving faster than they can be executed.</para>
<para>A more stable resource management strategy is to use a bounded queue, such as an <literal>ArrayBlockingQueue</literal> or a bounded <literal>LinkedBlockingQueue</literal> or <literal>Priority-BlockingQueue</literal>. Bounded queues help prevent resource exhaustion but introduce the question of what to do with new tasks when the queue is full. (There are a number of possible <emphasis>saturation policies</emphasis> for addressing this problem; see <link linkend="ch08lev2sec5" preference="0">Section 8.3.3</link>.) With a bounded work queue, the queue size and pool size must be tuned together. A large queue coupled with a small pool can help reduce memory usage, CPU usage, and context switching, at the cost of potentially constraining throughput.</para>
<para>For very large or unbounded pools, you can also bypass queueing entirely and instead hand off tasks directly from producers to worker threads using a <literal>SynchronousQueue</literal>. A <literal>SynchronousQueue</literal> is not really a queue at all, but a mechanism for managing handoffs between threads. In order to put an element on a <literal>SynchronousQueue</literal>, another thread must already be waiting to accept the handoff. If no thread is waiting but the current pool size is less than the maximum, <literal>Thread-PoolExecutor</literal> creates a new thread; otherwise the task is rejected according to the saturation policy. Using a direct handoff is more efficient because the task can be handed right to the thread that will execute it, rather than first placing it on a queue and then having the worker thread fetch it from the queue. <literal>SynchronousQueue</literal> is a practical choice only if the pool is unbounded or if rejecting excess tasks is acceptable. The <literal>newCachedThreadPool</literal> factory uses a <literal>SynchronousQueue</literal>.</para>
<para>Using a FIFO queue like <literal>LinkedBlockingQueue</literal> or <literal>ArrayBlockingQueue</literal> causes tasks to be started in the order in which they arrived. For more control over task execution order, you can use a <literal>PriorityBlockingQueue</literal>, which <?docpage num="174"?><indexterm id="iddle1006" significance="normal"><?indexkey A?><?primarykey abort saturation policy?><primary><emphasis role="strong">abort saturation policy</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle1007" significance="normal"><?indexkey A?><?primarykey abort saturation policy?><primary><emphasis role="strong">abort saturation policy</emphasis></primary><seealso> <link linkend="iddle4835" preference="0"><emphasis role="strong">thread(s)</emphasis>, termination</link>.</seealso></indexterm><indexterm id="iddle1059" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey NONBLOCKING?><?tertiarykey SYNCHRONOUSQUEUE?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>nonblocking</secondary><tertiary><literal>SynchronousQueue</literal></tertiary></indexterm><indexterm id="iddle1250" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey QUEUES?><?tertiarykey SATURATION POLICIES?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>queues</secondary><tertiary>saturation policies</tertiary></indexterm><indexterm id="iddle1295" significance="normal"><?indexkey C?><?primarykey caller-runs saturation policy?><primary><emphasis role="strong">caller-runs saturation policy</emphasis></primary></indexterm><indexterm id="iddle1952" significance="normal"><?indexkey D?><?primarykey discard saturation policy?><primary><emphasis role="strong">discard saturation policy</emphasis></primary></indexterm><indexterm id="iddle1953" significance="normal"><?indexkey D?><?primarykey discard-oldest saturation policy?><primary><emphasis role="strong">discard-oldest saturation policy</emphasis></primary></indexterm><indexterm id="iddle2607" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey THREADS?><?tertiarykey POOLS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>threads</secondary><tertiary>pools</tertiary></indexterm><indexterm id="iddle3306" significance="normal"><?indexkey N?><?primarykey nonblocking algorithms?><?secondarykey SYNCHRONOUSQUEUE?><primary><emphasis role="strong">nonblocking algorithms</emphasis></primary><secondary><literal>SynchronousQueue</literal></secondary></indexterm><indexterm id="iddle3532" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey SYNCHRONOUSQUEUE?><primary><emphasis role="strong">performance</emphasis></primary><secondary><literal>SynchronousQueue</literal></secondary></indexterm><indexterm id="iddle3586" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SATURATION?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>saturation</secondary></indexterm><indexterm id="iddle3755" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey BOUNDED?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>bounded</secondary></indexterm><indexterm id="iddle3756" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey BOUNDED?><?tertiarykey SATURATION POLICIES?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>bounded</secondary><tertiary>saturation policies</tertiary></indexterm><indexterm id="iddle3828" significance="normal"><?indexkey R?><?primarykey RejectedExecutionException?><primary><emphasis role="strong">RejectedExecutionException</emphasis></primary></indexterm><indexterm id="iddle3829" significance="normal"><?indexkey R?><?primarykey RejectedExecutionException?><?secondarykey ABORT SATURATION POLICY USE?><primary><emphasis role="strong">RejectedExecutionException</emphasis></primary><secondary>abort saturation policy use</secondary></indexterm><indexterm id="iddle3832" significance="normal"><?indexkey R?><?primarykey RejectedExecutionHandler?><primary><emphasis role="strong">RejectedExecutionHandler</emphasis></primary></indexterm><indexterm id="iddle3833" significance="normal"><?indexkey R?><?primarykey RejectedExecutionHandler?><?secondarykey AND SATURATION POLICY?><primary><emphasis role="strong">RejectedExecutionHandler</emphasis></primary><secondary>and saturation policy</secondary></indexterm><indexterm id="iddle3925" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey SATURATION POLICIES?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>saturation policies</tertiary></indexterm><indexterm id="iddle4052" significance="normal"><?indexkey S?><?primarykey saturation?><primary><emphasis role="strong">saturation</emphasis></primary></indexterm><indexterm id="iddle4053" significance="normal"><?indexkey S?><?primarykey saturation?><?secondarykey POLICIES?><primary><emphasis role="strong">saturation</emphasis></primary><secondary>policies</secondary></indexterm><indexterm id="iddle4598" significance="normal"><?indexkey S?><?primarykey SynchronousQueue?><?secondarykey PERFORMANCE ADVANTAGES?><primary><emphasis role="strong">SynchronousQueue</emphasis></primary><secondary>performance advantages</secondary></indexterm><indexterm id="iddle4600" significance="normal"><?indexkey S?><?primarykey SynchronousQueue?><?secondarykey THREAD POOL USE OF?><primary><emphasis role="strong">SynchronousQueue</emphasis></primary><secondary>thread pool use of</secondary></indexterm><indexterm id="iddle4805" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey TASK QUEUE CONFIGURATION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>task queue configuration</tertiary></indexterm><indexterm id="iddle4865" significance="normal"><?indexkey T?><?primarykey throttling?><?secondarykey SATURATION POLICY USE?><primary><emphasis role="strong">throttling</emphasis></primary><secondary>saturation policy use</secondary></indexterm>orders tasks according to priority. Priority can be defined by natural order (if tasks implement <literal>Comparable</literal>) or by a <literal>Comparator</literal>.</para>
<sidebar float="1" id="ch08sb03" condition="174"><title/>
<para>The <literal>newCachedThreadPool</literal> factory is a good default choice for an <literal>Executor</literal>, providing better queuing performance than a fixed thread pool.<footnote id="ch08fn05" label="5"><para>This performance difference comes from the use of <literal>SynchronousQueue</literal> instead of <literal>LinkedBlocking-Queue</literal>. <literal>SynchronousQueue</literal> was replaced in Java 6 with a new nonblocking algorithm that improved throughput in <literal>Executor</literal> benchmarks by a factor of three over the Java 5.0 <literal>SynchronousQueue</literal> implementation (<link linkend="biblio01_030" preference="0">Scherer et al., 2006</link>).</para></footnote> A fixed size thread pool is a good choice when you need to limit the number of concurrent tasks for resource-management purposes, as in a server application that accepts requests from network clients and would otherwise be vulnerable to overload.</para>
</sidebar>
<para>Bounding either the thread pool or the work queue is suitable only when tasks are independent. With tasks that depend on other tasks, bounded thread pools or queues can cause thread starvation deadlock; instead, use an unbounded pool configuration like <literal>newCachedThreadPool</literal>.<footnote id="ch08fn06" label="6"><para>An alternative configuration for tasks that submit other tasks and wait for their results is to use a bounded thread pool, a <literal>SynchronousQueue</literal> as the work queue, and the caller-runs saturation policy.</para></footnote></para>
</section>
<section id="ch08lev2sec5" label="8.3.3" xreflabel="8.3.3">
<title id="ch08lev2sec5__title">Saturation Policies</title>
<para>When a bounded work queue fills up, the <emphasis>saturation policy</emphasis> comes into play. The saturation policy for a <literal>ThreadPoolExecutor</literal> can be modified by calling <literal>setRejectedExecutionHandler</literal>. (The saturation policy is also used when a task is submitted to an <literal>Executor</literal> that has been shut down.) Several implementations of <literal>RejectedExecutionHandler</literal> are provided, each implementing a different saturation policy: <literal>AbortPolicy</literal>, <literal>CallerRunsPolicy</literal>, <literal>DiscardPolicy</literal>, and <literal>DiscardOldestPolicy</literal>.</para>
<para>The default policy, <emphasis>abort</emphasis>, causes <literal>execute</literal> to throw the unchecked <literal>Rejected-ExecutionException</literal>; the caller can catch this exception and implement its own overflow handling as it sees fit. The <emphasis>discard</emphasis> policy silently discards the newly submitted task if it cannot be queued for execution; the <emphasis>discard-oldest</emphasis> policy discards the task that would otherwise be executed next and tries to resubmit the new task. (If the work queue is a priority queue, this discards the highest-priority element, so the combination of a discard-oldest saturation policy and a priority queue is not a good one.)</para>
<para>The <emphasis>caller-runs</emphasis> policy implements a form of throttling that neither discards tasks nor throws an exception, but instead tries to slow down the flow of new tasks by pushing some of the work back to the caller. It executes the newly submitted task not in a pool thread, but in the thread that calls <literal>execute</literal>. If we modified our <literal>WebServer</literal> example to use a bounded queue and the caller-runs policy, after all the pool threads were occupied and the work queue filled up the next task would be executed in the main thread during the call to <literal>execute</literal>. Since <?docpage num="175"?><indexterm id="iddle1527" significance="normal"><?indexkey C?><?primarykey configuration?><?secondarykey THREAD CREATION?><primary><emphasis role="strong">configuration</emphasis></primary><secondary>thread creation</secondary></indexterm><indexterm id="iddle1528" significance="normal"><?indexkey C?><?primarykey configuration?><?secondarykey THREAD CREATION?><?tertiarykey AND THREAD FACTORIES?><primary><emphasis role="strong">configuration</emphasis></primary><secondary>thread creation</secondary><tertiary>and thread factories</tertiary></indexterm><indexterm id="iddle1731" significance="normal"><?indexkey C?><?primarykey creation?><?secondarykey THREAD?><?tertiarykey THREAD FACTORY USE?><primary><emphasis role="strong">creation</emphasis></primary><secondary>thread</secondary><tertiary>thread factory use</tertiary></indexterm><indexterm id="iddle1736" significance="normal"><?indexkey C?><?primarykey customization?><primary><emphasis role="strong">customization</emphasis></primary></indexterm><indexterm id="iddle1737" significance="normal"><?indexkey C?><?primarykey customization?><?secondarykey THREAD CONFIGURATION?><primary><emphasis role="strong">customization</emphasis></primary><secondary>thread configuration</secondary></indexterm><indexterm id="iddle1738" significance="normal"><?indexkey C?><?primarykey customization?><?secondarykey THREAD CONFIGURATION?><?tertiarykey THREADFACTORY USE?><primary><emphasis role="strong">customization</emphasis></primary><secondary>thread configuration</secondary><tertiary><literal>ThreadFactory</literal> use</tertiary></indexterm><indexterm id="iddle1831" significance="normal"><?indexkey D?><?primarykey debugging?><?secondarykey CUSTOM THREAD FACTORY AS AID FOR?><primary><emphasis role="strong">debugging</emphasis></primary><secondary>custom thread factory as aid for</secondary></indexterm><indexterm id="iddle2090" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BOUNDEDEXECUTOR?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BoundedExecutor</literal></secondary></indexterm><indexterm id="iddle2298" significance="normal"><?indexkey F?><?primarykey factory(s)?><?secondarykey THREAD?><primary><emphasis role="strong">factory(s)</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle2299" significance="normal"><?indexkey F?><?primarykey factory(s)?><?secondarykey THREAD?><primary><emphasis role="strong">factory(s)</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle2459" significance="normal"><?indexkey G?><?primarykey graceful?><?secondarykey DEGRADATION?><?tertiarykey AND SATURATION POLICY?><primary><emphasis role="strong">graceful</emphasis></primary><secondary>degradation</secondary><tertiary>and saturation policy</tertiary></indexterm><indexterm id="iddle3923" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey GRACEFUL DEGRADATION, SATURATION POLICY ADVANTAGES?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>graceful degradation, saturation policy advantages</tertiary></indexterm><indexterm id="iddle4142" significance="normal"><?indexkey S?><?primarykey Semaphore?><?secondarykey SATURATION POLICY USE?><primary><emphasis role="strong">Semaphore</emphasis></primary><secondary>saturation policy use</secondary></indexterm><indexterm id="iddle4771" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey FACTORIES?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>factories</secondary></indexterm><indexterm id="iddle4772" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey FACTORIES?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>factories</secondary></indexterm><indexterm id="iddle4846" significance="normal"><?indexkey T?><?primarykey ThreadFactory?><?secondarykey CUSTOMIZING THREAD POOL WITH?><primary><emphasis role="strong">ThreadFactory</emphasis></primary><secondary>customizing thread pool with</secondary></indexterm><indexterm id="iddle5001" significance="normal"><?indexkey U?><?primarykey UncaughtExceptionHandler?><?secondarykey CUSTOM THREAD CLASS USE?><primary><emphasis role="strong">UncaughtExceptionHandler</emphasis></primary><secondary>custom thread class use</secondary></indexterm>this would probably take some time, the main thread cannot submit any more tasks for at least a little while, giving the worker threads some time to catch up on the backlog. The main thread would also not be calling <literal>accept</literal> during this time, so incoming requests will queue up in the TCP layer instead of in the application. If the overload persisted, eventually the TCP layer would decide it has queued enough connection requests and begin discarding connection requests as well. As the server becomes overloaded, the overload is gradually pushed outward—from the pool threads to the work queue to the application to the TCP layer, and eventually to the client—enabling more graceful degradation under load.</para>
<para>Choosing a saturation policy or making other changes to the execution policy can be done when the <literal>Executor</literal> is created. <link linkend="ch08list03" preference="0">Listing 8.3</link> illustrates creating a fixedsize thread pool with the caller-runs saturation policy.</para>
<example id="ch08list03" label="8.3" role="Listing" xreflabel="8.3" condition="175">
<title id="ch08list03__title">Creating a Fixed-sized Thread Pool with a Bounded Queue and the Caller-runs Saturation Policy.</title>
<programlisting format="linespecific" linenumbering="unnumbered">ThreadPoolExecutor executor
    = new ThreadPoolExecutor(N_THREADS, N_THREADS,
        0L, TimeUnit.MILLISECONDS,
        new LinkedBlockingQueue&lt;Runnable&gt;(CAPACITY));
executor.setRejectedExecutionHandler(
    new ThreadPoolExecutor.CallerRunsPolicy());
</programlisting>
</example>
<para>There is no predefined saturation policy to make <literal>execute</literal> block when the work queue is full. However, the same effect can be accomplished by using a <literal>Semaphore</literal> to bound the task injection rate, as shown in <literal>BoundedExecutor</literal> in <link linkend="ch08list04" preference="0">Listing 8.4</link>. In such an approach, use an unbounded queue (there’s no reason to bound both the queue size and the injection rate) and set the bound on the semaphore to be equal to the pool size <emphasis>plus</emphasis> the number of queued tasks you want to allow, since the semaphore is bounding the number of tasks both currently executing and awaiting execution.</para>
</section>
<section id="ch08lev2sec6" label="8.3.4" xreflabel="8.3.4">
<title id="ch08lev2sec6__title">Thread Factories</title>
<para>Whenever a thread pool needs to create a thread, it does so through a <emphasis>thread factory</emphasis> (see <link linkend="ch08list05" preference="0">Listing 8.5</link>). The default thread factory creates a new, nondaemon thread with no special configuration. Specifying a thread factory allows you to customize the configuration of pool threads. <literal>ThreadFactory</literal> has a single method, <literal>newThread</literal>, that is called whenever a thread pool needs to create a new thread.</para>
<para>There are a number of reasons to use a custom thread factory. You might want to specify an <literal>UncaughtExceptionHandler</literal> for pool threads, or instantiate an instance of a custom <literal>Thread</literal> class, such as one that performs debug logging. You might want to modify the priority (generally not a very good idea; see <link linkend="ch10lev2sec8" preference="0">Section 10.3.1</link>) or set the daemon status (again, not all that good an idea; see <link linkend="ch07lev2sec15" preference="0">Section 7.4.2</link>) of pool threads. Or maybe you just want to give pool threads more meaningful names to simplify interpreting thread dumps and error logs.</para>

<para><?docpage num="176"?></para><example id="ch08list04" label="8.4" role="Listing" xreflabel="8.4" condition="176">

<title id="ch08list04__title">Using a <literal>Semaphore</literal> to Throttle Task Submission.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class BoundedExecutor {
    private final Executor exec;
    private final Semaphore semaphore;

    public BoundedExecutor(Executor exec, int bound) {
        this.exec = exec;
        this.semaphore = new Semaphore(bound);
    }

    public void submitTask(final Runnable command)
            throws InterruptedException {
        semaphore.acquire();
        try {
            exec.execute(new Runnable() {
                public void run() {
                    try {
                        command.run();
                    } finally {
                        semaphore.release();
                    }
                }
            });
        } catch (RejectedExecutionException e) {
            semaphore.release();
        }
    }
}
</programlisting>
</example>
<example id="ch08list05" label="8.5" role="Listing" xreflabel="8.5" condition="176">
<title id="ch08list05__title"><literal>ThreadFactory</literal> Interface.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface ThreadFactory {
    Thread newThread(Runnable r);
}
</programlisting>
</example>
<para><?docpage num="177"?><?docpage num="178"?><indexterm id="iddle4139" significance="normal"><?indexkey S?><?primarykey Semaphore?><?secondarykey EXAMPLE USE?><primary><emphasis role="strong">Semaphore</emphasis></primary><secondary>example use</secondary></indexterm><indexterm id="iddle4845" significance="normal"><?indexkey T?><?primarykey ThreadFactory?><primary><emphasis role="strong">ThreadFactory</emphasis></primary></indexterm><indexterm id="iddle4866" significance="normal"><?indexkey T?><?primarykey throttling?><?secondarykey SEMAPHORE USE IN BOUNDEDEXECUTOR EXAMPLE?><primary><emphasis role="strong">throttling</emphasis></primary><secondary><literal>Semaphore</literal> use in <literal>BoundedExecutor</literal> example</secondary></indexterm><indexterm id="iddle1032" significance="normal"><?indexkey A?><?primarykey AccessControlContext?><primary><emphasis role="strong">AccessControlContext</emphasis></primary></indexterm><indexterm id="iddle1033" significance="normal"><?indexkey A?><?primarykey AccessControlContext?><?secondarykey CUSTOM THREAD FACTORY HANDLING?><primary><emphasis role="strong">AccessControlContext</emphasis></primary><secondary>custom thread factory handling</secondary></indexterm><indexterm id="iddle1477" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey PREVENTION?><?tertiarykey SINGLE-THREADED EXECUTOR USE?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>prevention</secondary><tertiary>single-threaded executor use</tertiary></indexterm><indexterm id="iddle1529" significance="normal"><?indexkey C?><?primarykey configuration?><?secondarykey THREAD POOL?><primary><emphasis role="strong">configuration</emphasis></primary><secondary>thread pool</secondary></indexterm><indexterm id="iddle1530" significance="normal"><?indexkey C?><?primarykey configuration?><?secondarykey THREAD POOL?><?tertiarykey POST-CONSTRUCTION MANIPULATION?><primary><emphasis role="strong">configuration</emphasis></primary><secondary>thread pool</secondary><tertiary>post-construction manipulation</tertiary></indexterm><indexterm id="iddle1575" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey THREADPOOLEXECUTOR?><?tertiarykey POST-CONSTRUCTION CUSTOMIZATION?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary><literal>ThreadPoolExecutor</literal></secondary><tertiary>post-construction customization</tertiary></indexterm><indexterm id="iddle1739" significance="normal"><?indexkey C?><?primarykey customization?><?secondarykey THREAD POOL CONFIGURATION?><primary><emphasis role="strong">customization</emphasis></primary><secondary>thread pool configuration</secondary></indexterm><indexterm id="iddle1740" significance="normal"><?indexkey C?><?primarykey customization?><?secondarykey THREAD POOL CONFIGURATION?><?tertiarykey POST-CONSTRUCTION?><primary><emphasis role="strong">customization</emphasis></primary><secondary>thread pool configuration</secondary><tertiary>post-construction</tertiary></indexterm><indexterm id="iddle2142" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MYAPPTHREAD?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>MyAppThread</literal></secondary></indexterm><indexterm id="iddle2144" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MYTHREADFACTORY?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>MyThreadFactory</literal></secondary></indexterm><indexterm id="iddle3171" significance="normal"><?indexkey L?><?primarykey logging?><?secondarykey THREAD CUSTOMIZATION EXAMPLE?><primary><emphasis role="strong">logging</emphasis></primary><secondary>thread customization example</secondary></indexterm><indexterm id="iddle3548" significance="normal"><?indexkey P?><?primarykey permission?><primary><emphasis role="strong">permission</emphasis></primary></indexterm><indexterm id="iddle3549" significance="normal"><?indexkey P?><?primarykey permission?><?secondarykey CODEBASE?><primary><emphasis role="strong">permission</emphasis></primary><secondary>codebase</secondary></indexterm><indexterm id="iddle3550" significance="normal"><?indexkey P?><?primarykey permission?><?secondarykey CODEBASE?><?tertiarykey AND CUSTOM THREAD FACTORY?><primary><emphasis role="strong">permission</emphasis></primary><secondary>codebase</secondary><tertiary>and custom thread factory</tertiary></indexterm><indexterm id="iddle3587" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SECURITY?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>security</secondary></indexterm><indexterm id="iddle3588" significance="normal"><?indexkey P?><?primarykey policy(s)?><?secondarykey SECURITY?><?tertiarykey CUSTOM THREAD FACTORY HANDLING?><primary><emphasis role="strong">policy(s)</emphasis></primary><secondary>security</secondary><tertiary>custom thread factory handling</tertiary></indexterm><indexterm id="iddle3626" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey CONFIGURATION POST-CONSTRUCTION MANIPULATION?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>configuration post-construction manipulation</tertiary></indexterm><indexterm id="iddle4116" significance="normal"><?indexkey S?><?primarykey security policies?><primary><emphasis role="strong">security policies</emphasis></primary></indexterm><indexterm id="iddle4117" significance="normal"><?indexkey S?><?primarykey security policies?><?secondarykey AND CUSTOM THREAD FACTORY?><primary><emphasis role="strong">security policies</emphasis></primary><secondary>and custom thread factory</secondary></indexterm><indexterm id="iddle4304" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><?secondarykey TASK EXECUTION?><?tertiarykey EXECUTOR USE, CONCURRENCY PREVENTION?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><secondary>task execution</secondary><tertiary>executor use, concurrency prevention</tertiary></indexterm><indexterm id="iddle4802" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey POST-CONSTRUCTION CONFIGURATION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>post-construction configuration</tertiary></indexterm><literal>MyThreadFactory</literal> in <link linkend="ch08list06" preference="0">Listing 8.6</link> illustrates a custom thread factory. It instantiates a new <literal>MyAppThread</literal>, passing a pool-specific name to the constructor so that threads from each pool can be distinguished in thread dumps and error logs. <literal>My-AppThread</literal> can also be used elsewhere in the application so that all threads can take advantage of its debugging features.</para>
<example id="ch08list06" label="8.6" role="Listing" xreflabel="8.6" condition="177">
<title id="ch08list06__title">Custom Thread Factory.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class MyThreadFactory implements ThreadFactory {
    private final String poolName;

    public MyThreadFactory(String poolName) {
        this.poolName = poolName;
    }

    public Thread newThread(Runnable runnable) {
        return new MyAppThread(runnable, poolName);
    }
}
</programlisting>
</example>
<para>The interesting customization takes place in <literal>MyAppThread</literal>, shown in <link linkend="ch08list07" preference="0">Listing 8.7</link>, which lets you provide a thread name, sets a custom <literal>UncaughtException-Handler</literal> that writes a message to a <literal>Logger</literal>, maintains statistics on how many threads have been created and destroyed, and optionally writes a debug message to the log when a thread is created or terminates.</para>
<para>If your application takes advantage of <emphasis>security policies</emphasis> to grant permissions to particular codebases, you may want to use the <literal>privilegedThreadFactory</literal> factory method in <literal>Executors</literal> to construct your thread factory. It creates pool threads that have the same permissions, <literal>AccessControlContext</literal>, and <literal>contextClassLoader</literal> as the thread creating the <literal>privilegedThreadFactory</literal>. Otherwise, threads created by the thread pool inherit permissions from whatever client happens to be calling <literal>execute</literal> or <literal>submit</literal> at the time a new thread is needed, which could cause confusing security-related exceptions.</para>
</section>
<section id="ch08lev2sec7" label="8.3.5" xreflabel="8.3.5">
<title id="ch08lev2sec7__title">Customizing ThreadPoolExecutor After Construction</title>
<para>Most of the options passed to the <literal>ThreadPoolExecutor</literal> constructors can also be modified after construction via setters (such as the core thread pool size, maximum thread pool size, keep-alive time, thread factory, and rejected execution handler). If the <literal>Executor</literal> is created through one of the factory methods in <literal>Executors</literal> (except <literal>newSingleThreadExecutor</literal>), you can cast the result to <literal>Thread-PoolExecutor</literal> to access the setters as in <link linkend="ch08list08" preference="0">Listing 8.8</link>.</para>
<para><literal>Executors</literal> includes a factory method, <literal>unconfigurableExecutorService</literal>, which takes an existing <literal>ExecutorService</literal> and wraps it with one exposing only the methods of <literal>ExecutorService</literal> so it cannot be further configured. Unlike the pooled implementations, <literal>newSingleThreadExecutor</literal> returns an <literal>ExecutorService</literal> wrapped in this manner, rather than a raw <literal>ThreadPoolExecutor</literal>. While <?docpage num="179"?><indexterm id="iddle2143" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey MYAPPTHREAD?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>MyAppThread</literal></secondary></indexterm><indexterm id="iddle1165" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey STATISTICS GATHERING HOOKS USE?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>statistics gathering hooks use</secondary></indexterm><indexterm id="iddle2289" significance="normal"><?indexkey E?><?primarykey extending?><?secondarykey THREADPOOLEXECUTOR?><primary><emphasis role="strong">extending</emphasis></primary><secondary><literal>ThreadPoolExecutor</literal></secondary></indexterm><indexterm id="iddle2652" significance="normal"><?indexkey H?><?primarykey hooks?><?secondarykey THREADPOOLEXECUTOR EXTENSION?><primary><emphasis role="strong">hooks</emphasis></primary><secondary><literal>ThreadPoolExecutor</literal> extension</secondary></indexterm><indexterm id="iddle2764" significance="normal"><?indexkey I?><?primarykey instrumentation?><?secondarykey THREADPOOLEXECUTOR HOOKS FOR?><primary><emphasis role="strong">instrumentation</emphasis></primary><secondary><literal>ThreadPoolExecutor</literal> hooks for</secondary></indexterm><indexterm id="iddle3172" significance="normal"><?indexkey L?><?primarykey logging?><?secondarykey THREADPOOLEXECUTOR HOOKS FOR?><primary><emphasis role="strong">logging</emphasis></primary><secondary><literal>ThreadPoolExecutor</literal> hooks for</secondary></indexterm><indexterm id="iddle3191" significance="normal"><?indexkey M?><?primarykey measurement?><?secondarykey THREADPOOLEXECUTOR HOOKS FOR?><primary><emphasis role="strong">measurement</emphasis></primary><secondary><literal>ThreadPoolExecutor</literal> hooks for</secondary></indexterm><indexterm id="iddle3253" significance="normal"><?indexkey M?><?primarykey monitoring?><?secondarykey THREADPOOLEXECUTOR HOOKS FOR?><primary><emphasis role="strong">monitoring</emphasis></primary><secondary><literal>ThreadPoolExecutor</literal> hooks for</secondary></indexterm><indexterm id="iddle3620" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey ADDING STATISTICS TO?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>adding statistics to</tertiary></indexterm><indexterm id="iddle4443" significance="normal"><?indexkey S?><?primarykey statistics gathering?><?secondarykey ADDING TO THREAD POOLS?><primary><emphasis role="strong">statistics gathering</emphasis></primary><secondary>adding to thread pools</secondary></indexterm><indexterm id="iddle4444" significance="normal"><?indexkey S?><?primarykey statistics gathering?><?secondarykey THREADPOOLEXECUTOR HOOKS FOR?><primary><emphasis role="strong">statistics gathering</emphasis></primary><secondary><literal>ThreadPoolExecutor</literal> hooks for</secondary></indexterm><indexterm id="iddle4793" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey ADDING STATISTICS TO?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>adding statistics to</tertiary></indexterm><indexterm id="iddle4857" significance="normal"><?indexkey T?><?primarykey ThreadPoolExecutor?><?secondarykey EXTENSION HOOKS?><primary><emphasis role="strong">ThreadPoolExecutor</emphasis></primary><secondary>extension hooks</secondary></indexterm><indexterm id="iddle4914" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey MEASURING?><?tertiarykey THREADPOOLEXECUTOR HOOKS FOR?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>measuring</secondary><tertiary><literal>ThreadPoolExecutor</literal> hooks for</tertiary></indexterm><indexterm id="iddle5012" significance="normal"><?indexkey U?><?primarykey untrusted code behavior?><?secondarykey EXECUTORSERVICE CODE PROTECTION STRATEGIES?><primary><emphasis role="strong">untrusted code behavior</emphasis></primary><secondary><literal>ExecutorService</literal> code protection strategies</secondary></indexterm>a single-threaded executor is actually implemented as a thread pool with one thread, it also promises not to execute tasks concurrently. If some misguided code were to increase the pool size on a single-threaded executor, it would undermine the intended execution semantics.</para>
<example id="ch08list07" label="8.7" role="Listing" xreflabel="8.7" condition="178">
<?docpage num="178"?>
<title id="ch08list07__title">Custom Thread Base Class.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class MyAppThread extends Thread {
    public static final String DEFAULT_NAME = "MyAppThread";
    private static volatile boolean debugLifecycle = false;
    private static final AtomicInteger created = new AtomicInteger();
    private static final AtomicInteger alive = new AtomicInteger();
    private static final Logger log = Logger.getAnonymousLogger();

    public MyAppThread(Runnable r) { this(r, DEFAULT_NAME); }

    public MyAppThread(Runnable runnable, String name) {
        super(runnable, name + "-" + created.incrementAndGet());
        setUncaughtExceptionHandler(
            new Thread.UncaughtExceptionHandler() {
                public void uncaughtException(Thread t,
                                              Throwable e) {
                    log.log(Level.SEVERE,
                        "UNCAUGHT in thread " + t.getName(), e);
                }
            });
    }

    public void run() {
        // <emphasis>Copy debug flag to ensure consistent value throughout.</emphasis>
        boolean debug = debugLifecycle;
        if (debug) log.log(Level.FINE, "Created "+getName());
        try {
            alive.incrementAndGet();
            super.run();
        } finally {
            alive.decrementAndGet();
            if (debug) log.log(Level.FINE, "Exiting "+getName());
        }
    }

    public static int getThreadsCreated() { return created.get(); }
    public static int getThreadsAlive() { return alive.get(); }
    public static boolean getDebug() { return debugLifecycle; }
    public static void setDebug(boolean b) { debugLifecycle = b; }
}
</programlisting>
</example>
<example id="ch08list08" label="8.8" role="Listing" xreflabel="8.8" condition="179">
<title id="ch08list08__title">Modifying an <literal>Executor</literal> Created with the Standard Factories.</title>
<programlisting format="linespecific" linenumbering="unnumbered">ExecutorService exec = Executors.newCachedThreadPool();
if (exec instanceof ThreadPoolExecutor)
    ((ThreadPoolExecutor) exec).setCorePoolSize(10);
else
    throw new AssertionError("Oops, bad assumption");
</programlisting>
</example>
<para>You can use this technique with your own executors to prevent the execution policy from being modified. If you will be exposing an <literal>ExecutorService</literal> to code you don’t trust not to modify it, you can wrap it with an <literal>unconfigurableExecutorService</literal>.</para>
</section>
</section>
<section id="ch08lev1sec4" condition="179" label="8.4" xreflabel="8.4"><?docpage num="179"?>
<title id="ch08lev1sec4__title">Extending ThreadPoolExecutor</title>
<para><literal>ThreadPoolExecutor</literal> was designed for extension, providing several “hooks” for subclasses to override—<literal>beforeExecute</literal>, <literal>afterExecute</literal>, and <literal>terminated</literal>—that can be used to extend the behavior of <literal>ThreadPoolExecutor</literal>.</para>
<para>The <literal>beforeExecute</literal> and <literal>afterExecute</literal> hooks are called in the thread that executes the task, and can be used for adding logging, timing, monitoring, or statistics gathering. The <literal>afterExecute</literal> hook is called whether the task completes by returning normally from <literal>run</literal> or by throwing an <literal>Exception</literal>. (If the task completes with an <literal>Error</literal>, <literal>afterExecute</literal> is not called.) If <literal>beforeExecute</literal> throws a <literal>RuntimeException</literal>, the task is not executed and <literal>afterExecute</literal> is not called.</para>
<para>The <literal>terminated</literal> hook is called when the thread pool completes the shutdown process, after all tasks have finished and all worker threads have shut down. It can be used to release resources allocated by the <literal>Executor</literal> during its lifecycle, perform notification or logging, or finalize statistics gathering.</para>
<section id="ch08lev2sec8" label="8.4.1" xreflabel="8.4.1">
<title id="ch08lev2sec8__title">Example: Adding Statistics to a Thread Pool</title>
<para><literal>TimingThreadPool</literal> in <link linkend="ch08list09" preference="0">Listing 8.9</link> shows a custom thread pool that uses <literal>before-Execute</literal>, <literal>afterExecute</literal>, and <literal>terminated</literal> to add logging and statistics gathering. To measure a task’s runtime, <literal>beforeExecute</literal> must record the start time and store it somewhere <literal>afterExecute</literal> can find it. Because execution hooks are called in the thread that executes the task, a value placed in a <literal>ThreadLocal</literal> by <literal>beforeExecute</literal> can be retrieved by <literal>afterExecute</literal>. <literal>TimingThreadPool</literal> uses a pair of <literal>AtomicLong</literal>s to keep track of the total number of tasks processed and the total processing time, and uses the <literal>terminated</literal> hook to print a log message showing the average task time.</para>

<para><?docpage num="180"?></para><example id="ch08list09" label="8.9" role="Listing" xreflabel="8.9" condition="180">

<title id="ch08list09__title">Thread Pool Extended with Logging and Timing.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class TimingThreadPool extends ThreadPoolExecutor {
    private final ThreadLocal&lt;Long&gt; startTime
            = new ThreadLocal&lt;Long&gt;();
    private final Logger log = Logger.getLogger("TimingThreadPool");
    private final AtomicLong numTasks = new AtomicLong();
    private final AtomicLong totalTime = new AtomicLong();

    protected void beforeExecute(Thread t, Runnable r) {
        super.beforeExecute(t, r);
        log.fine(String.format("Thread %s: start %s", t, r));
        startTime.set(System.nanoTime());
    }

    protected void afterExecute(Runnable r, Throwable t) {
        try {
            long endTime = System.nanoTime();
            long taskTime = endTime - startTime.get();
            numTasks.incrementAndGet();
            totalTime.addAndGet(taskTime);
            log.fine(String.format("Thread %s: end %s, time=%dns",
                    t, r, taskTime));
        } finally {
            super.afterExecute(r, t);
        }
    }

    protected void terminated() {
        try {
            log.info(String.format("Terminated: avg time=%dns",
                    totalTime.get() / numTasks.get()));
        } finally {
            super.terminated();
        }
    }
}
</programlisting>
</example>
</section>
</section>
<section id="ch08lev1sec5" condition="181" label="8.5" xreflabel="8.5">
<?docpage num="181"?>
<title id="ch08lev1sec5__title">Parallelizing Recursive Algorithms</title>
<para><indexterm id="iddle2206" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey TIMINGTHREADPOOL?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>TimingThreadPool</literal></secondary></indexterm><indexterm id="iddle1062" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey RECURSIVE?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>recursive</secondary></indexterm><indexterm id="iddle1063" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey RECURSIVE?><?tertiarykey PARALLELIZING?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>recursive</secondary><tertiary>parallelizing</tertiary></indexterm><indexterm id="iddle1915" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PARALLELIZATION CRITERIA?><primary><emphasis role="strong">design</emphasis></primary><secondary>parallelization criteria</secondary></indexterm><indexterm id="iddle2577" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SEQUENTIAL LOOPS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>sequential loops</secondary></indexterm><indexterm id="iddle2578" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SEQUENTIAL LOOPS?><?tertiarykey PARALLELIZATION CRITERIA?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>sequential loops</secondary><tertiary>parallelization criteria</tertiary></indexterm><indexterm id="iddle2884" significance="normal"><?indexkey I?><?primarykey iterators/iteration?><?secondarykey PARALLELIZATION OF?><primary><emphasis role="strong">iterators/iteration</emphasis></primary><secondary>parallelization of</secondary></indexterm><indexterm id="iddle3455" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey RECURSIVE ALGORITHMS?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>recursive algorithms</secondary></indexterm><indexterm id="iddle3804" significance="normal"><?indexkey R?><?primarykey recursion?><?secondarykey PARALLELIZING?><primary><emphasis role="strong">recursion</emphasis></primary><secondary>parallelizing</secondary><seealso> <link linkend="iddle5168" preference="0"><emphasis role="strong">wrapper(s)</emphasis>, factories, Decorator pattern</link>.</seealso></indexterm><indexterm id="iddle4115" significance="normal"><?indexkey S?><?primarykey search?><?secondarykey DEPTH-FIRST?><?tertiarykey PARALLELIZATION OF?><primary><emphasis role="strong">search</emphasis></primary><secondary>depth-first</secondary><tertiary>parallelization of</tertiary></indexterm><indexterm id="iddle4165" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey EXECUTION?><?tertiarykey PARALLELIZATION OF?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>execution</secondary><tertiary>parallelization of</tertiary></indexterm><indexterm id="iddle4967" significance="normal"><?indexkey T?><?primarykey tree(s)?><?secondarykey TRAVERSAL?><primary><emphasis role="strong">tree(s)</emphasis></primary><secondary>traversal</secondary></indexterm><indexterm id="iddle4968" significance="normal"><?indexkey T?><?primarykey tree(s)?><?secondarykey TRAVERSAL?><?tertiarykey PARALLELIZATION OF?><primary><emphasis role="strong">tree(s)</emphasis></primary><secondary>traversal</secondary><tertiary>parallelization of</tertiary></indexterm>The page rendering examples in <link linkend="ch06list03" preference="0">Section 6.3</link> went through a series of refinements in search of exploitable parallelism. The first attempt was entirely sequential; the second used two threads but still performed all the image downloads sequentially; the final version treated each image download as a separate task to achieve greater parallelism. Loops whose bodies contain nontrivial computation or perform potentially blocking I/O are frequently good candidates for parallelization, as long as the iterations are independent.</para>
<para>If we have a loop whose iterations are independent and we don’t need to wait for all of them to complete before proceeding, we can use an <literal>Executor</literal> to transform a sequential loop into a parallel one, as shown in <literal>processSequentially</literal> and <literal>processInParallel</literal> in <link linkend="ch08list10" preference="0">Listing 8.10</link>.</para>
<example id="ch08list10" label="8.10" role="Listing" xreflabel="8.10" condition="181">
<title id="ch08list10__title">Transforming Sequential Execution into Parallel Execution.</title>
<programlisting format="linespecific" linenumbering="unnumbered">void processSequentially(List&lt;Element&gt; elements) {
    for (Element e : elements)
        process(e);
}

void processInParallel(Executor exec, List&lt;Element&gt; elements) {
    for (final Element e : elements)
        exec.execute(new Runnable() {
            public void run() { process(e); }
        });
}
</programlisting>
</example>
<para>A call to <literal>processInParallel</literal> returns more quickly than a call to <literal>processSequentially</literal> because it returns as soon as all the tasks are queued to the <literal>Executor</literal>, rather than waiting for them all to complete. If you want to submit a set of tasks and wait for them all to complete, you can use <literal>ExecutorService.invokeAll</literal>; to retrieve the results as they become available, you can use a <literal>CompletionService</literal>, as in <literal>Renderer</literal> on page <link linkend="ch06list15" preference="0" role="pageref">130</link>.</para>
<sidebar float="1" id="ch08sb04" condition="181"><title/>
<para>Sequential loop iterations are suitable for parallelization when each iteration is independent of the others and the work done in each iteration of the loop body is significant enough to offset the cost of managing a new task.</para>
</sidebar>
<para>Loop parallelization can also be applied to some recursive designs; there are often sequential loops within the recursive algorithm that can be parallelized in the same manner as <link linkend="ch08list10" preference="0">Listing 8.10</link>. The easier case is when each iteration does not require the results of the recursive iterations it invokes. For example, <literal>sequentialRecursive</literal> in <link linkend="ch08list11" preference="0">Listing 8.11</link> does a depth-first traversal of a tree, performing a <?docpage num="182"?>calculation on each node and placing the result in a collection. The transformed version, <literal>parallelRecursive</literal>, also does a depth-first traversal, but instead of computing the result as each node is visited, it submits a task to compute the node result.</para>
<example id="ch08list11" label="8.11" role="Listing" xreflabel="8.11" condition="182">
<title id="ch08list11__title">Transforming Sequential Tail-recursion into Parallelized Recursion.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public&lt;T&gt; void sequentialRecursive(List&lt;Node&lt;T&gt;&gt; nodes,
                                   Collection&lt;T&gt; results) {
    for (Node&lt;T&gt; n : nodes) {
        results.add(n.compute());
        sequentialRecursive(n.getChildren(), results);
    }
}

public&lt;T&gt; void parallelRecursive(final Executor exec,
                                 List&lt;Node&lt;T&gt;&gt; nodes,
                                 final Collection&lt;T&gt; results) {
    for (final Node&lt;T&gt; n : nodes) {
        exec.execute(new Runnable() {
            public void run() {
                results.add(n.compute());
            }
        });
        parallelRecursive(exec, n.getChildren(), results);
    }
}
</programlisting>
</example>
<para>When <literal>parallelRecursive</literal> returns, each node in the tree has been visited (the traversal is still sequential: only the calls to <literal>compute</literal> are executed in parallel) and the computation for each node has been queued to the <literal>Executor</literal>. Callers of <literal>parallelRecursive</literal> can wait for all the results by creating an <literal>Executor</literal> specific to the traversal and using <literal>shutdown</literal> and <literal>awaitTermination</literal>, as shown in <link linkend="ch08list12" preference="0">Listing 8.12</link>.</para>
<example id="ch08list12" label="8.12" role="Listing" xreflabel="8.12" condition="182">
<title id="ch08list12__title">Waiting for Results to be Calculated in Parallel.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public&lt;T&gt; Collection&lt;T&gt; getParallelResults(List&lt;Node&lt;T&gt;&gt; nodes)
        throws InterruptedException {
    ExecutorService exec = Executors.newCachedThreadPool();
    Queue&lt;T&gt; resultQueue = new ConcurrentLinkedQueue&lt;T&gt;();
    parallelRecursive(exec, nodes, resultQueue);
    exec.shutdown();
    exec.awaitTermination(Long.MAX_VALUE, TimeUnit.SECONDS);
    return resultQueue;
}
</programlisting>
</example>
<section id="ch08lev2sec9" condition="183" label="8.5.1" xreflabel="8.5.1">
<?docpage num="183"?>
<title id="ch08lev2sec9__title">Example: A Puzzle Framework</title>
<para><indexterm id="iddle2163" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PUZZLE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Puzzle</literal></secondary></indexterm><indexterm id="iddle2727" significance="normal"><?indexkey I?><?primarykey independent/independence?><?secondarykey PARALLELIZATION USE?><primary><emphasis role="strong">independent/independence</emphasis></primary><secondary>parallelization use</secondary></indexterm><indexterm id="iddle3454" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey PUZZLE-SOLVING FRAMEWORK?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>puzzle-solving framework</secondary></indexterm><indexterm id="iddle3740" significance="normal"><?indexkey P?><?primarykey puzzle solving framework?><primary><emphasis role="strong">puzzle solving framework</emphasis></primary></indexterm><indexterm id="iddle3741" significance="normal"><?indexkey P?><?primarykey puzzle solving framework?><?secondarykey AS PARALLELIZATION EXAMPLE?><primary><emphasis role="strong">puzzle solving framework</emphasis></primary><secondary>as parallelization example</secondary></indexterm><indexterm id="iddle4427" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey TRANSFORMATIONS?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>transformations</secondary></indexterm><indexterm id="iddle4428" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey TRANSFORMATIONS?><?tertiarykey IN PUZZLE-SOLVING FRAMEWORK EXAMPLE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>transformations</secondary><tertiary>in puzzle-solving framework example</tertiary></indexterm><indexterm id="iddle4736" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey IN PUZZLE-SOLVING FRAMEWORK?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>in puzzle-solving framework</secondary></indexterm><indexterm id="iddle4956" significance="normal"><?indexkey T?><?primarykey transformations?><primary><emphasis role="strong">transformations</emphasis></primary></indexterm><indexterm id="iddle4957" significance="normal"><?indexkey T?><?primarykey transformations?><?secondarykey STATE?><primary><emphasis role="strong">transformations</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle4958" significance="normal"><?indexkey T?><?primarykey transformations?><?secondarykey STATE?><?tertiarykey IN PUZZLE-SOLVING FRAMEWORK EXAMPLE?><primary><emphasis role="strong">transformations</emphasis></primary><secondary>state</secondary><tertiary>in puzzle-solving framework example</tertiary></indexterm>An appealing application of this technique is solving puzzles that involve finding a sequence of transformations from some initial state to reach a goal state, such as the familiar “sliding block puzzles”,<footnote id="ch08fn07" label="7"><para>See <literal><ulink url="http://www.puzzleworld.org/SlidingBlockPuzzles">http://www.puzzleworld.org/SlidingBlockPuzzles</ulink></literal>.</para></footnote> “Hi-Q”, “Instant Insanity”, and other solitaire puzzles.</para>
<para>We define a “puzzle” as a combination of an initial position, a goal position, and a set of rules that determine valid moves. The rule set has two parts: computing the list of legal moves from a given position and computing the result of applying a move to a position. <literal>Puzzle</literal> in <link linkend="ch08list13" preference="0">Listing 8.13</link> shows our puzzle abstraction; the type parameters <literal>P</literal> and <literal>M</literal> represent the classes for a position and a move. From this interface, we can write a simple sequential solver that searches the puzzle space until a solution is found or the puzzle space is exhausted.</para>
<example id="ch08list13" label="8.13" role="Listing" xreflabel="8.13" condition="183">
<title id="ch08list13__title">Abstraction for Puzzles Like the “Sliding Blocks Puzzle”.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface Puzzle&lt;P, M&gt; {
    P initialPosition();
    boolean isGoal(P position);
    Set&lt;M&gt; legalMoves(P position);
    P move(P position, M move);
}
</programlisting>
</example>
<para><literal>Node</literal> in <link linkend="ch08list14" preference="0">Listing 8.14</link> represents a position that has been reached through some series of moves, holding a reference to the move that created the position and the previous <literal>Node</literal>. Following the links back from a <literal>Node</literal> lets us reconstruct the sequence of moves that led to the current position.</para>
<para><literal>SequentialPuzzleSolver</literal> in <link linkend="ch08list15" preference="0">Listing 8.15</link> shows a sequential solver for the puzzle framework that performs a depth-first search of the puzzle space. It terminates when it finds a solution (which is not necessarily the shortest solution).</para>
<para>Rewriting the solver to exploit concurrency would allow us to compute next moves and evaluate the goal condition in parallel, since the process of evaluating one move is mostly independent of evaluating other moves. (We say “mostly” because tasks share some mutable state, such as the set of seen positions.) If multiple processors are available, this could reduce the time it takes to find a solution.</para>
<para><literal>ConcurrentPuzzleSolver</literal> in <link linkend="ch08list16" preference="0">Listing 8.16</link> uses an inner <literal>SolverTask</literal> class that extends <literal>Node</literal> and implements <literal>Runnable</literal>. Most of the work is done in <literal>run</literal>: evaluating the set of possible next positions, pruning positions already searched, evaluating whether success has yet been achieved (by this task or by some other task), and submitting unsearched positions to an <literal>Executor</literal>.</para>
<para>To avoid infinite loops, the sequential version maintained a <literal>Set</literal> of previously searched positions; <literal>ConcurrentPuzzleSolver</literal> uses a <literal>ConcurrentHashMap</literal> for this purpose. This provides thread safety and avoids the race condition inherent in conditionally updating a shared collection by using <literal>putIfAbsent</literal> to atomically <?docpage num="184"?><?docpage num="185"?><?docpage num="186"?><indexterm id="iddle2176" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SEQUENTIALPUZZLESOLVER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SequentialPuzzleSolver</literal></secondary></indexterm><indexterm id="iddle1699" significance="normal"><?indexkey C?><?primarykey CountDownLatch?><?secondarykey PUZZLE-SOLVING FRAMEWORK USE?><primary><emphasis role="strong">CountDownLatch</emphasis></primary><secondary>puzzle-solving framework use</secondary></indexterm><indexterm id="iddle2145" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey NODE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Node</literal></secondary></indexterm><indexterm id="iddle2213" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey VALUELATCH?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ValueLatch</literal></secondary></indexterm><indexterm id="iddle2941" significance="normal"><?indexkey L?><?primarykey latch(es)?><?secondarykey PUZZLE-SOLVING FRAMEWORK USE?><primary><emphasis role="strong">latch(es)</emphasis></primary><secondary>puzzle-solving framework use</secondary></indexterm><indexterm id="iddle3976" significance="normal"><?indexkey R?><?primarykey result(s)?><primary><emphasis role="strong">result(s)</emphasis></primary></indexterm><indexterm id="iddle3977" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey %?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>-bearing latches</secondary></indexterm><indexterm id="iddle3978" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey %?><?tertiarykey PUZZLE FRAMEWORK USE?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>-bearing latches</secondary><tertiary>puzzle framework use</tertiary></indexterm><indexterm id="iddle4112" significance="normal"><?indexkey S?><?primarykey search?><primary><emphasis role="strong">search</emphasis></primary></indexterm><indexterm id="iddle4113" significance="normal"><?indexkey S?><?primarykey search?><?secondarykey DEPTH-FIRST?><primary><emphasis role="strong">search</emphasis></primary><secondary>depth-first</secondary></indexterm><indexterm id="iddle4114" significance="normal"><?indexkey S?><?primarykey search?><?secondarykey DEPTH-FIRST?><?tertiarykey BREADTH-FIRST SEARCH VS?><primary><emphasis role="strong">search</emphasis></primary><secondary>depth-first</secondary><tertiary>breadth-first search vs</tertiary></indexterm><indexterm id="iddle4360" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey SIZE?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>size</secondary></indexterm><indexterm id="iddle4361" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey SIZE?><?tertiarykey SEARCH STRATEGY IMPACT?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>size</secondary><tertiary>search strategy impact</tertiary></indexterm><indexterm id="iddle4483" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey SEARCH?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>search</secondary></indexterm><indexterm id="iddle4484" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey SEARCH?><?tertiarykey STACK SIZE IMPACT ON?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>search</secondary><tertiary>stack size impact on</tertiary></indexterm><indexterm id="iddle5039" significance="normal"><?indexkey V?><?primarykey value(s)?><primary><emphasis role="strong">value(s)</emphasis></primary><see> <link linkend="iddle3976" preference="0"><emphasis role="strong">result(s)</emphasis></link>.</see></indexterm>add a position only if it was not previously known. <literal>ConcurrentPuzzleSolver</literal> uses the internal work queue of the thread pool instead of the call stack to hold the state of the search.</para>
<example id="ch08list14" label="8.14" role="Listing" xreflabel="8.14" condition="184">
<title id="ch08list14__title">Link Node for the Puzzle Solver Framework.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@Immutable
static class Node&lt;P, M&gt; {
    final P pos;
    final M move;
    final Node&lt;P, M&gt; prev;

    Node(P pos, M move, Node&lt;P, M&gt; prev) {...}

    List&lt;M&gt; asMoveList() {
        List&lt;M&gt; solution = new LinkedList&lt;M&gt;();
        for (Node&lt;P, M&gt; n = this; n.move != null; n = n.prev)
            solution.add(0, n.move);
        return solution;
    }
}
</programlisting>
</example>
<para>The concurrent approach also trades one form of limitation for another that might be more suitable to the problem domain. The sequential version performs a depth-first search, so the search is bounded by the available stack size. The concurrent version performs a breadth-first search and is therefore free of the stack size restriction (but can still run out of memory if the set of positions to be searched or already searched exceeds the available memory).</para>
<para>In order to stop searching when we find a solution, we need a way to determine whether any thread has found a solution yet. If we want to accept the first solution found, we also need to update the solution only if no other task has already found one. These requirements describe a sort of <emphasis>latch</emphasis> (see <link linkend="ch05lev2sec10" preference="0">Section 5.5.1</link>) and in particular, a <emphasis>result-bearing latch</emphasis>. We could easily build a blocking resultbearing latch using the techniques in <link linkend="ch14" preference="0">Chapter 14</link>, but it is often easier and less error-prone to use existing library classes rather than low-level language mechanisms. <literal>ValueLatch</literal> in <link linkend="ch08list17" preference="0">Listing 8.17</link> uses a <literal>CountDownLatch</literal> to provide the needed latching behavior, and uses locking to ensure that the solution is set only once.</para>
<para>Each task first consults the solution latch and stops if a solution has already been found. The main thread needs to wait until a solution is found; <literal>getValue</literal> in <literal>ValueLatch</literal> blocks until some thread has set the value. <literal>ValueLatch</literal> provides a way to hold a value such that only the first call actually sets the value, callers can test whether it has been set, and callers can block waiting for it to be set. On the first call to <literal>setValue</literal>, the solution is updated and the <literal>CountDownLatch</literal> is decremented, releasing the main solver thread from <literal>getValue</literal>.</para>
<para>The first thread to find a solution also shuts down the <literal>Executor</literal>, to prevent new tasks from being accepted. To avoid having to deal with <literal>RejectedExecutionException</literal>, <?docpage num="187"?><indexterm id="iddle2099" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CONCURRENTPUZZLESOLVER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ConcurrentPuzzleSolver</literal></secondary></indexterm><indexterm id="iddle2184" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SOLVERTASK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SolverTask</literal></secondary></indexterm><indexterm id="iddle2214" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey VALUELATCH?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ValueLatch</literal></secondary></indexterm><indexterm id="iddle3827" significance="normal"><?indexkey R?><?primarykey rejected execution handler?><?secondarykey PUZZLE-SOLVING FRAMEWORK?><primary><emphasis role="strong">rejected execution handler</emphasis></primary><secondary>puzzle-solving framework</secondary></indexterm><indexterm id="iddle3831" significance="normal"><?indexkey R?><?primarykey RejectedExecutionException?><?secondarykey PUZZLE-SOLVING FRAMEWORK USE?><primary><emphasis role="strong">RejectedExecutionException</emphasis></primary><secondary>puzzle-solving framework use</secondary></indexterm><indexterm id="iddle4677" significance="normal"><?indexkey T?><?primarykey termination?><?secondarykey PUZZLE-SOLVING FRAMEWORK?><primary><emphasis role="strong">termination</emphasis></primary><secondary>puzzle-solving framework</secondary></indexterm><indexterm id="iddle4893" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey CONSTRAINTS?><?tertiarykey IN PUZZLE-SOLVING FRAMEWORK?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>constraints</secondary><tertiary>in puzzle-solving framework</tertiary></indexterm>the rejected execution handler should be set to discard submitted tasks. Then, all unfinished tasks eventually run to completion and any subsequent attempts to execute new tasks fail silently, allowing the executor to terminate. (If the tasks took longer to run, we might want to interrupt them instead of letting them finish.)</para>
<example id="ch08list15" label="8.15" role="Listing" xreflabel="8.15" condition="185">
<?docpage num="185"?>
<title id="ch08list15__title">Sequential Puzzle Solver.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class SequentialPuzzleSolver&lt;P, M&gt; {
    private final Puzzle&lt;P, M&gt; puzzle;
    private final Set&lt;P&gt; seen = new HashSet&lt;P&gt;();

    public SequentialPuzzleSolver(Puzzle&lt;P, M&gt; puzzle) {
        this.puzzle = puzzle;
    }

    public List&lt;M&gt; solve() {
        P pos = puzzle.initialPosition();
        return search(new Node&lt;P, M&gt;(pos, null, null));
    }

    private List&lt;M&gt; search(Node&lt;P, M&gt; node) {
        if (!seen.contains(node.pos)) {
            seen.add(node.pos);
            if (puzzle.isGoal(node.pos))
                return node.asMoveList();
            for (M move : puzzle.legalMoves(node.pos)) {
                P pos = puzzle.move(node.pos, move);
                Node&lt;P, M&gt; child = new Node&lt;P, M&gt;(pos, move, node);
                List&lt;M&gt; result = search(child);
                if (result != null)
                    return result;
            }
        }
        return null;
    }

    static class Node&lt;P, M&gt; {  /*  Listing 8.14  */  }
}
</programlisting>
</example>
<example id="ch08list16" label="8.16" role="Listing" xreflabel="8.16" condition="186">
<?docpage num="186"?>
<title id="ch08list16__title">Concurrent Version of Puzzle Solver.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class ConcurrentPuzzleSolver&lt;P, M&gt; {
    private final Puzzle&lt;P, M&gt; puzzle;
    private final ExecutorService exec;
    private final ConcurrentMap&lt;P, Boolean&gt; seen;
    final ValueLatch&lt;Node&lt;P, M&gt;&gt; solution
            = new ValueLatch&lt;Node&lt;P, M&gt;&gt;();
    ...
    public List&lt;M&gt; solve() throws InterruptedException {
        try {
            P p = puzzle.initialPosition();
            exec.execute(newTask(p, null, null));
            // <emphasis>block until solution found</emphasis>
            Node&lt;P, M&gt; solnNode = solution.getValue();
            return (solnNode == null) ? null : solnNode.asMoveList();
        } finally {
            exec.shutdown();
        }
    }

    protected Runnable newTask(P p, M m, Node&lt;P,M&gt; n) {
        return new SolverTask(p, m, n);
    }

    class SolverTask extends Node&lt;P, M&gt; implements Runnable {
        ...
        public void run() {
            if (solution.isSet()
                    || seen.putIfAbsent(pos, true) != null)
                return; // already solved or seen this position
            if (puzzle.isGoal(pos))
                solution.setValue(this);
            else
                for (M m : puzzle.legalMoves(pos))
                    exec.execute(
                        newTask(puzzle.move(pos, m), m, this));
        }
    }
}
</programlisting>
</example>
<example id="ch08list17" label="8.17" role="Listing" xreflabel="8.17" condition="187">
<title id="ch08list17__title">Result-bearing Latch Used by <literal>ConcurrentPuzzleSolver</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ValueLatch&lt;T&gt; {
    @GuardedBy("this") private T value = null;
    private final CountDownLatch done = new CountDownLatch(1);

    public boolean isSet() {
        return (done.getCount() == 0);
    }

    public synchronized void setValue(T newValue) {
        if (!isSet()) {
            value = newValue;
            done.countDown();
        }
    }

    public T getValue() throws InterruptedException {
        done.await();
        synchronized (this) {
            return value;
        }
    }
}
</programlisting>
</example>
<para><literal>ConcurrentPuzzleSolver</literal> does not deal well with the case where there is no solution: if all possible moves and positions have been evaluated and no solution has been found, <literal>solve</literal> waits forever in the call to <literal>getSolution</literal>. The sequential version terminated when it had exhausted the search space, but getting concurrent programs to terminate can sometimes be more difficult. One possible solution is to keep a count of active solver tasks and set the solution to null when the count drops to zero, as in <link linkend="ch08list18" preference="0">Listing 8.18</link>.</para>
<para>Finding the solution may also take longer than we are willing to wait; there are several additional termination conditions we could impose on the solver. One is a time limit; this is easily done by implementing a timed <literal>getValue</literal> in <literal>ValueLatch</literal> (which would use the timed version of <literal>await</literal>), and shutting down the <literal>Executor</literal> and declaring failure if <literal>getValue</literal> times out. Another is some sort of puzzle-specific metric such as searching only up to a certain number of positions. Or we can provide a cancellation mechanism and let the client make its own <?docpage num="188"?><indexterm id="iddle2164" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PUZZLESOLVER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>PuzzleSolver</literal></secondary></indexterm>decision about when to stop searching.</para>
<example id="ch08list18" label="8.18" role="Listing" xreflabel="8.18" condition="188">
<title id="ch08list18__title">Solver that Recognizes when No Solution Exists.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class PuzzleSolver&lt;P,M&gt; extends ConcurrentPuzzleSolver&lt;P,M&gt; {
    ...
    private final AtomicInteger taskCount = new AtomicInteger(0);

    protected Runnable newTask(P p, M m, Node&lt;P,M&gt; n) {
        return new CountingSolverTask(p, m, n);
    }

    class CountingSolverTask extends SolverTask {
        CountingSolverTask(P pos, M move, Node&lt;P, M&gt; prev) {
            super(pos, move, prev);
            taskCount.incrementAndGet();
        }
        public void run() {
            try {
                super.run();
            } finally {
                if (taskCount.decrementAndGet() == 0)
                    solution.setValue(null);
            }
        }
    }
}
</programlisting>
</example>
</section>
</section>



<section id="ch08lev1sec6" condition="188" label="" xreflabel=""><?docpage num="188"?>
<title id="ch08lev1sec6__title">Summary</title>
<para>The <literal>Executor</literal> framework is a powerful and flexible framework for concurrently executing tasks. It offers a number of tuning options, such as policies for creating and tearing down threads, handling queued tasks, and what to do with excess tasks, and provides several hooks for extending its behavior. As in most powerful frameworks, however, there are combinations of settings that do not work well together; some types of tasks require specific execution policies, and some combinations of tuning parameters may produce strange results.</para>
</section>

</chapter>

<chapter id="ch09" label="9" xreflabel="9" condition="189">
<?docpage num="189"?>
<title id="ch09__title">GUI Applications</title>


<para><indexterm id="iddle1110" significance="normal"><?indexkey A?><?primarykey application(s)?><?secondarykey GUI?><primary><emphasis role="strong">application(s)</emphasis></primary><secondary>GUI</secondary></indexterm><indexterm id="iddle1907" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey GUI SINGLE-THREADED USE?><primary><emphasis role="strong">design</emphasis></primary><secondary>GUI single-threaded use</secondary></indexterm><indexterm id="iddle1908" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey GUI SINGLE-THREADED USE?><?tertiarykey RATIONALE FOR?><primary><emphasis role="strong">design</emphasis></primary><secondary>GUI single-threaded use</secondary><tertiary>rationale for</tertiary></indexterm><indexterm id="iddle1981" significance="normal"><?indexkey E?><?primarykey EDT (event dispatch thread)?><?secondarykey SINGLE-THREADED GUI USE?><primary><emphasis role="strong">EDT (event dispatch thread)</emphasis></primary><secondary>single-threaded GUI use</secondary></indexterm><indexterm id="iddle2486" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey APPLICATIONS?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>applications</secondary></indexterm><indexterm id="iddle2495" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey SINGLE-THREADED USE?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>single-threaded use</secondary></indexterm><indexterm id="iddle2496" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey SINGLE-THREADED USE?><?tertiarykey RATIONALE FOR?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>single-threaded use</secondary><tertiary>rationale for</tertiary></indexterm><indexterm id="iddle3269" significance="normal"><?indexkey M?><?primarykey multithreaded?><?secondarykey GUI FRAMEWORKS?><primary><emphasis role="strong">multithreaded</emphasis></primary><secondary>GUI frameworks</secondary></indexterm><indexterm id="iddle3270" significance="normal"><?indexkey M?><?primarykey multithreaded?><?secondarykey GUI FRAMEWORKS?><?tertiarykey ISSUES WITH?><primary><emphasis role="strong">multithreaded</emphasis></primary><secondary>GUI frameworks</secondary><tertiary>issues with</tertiary></indexterm><indexterm id="iddle3783" significance="normal"><?indexkey R?><?primarykey race conditions?><?secondarykey IN GUI FRAMEWORKS?><primary><emphasis role="strong">race conditions</emphasis></primary><secondary>in GUI frameworks</secondary></indexterm><indexterm id="iddle4243" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey THREAD?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle4244" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey THREAD?><?tertiarykey NECESSITIES AND DANGERS IN GUI APPLICATIONS?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>thread</secondary><tertiary>necessities and dangers in GUI applications</tertiary></indexterm><indexterm id="iddle4299" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><?secondarykey SUBSYSTEMS?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><secondary>subsystems</secondary></indexterm><indexterm id="iddle4300" significance="normal"><?indexkey S?><?primarykey single-thread(ed)?><?secondarykey SUBSYSTEMS?><?tertiarykey GUI IMPLEMENTATION AS?><primary><emphasis role="strong">single-thread(ed)</emphasis></primary><secondary>subsystems</secondary><tertiary>GUI implementation as</tertiary></indexterm><indexterm id="iddle4818" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SHARING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>sharing</secondary></indexterm><indexterm id="iddle4819" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SHARING?><?tertiarykey NECESSITIES AND DANGERS IN GUI APPLICATIONS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>sharing</secondary><tertiary>necessities and dangers in GUI applications</tertiary></indexterm>If you’ve tried to write even a simple GUI application using Swing, you know that GUI applications have their own peculiar threading issues. To maintain safety, certain tasks must run in the Swing event thread. But you cannot execute longrunning tasks in the event thread, lest the UI become unresponsive. And Swing data structures are not thread-safe, so you must be careful to confine them to the event thread.</para>
<para>Nearly all GUI toolkits, including Swing and SWT, are implemented as <emphasis>singlethreaded subsystems</emphasis> in which all GUI activity is confined to a single thread. If you are not planning to write a totally single-threaded program, there will be activities that run partially in an application thread and partially in the event thread. Like many other threading bugs, getting this division wrong may not necessarily make your program crash immediately; instead, it could behave oddly under hard-to-identify conditions. Even though the GUI frameworks themselves are single-threaded subsystems, your application may not be, and you still need to consider threading issues carefully when writing GUI code.</para>



<section id="ch09lev1sec1" condition="189" label="9.1" xreflabel="9.1"><?docpage num="189"?>
<title id="ch09lev1sec1__title">Why are GUIs Single-threaded?</title>
<para>In the old days, GUI applications were single-threaded and GUI events were processed from a “main event loop”. Modern GUI frameworks use a model that is only slightly different: they create a dedicated <emphasis>event dispatch thread</emphasis> (EDT) for handling GUI events.</para>
<para>Single-threaded GUI frameworks are not unique to Java; Qt, NextStep, MacOS Cocoa, X Windows, and many others are also single-threaded. This is not for lack of trying; there have been many attempts to write multithreaded GUI frameworks, but because of persistent problems with race conditions and deadlock, they all eventually arrived at the single-threaded event queue model in which a dedicated thread fetches events off a queue and dispatches them to applicationdefined event handlers. (AWT originally tried to support a greater degree of multithreaded access, and the decision to make Swing single-threaded was based largely on experience with AWT.)</para>
<para><?docpage num="190"?><indexterm id="iddle1545" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><?tertiarykey SINGLE-THREADED GUI FRAMEWORK USE?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary><tertiary>single-threaded GUI framework use</tertiary></indexterm><indexterm id="iddle1630" significance="normal"><?indexkey C?><?primarykey control flow?><?secondarykey MODEL-VIEW-CONTROLLER PATTERN?><primary><emphasis role="strong">control flow</emphasis></primary><secondary>model-view-controller pattern</secondary></indexterm><indexterm id="iddle1631" significance="normal"><?indexkey C?><?primarykey control flow?><?secondarykey MODEL-VIEW-CONTROLLER PATTERN?><?tertiarykey AND INCONSISTENT LOCK ORDERING?><primary><emphasis role="strong">control flow</emphasis></primary><secondary>model-view-controller pattern</secondary><tertiary>and inconsistent lock ordering</tertiary></indexterm><indexterm id="iddle1644" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey MODEL, VIEW, AND CONTROLLER OBJECTS IN GUI APPLICATIONS?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>model, view, and controller objects in GUI applications</secondary></indexterm><indexterm id="iddle1645" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey MODEL, VIEW, AND CONTROLLER OBJECTS IN GUI APPLICATIONS?><?tertiarykey INCONSISTENT LOCK ORDERING?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>model, view, and controller objects in GUI applications</secondary><tertiary>inconsistent lock ordering</tertiary></indexterm><indexterm id="iddle1807" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey IN GUI FRAMEWORK?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>in GUI framework</secondary></indexterm><indexterm id="iddle2998" significance="normal"><?indexkey L?><?primarykey listeners?><?secondarykey SWING?><primary><emphasis role="strong">listeners</emphasis></primary><secondary>Swing</secondary></indexterm><indexterm id="iddle2999" significance="normal"><?indexkey L?><?primarykey listeners?><?secondarykey SWING?><?tertiarykey SINGLE-THREAD RULE EXCEPTIONS?><primary><emphasis role="strong">listeners</emphasis></primary><secondary>Swing</secondary><tertiary>single-thread rule exceptions</tertiary></indexterm><indexterm id="iddle3127" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ORDERING?><?tertiarykey INCONSISTENT, AS MULTITHREADED GUI FRAMEWORK PROBLEM?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>ordering</secondary><tertiary>inconsistent, as multithreaded GUI framework problem</tertiary></indexterm><indexterm id="iddle3225" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey MODEL-VIEW-CONTROLLER PATTERN?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>model-view-controller pattern</secondary></indexterm><indexterm id="iddle3226" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey MODEL-VIEW-CONTROLLER PATTERN?><?tertiarykey DEADLOCK RISK?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>model-view-controller pattern</secondary><tertiary>deadlock risk</tertiary></indexterm><indexterm id="iddle3287" significance="normal"><?indexkey M?><?primarykey MVC (model-view-controller) pattern?><primary><emphasis role="strong">MVC (model-view-controller) pattern</emphasis></primary></indexterm><indexterm id="iddle3288" significance="normal"><?indexkey M?><?primarykey MVC (model-view-controller) pattern?><?secondarykey DEADLOCK RISKS?><primary><emphasis role="strong">MVC (model-view-controller) pattern</emphasis></primary><secondary>deadlock risks</secondary></indexterm><indexterm id="iddle3408" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey LOCK?><?tertiarykey INCONSISTENT, AS MULTITHREADED GUI FRAMEWORK PROBLEM?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>lock</secondary><tertiary>inconsistent, as multithreaded GUI framework problem</tertiary></indexterm><indexterm id="iddle4753" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><?tertiarykey IN GUI FRAMEWORKS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><tertiary>in GUI frameworks</tertiary></indexterm><indexterm id="iddle5087" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey MODEL-VIEW-CONTROLLER PATTERN?><primary><emphasis role="strong">views</emphasis></primary><secondary>model-view-controller pattern</secondary></indexterm><indexterm id="iddle5088" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey MODEL-VIEW-CONTROLLER PATTERN?><?tertiarykey DEADLOCK RISKS?><primary><emphasis role="strong">views</emphasis></primary><secondary>model-view-controller pattern</secondary><tertiary>deadlock risks</tertiary></indexterm>Multithreaded GUI frameworks tend to be particularly susceptible to deadlock, partially because of the unfortunate interaction between input event processing and any sensible object-oriented modeling of GUI components. Actions initiated by the user tend to “bubble up” from the OS to the application—a mouse click is detected by the OS, is turned into a “mouse click” event by the toolkit, and is eventually delivered to an application listener as a higher level event such as a “button pressed” event. On the other hand, application-initiated actions “bubble down” from the application to the OS—changing the background color of a component originates in the application and is dispatched to a specific component class and eventually into the OS for rendering. Combining this tendency for activities to access the same GUI objects in the opposite order with the requirement of making each object thread-safe yields a recipe for inconsistent lock ordering, which leads to deadlock (see <link linkend="ch10" preference="0">Chapter 10</link>). And this is exactly what nearly every GUI toolkit development effort rediscovered through experience.</para>
<para>Another factor leading to deadlock in multithreaded GUI frameworks is the prevalence of the model-view-control (MVC) pattern. Factoring user interactions into cooperating model, view, and controller objects greatly simplifies implementing GUI applications, but again raises the risk of inconsistent lock ordering. The controller calls into the model, which notifies the view that something has changed. But the controller can also call into the view, which may in turn call back into the model to query the model state. The result is again inconsistent lock ordering, with the attendant risk of deadlock.</para>
<para>In his weblog,<footnote id="ch09fn01" label="1"><para><literal><ulink url="http://weblogs.java.net/blog/kgh/archive/2004/10">http://weblogs.java.net/blog/kgh/archive/2004/10</ulink></literal></para></footnote> Sun VP Graham Hamilton nicely sums up the challenges, describing why the multithreaded GUI toolkit is one of the recurring “failed dreams” of computer science.</para>
<blockquote>
<para>I believe you can program successfully with multithreaded GUI toolkits if the toolkit is very carefully designed; if the toolkit exposes its locking methodology in gory detail; if you are very smart, very careful, and have a global understanding of the whole structure of the toolkit. If you get one of these things slightly wrong, things will mostly work, but you will get occasional hangs (due to deadlocks) or glitches (due to races). This multithreaded approach works best for people who have been intimately involved in the design of the toolkit.</para>
<para>Unfortunately, I don’t think this set of characteristics scales to widespread commercial use. What you tend to end up with is normal smart programmers building apps that don’t quite work reliably for reasons that are not at all obvious. So the authors get very disgruntled and frustrated and use bad words on the poor innocent toolkit.</para>
</blockquote>
<para>Single-threaded GUI frameworks achieve thread safety via thread confinement; all GUI objects, including visual components and data models, are accessed exclusively from the event thread. Of course, this just pushes some of the thread safety burden back onto the application developer, who must make sure these objects are properly confined.</para>
<section id="ch09lev2sec1" condition="191" label="9.1.1" xreflabel="9.1.1">
<?docpage num="191"?>
<title id="ch09lev2sec1__title">Sequential Event Processing</title>
<para><indexterm id="iddle1179" significance="normal"><?indexkey A?><?primarykey AWT (Abstract Window Toolkit)?><primary><emphasis role="strong">AWT (Abstract Window Toolkit)</emphasis></primary><seealso> <link linkend="iddle1110" preference="0"><emphasis role="strong">application(s)</emphasis>, GUI</link>.</seealso></indexterm><indexterm id="iddle1541" significance="normal"><?indexkey C?><?primarykey confinement?><?secondarykey THREAD?><?tertiarykey IN SWING?><primary><emphasis role="strong">confinement</emphasis></primary><secondary>thread</secondary><tertiary>in Swing</tertiary></indexterm><indexterm id="iddle1621" significance="normal"><?indexkey C?><?primarykey control flow?><primary><emphasis role="strong">control flow</emphasis></primary><seealso> <link linkend="iddle2059" preference="0"><emphasis role="strong">event(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1622" significance="normal"><?indexkey C?><?primarykey control flow?><primary><emphasis role="strong">control flow</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle1623" significance="normal"><?indexkey C?><?primarykey control flow?><primary><emphasis role="strong">control flow</emphasis></primary><seealso> <link linkend="iddle3287" preference="0"><emphasis role="strong">MVC (model-view-controller) pattern</emphasis></link>.</seealso></indexterm><indexterm id="iddle2059" significance="normal"><?indexkey E?><?primarykey event(s)?><primary><emphasis role="strong">event(s)</emphasis></primary></indexterm><indexterm id="iddle2072" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey SEQUENTIAL PROCESSING?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>sequential processing</secondary></indexterm><indexterm id="iddle2073" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey SEQUENTIAL PROCESSING?><?tertiarykey IN GUI APPLICATIONS?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>sequential processing</secondary><tertiary>in GUI applications</tertiary></indexterm><indexterm id="iddle2187" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SWINGUTILITIES?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SwingUtilities</literal></secondary></indexterm><indexterm id="iddle2256" significance="normal"><?indexkey E?><?primarykey Executor framework?><?secondarykey AND GUI EVENT PROCESSING?><primary><emphasis role="strong">Executor framework</emphasis></primary><secondary>and GUI event processing</secondary></indexterm><indexterm id="iddle2335" significance="normal"><?indexkey F?><?primarykey feedback?><primary><emphasis role="strong">feedback</emphasis></primary><seealso> <link linkend="iddle1110" preference="0"><emphasis role="strong">application(s)</emphasis>, GUI</link>.</seealso></indexterm><indexterm id="iddle2483" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><seealso> <link linkend="iddle2059" preference="0"><emphasis role="strong">event(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2484" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><seealso> <link linkend="iddle2263" preference="0"><emphasis role="strong">Executor framework</emphasis>, single-threaded</link>.</seealso></indexterm><indexterm id="iddle2485" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><seealso> <link linkend="iddle2998" preference="0"><emphasis role="strong">listeners</emphasis>, Swing</link>.</seealso></indexterm><indexterm id="iddle2996" significance="normal"><?indexkey L?><?primarykey listeners?><primary><emphasis role="strong">listeners</emphasis></primary><seealso> <link linkend="iddle2059" preference="0"><emphasis role="strong">event(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle3365" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey SWING?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>Swing</secondary></indexterm><indexterm id="iddle3366" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey SWING?><?tertiarykey THREAD-CONFINEMENT?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>Swing</secondary><tertiary>thread-confinement</tertiary></indexterm><indexterm id="iddle3528" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey SEQUENTIAL EVENT PROCESSING?><primary><emphasis role="strong">performance</emphasis></primary><secondary>sequential event processing</secondary></indexterm><indexterm id="iddle3652" significance="normal"><?indexkey P?><?primarykey presentation?><primary><emphasis role="strong">presentation</emphasis></primary><see> <link linkend="iddle1110" preference="0"><emphasis role="strong">application(s)</emphasis>, GUI</link>.</see></indexterm><indexterm id="iddle3699" significance="normal"><?indexkey P?><?primarykey progress indication?><primary><emphasis role="strong">progress indication</emphasis></primary><seealso> <link linkend="iddle1110" preference="0"><emphasis role="strong">application(s)</emphasis>, GUI</link>.</seealso></indexterm><indexterm id="iddle3801" significance="normal"><?indexkey R?><?primarykey recursion?><primary><emphasis role="strong">recursion</emphasis></primary><seealso> <link linkend="iddle1653" preference="0"><emphasis role="strong">coordination</emphasis>, control flow</link>.</seealso></indexterm><indexterm id="iddle3802" significance="normal"><?indexkey R?><?primarykey recursion?><primary><emphasis role="strong">recursion</emphasis></primary><seealso> <link linkend="iddle2870" preference="0"><emphasis role="strong">iterators/iteration</emphasis></link>.</seealso></indexterm><indexterm id="iddle4161" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey EVENT PROCESSING?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>event processing</secondary></indexterm><indexterm id="iddle4162" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey EVENT PROCESSING?><?tertiarykey IN GUI APPLICATIONS?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>event processing</secondary><tertiary>in GUI applications</tertiary></indexterm><indexterm id="iddle4519" significance="normal"><?indexkey S?><?primarykey Swing?><primary><emphasis role="strong">Swing</emphasis></primary><seealso> <link linkend="iddle1110" preference="0"><emphasis role="strong">application(s)</emphasis>, GUI</link>.</seealso></indexterm><indexterm id="iddle4522" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey METHODS?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>methods</secondary></indexterm><indexterm id="iddle4523" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey METHODS?><?tertiarykey SINGLE-THREAD RULE EXCEPTIONS?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>methods</secondary><tertiary>single-thread rule exceptions</tertiary></indexterm><indexterm id="iddle4526" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey THREAD?><?tertiarykey CONFINEMENT IN?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>thread</secondary><tertiary>confinement in</tertiary></indexterm><indexterm id="iddle4754" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey CONFINEMENT?><?tertiarykey IN SWING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>confinement</secondary><tertiary>in Swing</tertiary></indexterm><indexterm id="iddle4954" significance="normal"><?indexkey T?><?primarykey transactions?><primary><emphasis role="strong">transactions</emphasis></primary><seealso> <link linkend="iddle2059" preference="0"><emphasis role="strong">event(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle5023" significance="normal"><?indexkey U?><?primarykey user?><primary><emphasis role="strong">user</emphasis></primary><seealso> <link linkend="iddle1110" preference="0"><emphasis role="strong">application(s)</emphasis>, GUI</link>.</seealso></indexterm>GUI applications are oriented around processing fine-grained <emphasis>events</emphasis> such as mouse clicks, key presses, or timer expirations. Events are a kind of task; the event handling machinery provided by AWT and Swing is structurally similar to an <literal>Executor</literal>.</para>
<para>Because there is only a single thread for processing GUI tasks, they are processed sequentially—one task finishes before the next one begins, and no two tasks overlap. Knowing this makes writing task code easier—you don’t have to worry about interference from other tasks.</para>
<para>The downside of sequential task processing is that if one task takes a long time to execute, other tasks must wait until it is finished. If those other tasks are responsible for responding to user input or providing visual feedback, the application will appear to have frozen. If a lengthy task is running in the event thread, the user cannot even click “Cancel” because the cancel button listener is not called until the lengthy task completes. Therefore, tasks that execute in the event thread must return control to the event thread quickly. To initiate a longrunning task such as spell-checking a large document, searching the file system, or fetching a resource over a network, you must run that task in another thread so control can return quickly to the event thread. To update a progress indicator while a long-running task executes or provide visual feedback when it completes, you again need to execute code in the event thread. This can get complicated quickly.</para>
</section>
<section id="ch09lev2sec2" label="9.1.2" xreflabel="9.1.2">
<title id="ch09lev2sec2__title">Thread Confinement in Swing</title>
<para>All Swing components (such as <literal>JButton</literal> and <literal>JTable</literal>) and data model objects (such as <literal>TableModel</literal> and <literal>TreeModel</literal>) are confined to the event thread, so any code that accesses these objects must run in the event thread. GUI objects are kept consistent not by synchronization, but by thread confinement. The upside is that tasks that run in the event thread need not worry about synchronization when accessing presentation objects; the downside is that you cannot access presentation objects from outside the event thread at all.</para>
<sidebar float="1" id="ch09sb01" condition="191"><title/>
<para>The <emphasis>Swing single-thread rule</emphasis>: Swing components and models should be created, modified, and queried only from the event-dispatching thread.</para>
</sidebar>
<para>As with all rules, there are a few exceptions. A small number of Swing methods may be called safely from any thread; these are clearly identified in the Javadoc as being thread-safe. Other exceptions to the single-thread rule include:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para><literal>SwingUtilities</literal>.<literal>isEventDispatchThread</literal>, which determines whether the current thread is the event thread;</para></listitem>
<listitem><para><literal>SwingUtilities</literal>.<literal>invokeLater</literal>, which schedules a <literal>Runnable</literal> for execution on the event thread (callable from any thread);</para></listitem>
<listitem><para><?docpage num="192"?><indexterm id="iddle2189" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SWINGUTILITIES?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SwingUtilities</literal></secondary></indexterm><indexterm id="iddle2119" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey GUIEXECUTOR?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>GuiExecutor</literal></secondary></indexterm><indexterm id="iddle2188" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SWINGUTILITIES?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SwingUtilities</literal></secondary></indexterm><indexterm id="iddle2257" significance="normal"><?indexkey E?><?primarykey Executor framework?><?secondarykey AND GUI EVENT PROCESSING?><primary><emphasis role="strong">Executor framework</emphasis></primary><secondary>and GUI event processing</secondary></indexterm><indexterm id="iddle4520" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey LISTENERS?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>listeners</secondary></indexterm><indexterm id="iddle4521" significance="normal"><?indexkey S?><?primarykey Swing?><?secondarykey LISTENERS?><?tertiarykey SINGLE-THREAD RULE EXCEPTIONS?><primary><emphasis role="strong">Swing</emphasis></primary><secondary>listeners</secondary><tertiary>single-thread rule exceptions</tertiary></indexterm><indexterm id="iddle4627" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey GUI?><?tertiarykey SHORT-RUNNING TASKS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>GUI</secondary><tertiary>short-running tasks</tertiary></indexterm><indexterm id="iddle4924" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey SHORT-RUNNING GUI TASKS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>short-running GUI tasks</secondary></indexterm><literal>SwingUtilities</literal>.<literal>invokeAndWait</literal>, which schedules a <literal>Runnable</literal> task for execution on the event thread and blocks the current thread until it completes (callable <emphasis>only</emphasis> from a non-GUI thread);</para></listitem>
<listitem><para>methods to enqueue a repaint or revalidation request on the event queue (callable from any thread); and</para></listitem>
<listitem><para>methods for adding and removing listeners (can be called from any thread, but listeners will always be invoked in the event thread).</para></listitem>
</itemizedlist>
<para role="continued">The <literal>invokeLater</literal> and <literal>invokeAndWait</literal> methods function a lot like an <literal>Executor</literal>. In fact, it is trivial to implement the threading-related methods from <literal>SwingUtilities</literal> using a single-threaded <literal>Executor</literal>, as shown in <link linkend="ch09list01" preference="0">Listing 9.1</link>. This is not how <literal>SwingUtilities</literal> is actually implemented, as Swing predates the <literal>Executor</literal> framework, but is probably how it would be if Swing were being implemented today.</para>
<para>The Swing event thread can be thought of as a single-threaded <literal>Executor</literal> that processes tasks from the event queue. As with thread pools, sometimes the worker thread dies and is replaced by a new one, but this should be transparent to tasks. Sequential, single-threaded execution is a sensible execution policy when tasks are short-lived, scheduling predictability is not important, or it is imperative that tasks not execute concurrently.</para>
<para><literal>GuiExecutor</literal> in <link linkend="ch09list02" preference="0">Listing 9.2</link> is an <literal>Executor</literal> that delegates tasks to <literal>SwingUtilities</literal> for execution. It could be implemented in terms of other GUI frameworks as well; for example, SWT provides the <literal>Display.asyncExec</literal> method, which is similar to Swing’s <literal>invokeLater</literal>.</para>
</section>
</section>
<section id="ch09lev1sec2" condition="192" label="9.2" xreflabel="9.2"><?docpage num="192"?>
<title id="ch09lev1sec2__title">Short-running GUI Tasks</title>
<para>In a GUI application, events originate in the event thread and bubble up to application-provided listeners, which will probably perform some computation that affects the presentation objects. For simple, short-running tasks, the entire action can stay in the event thread; for longer-running tasks, some of the processing should be offloaded to another thread.</para>
<para>In the simple case, confining presentation objects to the event thread is completely natural. <link linkend="ch09list03" preference="0">Listing 9.3</link> creates a button whose color changes randomly when pressed. When the user clicks on the button, the toolkit delivers an <literal>ActionEvent</literal> in the event thread to all registered action listeners. In response, the action listener picks a new color and changes the button’s background color. So the event originates in the GUI toolkit and is delivered to the application, and the application modifies the GUI in response to the user’s action. Control never has to leave the event thread, as illustrated in <link linkend="ch09fig01" preference="1">Figure 9.1</link>.</para>
<figure float="1" id="ch09fig01" label="9.1" xreflabel="9.1" condition="194">
<?docpage num="194"?>
<title id="ch09fig01__title">Control Flow of a Simple Button Click.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="61" fileref="graphics/09fig01.gif" format="GIF" width="487"/></imageobject>

</mediaobject>
</figure>
<para>This trivial example characterizes the majority of interactions between GUI applications and GUI toolkits. So long as tasks are short-lived and access only GUI objects (or other thread-confined or thread-safe application objects), you can almost totally ignore threading concerns and do everything from the event thread, and the right thing happens.</para>

<para><?docpage num="193"?></para><example id="ch09list01" label="9.1" role="Listing" xreflabel="9.1" condition="193">

<title id="ch09list01__title">Implementing <literal>SwingUtilities</literal> Using an <literal>Executor</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class SwingUtilities {
    private static final ExecutorService exec =
        Executors.newSingleThreadExecutor(new SwingThreadFactory());
    private static volatile Thread swingThread;

    private static class SwingThreadFactory implements ThreadFactory {
        public Thread newThread(Runnable r) {
            swingThread = new Thread(r);
            return swingThread;
        }
    }

    public static boolean isEventDispatchThread() {
        return Thread.currentThread() == swingThread;
    }

    public static void invokeLater(Runnable task) {
        exec.execute(task);
    }

    public static void invokeAndWait(Runnable task)
            throws InterruptedException, InvocationTargetException {
        Future f = exec.submit(task);
        try {
            f.get();
        } catch (ExecutionException e) {
            throw new InvocationTargetException(e);
        }
    }
}
</programlisting>
</example>

<para><?docpage num="194"?></para><example id="ch09list02" label="9.2" role="Listing" xreflabel="9.2" condition="194">

<title id="ch09list02__title"><literal>Executor</literal> Built Atop <literal>SwingUtilities</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class GuiExecutor extends AbstractExecutorService {
    <emphasis>// Singletons have a private constructor and a public factory</emphasis>
    private static final GuiExecutor instance = new GuiExecutor();

    private GuiExecutor() { }

    public static GuiExecutor instance() { return instance; }

    public void execute(Runnable r) {
        if (SwingUtilities.isEventDispatchThread())
            r.run();
        else
            SwingUtilities.invokeLater(r);
    }

    <emphasis>// Plus trivial implementations of lifecycle methods</emphasis>
}
</programlisting>
</example>
<example id="ch09list03" label="9.3" role="Listing" xreflabel="9.3" condition="194">
<title id="ch09list03__title">Simple Event Listener.</title>
<programlisting format="linespecific" linenumbering="unnumbered">final Random random = new Random();
final JButton button = new JButton("Change Color");
...
button.addActionListener(new ActionListener() {
    public void actionPerformed(ActionEvent e) {
        button.setBackground(new Color(random.nextInt()));
    }
});
</programlisting>
</example>
<para>A slightly more complicated version of this same scenario, illustrated in <link linkend="ch09fig02" preference="1">Figure 9.2</link>, involves the use of a formal data model such as a <literal>TableModel</literal> or <literal>TreeModel</literal>. Swing splits most visual components into two objects, a model and a view. The data to be displayed resides in the model and the rules governing how it is displayed reside in the view. The model objects can fire events indicating that the model data has changed, and views subscribe to these events. When the view receives an event indicating the model data may have changed, it queries the model for the new data and updates the display. So in a button listener that <?docpage num="195"?><indexterm id="iddle1628" significance="normal"><?indexkey C?><?primarykey control flow?><?secondarykey EVENT HANDLING?><?tertiarykey SIMPLE?><primary><emphasis role="strong">control flow</emphasis></primary><secondary>event handling</secondary><tertiary>simple</tertiary></indexterm><indexterm id="iddle2063" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey HANDLING?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>handling</secondary></indexterm><indexterm id="iddle2064" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey HANDLING?><?tertiarykey CONTROL FLOW, SIMPLE?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>handling</secondary><tertiary>control flow, simple</tertiary></indexterm><indexterm id="iddle2120" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey GUIEXECUTOR?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>GuiExecutor</literal></secondary></indexterm><indexterm id="iddle2262" significance="normal"><?indexkey E?><?primarykey Executor framework?><?secondarykey GUIEXECUTOR EXAMPLE?><primary><emphasis role="strong">Executor framework</emphasis></primary><secondary><literal>GuiExecutor</literal> example</secondary></indexterm><indexterm id="iddle3000" significance="normal"><?indexkey L?><?primarykey listeners?><?secondarykey SWING EVENT HANDLING?><primary><emphasis role="strong">listeners</emphasis></primary><secondary>Swing event handling</secondary></indexterm><indexterm id="iddle1026" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey REMOTE RESOURCE?><primary><emphasis role="strong">access</emphasis></primary><secondary>remote resource</secondary></indexterm><indexterm id="iddle1027" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey REMOTE RESOURCE?><?tertiarykey AS LONG-RUNNING GUI TASK?><primary><emphasis role="strong">access</emphasis></primary><secondary>remote resource</secondary><tertiary>as long-running GUI task</tertiary></indexterm><indexterm id="iddle1041" significance="normal"><?indexkey A?><?primarykey action(s)?><?secondarykey LISTENER?><primary><emphasis role="strong">action(s)</emphasis></primary><secondary>listener</secondary></indexterm><indexterm id="iddle1626" significance="normal"><?indexkey C?><?primarykey control flow?><?secondarykey EVENT HANDLING?><primary><emphasis role="strong">control flow</emphasis></primary><secondary>event handling</secondary></indexterm><indexterm id="iddle1627" significance="normal"><?indexkey C?><?primarykey control flow?><?secondarykey EVENT HANDLING?><?tertiarykey MODEL-VIEW OBJECTS?><primary><emphasis role="strong">control flow</emphasis></primary><secondary>event handling</secondary><tertiary>model-view objects</tertiary></indexterm><indexterm id="iddle2065" significance="normal"><?indexkey E?><?primarykey event(s)?><?secondarykey HANDLING?><?tertiarykey MODEL-VIEW OBJECTS?><primary><emphasis role="strong">event(s)</emphasis></primary><secondary>handling</secondary><tertiary>model-view objects</tertiary></indexterm><indexterm id="iddle2258" significance="normal"><?indexkey E?><?primarykey Executor framework?><?secondarykey AND LONG-RUNNING GUI TASKS?><primary><emphasis role="strong">Executor framework</emphasis></primary><secondary>and long-running GUI tasks</secondary></indexterm><indexterm id="iddle2366" significance="normal"><?indexkey F?><?primarykey fire-and-forget event handling strategy?><primary><emphasis role="strong">fire-and-forget event handling strategy</emphasis></primary></indexterm><indexterm id="iddle2367" significance="normal"><?indexkey F?><?primarykey fire-and-forget event handling strategy?><?secondarykey DRAWBACKS OF?><primary><emphasis role="strong">fire-and-forget event handling strategy</emphasis></primary><secondary>drawbacks of</secondary></indexterm><indexterm id="iddle2490" significance="normal"><?indexkey G?><?primarykey GUI (Graphical User Interface)?><?secondarykey LONG-RUNNING TASK HANDLING?><primary><emphasis role="strong">GUI (Graphical User Interface)</emphasis></primary><secondary>long-running task handling</secondary></indexterm><indexterm id="iddle2997" significance="normal"><?indexkey L?><?primarykey listeners?><?secondarykey ACTION?><primary><emphasis role="strong">listeners</emphasis></primary><secondary>action</secondary></indexterm><indexterm id="iddle3220" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey EVENT HANDLING?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>event handling</secondary></indexterm><indexterm id="iddle3221" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey EVENT HANDLING?><?tertiarykey MODEL-VIEW OBJECTS?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>event handling</secondary><tertiary>model-view objects</tertiary></indexterm><indexterm id="iddle3904" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey ACCESSING?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>accessing</secondary></indexterm><indexterm id="iddle3905" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey ACCESSING?><?tertiarykey AS LONG-RUNNING GUI TASK?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>accessing</secondary><tertiary>as long-running GUI task</tertiary></indexterm><indexterm id="iddle4339" significance="normal"><?indexkey S?><?primarykey spell checking?><primary><emphasis role="strong">spell checking</emphasis></primary></indexterm><indexterm id="iddle4340" significance="normal"><?indexkey S?><?primarykey spell checking?><?secondarykey AS LONG-RUNNING GUI TASK?><primary><emphasis role="strong">spell checking</emphasis></primary><secondary>as long-running GUI task</secondary></indexterm><indexterm id="iddle4625" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey GUI?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>GUI</secondary></indexterm><indexterm id="iddle4626" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey GUI?><?tertiarykey LONG-RUNNING TASKS?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>GUI</secondary><tertiary>long-running tasks</tertiary></indexterm><indexterm id="iddle4909" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey LONG-RUNNING GUI TASKS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>long-running GUI tasks</secondary></indexterm><indexterm id="iddle5084" significance="normal"><?indexkey V?><?primarykey views?><primary><emphasis role="strong">views</emphasis></primary></indexterm><indexterm id="iddle5085" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey EVENT HANDLING?><primary><emphasis role="strong">views</emphasis></primary><secondary>event handling</secondary></indexterm><indexterm id="iddle5086" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey EVENT HANDLING?><?tertiarykey MODEL-VIEW OBJECTS?><primary><emphasis role="strong">views</emphasis></primary><secondary>event handling</secondary><tertiary>model-view objects</tertiary></indexterm>modifies the contents of a table, the action listener would update the model and call one of the <literal>fireXxx</literal> methods, which would in turn invoke the view’s table model listeners, which would update the view. Again, control never leaves the event thread. (The Swing data model <literal>fireXxx</literal> methods always call the model listeners directly rather than submitting a new event to the event queue, so the <literal>fireXxx</literal> methods must be called only from the event thread.)</para>
<figure float="1" id="ch09fig02" label="9.2" xreflabel="9.2" condition="195">

<title id="ch09fig02__title">Control Flow with Separate Model and View Objects.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="122" fileref="graphics/09fig02.gif" format="GIF" width="489"/></imageobject>

</mediaobject>
</figure>
</section>
<section id="ch09lev1sec3" condition="195" label="9.3" xreflabel="9.3"><?docpage num="195"?>
<title id="ch09lev1sec3__title">Long-running GUI Tasks</title>
<para>If all tasks were short-running (and the application had no significant non-GUI portion), then the entire application could run within the event thread and you wouldn’t have to pay any attention to threads at all. However, sophisticated GUI applications may execute tasks that may take longer than the user is willing to wait, such as spell checking, background compilation, or fetching remote resources. These tasks must run in another thread so that the GUI remains responsive while they run.</para>
<para>Swing makes it easy to have a task run in the event thread, but (prior to Java 6) doesn’t provide any mechanism for helping GUI tasks execute code in other threads. But we don’t need Swing to help us here: we can create our own <literal>Executor</literal> for processing long-running tasks. A cached thread pool is a good choice for long-running tasks; only rarely do GUI applications initiate a large number of long-running tasks, so there is little risk of the pool growing without bound.</para>
<para>We start with a simple task that does not support cancellation or progress indication and that does not update the GUI on completion, and then add those features one by one. <link linkend="ch09list04" preference="0">Listing 9.4</link> shows an action listener, bound to a visual component, that submits a long-running task to an <literal>Executor</literal>. Despite the two layers of inner classes, having a GUI task initiate a task in this manner is fairly straightforward: the UI action listener is called in the event thread and submits a <literal>Runnable</literal> to execute in the thread pool.</para>
<para>This example gets the long-running task out of the event thread in a “fire and forget” manner, which is probably not very useful. There is usually some sort of visual feedback when a long-running task completes. But you cannot access presentation objects from the background thread, so on completion the task must submit another task to run in the event thread to update the user interface.</para>

<para><?docpage num="196"?></para><example id="ch09list04" label="9.4" role="Listing" xreflabel="9.4" condition="196">

<title id="ch09list04__title">Binding a Long-running Task to a Visual Component.</title>
<programlisting format="linespecific" linenumbering="unnumbered">ExecutorService backgroundExec = Executors.newCachedThreadPool();
...
button.addActionListener(new ActionListener() {
    public void actionPerformed(ActionEvent e) {
        backgroundExec.execute(new Runnable() {
            public void run() { doBigComputation(); }
        });
}});
</programlisting>
</example>
<para><indexterm id="iddle2336" significance="normal"><?indexkey F?><?primarykey feedback?><?secondarykey USER?><primary><emphasis role="strong">feedback</emphasis></primary><secondary>user</secondary></indexterm><indexterm id="iddle2337" significance="normal"><?indexkey F?><?primarykey feedback?><?secondarykey USER?><?tertiarykey IN LONG-RUNNING GUI TASKS?><primary><emphasis role="strong">feedback</emphasis></primary><secondary>user</secondary><tertiary>in long-running GUI tasks</tertiary></indexterm><indexterm id="iddle5026" significance="normal"><?indexkey U?><?primarykey user?><?secondarykey FEEDBACK?><primary><emphasis role="strong">user</emphasis></primary><secondary>feedback</secondary></indexterm><indexterm id="iddle5027" significance="normal"><?indexkey U?><?primarykey user?><?secondarykey FEEDBACK?><?tertiarykey IN LONG-RUNNING GUI TASKS?><primary><emphasis role="strong">user</emphasis></primary><secondary>feedback</secondary><tertiary>in long-running GUI tasks</tertiary></indexterm><link linkend="ch09list05" preference="0">Listing 9.5</link> illustrates the obvious way to do this, which is starting to get complicated; we’re now up to three layers of inner classes. The action listener first dims the button and sets a label indicating that a computation is in progress, then submits a task to the background executor. When that task finishes, it queues another task to run in the event thread, which reenables the button and restores the label text.</para>
<example id="ch09list05" label="9.5" role="Listing" xreflabel="9.5" condition="196">
<title id="ch09list05__title">Long-running Task with User Feedback.</title>
<programlisting format="linespecific" linenumbering="unnumbered">button.addActionListener(new ActionListener() {
    public void actionPerformed(ActionEvent e) {
        button.setEnabled(false);
        label.setText("busy");
        backgroundExec.execute(new Runnable() {
            public void run() {
                try {
                    doBigComputation();
                } finally {
                    GuiExecutor.instance().execute(new Runnable() {
                        public void run() {
                            button.setEnabled(true);
                            label.setText("idle");
                        }
                    });
                }
            }
        });
    }
});
</programlisting>
</example>
<para>The task triggered when the button is pressed is composed of three sequential subtasks whose execution alternates between the event thread and the background thread. The first subtask updates the user interface to show that a longrunning operation has begun and starts the second subtask in a background <?docpage num="197"?><indexterm id="iddle1305" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey LONG-RUNNING GUI TASKS?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>long-running GUI tasks</secondary></indexterm><indexterm id="iddle2420" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey CANCELLATION?><primary><emphasis role="strong">Future</emphasis></primary><secondary>cancellation</secondary></indexterm><indexterm id="iddle2421" significance="normal"><?indexkey F?><?primarykey Future?><?secondarykey CANCELLATION?><?tertiarykey OF LONG-RUNNING GUI TASK?><primary><emphasis role="strong">Future</emphasis></primary><secondary>cancellation</secondary><tertiary>of long-running GUI task</tertiary></indexterm>thread. Upon completion, the second subtask queues the third subtask to run again in the event thread, which updates the user interface to reflect that the operation has completed. This sort of “thread hopping” is typical of handling long-running tasks in GUI applications.</para>
<section id="ch09lev2sec3" label="9.3.1" xreflabel="9.3.1">
<title id="ch09lev2sec3__title">Cancellation</title>
<para>Any task that takes long enough to run in another thread probably also takes long enough that the user might want to cancel it. You could implement cancellation directly using thread interruption, but it is much easier to use <literal>Future</literal>, which was designed to manage cancellable tasks.</para>
<para>When you call <literal>cancel</literal> on a <literal>Future</literal> with <literal>mayInterruptIfRunning</literal> set to <literal>true</literal>, the <literal>Future</literal> implementation interrupts the thread that is executing the task if it is currently running. If your task is written to be responsive to interruption, it can return early if it is cancelled. <link linkend="ch09list06" preference="0">Listing 9.6</link> illustrates a task that polls the thread’s interrupted status and returns early on interruption.</para>
<example id="ch09list06" label="9.6" role="Listing" xreflabel="9.6" condition="197">
<title id="ch09list06__title">Cancelling a Long-running Task.</title>
<programlisting format="linespecific" linenumbering="unnumbered"><emphasis role="strong">Future&lt;?&gt;</emphasis>  runningTask = null;    // thread-confined
...
startButton.addActionListener(new ActionListener() {
    public void actionPerformed(ActionEvent e) {
        if (runningTask == null) {
            runningTask = backgroundExec<emphasis role="strong">.submit</emphasis>(new Runnable() {
                public void run() {
                   while (moreWork()) {
                       if (Thread.currentThread().isInterrupted()) {
                           cleanUpPartialWork();
                           break;
                       }
                       doSomeWork();
                   }
                }
            });
    };
}});

cancelButton.addActionListener(new ActionListener() {
    public void actionPerformed(ActionEvent event) {
        if (runningTask != null)
            runningTask<emphasis role="strong">.cancel</emphasis>(true);
}});
</programlisting>
</example>
<para>Because <literal>runningTask</literal> is confined to the event thread, no synchronization is required when setting or checking it, and the start button listener ensures that <?docpage num="198"?><indexterm id="iddle1398" significance="normal"><?indexkey C?><?primarykey completion?><?secondarykey NOTIFICATION?><primary><emphasis role="strong">completion</emphasis></primary><secondary>notification</secondary></indexterm><indexterm id="iddle1399" significance="normal"><?indexkey C?><?primarykey completion?><?secondarykey NOTIFICATION?><?tertiarykey OF LONG-RUNNING GUI TASK?><primary><emphasis role="strong">completion</emphasis></primary><secondary>notification</secondary><tertiary>of long-running GUI task</tertiary></indexterm><indexterm id="iddle1757" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey SHARING?><?tertiarykey SHARED DATA MODELS?><primary><emphasis role="strong">data</emphasis></primary><secondary>sharing</secondary><tertiary>shared data models</tertiary></indexterm><indexterm id="iddle2433" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey COMPLETION NOTIFICATION?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>completion notification</secondary></indexterm><indexterm id="iddle2434" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey COMPLETION NOTIFICATION?><?tertiarykey OF LONG-RUNNING GUI TASK?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>completion notification</secondary><tertiary>of long-running GUI task</tertiary></indexterm><indexterm id="iddle2646" significance="normal"><?indexkey H?><?primarykey hooks?><?secondarykey COMPLETION?><primary><emphasis role="strong">hooks</emphasis></primary><secondary>completion</secondary></indexterm><indexterm id="iddle2647" significance="normal"><?indexkey H?><?primarykey hooks?><?secondarykey COMPLETION?><?tertiarykey IN FUTURETASK?><primary><emphasis role="strong">hooks</emphasis></primary><secondary>completion</secondary><tertiary>in <literal>FutureTask</literal></tertiary></indexterm><indexterm id="iddle3231" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey SHARED DATA?><?tertiarykey IN GUI APPLICATIONS?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>shared data</secondary><tertiary>in GUI applications</tertiary></indexterm><indexterm id="iddle3319" significance="normal"><?indexkey N?><?primarykey notification?><?secondarykey COMPLETION?><primary><emphasis role="strong">notification</emphasis></primary><secondary>completion</secondary></indexterm><indexterm id="iddle3320" significance="normal"><?indexkey N?><?primarykey notification?><?secondarykey COMPLETION?><?tertiarykey OF LONG-RUNNING GUI TASK?><primary><emphasis role="strong">notification</emphasis></primary><secondary>completion</secondary><tertiary>of long-running GUI task</tertiary></indexterm><indexterm id="iddle3700" significance="normal"><?indexkey P?><?primarykey progress indication?><?secondarykey IN LONG-RUNNING GUI TASK?><primary><emphasis role="strong">progress indication</emphasis></primary><secondary>in long-running GUI task</secondary></indexterm><indexterm id="iddle4226" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey DATA?><?tertiarykey MODELS, GUI APPLICATION HANDLING?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>data</secondary><tertiary>models, GUI application handling</tertiary></indexterm><indexterm id="iddle4530" significance="normal"><?indexkey S?><?primarykey SwingWorker?><primary><emphasis role="strong">SwingWorker</emphasis></primary></indexterm><indexterm id="iddle4531" significance="normal"><?indexkey S?><?primarykey SwingWorker?><?secondarykey LONG-RUNNING GUI TASK SUPPORT?><primary><emphasis role="strong">SwingWorker</emphasis></primary><secondary>long-running GUI task support</secondary></indexterm><indexterm id="iddle4918" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey PROGRESS INDICATION?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>progress indication</secondary></indexterm><indexterm id="iddle4919" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey PROGRESS INDICATION?><?tertiarykey FOR LONG-RUNNING GUI TASKS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>progress indication</secondary><tertiary>for long-running GUI tasks</tertiary></indexterm>only one background task is running at a time. However, it would be better to be notified when the task completes so that, for example, the cancel button could be disabled. We address this in the next section.</para>
</section>
<section id="ch09lev2sec4" label="9.3.2" xreflabel="9.3.2">
<title id="ch09lev2sec4__title">Progress and Completion Indication</title>
<para>Using a <literal>Future</literal> to represent a long-running task greatly simplified implementing cancellation. <literal>FutureTask</literal> also has a <literal>done</literal> hook that similarly facilitates completion notification. After the background <literal>Callable</literal> completes, <literal>done</literal> is called. By having <literal>done</literal> trigger a completion task in the event thread, we can construct a <literal>BackgroundTask</literal> class providing an <literal>onCompletion</literal> hook that is called in the event thread, as shown in <link linkend="ch09list07" preference="0">Listing 9.7</link>.</para>
<para><literal>BackgroundTask</literal> also supports progress indication. The <literal>compute</literal> method can call <literal>setProgress</literal>, indicating progress in numerical terms. This causes <literal>onProgress</literal> to be called from the event thread, which can update the user interface to indicate progress visually.</para>
<para>To implement a <literal>BackgroundTask</literal> you need only implement <literal>compute</literal>, which is called in the background thread. You also have the option of overriding <literal>onCompletion</literal> and <literal>onProgress</literal>, which are invoked in the event thread.</para>
<para>Basing <literal>BackgroundTask</literal> on <literal>FutureTask</literal> also simplifies cancellation. Rather than having to poll the thread’s interrupted status, <literal>compute</literal> can call <literal>Future. is-Cancelled</literal>. <link linkend="ch09list08" preference="0">Listing 9.8</link> recasts the example from <link linkend="ch09list06" preference="0">Listing 9.6</link> using <literal>Background-Task</literal>.</para>
</section>
<section id="ch09lev2sec5" label="9.3.3" xreflabel="9.3.3">
<title id="ch09lev2sec5__title"><literal>SwingWorker</literal></title>
<para>We’ve built a simple framework using <literal>FutureTask</literal> and <literal>Executor</literal> to execute longrunning tasks in background threads without undermining the responsiveness of the GUI. These techniques can be applied to any single-threaded GUI framework, not just Swing. In Swing, many of the features developed here are provided by the <literal>SwingWorker</literal> class, including cancellation, completion notification, and progress indication. Various versions of <literal>SwingWorker</literal> have been published in <emphasis>The Swing Connection</emphasis> and <emphasis>The Java Tutorial</emphasis>, and an updated version is included in Java 6.</para>
</section>
</section>
<section id="ch09lev1sec4" condition="198" label="9.4" xreflabel="9.4"><?docpage num="198"?><?docpage num="199"?>
<title id="ch09lev1sec4__title">Shared Data Models</title>
<para>Swing presentation objects, including data model objects such as <literal>TableModel</literal> or <literal>TreeModel</literal>, are confined to the event thread. In simple GUI programs, all the mutable state is held in the presentation objects and the only thread besides the event thread is the main thread. In these programs enforcing the single-thread rule is easy: don’t access the data model or presentation components from the main thread. More complicated programs may use other threads to move data to or from a persistent store, such as a file system or database, so as not to compromise responsiveness.</para>
<para>In the simplest case, the data in the data model is entered by the user or loaded statically from a file or other data source at application startup, in which case the data is never touched by any thread other than the event thread. But sometimes <?docpage num="200"?><indexterm id="iddle2079" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BACKGROUNDTASK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BackgroundTask</literal></secondary></indexterm><indexterm id="iddle2439" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey EXAMPLE USE?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>example use</secondary></indexterm><indexterm id="iddle4965" significance="normal"><?indexkey T?><?primarykey tree(s)?><?secondarykey MODELS?><primary><emphasis role="strong">tree(s)</emphasis></primary><secondary>models</secondary></indexterm><indexterm id="iddle4966" significance="normal"><?indexkey T?><?primarykey tree(s)?><?secondarykey MODELS?><?tertiarykey GUI APPLICATION HANDLING?><primary><emphasis role="strong">tree(s)</emphasis></primary><secondary>models</secondary><tertiary>GUI application handling</tertiary></indexterm>the presentation model object is only a view onto another data source, such as a database, file system, or remote service. In this case, more than one thread is likely to touch the data as it goes into or out of the application.</para>
<example id="ch09list07" label="9.7" role="Listing" xreflabel="9.7" condition="199">
<?docpage num="199"?>
<title id="ch09list07__title">Background Task Class Supporting Cancellation, Completion Notification, and Progress Notification.</title>
<programlisting format="linespecific" linenumbering="unnumbered">abstract class BackgroundTask&lt;V&gt; implements Runnable, Future&lt;V&gt; {
    private final FutureTask&lt;V&gt; computation = new Computation();

    private class Computation extends FutureTask&lt;V&gt; {
        public Computation() {
            super(new Callable&lt;V&gt;() {
                public V call() throws Exception {
                    return <emphasis role="strong">BackgroundTask.this.compute() ;</emphasis>
                }
            });
        }
        protected final void done() {
            GuiExecutor.instance().execute(new Runnable() {
                public void run() {
                    V value = null;
                    Throwable thrown = null;
                    boolean cancelled = false;
                    try {
                        value = get();
                    } catch (ExecutionException e) {
                        thrown = e.getCause();
                    } catch (CancellationException e) {
                        cancelled = true;
                    } catch (InterruptedException consumed) {
                    } finally {
                        <emphasis role="strong">onCompletion(value, thrown, cancelled);</emphasis>
                    }
                };
            });
        }
    }
    protected void setProgress(final int current, final int max) {
        GuiExecutor.instance().execute(new Runnable() {
            public void run() { <emphasis role="strong">onProgress(current, max);</emphasis> }
        });
    }
    <emphasis>// Called in the background thread</emphasis>
    protected abstract V <emphasis role="strong">compute()</emphasis>  throws Exception;
    <emphasis>// Called in the event thread</emphasis>
    protected void <emphasis role="strong">onCompletion(V result, Throwable exception,</emphasis>
                                     <emphasis role="strong">boolean cancelled)</emphasis>  { }
    protected void  <emphasis role="strong">onProgress(int current, int max)</emphasis>  { }
    <emphasis>// Other Future methods forwarded to computation</emphasis>
}
</programlisting>
</example>
<example id="ch09list08" label="9.8" role="Listing" xreflabel="9.8" condition="200">
<title id="ch09list08__title">Initiating a Long-running, Cancellable Task with <literal>BackgroundTask</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">startButton.addActionListener(new ActionListener() {
  public void runInBackground(final Runnable task) {
      startButton.addActionListener(new ActionListener() {
          public void actionPerformed(ActionEvent e) {
              class CancelListener implements ActionListener {
                  BackgroundTask&lt;?&gt; task;
                  public void actionPerformed(ActionEvent event) {
                      if (task != null)
                          task.cancel(true);
                  }
              }
              final CancelListener listener = new CancelListener();
              listener.task = new BackgroundTask&lt;Void&gt;() {
                  public Void compute() {
                     while (moreWork() &amp;&amp; !isCancelled())
                         doSomeWork();
                     return null;
                  }
                  public void onCompletion(boolean cancelled, String s,
                                         Throwable exception) {
                     cancelButton<emphasis role="strong">.removeActionListener</emphasis>(listener);
                     label.setText("done");
                  }
              };
              cancelButton<emphasis role="strong">.addActionListener</emphasis>(listener);
              backgroundExec<emphasis role="strong">.execute</emphasis>(listener.task);
          }
      });
</programlisting>
</example>
<para>For example, you might display the contents of a remote file system using a tree control. You wouldn’t want to enumerate the entire file system before you can display the tree control—that would take too much time and memory. Instead, the tree can be lazily populated as nodes are expanded. Enumerating even a single directory on a remote volume can take a long time, so you may want to do the enumeration in a background task. When the background task completes, you have to get the data into the tree model somehow. This could be done by using a thread-safe tree model, by “pushing” the data from the background task to the event thread by posting a task with <literal>invokeLater</literal>, or by having the event thread poll to see if the data is available.</para>
<section id="ch09lev2sec6" condition="201" label="9.4.1" xreflabel="9.4.1">
<?docpage num="201"?>
<title id="ch09lev2sec6__title">Thread-safe Data Models</title>
<para><indexterm id="iddle1446" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1469" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey FINE-GRAINED?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>fine-grained</secondary></indexterm><indexterm id="iddle1470" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey FINE-GRAINED?><?tertiarykey AND THREAD-SAFE DATA MODELS?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>fine-grained</secondary><tertiary>and thread-safe data models</tertiary></indexterm><indexterm id="iddle1667" significance="normal"><?indexkey C?><?primarykey CopyOnWriteArrayList?><?secondarykey VERSIONED DATA MODEL USE?><primary><emphasis role="strong">CopyOnWriteArrayList</emphasis></primary><secondary>versioned data model use</secondary></indexterm><indexterm id="iddle1668" significance="normal"><?indexkey C?><?primarykey CopyOnWriteArrayList?><?secondarykey VERSIONED DATA MODEL USE?><?tertiarykey IN GUI APPLICATIONS?><primary><emphasis role="strong">CopyOnWriteArrayList</emphasis></primary><secondary>versioned data model use</secondary><tertiary>in GUI applications</tertiary></indexterm><indexterm id="iddle1759" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey SPLIT DATA MODELS?><primary><emphasis role="strong">data</emphasis></primary><secondary>split data models</secondary></indexterm><indexterm id="iddle1760" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey SPLIT DATA MODELS?><primary><emphasis role="strong">data</emphasis></primary><secondary>split data models</secondary></indexterm><indexterm id="iddle1762" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey VERSIONED DATA MODEL?><primary><emphasis role="strong">data</emphasis></primary><secondary>versioned data model</secondary></indexterm><indexterm id="iddle2108" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey DELEGATINGVEHICLETRACKER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>DelegatingVehicleTracker</literal></secondary></indexterm><indexterm id="iddle3004" significance="normal"><?indexkey L?><?primarykey lists?><?secondarykey COPYONWRITEARRAYLIST?><?tertiarykey VERSIONED DATA MODEL USE?><primary><emphasis role="strong">lists</emphasis></primary><secondary><literal>CopyOnWriteArrayList</literal></secondary><tertiary>versioned data model use</tertiary></indexterm><indexterm id="iddle3234" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey SPLIT DATA MODELS?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>split data models</secondary></indexterm><indexterm id="iddle3235" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey SPLIT DATA MODELS?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>split data models</secondary></indexterm><indexterm id="iddle3238" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey VERSIONED DATA MODEL?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>versioned data model</secondary></indexterm><indexterm id="iddle4238" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey SPLIT DATA MODELS?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>split data models</secondary></indexterm><indexterm id="iddle4345" significance="normal"><?indexkey S?><?primarykey split(ing)?><primary><emphasis role="strong">split(ing)</emphasis></primary></indexterm><indexterm id="iddle4346" significance="normal"><?indexkey S?><?primarykey split(ing)?><?secondarykey DATA MODELS?><primary><emphasis role="strong">split(ing)</emphasis></primary><secondary>data models</secondary></indexterm><indexterm id="iddle4347" significance="normal"><?indexkey S?><?primarykey split(ing)?><?secondarykey DATA MODELS?><primary><emphasis role="strong">split(ing)</emphasis></primary><secondary>data models</secondary></indexterm><indexterm id="iddle4733" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey DATA MODELS, GUI APPLICATION HANDLING?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>data models, GUI application handling</secondary></indexterm><indexterm id="iddle5017" significance="normal"><?indexkey U?><?primarykey updating?><?secondarykey VIEWS?><primary><emphasis role="strong">updating</emphasis></primary><secondary>views</secondary></indexterm><indexterm id="iddle5018" significance="normal"><?indexkey U?><?primarykey updating?><?secondarykey VIEWS?><?tertiarykey IN GUI TASKS?><primary><emphasis role="strong">updating</emphasis></primary><secondary>views</secondary><tertiary>in GUI tasks</tertiary></indexterm><indexterm id="iddle5083" significance="normal"><?indexkey V?><?primarykey versioned data model?><primary><emphasis role="strong">versioned data model</emphasis></primary></indexterm><indexterm id="iddle5094" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey UPDATING?><primary><emphasis role="strong">views</emphasis></primary><secondary>updating</secondary></indexterm><indexterm id="iddle5095" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey UPDATING?><?tertiarykey IN LONG-RUNNING GUI TASK HANDLING?><primary><emphasis role="strong">views</emphasis></primary><secondary>updating</secondary><tertiary>in long-running GUI task handling</tertiary></indexterm><indexterm id="iddle5096" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey WITH SPLIT DATA MODELS?><primary><emphasis role="strong">views</emphasis></primary><secondary>with split data models</secondary></indexterm>As long as responsiveness is not unduly affected by blocking, the problem of multiple threads operating on the data can be addressed with a thread-safe data model. If the data model supports fine-grained concurrency, the event thread and background threads should be able to share it without responsiveness problems. For example, <literal>DelegatingVehicleTracker</literal> on page <link linkend="ch04list07" preference="0" role="pageref">65</link> uses an underlying <literal>ConcurrentHashMap</literal> whose retrieval operations offer a high degree of concurrency. The downside is that it does not offer a consistent snapshot of the data, which may or may not be a requirement. Thread-safe data models must also generate events when the model has been updated, so that views can be updated when the data changes.</para>
<para>It may sometimes be possible to get thread safety, consistency and good responsiveness with a <emphasis>versioned data model</emphasis> such as <literal>CopyOnWriteArrayList</literal> [CPJ 2.2.3.3]. When you acquire an iterator for a copy-on-write collection, that iterator traverses the collection as it existed when the iterator was created. However, copy-on-write collections offer good performance only when traversals greatly outnumber modifications, which would probably not be the case in, say, a vehicle tracking application. More specialized versioned data structures may avoid this restriction, but building versioned data structures that provide both efficient concurrent access and do not retain old versions of data longer than needed is not easy, and thus should be considered only when other approaches are not practical.</para>
</section>
<section id="ch09lev2sec7" label="9.4.2" xreflabel="9.4.2">
<title id="ch09lev2sec7__title">Split Data Models</title>
<para>From the perspective of the GUI, the Swing table model classes like <literal>TableModel</literal> and <literal>TreeModel</literal> are the official repository for data to be displayed. However, these model objects are often themselves “views” of other objects managed by the application. A program that has both a presentation-domain and an applicationdomain data model is said to have a <emphasis>split-model</emphasis> design (<link linkend="biblio01_010" preference="0">Fowler, 2005</link>).</para>
<para>In a split-model design, the presentation model is confined to the event thread and the other model, the <emphasis>shared model</emphasis>, is thread-safe and may be accessed by both the event thread and application threads. The presentation model registers listeners with the shared model so it can be notified of updates. The presentation model can then be updated from the shared model by embedding a snapshot of the relevant state in the update message or by having the presentation model retrieve the data directly from the shared model when it receives an update event.</para>
<para>The snapshot approach is simple, but has limitations. It works well when the data model is small, updates are not too frequent, and the structure of the two models is similar. If the data model is large or updates are very frequent, or if one or both sides of the split contain information that is not visible to the other side, it can be more efficient to send incremental updates instead of entire snapshots. This approach has the effect of serializing updates on the shared model and recreating them in the event thread against the presentation model. Another advantage of incremental updates is that finer-grained information about what <?docpage num="202"?>changed can improve the perceived quality of the display—if only one vehicle moves, we don’t have to repaint the entire display, just the affected regions.</para>
<sidebar float="1" id="ch09sb02" condition="202"><title/>
<para>Consider a split-model design when a data model must be shared by more than one thread and implementing a thread-safe data model would be inadvisable because of blocking, consistency, or complexity reasons.</para>
</sidebar>
</section>
</section>
<section id="ch09lev1sec5" condition="202" label="9.5" xreflabel="9.5"><?docpage num="202"?>
<title id="ch09lev1sec5__title">Other Forms of Single-threaded Subsystems</title>
<para>Thread confinement is not restricted to GUIs: it can be used whenever a facility is implemented as a single-threaded subsystem. Sometimes thread confinement is forced on the developer for reasons that have nothing to do with avoiding synchronization or deadlock. For example, some native libraries require that all access to the library, even loading the library with <literal>System.loadLibrary</literal>, bemade from the same thread.</para>
<para>Borrowing from the approach taken by GUI frameworks, you can easily create a dedicated thread or single-threaded executor for accessing the native library, and provide a proxy object that intercepts calls to the thread-confined object and submits them as tasks to the dedicated thread. <literal>Future</literal> and <literal>newSingleThreadExecutor</literal> work together to make this easy; the proxy method can <literal>submit</literal> the task and immediately call <literal>Future.get</literal> to wait for the result. (If the class to be threadconfined implements an interface, you can automate the process of having each method submit a <literal>Callable</literal> to a background thread executor and waiting for the result using dynamic proxies.)</para>
</section>



<section id="ch09lev1sec6" condition="202" label="" xreflabel=""><?docpage num="202"?>
<title id="ch09lev1sec6__title">Summary</title>
<para>GUI frameworks are nearly always implemented as single-threaded subsystems in which all presentation-related code runs as tasks in an event thread. Because there is only a single event thread, long-running tasks can compromise responsiveness and so should be executed in background threads. Helper classes like <literal>SwingWorker</literal> or the <literal>BackgroundTask</literal> class built here, which provide support for cancellation, progress indication, and completion indication, can simplify the development of long-running tasks that have both GUI and non-GUI components.</para>
</section>

</chapter>

</part>

<part id="part03" label="III" xreflabel="III" condition="203">
<?docpage num="203"?><?docpage num="204"?>
<title id="part03__title">Liveness, Performance, and Testing</title>
<chapter id="ch10" label="10" xreflabel="10" condition="205">
<?docpage num="205"?>
<title id="ch10__title">Avoiding Liveness Hazards</title>


<para><indexterm id="iddle1465" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey ERRORS?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>errors</secondary><see> <link linkend="iddle1086" preference="0"><emphasis role="strong">analysis</emphasis>, deadlock</link>.</see></indexterm><indexterm id="iddle1466" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey ERRORS?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>errors</secondary><see> <link linkend="iddle3011" preference="0"><emphasis role="strong">livelock</emphasis></link>.</see></indexterm><indexterm id="iddle1467" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey ERRORS?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>errors</secondary><see> <link linkend="iddle3776" preference="0"><emphasis role="strong">race conditions</emphasis></link>.</see></indexterm><indexterm id="iddle1468" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey ERRORS?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>errors</secondary><see> <link linkend="iddle4367" preference="0"><emphasis role="strong">starvation</emphasis></link>.</see></indexterm><indexterm id="iddle1633" significance="normal"><?indexkey C?><?primarykey convenience?><primary><emphasis role="strong">convenience</emphasis></primary><seealso> <link linkend="iddle3188" preference="0"><emphasis role="strong">measurement</emphasis>, responsiveness</link>.</seealso></indexterm><indexterm id="iddle1791" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle1792" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><seealso> <link linkend="iddle3497" preference="0"><emphasis role="strong">performance</emphasis>, liveness</link>.</seealso></indexterm><indexterm id="iddle1793" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle1794" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><primary><emphasis role="strong">deadlock(s)</emphasis></primary></indexterm><indexterm id="iddle1820" significance="normal"><?indexkey D?><?primarykey deadly embrace?><primary><emphasis role="strong">deadly embrace</emphasis></primary><see> <link linkend="iddle1086" preference="0"><emphasis role="strong">analysis</emphasis>, deadlock</link>.</see></indexterm><indexterm id="iddle1851" significance="normal"><?indexkey D?><?primarykey delayed tasks?><primary><emphasis role="strong">delayed tasks</emphasis></primary><seealso> <link linkend="iddle48911" preference="0"><emphasis role="strong">time/timing</emphasis></link>.</seealso></indexterm><indexterm id="iddle1951" significance="normal"><?indexkey D?><?primarykey dining philosophers problem?><primary><emphasis role="strong">dining philosophers problem</emphasis></primary><seealso> <link linkend="iddle1086" preference="0"><emphasis role="strong">analysis</emphasis>, deadlock</link>.</seealso></indexterm><indexterm id="iddle1975" significance="normal"><?indexkey D?><?primarykey dynamic?><primary><emphasis role="strong">dynamic</emphasis></primary><seealso> <link linkend="iddle3188" preference="0"><emphasis role="strong">measurement</emphasis>, responsiveness</link>.</seealso></indexterm><indexterm id="iddle2043" significance="normal"><?indexkey E?><?primarykey error(s)?><?secondarykey CONCURRENCY?><primary><emphasis role="strong">error(s)</emphasis></primary><secondary>concurrency</secondary><see> <link linkend="iddle1086" preference="0"><emphasis role="strong">analysis</emphasis>, deadlock</link>.</see></indexterm><indexterm id="iddle2044" significance="normal"><?indexkey E?><?primarykey error(s)?><?secondarykey CONCURRENCY?><primary><emphasis role="strong">error(s)</emphasis></primary><secondary>concurrency</secondary><see> <link linkend="iddle3011" preference="0"><emphasis role="strong">livelock</emphasis></link>.</see></indexterm><indexterm id="iddle2045" significance="normal"><?indexkey E?><?primarykey error(s)?><?secondarykey CONCURRENCY?><primary><emphasis role="strong">error(s)</emphasis></primary><secondary>concurrency</secondary><see> <link linkend="iddle3776" preference="0"><emphasis role="strong">race conditions</emphasis></link>.</see></indexterm><indexterm id="iddle2319" significance="normal"><?indexkey F?><?primarykey fairness?><primary><emphasis role="strong">fairness</emphasis></primary><seealso> <link linkend="iddle3188" preference="0"><emphasis role="strong">measurement</emphasis>, responsiveness</link>.</seealso></indexterm><indexterm id="iddle2320" significance="normal"><?indexkey F?><?primarykey fairness?><primary><emphasis role="strong">fairness</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle2372" significance="normal"><?indexkey F?><?primarykey flexibility?><primary><emphasis role="strong">flexibility</emphasis></primary><seealso> <link linkend="iddle3188" preference="0"><emphasis role="strong">measurement</emphasis>, responsiveness</link>.</seealso></indexterm><indexterm id="iddle2373" significance="normal"><?indexkey F?><?primarykey flexibility?><primary><emphasis role="strong">flexibility</emphasis></primary><seealso> <link linkend="iddle2574" preference="0"><emphasis role="strong">guidelines</emphasis>, scalability</link>.</seealso></indexterm><indexterm id="iddle3017" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey CAUSES?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>causes</secondary><see> <link linkend="iddle1086" preference="0"><emphasis role="strong">analysis</emphasis>, deadlock</link>.</see></indexterm><indexterm id="iddle3018" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey CAUSES?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>causes</secondary><see> <link linkend="iddle3011" preference="0"><emphasis role="strong">livelock</emphasis></link>.</see></indexterm><indexterm id="iddle3019" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey CAUSES?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>causes</secondary><see> <link linkend="iddle3213" preference="0"><emphasis role="strong">missed signals</emphasis></link>.</see></indexterm><indexterm id="iddle3020" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey CAUSES?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>causes</secondary><see> <link linkend="iddle4367" preference="0"><emphasis role="strong">starvation</emphasis></link>.</see></indexterm><indexterm id="iddle3021" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey FAILURE?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>failure</secondary></indexterm><indexterm id="iddle3022" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey FAILURE?><?tertiarykey AVOIDANCE?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>failure</secondary><tertiary>avoidance</tertiary></indexterm><indexterm id="iddle3085" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CYCLIC LOCKING DEPENDENCIES?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>cyclic locking dependencies</secondary></indexterm><indexterm id="iddle3086" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CYCLIC LOCKING DEPENDENCIES?><?tertiarykey AS DEADLOCK CAUSE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>cyclic locking dependencies</secondary><tertiary>as deadlock cause</tertiary></indexterm><indexterm id="iddle3648" significance="normal"><?indexkey P?><?primarykey predictability?><primary><emphasis role="strong">predictability</emphasis></primary><seealso> <link linkend="iddle3188" preference="0"><emphasis role="strong">measurement</emphasis>, responsiveness</link>.</seealso></indexterm><indexterm id="iddle3800" significance="normal"><?indexkey R?><?primarykey recovery, deadlock?><primary><emphasis role="strong">recovery, deadlock</emphasis></primary><see> <link linkend="iddle1791" preference="0"><emphasis role="strong">deadlock(s)</emphasis></link>.</see></indexterm><indexterm id="iddle3944" significance="normal"><?indexkey R?><?primarykey responsiveness?><primary><emphasis role="strong">responsiveness</emphasis></primary><seealso> <link linkend="iddle1086" preference="0"><emphasis role="strong">analysis</emphasis>, deadlock</link>.</seealso></indexterm><indexterm id="iddle3945" significance="normal"><?indexkey R?><?primarykey responsiveness?><primary><emphasis role="strong">responsiveness</emphasis></primary><seealso> <link linkend="iddle1110" preference="0"><emphasis role="strong">application(s)</emphasis>, GUI</link>.</seealso></indexterm><indexterm id="iddle3946" significance="normal"><?indexkey R?><?primarykey responsiveness?><primary><emphasis role="strong">responsiveness</emphasis></primary><seealso> <link linkend="iddle3011" preference="0"><emphasis role="strong">livelock</emphasis></link>.</seealso></indexterm><indexterm id="iddle3947" significance="normal"><?indexkey R?><?primarykey responsiveness?><primary><emphasis role="strong">responsiveness</emphasis></primary><seealso> <link linkend="iddle3497" preference="0"><emphasis role="strong">performance</emphasis>, liveness</link>.</seealso></indexterm><indexterm id="iddle3948" significance="normal"><?indexkey R?><?primarykey responsiveness?><primary><emphasis role="strong">responsiveness</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle4037" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey LIVENESS VS?><primary><emphasis role="strong">safety</emphasis></primary><secondary>liveness vs</secondary></indexterm><indexterm id="iddle4882" significance="normal"><?indexkey T?><?primarykey time/timing?><primary><emphasis role="strong">time/timing</emphasis></primary><seealso> <link linkend="iddle1086" preference="0"><emphasis role="strong">analysis</emphasis>, deadlock</link>.</seealso></indexterm><indexterm id="iddle4883" significance="normal"><?indexkey T?><?primarykey time/timing?><primary><emphasis role="strong">time/timing</emphasis></primary><seealso> <link linkend="iddle4633" preference="0"><emphasis role="strong">task(s)</emphasis>, lifecycle</link>.</seealso></indexterm><indexterm id="iddle4884" significance="normal"><?indexkey T?><?primarykey time/timing?><primary><emphasis role="strong">time/timing</emphasis></primary><seealso> <link linkend="iddle3398" preference="0"><emphasis role="strong">order(ing)</emphasis></link>.</seealso></indexterm><indexterm id="iddle4885" significance="normal"><?indexkey T?><?primarykey time/timing?><primary><emphasis role="strong">time/timing</emphasis></primary><seealso> <link linkend="iddle3776" preference="0"><emphasis role="strong">race conditions</emphasis></link>.</seealso></indexterm>There is often a tension between safety and liveness. We use locking to ensure thread safety, but indiscriminate use of locking can cause <emphasis>lock-ordering deadlocks</emphasis>. Similarly, we use thread pools and semaphores to bound resource consumption, but failure to understand the activities being bounded can cause <emphasis>resource deadlocks</emphasis>. Java applications do not recover from deadlock, so it is worthwhile to ensure that your design precludes the conditions that could cause it. This chapter explores some of the causes of liveness failures and what can be done to prevent them.</para>



<section id="ch10lev1sec1" condition="205" label="10.1" xreflabel="10.1"><?docpage num="205"?>
<title id="ch10lev1sec1__title">Deadlock</title>
<para>Deadlock is illustrated by the classic, if somewhat unsanitary, “dining philosophers” problem. Five philosophers go out for Chinese food and are seated at a circular table. There are five chopsticks (not five pairs), one placed between each pair of diners. The philosophers alternate between thinking and eating. Each needs to acquire two chopsticks for long enough to eat, but can then put the chopsticks back and return to thinking. There are some chopstick-management algorithms that let everyone eat on a more or less timely basis (a hungry philosopher tries to grab both adjacent chopsticks, but if one is not available, puts down the one that is available and waits a minute or so before trying again), and some that can result in some or all of the philosophers dying of hunger (each philosopher immediately grabs the chopstick to his left and waits for the chopstick to his right to be available before putting down the left). The latter situation, where each has a resource needed by another and is waiting for a resource held by another, and will not release the one they hold until they acquire the one they don’t, illustrates deadlock.</para>
<para>When a thread holds a lock forever, other threads attempting to acquire that lock will block forever waiting. When thread <emphasis>A</emphasis> holds lock <emphasis>L</emphasis> and tries to acquire lock <emphasis>M</emphasis>, but at the same time thread <emphasis>B</emphasis> holds <emphasis>M</emphasis> and tries to acquire <emphasis>L</emphasis>, <emphasis>both</emphasis> threads will wait forever. This situation is the simplest case of deadlock (or <emphasis>deadly embrace</emphasis>), where multiple threads wait forever due to a cyclic locking dependency. (Think of the threads as the nodes of a directed graph whose edges represent the relation <?docpage num="206"?><indexterm id="iddle1556" significance="normal"><?indexkey C?><?primarykey consistent/consistency?><?secondarykey LOCK ORDERING?><primary><emphasis role="strong">consistent/consistency</emphasis></primary><secondary>lock ordering</secondary></indexterm><indexterm id="iddle1557" significance="normal"><?indexkey C?><?primarykey consistent/consistency?><?secondarykey LOCK ORDERING?><?tertiarykey AND DEADLOCK AVOIDANCE?><primary><emphasis role="strong">consistent/consistency</emphasis></primary><secondary>lock ordering</secondary><tertiary>and deadlock avoidance</tertiary></indexterm><indexterm id="iddle1780" significance="normal"><?indexkey D?><?primarykey database(s)?><primary><emphasis role="strong">database(s)</emphasis></primary></indexterm><indexterm id="iddle1781" significance="normal"><?indexkey D?><?primarykey database(s)?><?secondarykey DEADLOCK RECOVERY CAPABILITIES?><primary><emphasis role="strong">database(s)</emphasis></primary><secondary>deadlock recovery capabilities</secondary></indexterm><indexterm id="iddle1810" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey RECOVERY?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>recovery</secondary></indexterm><indexterm id="iddle1811" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey RECOVERY?><?tertiarykey DATABASE CAPABILITIES?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>recovery</secondary><tertiary>database capabilities</tertiary></indexterm><indexterm id="iddle2515" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey DEADLOCK AVOIDANCE?><?tertiarykey LOCK ORDERING?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>deadlock avoidance</secondary><tertiary>lock ordering</tertiary></indexterm><indexterm id="iddle2552" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey LOCK?><?tertiarykey ORDERING, DEADLOCK AVOIDANCE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>lock</secondary><tertiary>ordering, deadlock avoidance</tertiary></indexterm><indexterm id="iddle2915" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey DEADLOCK HANDLING LIMITATIONS?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>deadlock handling limitations</secondary></indexterm><indexterm id="iddle3124" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ORDERING?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>ordering</secondary></indexterm><indexterm id="iddle3125" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ORDERING?><?tertiarykey DEADLOCK RISKS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>ordering</secondary><tertiary>deadlock risks</tertiary></indexterm><indexterm id="iddle3405" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey LOCK?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle3406" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey LOCK?><?tertiarykey DEADLOCK RISKS?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>lock</secondary><tertiary>deadlock risks</tertiary></indexterm>“Thread <emphasis>A</emphasis> is waiting for a resource held by thread <emphasis>B</emphasis>”. If this graph is cyclical, there is a deadlock.)</para>
<para>Database systems are designed to detect and recover from deadlock. A transaction may acquire many locks, and locks are held until the transaction commits. So it is quite possible, and in fact not uncommon, for two transactions to deadlock. Without intervention, they would wait forever (holding locks that are probably required by other transactions as well). But the database server is not going to let this happen. When it detects that a set of transactions is deadlocked (which it does by searching the <emphasis>is-waiting-for</emphasis> graph for cycles), it picks a victim and aborts that transaction. This releases the locks held by the victim, allowing the other transactions to proceed. The application can then retry the aborted transaction, which may be able to complete now that any competing transactions have completed.</para>
<para>The JVM is not nearly as helpful in resolving deadlocks as database servers are. When a set of Java threads deadlock, that’s the end of the game—those threads are permanently out of commission. Depending on what those threads do, the application may stall completely, or a particular subsystem may stall, or performance may suffer. The only way to restore the application to health is to abort and restart it—and hope the same thing doesn’t happen again.</para>
<para>Like many other concurrency hazards, deadlocks rarely manifest themselves immediately. The fact that a class has a potential deadlock doesn’t mean that it ever <emphasis>will</emphasis> deadlock, just that it can. When deadlocks do manifest themselves, it is often at the worst possible time—under heavy production load.</para>
<section id="ch10lev2sec1" label="10.1.1" xreflabel="10.1.1">
<title id="ch10lev2sec1__title">Lock-ordering Deadlocks</title>
<para><literal>LeftRightDeadlock</literal> in <link linkend="ch10list01" preference="0">Listing 10.1</link> is at risk for deadlock. The <literal>leftRight</literal> and <literal>rightLeft</literal> methods each acquire the <literal>left</literal> and <literal>right</literal> locks. If one thread calls <literal>leftRight</literal> and another calls <literal>rightLeft</literal>, and their actions are interleaved as shown in <link linkend="ch10fig01" preference="1">Figure 10.1</link>, they will deadlock.</para>
<figure float="1" id="ch10fig01" label="10.1" xreflabel="10.1" condition="207">
<?docpage num="207"?>
<title id="ch10fig01__title">Unlucky Timing in <literal>LeftRightDeadlock</literal>.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="122" fileref="graphics/10fig01.gif" format="GIF" width="395"/></imageobject>

</mediaobject>
</figure>
<para>The deadlock in <literal>LeftRightDeadlock</literal> came about because the two threads attempted to acquire the same locks in a <emphasis>different order</emphasis>. If they asked for the locks in the same order, there would be no cyclic locking dependency and therefore no deadlock. If you can guarantee that every thread that needs locks <emphasis>L</emphasis> and <emphasis>M</emphasis> at the same time always acquires <emphasis>L</emphasis> and <emphasis>M</emphasis> in the same order, there will be no deadlock.</para>
<sidebar float="1" id="ch10sb01" condition="206"><title/>
<para>A program will be free of lock-ordering deadlocks if all threads acquire the locks they need in a fixed global order.</para>
</sidebar>
<para>Verifying consistent lock ordering requires a global analysis of your program’s locking behavior. It is not sufficient to inspect code paths that acquire multiple locks individually; both <literal>leftRight</literal> and <literal>rightLeft</literal> are “reasonable” ways to acquire the two locks, they are just not compatible. When it comes to locking, the left hand needs to know what the right hand is doing.</para>

<para><?docpage num="207"?></para><example id="ch10list01" label="10.1" role="Listing" xreflabel="10.1" condition="207">

<title id="ch10list01__title">Simple Lock-ordering Deadlock. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered"><emphasis>// Warning: deadlock-prone!</emphasis>
public class LeftRightDeadlock {
    private final Object left = new Object();
    private final Object right = new Object();

    public void leftRight() {
        synchronized (left) {
            synchronized (right) {
                doSomething();
            }
        }
    }

    public void rightLeft() {
        synchronized (right) {
            synchronized (left) {
                doSomethingElse();
            }
        }
    }
}
</programlisting>
</example>
</section>
<section id="ch10lev2sec2" label="10.1.2" xreflabel="10.1.2">
<title id="ch10lev2sec2__title">Dynamic Lock Order Deadlocks</title>
<para><indexterm id="iddle1806" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey DYNAMIC LOCK ORDER?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>dynamic lock order</secondary></indexterm><indexterm id="iddle1978" significance="normal"><?indexkey D?><?primarykey dynamic?><?secondarykey LOCK ORDER DEADLOCKS?><primary><emphasis role="strong">dynamic</emphasis></primary><secondary>lock order deadlocks</secondary></indexterm><indexterm id="iddle2127" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey LEFTRIGHTDEADLOCK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>LeftRightDeadlock</literal></secondary></indexterm><indexterm id="iddle3126" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ORDERING?><?tertiarykey DYNAMIC, DEADLOCKS RESULTING FROM?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>ordering</secondary><tertiary>dynamic, deadlocks resulting from</tertiary></indexterm><indexterm id="iddle3407" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey LOCK?><?tertiarykey DYNAMIC DEADLOCK RISKS?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>lock</secondary><tertiary>dynamic deadlock risks</tertiary></indexterm><indexterm id="iddle4905" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey LEFTRIGHTDEADLOCK EXAMPLE?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary><literal>LeftRightDeadlock</literal> example</secondary></indexterm>Sometimes it is not obvious that you have sufficient control over lock ordering to prevent deadlocks. Consider the harmless-looking code in <link linkend="ch10list02" preference="0">Listing 10.2</link> that transfers funds from one account to another. It acquires the locks on both <literal>Account</literal> objects before executing the transfer, ensuring that the balances are updated atomically and without violating invariants such as “an account cannot have a negative balance”.</para>
<para>How can <literal>transferMoney</literal> deadlock? It may appear as if all the threads acquire their locks in the same order, but in fact the lock order depends on the order of arguments passed to <literal>transferMoney</literal>, and these in turn might depend on external inputs. Deadlock can occur if two threads call <literal>transferMoney</literal> at the same time, <?docpage num="208"?><?docpage num="209"?><indexterm id="iddle2628" significance="normal"><?indexkey H?><?primarykey hashcodes/hashtables?><?secondarykey INDUCING LOCK ORDERING WITH?><primary><emphasis role="strong">hashcodes/hashtables</emphasis></primary><secondary>inducing lock ordering with</secondary></indexterm><indexterm id="iddle2733" significance="normal"><?indexkey I?><?primarykey inducing lock ordering?><primary><emphasis role="strong">inducing lock ordering</emphasis></primary></indexterm><indexterm id="iddle2734" significance="normal"><?indexkey I?><?primarykey inducing lock ordering?><?secondarykey FOR DEADLOCK AVOIDANCE?><primary><emphasis role="strong">inducing lock ordering</emphasis></primary><secondary>for deadlock avoidance</secondary></indexterm><indexterm id="iddle3054" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><?tertiarykey NESTED, AS DEADLOCK RISK?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary><tertiary>nested, as deadlock risk</tertiary></indexterm><indexterm id="iddle4459" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey DEADLOCK AVOIDANCE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>deadlock avoidance</secondary></indexterm>one transferring from <emphasis>X</emphasis> to <emphasis>Y</emphasis>, and the other doing the opposite:</para>
<example id="ch10list02" label="10.2" role="Listing" xreflabel="10.2" condition="208">
<title id="ch10list02__title">Dynamic Lock-ordering Deadlock. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered"><emphasis>// Warning: deadlock-prone!</emphasis>
public void transferMoney(Account fromAccount,
                          Account toAccount,
                          DollarAmount amount)
        throws InsufficientFundsException {
    synchronized (fromAccount) {
        synchronized (toAccount) {
            if (fromAccount.getBalance().compareTo(amount) &lt; 0)
                throw new InsufficientFundsException();
            else {
                fromAccount.debit(amount);
                toAccount.credit(amount);
            }
        }
    }
}
</programlisting>
</example>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">A: transferMoney(myAccount, yourAccount, 10);
B: transferMoney(yourAccount, myAccount, 20);
</programlisting>
</informalexample>
<para role="continued">With unlucky timing, <emphasis>A</emphasis> will acquire the lock on <literal>myAccount</literal> and wait for the lock on <literal>yourAccount</literal>, while <emphasis>B</emphasis> is holding the lock on <literal>yourAccount</literal> and waiting for the lock on <literal>myAccount</literal>.</para>
<para>Deadlocks like this one can be spotted the same way as in <link linkend="ch10list01" preference="0">Listing 10.1</link>—look for nested lock acquisitions. Since the order of arguments is out of our control, to fix the problem we must <emphasis>induce</emphasis> an ordering on the locks and acquire them according to the induced ordering consistently throughout the application.</para>
<para>One way to induce an ordering on objects is to use <literal>System.identityHashCode</literal>, which returns the value that would be returned by <literal>Object.hashCode</literal>. <link linkend="ch10list03" preference="0">Listing 10.3</link> shows a version of <literal>transferMoney</literal> that uses <literal>System.identityHashCode</literal> to induce a lock ordering. It involves a few extra lines of code, but eliminates the possibility of deadlock.</para>
<para>In the rare case that two objects have the same hash code, we must use an arbitrary means of ordering the lock acquisitions, and this reintroduces the possibility of deadlock. To prevent inconsistent lock ordering in this case, a third “tie breaking” lock is used. By acquiring the tie-breaking lock before acquiring either <literal>Account</literal> lock, we ensure that only one thread at a time performs the risky task of acquiring two locks in an arbitrary order, eliminating the possibility of deadlock (so long as this mechanism is used consistently). If hash collisions were common, this technique might become a concurrency bottleneck (just as having a single, program-wide lock would), but because hash collisions with <literal>System.identityHashCode</literal> are vanishingly infrequent, this technique provides that last bit of safety at little cost.</para>
<example id="ch10list03" label="10.3" role="Listing" xreflabel="10.3" condition="209">
<?docpage num="209"?>
<title id="ch10list03__title">Inducing a Lock Ordering to Avoid Deadlock.</title>
<programlisting format="linespecific" linenumbering="unnumbered">private static final Object tieLock = new Object();

public void transferMoney(final Account fromAcct,
                          final Account toAcct,
                          final DollarAmount amount)
        throws InsufficientFundsException {
    class Helper {
        public void transfer() throws InsufficientFundsException {
            if (fromAcct.getBalance().compareTo(amount) &lt; 0)
                throw new InsufficientFundsException();
            else {
                fromAcct.debit(amount);
                toAcct.credit(amount);
            }
        }
    }
    int fromHash = System.identityHashCode(fromAcct);
    int toHash = System.identityHashCode(toAcct);

    if (fromHash &lt; toHash) {
        synchronized (fromAcct) {
            synchronized (toAcct) {
                new Helper().transfer();
            }
        }
    } else if (fromHash &gt; toHash) {
        synchronized (toAcct) {
            synchronized (fromAcct) {
                new Helper().transfer();
            }
        }
    } else {
        synchronized (tieLock) {
            synchronized (fromAcct) {
                synchronized (toAcct) {
                   new Helper().transfer();
                }
            }
        }
    }
}
</programlisting>
</example>
<para><?docpage num="210"?><indexterm id="iddle2109" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey DEMONSTRATEDEADLOCK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>DemonstrateDeadlock</literal></secondary></indexterm><indexterm id="iddle4694" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey DEADLOCK RISKS?><primary><emphasis role="strong">testing</emphasis></primary><secondary>deadlock risks</secondary></indexterm>If <literal>Account</literal> has a unique, immutable, comparable key such as an account number, inducing a lock ordering is even easier: order objects by their key, thus eliminating the need for the tie-breaking lock.</para>
<para>You may think we’re overstating the risk of deadlock because locks are usually held only briefly, but deadlocks are a serious problem in real systems. A production application may perform billions of lock acquire-release cycles per day. Only one of those needs to be timed just wrong to bring the application to deadlock, and even a thorough load-testing regimen may not disclose all latent deadlocks.<footnote id="ch10fn01" label="1"><para>Ironically, holding locks for short periods of time, as you are supposed to do to reduce lock contention, increases the likelihood that testing will not disclose latent deadlock risks.</para></footnote> <literal>DemonstrateDeadlock</literal> in <link linkend="ch10list04" preference="0">Listing 10.4</link><footnote id="ch10fn02" label="2"><para>For simplicity, <literal>DemonstrateDeadlock</literal> ignores the issue of negative account balances.</para></footnote> deadlocks fairly quickly on most systems.</para>
<example id="ch10list04" label="10.4" role="Listing" xreflabel="10.4" condition="210">
<title id="ch10list04__title">Driver Loop that Induces Deadlock Under Typical Conditions.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class DemonstrateDeadlock {
    private static final int NUM_THREADS = 20;
    private static final int NUM_ACCOUNTS = 5;
    private static final int NUM_ITERATIONS = 1000000;

    public static void main(String[] args) {
        final Random rnd = new Random();
        final Account[] accounts = new Account[NUM_ACCOUNTS];

        for (int i = 0; i &lt; accounts.length; i++)
            accounts[i] = new Account();

        class TransferThread extends Thread {
            public void run() {
                for (int i=0; i&lt;NUM_ITERATIONS; i++) {
                    int fromAcct = rnd.nextInt(NUM_ACCOUNTS);
                    int toAcct = rnd.nextInt(NUM_ACCOUNTS);
                    DollarAmount amount =
                        new DollarAmount(rnd.nextInt(1000));
                    transferMoney(accounts[fromAcct],
                                  accounts[toAcct], amount);
                }
            }
        }
        for (int i = 0; i &lt; NUM_THREADS; i++)
            new TransferThread().start();
    }
}
</programlisting>
</example>
</section>
<section id="ch10lev2sec3" condition="211" label="10.1.3" xreflabel="10.1.3">
<?docpage num="211"?><?docpage num="212"?>
<title id="ch10lev2sec3__title">Deadlocks Between Cooperating Objects</title>
<para><indexterm id="iddle1069" significance="normal"><?indexkey A?><?primarykey alien method?><?secondarykey DEADLOCK RISKS POSED BY?><primary><emphasis role="strong">alien method</emphasis></primary><secondary>deadlock risks posed by</secondary></indexterm><indexterm id="iddle1447" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1592" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey LOCK?><?tertiarykey REDUCTION IMPACT?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>lock</secondary><tertiary>reduction impact</tertiary></indexterm><indexterm id="iddle1648" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey OBJECTS?><?tertiarykey DEADLOCK, POSSIBILITIES?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>objects</secondary><tertiary>deadlock, possibilities</tertiary></indexterm><indexterm id="iddle1803" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey COOPERATING OBJECTS?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>cooperating objects</secondary></indexterm><indexterm id="iddle2513" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey DEADLOCK AVOIDANCE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>deadlock avoidance</secondary></indexterm><indexterm id="iddle2514" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey DEADLOCK AVOIDANCE?><?tertiarykey ALIEN METHOD RISKS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>deadlock avoidance</secondary><tertiary>alien method risks</tertiary></indexterm><indexterm id="iddle3081" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONTENTION?><?tertiarykey REDUCTION, IMPACT?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>contention</secondary><tertiary>reduction, impact</tertiary></indexterm><indexterm id="iddle3122" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey OPEN CALLS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>open calls</secondary></indexterm><indexterm id="iddle3123" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey OPEN CALLS?><?tertiarykey FOR DEADLOCK AVOIDANCE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>open calls</secondary><tertiary>for deadlock avoidance</tertiary></indexterm><indexterm id="iddle3369" significance="normal"><?indexkey O?><?primarykey open calls?><primary><emphasis role="strong">open calls</emphasis></primary></indexterm><indexterm id="iddle3370" significance="normal"><?indexkey O?><?primarykey open calls?><primary><emphasis role="strong">open calls</emphasis></primary><seealso> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</seealso></indexterm>Multiple lock acquisition is not always as obvious as in <literal>LeftRightDeadlock</literal> or <literal>transferMoney</literal>; the two locks need not be acquired by the same method. Consider the cooperating classes in <link linkend="ch10list05" preference="0">Listing 10.5</link>, which might be used in a taxicab dispatching application. <literal>Taxi</literal> represents an individual taxi with a location and a destination; <literal>Dispatcher</literal> represents a fleet of taxis.</para>
<para>While no method <emphasis>explicitly</emphasis> acquires two locks, callers of <literal>setLocation</literal> and <literal>getImage</literal> can acquire two locks just the same. If a thread calls <literal>setLocation</literal> in response to an update from a GPS receiver, it first updates the taxi’s location and then checks to see if it has reached its destination. If it has, it informs the dispatcher that it needs a new destination. Since both <literal>setLocation</literal> and <literal>notifyAvailable</literal> are <literal>synchronized</literal>, the thread calling <literal>setLocation</literal> acquires the <literal>Taxi</literal> lock and then the <literal>Dispatcher</literal> lock. Similarly, a thread calling <literal>getImage</literal> acquires the <literal>Dispatcher</literal> lock and then each <literal>Taxi</literal> lock (one at at time). Just as in <literal>LeftRightDeadlock</literal>, two locks are acquired by two threads in different orders, risking deadlock.</para>
<para>It was easy to spot the deadlock possibility in <literal>LeftRightDeadlock</literal> or <literal>transferMoney</literal> by looking for methods that acquire two locks. Spotting the deadlock possibility in <literal>Taxi</literal> and <literal>Dispatcher</literal> is a little harder: the warning sign is that an <emphasis>alien</emphasis> method (defined on page 40) is being called while holding a lock.</para>
<sidebar float="1" id="ch10sb02" condition="211"><title/>
<para>Invoking an alien method with a lock held is asking for liveness trouble. The alien method might acquire other locks (risking deadlock) or block for an unexpectedly long time, stalling other threads that need the lock you hold.</para>
</sidebar>
</section>
<section id="ch10lev2sec4" label="10.1.4" xreflabel="10.1.4">
<title id="ch10lev2sec4__title">Open Calls</title>
<para>Of course, <literal>Taxi</literal> and <literal>Dispatcher</literal> didn’t <emphasis>know</emphasis> that they were each half of a deadlock waiting to happen. And they shouldn’t have to; a method call is an abstraction barrier intended to shield you from the details of what happens on the other side. But because you don’t know what is happening on the other side of the call, <emphasis>calling an alien method with a lock held is difficult to analyze and therefore risky.</emphasis></para>
<para>Calling a method with no locks held is called an <emphasis>open call</emphasis> [CPJ 2.4.1.3], and classes that rely on open calls are more well-behaved and composable than classes that make calls with locks held. Using open calls to avoid deadlock is analogous to using encapsulation to provide thread safety: while one can certainly construct a thread-safe program without any encapsulation, the thread safety analysis of a program that makes effective use of encapsulation is far easier than that of one that does not. Similarly, the liveness analysis of a program that relies exclusively on open calls is far easier than that of one that does not. Restricting yourself to <?docpage num="213"?><?docpage num="214"?><indexterm id="iddle1646" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey OBJECTS?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>objects</secondary></indexterm><indexterm id="iddle1647" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey OBJECTS?><?tertiarykey DEADLOCK, LOCK-ORDERING?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>objects</secondary><tertiary>deadlock, lock-ordering</tertiary></indexterm><indexterm id="iddle2110" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey DISPATCHER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Dispatcher</literal></secondary></indexterm><indexterm id="iddle2195" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey TAXI?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Taxi</literal></secondary></indexterm><indexterm id="iddle1152" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey AND OPEN CALL RESTRUCTURING?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>and open call restructuring</secondary></indexterm><indexterm id="iddle1816" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey RESOURCE?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>resource</secondary></indexterm><indexterm id="iddle2516" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey DEADLOCK AVOIDANCE?><?tertiarykey OPEN CALL ADVANTAGES?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>deadlock avoidance</secondary><tertiary>open call advantages</tertiary></indexterm><indexterm id="iddle3713" significance="normal"><?indexkey P?><?primarykey protocol(s)?><?secondarykey THREAD CONFINEMENT?><primary><emphasis role="strong">protocol(s)</emphasis></primary><secondary>thread confinement</secondary></indexterm><indexterm id="iddle3714" significance="normal"><?indexkey P?><?primarykey protocol(s)?><?secondarykey THREAD CONFINEMENT?><?tertiarykey ATOMICITY PRESERVATION WITH OPEN CALLS?><primary><emphasis role="strong">protocol(s)</emphasis></primary><secondary>thread confinement</secondary><tertiary>atomicity preservation with open calls</tertiary></indexterm><indexterm id="iddle3909" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey DEADLOCKS?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>deadlocks</secondary></indexterm><indexterm id="iddle4073" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey OPEN CALL STRATEGY IMPACT ON?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>open call strategy impact on</secondary></indexterm>open calls makes it far easier to identify the code paths that acquire multiple locks and therefore to ensure that locks are acquired in a consistent order.<footnote id="ch10fn03" label="3"><para>The need to rely on open calls and careful lock ordering reflects the fundamental messiness of composing synchronized objects rather than synchronizing composed objects.</para></footnote></para>
<example id="ch10list05" label="10.5" role="Listing" xreflabel="10.5" condition="212">
<?docpage num="212"?>
<title id="ch10list05__title">Lock-ordering Deadlock Between Cooperating Objects. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered"><emphasis>// Warning: deadlock-prone!</emphasis>
class Taxi {
    @GuardedBy("this") private Point location, destination;
    private final Dispatcher dispatcher;

    public Taxi(Dispatcher dispatcher) {
        this.dispatcher = dispatcher;
    }

    public synchronized Point getLocation() {
        return location;
    }

    public synchronized void setLocation(Point location) {
        this.location = location;
        if (location.equals(destination))
            dispatcher.notifyAvailable(this);
    }
}

class Dispatcher {
    @GuardedBy("this") private final Set&lt;Taxi&gt; taxis;
    @GuardedBy("this") private final Set&lt;Taxi&gt; availableTaxis;

    public Dispatcher() {
        taxis = new HashSet&lt;Taxi&gt;();
        availableTaxis = new HashSet&lt;Taxi&gt;();
    }

    public synchronized void notifyAvailable(Taxi taxi) {
        availableTaxis.add(taxi);
    }

    public synchronized Image getImage() {
        Image image = new Image();
        for (Taxi t : taxis)
            image.drawMarker(t.getLocation());
        return image;
    }
}
</programlisting>
</example>
<para><literal>Taxi</literal> and <literal>Dispatcher</literal> in <link linkend="ch10list05" preference="0">Listing 10.5</link> can be easily refactored to use open calls and thus eliminate the deadlock risk. This involves shrinking the <literal>synchronized</literal> blocks to guard only operations that involve shared state, as in <link linkend="ch10list06" preference="0">Listing 10.6</link>. Very often, the cause of problems like those in <link linkend="ch10list05" preference="0">Listing 10.5</link> is the use of <literal>synchronized</literal> methods instead of smaller <literal>synchronized</literal> blocks for reasons of compact syntax or simplicity rather than because the entire method must be guarded by a lock. (As a bonus, shrinking the <literal>synchronized</literal> block may also improve scalability as well; see <link linkend="ch11lev2sec8" preference="0">Section 11.4.1</link> for advice on sizing <literal>synchronized</literal> blocks.)</para>
<sidebar float="1" id="ch10sb03" condition="213"><title/>
<para>Strive to use open calls throughout your program. Programs that rely on open calls are far easier to analyze for deadlock-freedom than those that allow calls to alien methods with locks held.</para>
</sidebar>
<para>Restructuring a <literal>synchronized</literal> block to allow open calls can sometimes have undesirable consequences, since it takes an operation that was atomic and makes it not atomic. In many cases, the loss of atomicity is perfectly acceptable; there’s no reason that updating a taxi’s location and notifying the dispatcher that it is ready for a new destination need be an atomic operation. In other cases, the loss of atomicity is noticeable but the semantic changes are still acceptable. In the deadlock-prone version, <literal>getImage</literal> produces a complete snapshot of the fleet locations at that instant; in the refactored version, it fetches the location of each taxi at slightly different times.</para>
<para>In some cases, however, the loss of atomicity is a problem, and here you will have to use another technique to achieve atomicity. One such technique is to structure a concurrent object so that only one thread can execute the code path following the open call. For example, when shutting down a service, you may want to wait for in-progress operations to complete and then release resources used by the service. Holding the service lock while waiting for operations to complete is inherently deadlock-prone, but releasing the service lock before the service is shut down may let other threads start new operations. The solution is to hold the lock long enough to update the service state to “shutting down” so that other threads wanting to start new operations—including shutting down the service—see that the service is unavailable, and do not try. You can then wait for shutdown to complete, knowing that only the shutdown thread has access to the service state after the open call completes. Thus, rather than using locking to keep the other threads out of a critical section of code, this technique relies on constructing protocols so that other threads don’t try to get in.</para>
</section>
<section id="ch10lev2sec5" label="10.1.5" xreflabel="10.1.5">
<title id="ch10lev2sec5__title">Resource Deadlocks</title>
<para>Just as threads can deadlock when they are each waiting for a lock that the other holds and will not release, they can also deadlock when waiting for resources.</para>
<example id="ch10list06" label="10.6" role="Listing" xreflabel="10.6" condition="214">
<?docpage num="214"?>
<title id="ch10list06__title">Using Open Calls to Avoiding Deadlock Between Cooperating Objects.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
class Taxi {
    @GuardedBy("this") private Point location, destination;
    private final Dispatcher dispatcher;
    ...
    public synchronized Point getLocation() {
        return location;
    }

    public void setLocation(Point location) {
        boolean reachedDestination;
        <emphasis role="strong">synchronized</emphasis>  (this) {
            this.location = location;
            reachedDestination = location.equals(destination);
        }
        if (reachedDestination)
            dispatcher.notifyAvailable(this);
    }
}

@ThreadSafe
class Dispatcher {
    @GuardedBy("this") private final Set&lt;Taxi&gt; taxis;
    @GuardedBy("this") private final Set&lt;Taxi&gt; availableTaxis;
    ...
    public synchronized void notifyAvailable(Taxi taxi) {
        availableTaxis.add(taxi);
    }

    public Image getImage() {
        Set&lt;Taxi&gt; copy;
        <emphasis role="strong">synchronized</emphasis>  (this) {
            copy = new HashSet&lt;Taxi&gt;(taxis);
        }
        Image image = new Image();
        for (Taxi t : copy)
            image.drawMarker(t.getLocation());
        return image;
    }
}
</programlisting>
</example>
<para><?docpage num="215"?><indexterm id="iddle2111" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey DISPATCHER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Dispatcher</literal></secondary></indexterm><indexterm id="iddle2196" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey TAXI?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Taxi</literal></secondary></indexterm><indexterm id="iddle1802" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey AVOIDANCE?><?tertiarykey STRATEGIES FOR?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>avoidance</secondary><tertiary>strategies for</tertiary></indexterm><indexterm id="iddle1804" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey DIAGNOSIS?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>diagnosis</secondary></indexterm><indexterm id="iddle1805" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey DIAGNOSIS?><?tertiarykey STRATEGIES FOR?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>diagnosis</secondary><tertiary>strategies for</tertiary></indexterm><indexterm id="iddle1814" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey RECOVERY?><?tertiarykey TIMED LOCKS USE?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>recovery</secondary><tertiary>timed locks use</tertiary></indexterm><indexterm id="iddle1819" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey THREAD STARVATION?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>thread starvation</secondary></indexterm><indexterm id="iddle2317" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey TIMEOUT?><primary><emphasis role="strong">failure</emphasis></primary><secondary>timeout</secondary></indexterm><indexterm id="iddle2318" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey TIMEOUT?><?tertiarykey DEADLOCK DETECTION USE?><primary><emphasis role="strong">failure</emphasis></primary><secondary>timeout</secondary><tertiary>deadlock detection use</tertiary></indexterm><indexterm id="iddle3043" significance="normal"><?indexkey L?><?primarykey Lock?><?secondarykey TIMED ACQUISITION?><primary><emphasis role="strong">Lock</emphasis></primary><secondary>timed acquisition</secondary></indexterm><indexterm id="iddle3158" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey TIMED?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>timed</secondary></indexterm><indexterm id="iddle3629" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey DEADLOCK RISKS?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>deadlock risks</tertiary></indexterm><indexterm id="iddle4376" significance="normal"><?indexkey S?><?primarykey starvation?><?secondarykey THREAD STARVATION DEADLOCKS?><primary><emphasis role="strong">starvation</emphasis></primary><secondary>thread starvation deadlocks</secondary></indexterm><indexterm id="iddle4460" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey DEADLOCK AVOIDANCE?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>deadlock avoidance</secondary></indexterm><indexterm id="iddle4800" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey DEADLOCK RISKS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>deadlock risks</tertiary></indexterm><indexterm id="iddle4837" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey THREAD STARVATION DEADLOCKS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>thread starvation deadlocks</secondary></indexterm><indexterm id="iddle4927" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey TIMED LOCKS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>timed locks</secondary></indexterm>Say you have two pooled resources, such as connection pools for two different databases. Resource pools are usually implemented with semaphores (see <link linkend="ch05lev2sec12" preference="0">Section 5.5.3</link>) to facilitate blocking when the pool is empty. If a task requires connections to both databases and the two resources are not always requested in the same order, thread <emphasis>A</emphasis> could be holding a connection to database <emphasis>D</emphasis><subscript>1</subscript> while waiting for a connection to database <emphasis>D</emphasis><subscript>2</subscript>, and thread <emphasis>B</emphasis> could be holding a connection to <emphasis>D</emphasis><subscript>2</subscript> while waiting for a connection to <emphasis>D</emphasis><subscript>1</subscript>. (The larger the pools are, the less likely this is to occur; if each pool has <emphasis>N</emphasis> connections, deadlock requires <emphasis>N</emphasis> sets of cyclically waiting threads and a lot of unlucky timing.)</para>
<para>Another form of resource-based deadlock is <emphasis>thread-starvation deadlock</emphasis>. We saw an example of this hazard in <link linkend="ch08lev2sec1" preference="0">Section 8.1.1</link>, where a task that submits a task and waits for its result executes in a single-threaded <literal>Executor</literal>. In that case, the first task will wait forever, permanently stalling that task and all others waiting to execute in that <literal>Executor</literal>. Tasks that wait for the results of other tasks are the primary source of thread-starvation deadlock; bounded pools and interdependent tasks do not mix well.</para>
</section>
</section>
<section id="ch10lev1sec2" condition="215" label="10.2" xreflabel="10.2"><?docpage num="215"?>
<title id="ch10lev1sec2__title">Avoiding and Diagnosing Deadlocks</title>
<para>A program that never acquires more than one lock at a time cannot experience lock-ordering deadlock. Of course, this is not always practical, but if you can get away with it, it’s a lot less work. If you must acquire multiple locks, lock ordering must be a part of your design: try to minimize the number of potential locking interactions, and follow and document a lock-ordering protocol for locks that may be acquired together.</para>
<para>In programs that use fine-grained locking, audit your code for deadlock freedom using a two-part strategy: first, identify where multiple locks could be acquired (try to make this a small set), and then perform a global analysis of all such instances to ensure that lock ordering is consistent across your entire program. Using open calls wherever possible simplifies this analysis substantially. With no non-open calls, finding instances where multiple locks are acquired is fairly easy, either by code review or by automated bytecode or source code analysis.</para>
<section id="ch10lev2sec6" label="10.2.1" xreflabel="10.2.1">
<title id="ch10lev2sec6__title">Timed Lock Attempts</title>
<para>Another technique for detecting and recovering from deadlocks is to use the timed <literal>tryLock</literal> feature of the explicit <literal>Lock</literal> classes (see <link linkend="ch13" preference="0">Chapter 13</link>) instead of intrinsic locking. Where intrinsic locks wait forever if they cannot acquire the lock, explicit locks let you specify a timeout after which <literal>tryLock</literal> returns failure. By using a timeout that is much longer than you expect acquiring the lock to take, you can regain control when something unexpected happens. (<link linkend="ch13list03" preference="0">Listing 13.3</link> on page 280 shows an alternative implementation of <literal>transferMoney</literal> using the polled <literal>tryLock</literal> with retries for probabilistic deadlock avoidance.)</para>
<para>When a timed lock attempt fails, you do not necessarily know <emphasis>why</emphasis>. Maybe there was a deadlock; maybe a thread erroneously entered an infinite loop while <?docpage num="216"?><indexterm id="iddle1086" significance="normal"><?indexkey A?><?primarykey analysis?><?secondarykey DEADLOCK?><primary><emphasis role="strong">analysis</emphasis></primary><secondary>deadlock</secondary></indexterm><indexterm id="iddle1087" significance="normal"><?indexkey A?><?primarykey analysis?><?secondarykey DEADLOCK?><?tertiarykey THREAD DUMP USE?><primary><emphasis role="strong">analysis</emphasis></primary><secondary>deadlock</secondary><tertiary>thread dump use</tertiary></indexterm><indexterm id="iddle1795" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey ANALYSIS?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>analysis</secondary></indexterm><indexterm id="iddle1796" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey ANALYSIS?><?tertiarykey THREAD DUMP USE?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>analysis</secondary><tertiary>thread dump use</tertiary></indexterm><indexterm id="iddle1833" significance="normal"><?indexkey D?><?primarykey debugging?><?secondarykey THREAD DUMP USE?><primary><emphasis role="strong">debugging</emphasis></primary><secondary>thread dump use</secondary></indexterm><indexterm id="iddle3155" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey THREAD DUMP INFORMATION ABOUT?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>thread dump information about</secondary></indexterm><indexterm id="iddle4362" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey TRACE?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>trace</secondary></indexterm><indexterm id="iddle4363" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey TRACE?><?tertiarykey THREAD DUMP USE?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>trace</secondary><tertiary>thread dump use</tertiary></indexterm><indexterm id="iddle4767" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey DUMPS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>dumps</secondary></indexterm><indexterm id="iddle4768" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey DUMPS?><?tertiarykey DEADLOCK ANALYSIS USE?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>dumps</secondary><tertiary>deadlock analysis use</tertiary></indexterm><indexterm id="iddle4976" significance="normal"><?indexkey T?><?primarykey trigger(ing)?><?secondarykey THREAD DUMPS?><primary><emphasis role="strong">trigger(ing)</emphasis></primary><secondary>thread dumps</secondary></indexterm>holding that lock; or maybe some activity is just running a lot slower than you expected. Still, at least you have the opportunity to record that your attempt failed, log any useful information about what you were trying to do, and restart the computation somewhat more gracefully than killing the entire process.</para>
<para>Using timed lock acquisition to acquire multiple locks can be effective against deadlock even when timed locking is not used consistently throughout the program. If a lock acquisition times out, you can release the locks, back off and wait for a while, and try again, possibly clearing the deadlock condition and allowing the program to recover. (This technique works only when the two locks are acquired together; if multiple locks are acquired due to the nesting of method calls, you cannot just release the outer lock, even if you know you hold it.)</para>
</section>
<section id="ch10lev2sec7" label="10.2.2" xreflabel="10.2.2">
<title id="ch10lev2sec7__title">Deadlock Analysis with Thread Dumps</title>
<para>While preventing deadlocks is mostly your problem, the JVM can help identify them when they do happen using <emphasis>thread dumps</emphasis>. A thread dump includes a stack trace for each running thread, similar to the stack trace that accompanies an exception. Thread dumps also include locking information, such as which locks are held by each thread, in which stack frame they were acquired, and which lock a blocked thread is waiting to acquire.<footnote id="ch10fn04" label="4"><para>This information is useful for debugging even when you don’t have a deadlock; periodically triggering thread dumps lets you observe your program’s locking behavior.</para></footnote> Before generating a thread dump, the JVM searches the is-waiting-for graph for cycles to find deadlocks. If it finds one, it includes deadlock information identifying which locks and threads are involved, and where in the program the offending lock acquisitions are.</para>
<para>To trigger a thread dump, you can send the JVM process a <literal>SIGQUIT</literal> signal (<literal>kill -3</literal>) on Unix platforms, or press the <literal>Ctrl-\</literal> key on Unix or <literal>Ctrl-Break</literal> on Windows platforms. Many IDEs can request a thread dump as well.</para>
<para>If you are using the explicit <literal>Lock</literal> classes instead of intrinsic locking, Java 5.0 has no support for associating <literal>Lock</literal> information with the thread dump; explicit <literal>Lock</literal>s do not show up at all in thread dumps. Java 6 does include thread dump support and deadlock detection with explicit <literal>Lock</literal>s, but the information on where <literal>Lock</literal>s are acquired is necessarily less precise than for intrinsic locks. Intrinsic locks are associated with the stack frame in which they were acquired; explicit <literal>Lock</literal>s are associated only with the acquiring thread.</para>
<para><link linkend="ch10list07" preference="0">Listing 10.7</link> shows portions of a thread dump taken from a production J2EE application. The failure that caused the deadlock involves three components—a J2EE application, a J2EE container, and a JDBC driver, each from different vendors. (The names have been changed to protect the guilty.) All three were commercial products that had been through extensive testing cycles; each had a bug that was harmless until they all interacted and caused a fatal server failure.</para>
<para>We’ve shown only the portion of the thread dump relevant to identifying the deadlock. The JVM has done a lot of work for us in diagnosing the deadlock—which locks are causing the problem, which threads are involved, which other locks they hold, and whether other threads are being indirectly inconvenienced. One thread holds the lock on the <literal>MumbleDBConnection</literal> and is waiting to acquire <?docpage num="217"?>the lock on the <literal>MumbleDBCallableStatement</literal>; the other holds the lock on the <literal>MumbleDBCallableStatement</literal> and is waiting for the lock on the <literal>MumbleDBConnection</literal>.</para>
<example id="ch10list07" label="10.7" role="Listing" xreflabel="10.7" condition="217">
<title id="ch10list07__title">Portion of Thread Dump After Deadlock.</title>
<programlisting format="linespecific" linenumbering="unnumbered">Found one Java-level deadlock:
=============================
"ApplicationServerThread":
  waiting to lock monitor 0x080f0cdc (a MumbleDBConnection),
  which is held by "ApplicationServerThread"
"ApplicationServerThread":
  waiting to lock monitor 0x080f0ed4 (a MumbleDBCallableStatement),
  which is held by "ApplicationServerThread"

Java stack information for the threads listed above:
"ApplicationServerThread":
        at MumbleDBConnection.remove_statement
        - waiting to lock &lt;0x650f7f30&gt; (a MumbleDBConnection)
        at MumbleDBStatement.close
        - locked &lt;0x6024ffb0&gt; (a MumbleDBCallableStatement)
     ...

"ApplicationServerThread":
        at MumbleDBCallableStatement.sendBatch
        - waiting to lock &lt;0x6024ffb0&gt; (a MumbleDBCallableStatement)
        at MumbleDBConnection.commit
        - locked &lt;0x650f7f30&gt; (a MumbleDBConnection)
     ...
</programlisting>
</example>
<para>The JDBC driver being used here clearly has a lock-ordering bug: different call chains through the JDBC driver acquire multiple locks in different orders. But this problem would not have manifested itself were it not for another bug: multiple threads were trying to use the same JDBC <literal>Connection</literal> at the same time. This was not how the application was supposed to work—the developers were surprised to see the same <literal>Connection</literal> used concurrently by two threads. There’s nothing in the JDBC specification that requires a <literal>Connection</literal> to be thread-safe, and it is common to confine use of a <literal>Connection</literal> to a single thread, as was intended here. This vendor tried to deliver a thread-safe JDBC driver, as evidenced by the synchronization on multiple JDBC objects within the driver code. Unfortunately, because the vendor did not take lock ordering into account, the driver was prone to deadlock, but it was only the interaction of the deadlock-prone driver and the incorrect <literal>Connection</literal> sharing by the application that disclosed the problem. Because neither bug was fatal in isolation, both persisted despite extensive testing.</para>
</section>
</section>
<section id="ch10lev1sec3" condition="218" label="10.3" xreflabel="10.3">
<?docpage num="218"?>
<title id="ch10lev1sec3__title">Other Liveness Hazards</title>
<para><indexterm id="iddle1649" significance="normal"><?indexkey C?><?primarykey cooperation/cooperating?><?secondarykey OBJECTS?><?tertiarykey LIVELOCK POSSIBILITIES?><primary><emphasis role="strong">cooperation/cooperating</emphasis></primary><secondary>objects</secondary><tertiary>livelock possibilities</tertiary></indexterm><indexterm id="iddle2330" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey SCHEDULING?><primary><emphasis role="strong">fairness</emphasis></primary><secondary>scheduling</secondary></indexterm><indexterm id="iddle2331" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey SCHEDULING?><?tertiarykey THREAD PRIORITY MANIPULATION RISKS?><primary><emphasis role="strong">fairness</emphasis></primary><secondary>scheduling</secondary><tertiary>thread priority manipulation risks</tertiary></indexterm><indexterm id="iddle2585" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey STARVATION AVOIDANCE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>starvation avoidance</secondary></indexterm><indexterm id="iddle2586" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey STARVATION AVOIDANCE?><?tertiarykey THREAD PRIORITY PRECAUTIONS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>starvation avoidance</secondary><tertiary>thread priority precautions</tertiary></indexterm><indexterm id="iddle2889" significance="normal"><?indexkey J?><?primarykey Java Language Specification, The?><primary><emphasis role="strong"><emphasis>Java Language Specification, The</emphasis></emphasis></primary></indexterm><indexterm id="iddle3660" significance="normal"><?indexkey P?><?primarykey priority(s)?><?secondarykey THREAD?><primary><emphasis role="strong">priority(s)</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle3661" significance="normal"><?indexkey P?><?primarykey priority(s)?><?secondarykey THREAD?><?tertiarykey MANIPULATION, LIVENESS HAZARDS?><primary><emphasis role="strong">priority(s)</emphasis></primary><secondary>thread</secondary><tertiary>manipulation, liveness hazards</tertiary></indexterm><indexterm id="iddle4095" significance="normal"><?indexkey S?><?primarykey scheduling?><?secondarykey PRIORITY MANIPULATION RISKS?><primary><emphasis role="strong">scheduling</emphasis></primary><secondary>priority manipulation risks</secondary></indexterm><indexterm id="iddle4131" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey UNDEFINED?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>undefined</secondary></indexterm><indexterm id="iddle4132" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey UNDEFINED?><?tertiarykey OF THREAD.YIELD?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>undefined</secondary><tertiary>of <literal>Thread.yield</literal></tertiary></indexterm><indexterm id="iddle4367" significance="normal"><?indexkey S?><?primarykey starvation?><primary><emphasis role="strong">starvation</emphasis></primary><seealso> <link linkend="iddle1086" preference="0"><emphasis role="strong">analysis</emphasis>, deadlock</link>.</seealso></indexterm><indexterm id="iddle4368" significance="normal"><?indexkey S?><?primarykey starvation?><primary><emphasis role="strong">starvation</emphasis></primary><seealso> <link linkend="iddle3011" preference="0"><emphasis role="strong">livelock</emphasis></link>.</seealso></indexterm><indexterm id="iddle4369" significance="normal"><?indexkey S?><?primarykey starvation?><primary><emphasis role="strong">starvation</emphasis></primary><seealso> <link linkend="iddle3497" preference="0"><emphasis role="strong">performance</emphasis>, liveness</link>.</seealso></indexterm><indexterm id="iddle4370" significance="normal"><?indexkey S?><?primarykey starvation?><primary><emphasis role="strong">starvation</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle4371" significance="normal"><?indexkey S?><?primarykey starvation?><primary><emphasis role="strong">starvation</emphasis></primary></indexterm><indexterm id="iddle4806" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey PRIORITIES?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>priorities</secondary></indexterm><indexterm id="iddle4807" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey PRIORITIES?><?tertiarykey MANIPULATION, LIVENESS RISKS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>priorities</secondary><tertiary>manipulation, liveness risks</tertiary></indexterm>While deadlock is the most widely encountered liveness hazard, there are several other liveness hazards you may encounter in concurrent programs including starvation, missed signals, and livelock. (Missed signals are covered in <link linkend="ch14lev2sec4" preference="0">Section 14.2.3</link>.)</para>
<section id="ch10lev2sec8" label="10.3.1" xreflabel="10.3.1">
<title id="ch10lev2sec8__title">Starvation</title>
<para><emphasis>Starvation</emphasis> occurs when a thread is perpetually denied access to resources it needs in order to make progress; the most commonly starved resource is CPU cycles. Starvation in Java applications can be caused by inappropriate use of thread priorities. It can also be caused by executing nonterminating constructs (infinite loops or resource waits that do not terminate) with a lock held, since other threads that need that lock will never be able to acquire it.</para>
<para>The thread priorities defined in the Thread API are merely scheduling hints. The Thread API defines ten priority levels that the JVM can map to operating system scheduling priorities as it sees fit. This mapping is platform-specific, so two Java priorities can map to the same OS priority on one system and different OS priorities on another. Some operating systems have fewer than ten priority levels, in which case multiple Java priorities map to the same OS priority.</para>
<para>Operating system schedulers go to great lengths to provide scheduling fairness and liveness beyond that required by the Java Language Specification. In most Java applications, all application threads have the same priority, <literal>Thread. NORM_PRIORITY</literal>. The thread priority mechanism is a blunt instrument, and it’s not always obvious what effect changing priorities will have; boosting a thread’s priority might do nothing or might always cause one thread to be scheduled in preference to the other, causing starvation.</para>
<para>It is generally wise to resist the temptation to tweak thread priorities. As soon as you start modifying priorities, the behavior of your application becomes platform-specific and you introduce the risk of starvation. You can often spot a program that is trying to recover from priority tweaking or other responsiveness problems by the presence of <literal>Thread.sleep</literal> or <literal>Thread.yield</literal> calls in odd places, in an attempt to give more time to lower-priority threads.<footnote id="ch10fn05" label="5"><para>The semantics of <literal>Thread.yield</literal> (and <literal>Thread.sleep(0)</literal>) are undefined [JLS 17.9]; the JVM is free to implement them as no-ops or treat them as scheduling hints. In particular, they are <emphasis>not</emphasis> required to have the semantics of <literal>sleep(0)</literal> on Unix systems—put the current thread at the end of the run queue for that priority, yielding to other threads of the same priority—though some JVMs implement <literal>yield</literal> in this way.</para></footnote></para>
<sidebar float="1" id="ch10sb04" condition="218"><title/>
<para>Avoid the temptation to use thread priorities, since they increase platform dependence and can cause liveness problems. Most concurrent applications can use the default priority for all threads.</para>
</sidebar>
</section>
<section id="ch10lev2sec9" condition="219" label="10.3.2" xreflabel="10.3.2">
<?docpage num="219"?>
<title id="ch10lev2sec9__title">Poor Responsiveness</title>
<para><indexterm id="iddle2053" significance="normal"><?indexkey E?><?primarykey Ethernet protocol?><primary><emphasis role="strong">Ethernet protocol</emphasis></primary></indexterm><indexterm id="iddle2054" significance="normal"><?indexkey E?><?primarykey Ethernet protocol?><?secondarykey EXPONENTIAL BACKOFF USE?><primary><emphasis role="strong">Ethernet protocol</emphasis></primary><secondary>exponential backoff use</secondary></indexterm><indexterm id="iddle2283" significance="normal"><?indexkey E?><?primarykey exponential backoff?><primary><emphasis role="strong">exponential backoff</emphasis></primary></indexterm><indexterm id="iddle2284" significance="normal"><?indexkey E?><?primarykey exponential backoff?><?secondarykey AND AVOIDING LIVELOCK?><primary><emphasis role="strong">exponential backoff</emphasis></primary><secondary>and avoiding livelock</secondary></indexterm><indexterm id="iddle3011" significance="normal"><?indexkey L?><?primarykey livelock?><primary><emphasis role="strong">livelock</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle3012" significance="normal"><?indexkey L?><?primarykey livelock?><primary><emphasis role="strong">livelock</emphasis></primary><seealso> <link linkend="iddle3497" preference="0"><emphasis role="strong">performance</emphasis>, liveness</link>.</seealso></indexterm><indexterm id="iddle3013" significance="normal"><?indexkey L?><?primarykey livelock?><primary><emphasis role="strong">livelock</emphasis></primary></indexterm><indexterm id="iddle3558" significance="normal"><?indexkey P?><?primarykey poison?><primary><emphasis role="strong">poison</emphasis></primary></indexterm><indexterm id="iddle3559" significance="normal"><?indexkey P?><?primarykey poison?><?secondarykey MESSAGE?><primary><emphasis role="strong">poison</emphasis></primary><secondary>message</secondary><seealso> <link linkend="iddle3011" preference="0"><emphasis role="strong">livelock</emphasis></link>.</seealso></indexterm><indexterm id="iddle3662" significance="normal"><?indexkey P?><?primarykey priority(s)?><?secondarykey THREAD?><?tertiarykey WHEN TO USE?><primary><emphasis role="strong">priority(s)</emphasis></primary><secondary>thread</secondary><tertiary>when to use</tertiary></indexterm><indexterm id="iddle3786" significance="normal"><?indexkey R?><?primarykey random(ness)?><primary><emphasis role="strong">random(ness)</emphasis></primary></indexterm><indexterm id="iddle3787" significance="normal"><?indexkey R?><?primarykey random(ness)?><?secondarykey LIVELOCK RESOLUTION USE?><primary><emphasis role="strong">random(ness)</emphasis></primary><secondary>livelock resolution use</secondary></indexterm><indexterm id="iddle3962" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey POOR?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>poor</secondary></indexterm><indexterm id="iddle3963" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey POOR?><?tertiarykey CAUSES AND RESOLUTION OF?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>poor</secondary><tertiary>causes and resolution of</tertiary></indexterm><indexterm id="iddle3993" significance="normal"><?indexkey R?><?primarykey retry?><primary><emphasis role="strong">retry</emphasis></primary></indexterm><indexterm id="iddle3994" significance="normal"><?indexkey R?><?primarykey retry?><?secondarykey RANDOMNESS, IN LIVELOCK RESOLUTION?><primary><emphasis role="strong">retry</emphasis></primary><secondary>randomness, in livelock resolution</secondary></indexterm><indexterm id="iddle4808" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey PRIORITY?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>priority</secondary></indexterm><indexterm id="iddle4809" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey PRIORITY?><?tertiarykey WHEN TO USE?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>priority</secondary><tertiary>when to use</tertiary></indexterm>One step removed from starvation is poor responsiveness, which is not uncommon in GUI applications using background threads. <link linkend="ch09" preference="0">Chapter 9</link> developed a framework for offloading long-running tasks onto background threads so as not to freeze the user interface. CPU-intensive background tasks can still affect responsiveness because they can compete for CPU cycles with the event thread. This is one case where altering thread priorities makes sense; when computeintensive background computations would affect responsiveness. If the work done by other threads are truly background tasks, lowering their priority can make the foreground tasks more responsive.</para>
<para>Poor responsiveness can also be caused by poor lock management. If a thread holds a lock for a long time (perhaps while iterating a large collection and performing substantial work for each element), other threads that need to access that collection may have to wait a very long time.</para>
</section>
<section id="ch10lev2sec10" label="10.3.3" xreflabel="10.3.3">
<title id="ch10lev2sec10__title">Livelock</title>
<para><emphasis>Livelock</emphasis> is a form of liveness failure in which a thread, while not blocked, still cannot make progress because it keeps retrying an operation that will always fail. Livelock often occurs in transactional messaging applications, where the messaging infrastructure rolls back a transaction if a message cannot be processed successfully, and puts it back at the head of the queue. If a bug in the message handler for a particular type of message causes it to fail, every time the message is dequeued and passed to the buggy handler, the transaction is rolled back. Since the message is now back at the head of the queue, the handler is called over and over with the same result. (This is sometimes called the <emphasis>poison message</emphasis> problem.) The message handling thread is not blocked, but it will never make progress either. This form of livelock often comes from overeager error-recovery code that mistakenly treats an unrecoverable error as a recoverable one.</para>
<para>Livelock can also occur when multiple cooperating threads change their state in response to the others in such a way that no thread can ever make progress. This is similar to what happens when two overly polite people are walking in opposite directions in a hallway: each steps out of the other’s way, and now they are again in each other’s way. So they both step aside again, and again, and again. . .</para>
<para>The solution for this variety of livelock is to introduce some randomness into the retry mechanism. For example, when two stations in an ethernet network try to send a packet on the shared carrier at the same time, the packets collide. The stations detect the collision, and each tries to send their packet again later. If they each retry <emphasis>exactly</emphasis> one second later, they collide over and over, and neither packet ever goes out, even if there is plenty of available bandwidth. To avoid this, we make each wait an amount of time that includes a random component. (The ethernet protocol also includes exponential backoff after repeated collisions, reducing both congestion and the risk of repeated failure with multiple colliding stations.) Retrying with random waits and backoffs can be equally effective for avoiding livelock in concurrent applications.</para>
</section>
</section>



<section id="ch10lev1sec4" condition="220" label="" xreflabel="">
<?docpage num="220"?>
<title id="ch10lev1sec4__title">Summary</title>
<para>Liveness failures are a serious problem because there is no way to recover from them short of aborting the application. The most common form of liveness failure is lock-ordering deadlock. Avoiding lock ordering deadlock starts at design time: ensure that when threads acquire multiple locks, they do so in a consistent order. The best way to do this is by using open calls throughout your program. This greatly reduces the number of places where multiple locks are held at once, and makes it more obvious where those places are.</para>
</section>

</chapter>

<chapter id="ch11" label="11" xreflabel="11" condition="221">
<?docpage num="221"?>
<title id="ch11__title">Performance and Scalability</title>


<para><indexterm id="iddle1092" significance="normal"><?indexkey A?><?primarykey analysis?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">analysis</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle1253" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey RESOURCE?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>resource</secondary></indexterm><indexterm id="iddle1617" significance="normal"><?indexkey C?><?primarykey context switching?><?secondarykey PERFORMANCE IMPACT OF?><primary><emphasis role="strong">context switching</emphasis></primary><secondary>performance impact of</secondary></indexterm><indexterm id="iddle1655" significance="normal"><?indexkey C?><?primarykey coordination?><?secondarykey IN MULTITHREADED ENVIRONMENTS?><primary><emphasis role="strong">coordination</emphasis></primary><secondary>in multithreaded environments</secondary></indexterm><indexterm id="iddle1656" significance="normal"><?indexkey C?><?primarykey coordination?><?secondarykey IN MULTITHREADED ENVIRONMENTS?><?tertiarykey PERFORMANCE IMPACT OF?><primary><emphasis role="strong">coordination</emphasis></primary><secondary>in multithreaded environments</secondary><tertiary>performance impact of</tertiary></indexterm><indexterm id="iddle1916" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">design</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle1917" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PERFORMANCE?><?tertiarykey ANALYSIS, MONITORING, AND IMPROVEMENT?><primary><emphasis role="strong">design</emphasis></primary><secondary>performance</secondary><tertiary>analysis, monitoring, and improvement</tertiary></indexterm><indexterm id="iddle3252" significance="normal"><?indexkey M?><?primarykey monitoring?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">monitoring</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle3482" significance="normal"><?indexkey P?><?primarykey performance?><primary><emphasis role="strong">performance</emphasis></primary></indexterm><indexterm id="iddle3483" significance="normal"><?indexkey P?><?primarykey performance?><primary><emphasis role="strong">performance</emphasis></primary></indexterm><indexterm id="iddle3906" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey BOUND?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>bound</secondary></indexterm><indexterm id="iddle3934" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle3935" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey PERFORMANCE?><?tertiarykey ANALYSIS, MONITORING, AND IMPROVEMENT?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>performance</secondary><tertiary>analysis, monitoring, and improvement</tertiary></indexterm><indexterm id="iddle3960" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle3961" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey PERFORMANCE?><?tertiarykey ANALYSIS, MONITORING, AND IMPROVEMENT?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>performance</secondary><tertiary>analysis, monitoring, and improvement</tertiary></indexterm><indexterm id="iddle4055" significance="normal"><?indexkey S?><?primarykey scalability?><primary><emphasis role="strong">scalability</emphasis></primary></indexterm>One of the primary reasons to use threads is to improve performance.<footnote id="ch11fn01" label="1"><para>Some might argue this is the <emphasis>only</emphasis> reason we put up with the complexity threads introduce.</para></footnote> Using threads can improve resource utilization by letting applications more easily exploit available processing capacity, and can improve responsiveness by letting applications begin processing new tasks immediately while existing tasks are still running.</para>
<para>This chapter explores techniques for analyzing, monitoring, and improving the performance of concurrent programs. Unfortunately, many of the techniques for improving performance also increase complexity, thus increasing the likelihood of safety and liveness failures. Worse, some techniques intended to improve performance are actually counterproductive or trade one sort of performance problem for another. While better performance is often desirable—and improving performance can be very satisfying—safety always comes first. First make your program right, then make it fast—and then only if your performance requirements and measurements tell you it needs to be faster. In designing a concurrent application, squeezing out the last bit of performance is often the least of your concerns.</para>



<section id="ch11lev1sec1" condition="221" label="11.1" xreflabel="11.1"><?docpage num="221"?>
<title id="ch11lev1sec1__title">Thinking about Performance</title>
<para>Improving performance means doing more work with fewer resources. The meaning of “resources” can vary; for a given activity, some specific resource is usually in shortest supply, whether it is CPU cycles, memory, network bandwidth, I/O bandwidth, database requests, disk space, or any number of other resources. When the performance of an activity is limited by availability of a particular resource, we say it is <emphasis>bound</emphasis> by that resource: CPU-bound, database-bound, etc.</para>
<para>While the goal may be to improve performance overall, using multiple threads always introduces some performance costs compared to the single-threaded approach. These include the overhead associated with coordinating between threads (locking, signaling, and memory synchronization), increased context switching, <?docpage num="222"?><indexterm id="iddle1714" significance="normal"><?indexkey C?><?primarykey CPU utilization?><?secondarykey OPTIMIZATION?><primary><emphasis role="strong">CPU utilization</emphasis></primary><secondary>optimization</secondary></indexterm><indexterm id="iddle1715" significance="normal"><?indexkey C?><?primarykey CPU utilization?><?secondarykey OPTIMIZATION?><?tertiarykey AS MULTITHREADING GOAL?><primary><emphasis role="strong">CPU utilization</emphasis></primary><secondary>optimization</secondary><tertiary>as multithreading goal</tertiary></indexterm><indexterm id="iddle2575" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SCALABILITY?><?tertiarykey ATTRIBUTES?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>scalability</secondary><tertiary>attributes</tertiary></indexterm><indexterm id="iddle2660" significance="normal"><?indexkey H?><?primarykey how fast?><primary sortas="how fast"><emphasis role="strong">’how fast’</emphasis></primary><seealso> <link linkend="iddle1110" preference="0"><emphasis role="strong">application(s)</emphasis>, GUI</link>.</seealso></indexterm><indexterm id="iddle2661" significance="normal"><?indexkey H?><?primarykey how fast?><primary sortas="how fast"><emphasis role="strong">’how fast’</emphasis></primary><seealso> latency.</seealso></indexterm><indexterm id="iddle2662" significance="normal"><?indexkey H?><?primarykey how fast?><primary sortas="how fast"><emphasis role="strong">’how fast’</emphasis></primary><seealso> <link linkend="iddle3188" preference="0"><emphasis role="strong">measurement</emphasis>, responsiveness</link>.</seealso></indexterm><indexterm id="iddle2663" significance="normal"><?indexkey H?><?primarykey how fast?><?secondarykey VS. &rsquo;HOW MUCH&rsquo;?><primary sortas="how fast"><emphasis role="strong">’how fast’</emphasis></primary><secondary>vs. ’how much’</secondary></indexterm><indexterm id="iddle2664" significance="normal"><?indexkey H?><?primarykey how much?><primary sortas="how much"><emphasis role="strong">’how much’</emphasis></primary><seealso> capacity.</seealso></indexterm><indexterm id="iddle2665" significance="normal"><?indexkey H?><?primarykey how much?><primary sortas="how much"><emphasis role="strong">’how much’</emphasis></primary><seealso> <link linkend="iddle2574" preference="0"><emphasis role="strong">guidelines</emphasis>, scalability</link>.</seealso></indexterm><indexterm id="iddle2666" significance="normal"><?indexkey H?><?primarykey how much?><primary sortas="how much"><emphasis role="strong">’how much’</emphasis></primary><seealso> <link linkend="iddle4867" preference="0"><emphasis role="strong">throughput</emphasis></link>.</seealso></indexterm><indexterm id="iddle2668" significance="normal"><?indexkey H?><?primarykey how much?><?secondarykey VS. &rsquo;HOW FAST&rsquo;?><primary sortas="how much"><emphasis role="strong">’how much’</emphasis></primary><secondary>vs. ’how fast’</secondary></indexterm><indexterm id="iddle3185" significance="normal"><?indexkey M?><?primarykey measurement?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">measurement</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle3393" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey PERFORMANCE?><?tertiarykey SCALABILITY REQUIREMENTS VS?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>performance</secondary><tertiary>scalability requirements vs</tertiary></indexterm><indexterm id="iddle3501" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey MEASUREMENT OF?><primary><emphasis role="strong">performance</emphasis></primary><secondary>measurement of</secondary><seealso> capacity.</seealso></indexterm><indexterm id="iddle3502" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey MEASUREMENT OF?><primary><emphasis role="strong">performance</emphasis></primary><secondary>measurement of</secondary><seealso> <link linkend="iddle1991" preference="0"><emphasis role="strong">efficiency</emphasis></link>.</seealso></indexterm><indexterm id="iddle3503" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey MEASUREMENT OF?><primary><emphasis role="strong">performance</emphasis></primary><secondary>measurement of</secondary><seealso> latency.</seealso></indexterm><indexterm id="iddle3504" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey MEASUREMENT OF?><primary><emphasis role="strong">performance</emphasis></primary><secondary>measurement of</secondary><seealso> <link linkend="iddle2574" preference="0"><emphasis role="strong">guidelines</emphasis>, scalability</link>.</seealso></indexterm><indexterm id="iddle3505" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey MEASUREMENT OF?><primary><emphasis role="strong">performance</emphasis></primary><secondary>measurement of</secondary><seealso> <link linkend="iddle5070" preference="0"><emphasis role="strong">variance</emphasis>, service time</link>.</seealso></indexterm><indexterm id="iddle3506" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey MEASUREMENT OF?><primary><emphasis role="strong">performance</emphasis></primary><secondary>measurement of</secondary><seealso> <link linkend="iddle4867" preference="0"><emphasis role="strong">throughput</emphasis></link>.</seealso></indexterm><indexterm id="iddle3524" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey SCALABILITY VS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>scalability vs</secondary></indexterm><indexterm id="iddle3912" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey INCREASE?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>increase</secondary></indexterm><indexterm id="iddle3913" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey INCREASE?><?tertiarykey SCALABILITY RELATIONSHIP TO?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>increase</secondary><tertiary>scalability relationship to</tertiary></indexterm><indexterm id="iddle4054" significance="normal"><?indexkey S?><?primarykey scalability?><primary><emphasis role="strong">scalability</emphasis></primary></indexterm><indexterm id="iddle4074" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey PERFORMANCE VS?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>performance vs</secondary></indexterm><indexterm id="iddle4092" significance="normal"><?indexkey S?><?primarykey scheduling?><primary><emphasis role="strong">scheduling</emphasis></primary></indexterm><indexterm id="iddle4093" significance="normal"><?indexkey S?><?primarykey scheduling?><?secondarykey OVERHEAD?><primary><emphasis role="strong">scheduling</emphasis></primary><secondary>overhead</secondary></indexterm><indexterm id="iddle4094" significance="normal"><?indexkey S?><?primarykey scheduling?><?secondarykey OVERHEAD?><?tertiarykey PERFORMANCE IMPACT OF?><primary><emphasis role="strong">scheduling</emphasis></primary><secondary>overhead</secondary><tertiary>performance impact of</tertiary></indexterm><indexterm id="iddle5035" significance="normal"><?indexkey U?><?primarykey utilization?><?secondarykey CPU?><?tertiarykey OPTIMIZATION, AS MULTITHREADING GOAL?><primary><emphasis role="strong">utilization</emphasis></primary><secondary>CPU</secondary><tertiary>optimization, as multithreading goal</tertiary></indexterm><indexterm id="iddle5037" significance="normal"><?indexkey U?><?primarykey utilization?><?secondarykey HARDWARE?><primary><emphasis role="strong">utilization</emphasis></primary><secondary>hardware</secondary></indexterm><indexterm id="iddle5038" significance="normal"><?indexkey U?><?primarykey utilization?><?secondarykey HARDWARE?><?tertiarykey IMPROVEMENT STRATEGIES?><primary><emphasis role="strong">utilization</emphasis></primary><secondary>hardware</secondary><tertiary>improvement strategies</tertiary></indexterm>thread creation and teardown, and scheduling overhead. When threading is employed effectively, these costs are more than made up for by greater throughput, responsiveness, or capacity. On the other hand, a poorly designed concurrent application can perform even worse than a comparable sequential one.<footnote id="ch11fn02" label="2"><para>A colleague provided this amusing anecodote: he had been involved in the testing of an expensive and complex application that managed its work via a tunable thread pool. After the system was complete, testing showed that the optimal number of threads for the pool was . . . 1. This should have been obvious from the outset; the target system was a single-CPU system and the application was almost entirely CPU-bound.</para></footnote></para>
<para>In using concurrency to achieve better performance, we are trying to do two things: utilize the processing resources we have more effectively, and enable our program to exploit additional processing resources if they become available. From a performance monitoring perspective, this means we are looking to keep the CPUs as busy as possible. (Of course, this doesn’t mean burning cycles with useless computation; we want to keep the CPUs busy with <emphasis>useful</emphasis> work.) If the program is compute-bound, then we may be able to increase its capacity by adding more processors; if it can’t even keep the processors we have busy, adding more won’t help. Threading offers a means to keep the CPU(s) “hotter” by decomposing the application so there is always work to be done by an available processor.</para>
<section id="ch11lev2sec1" label="11.1.1" xreflabel="11.1.1">
<title id="ch11lev2sec1__title">Performance Versus Scalability</title>
<para>Application performance can be measured in a number of ways, such as service time, latency, throughput, efficiency, scalability, or capacity. Some of these (service time, latency) aremeasures of “how fast” a given unit of work can be processed or acknowledged; others (capacity, throughput) are measures of “how much” work can be performed with a given quantity of computing resources.</para>
<sidebar float="1" id="ch11sb01" condition="222"><title/>
<para><emphasis>Scalability</emphasis> describes the ability to improve throughput or capacity when additional computing resources (such as additional CPUs, memory, storage, or I/O bandwidth) are added.</para>
</sidebar>
<para>Designing and tuning concurrent applications for scalability can be very different from traditional performance optimization. When tuning for performance, the goal is usually to do the <emphasis>same</emphasis> work with <emphasis>less</emphasis> effort, such as by reusing previously computed results through caching or replacing an <emphasis>O</emphasis>(<emphasis>n</emphasis><superscript>2</superscript>) algorithm with an <emphasis>O</emphasis>(<emphasis>n</emphasis> log <emphasis>n</emphasis>) one. When tuning for scalability, you are instead trying to find ways to parallelize the problem so you can take advantage of additional processing resources to do <emphasis>more</emphasis> work with <emphasis>more</emphasis> resources.</para>
<para>These two aspects of performance—<emphasis>how fast</emphasis> and <emphasis>how much</emphasis>—are completely separate, and sometimes even at odds with each other. In order to achieve higher scalability or better hardware utilization, we often end up <emphasis>increasing</emphasis> the amount of work done to process each <emphasis>individual</emphasis> task, such as when we divide tasks into multiple “pipelined” subtasks. Ironically, many of the tricks that improve performance in single-threaded programs are bad for scalability (see <link linkend="ch11lev2sec11" preference="0">Section 11.4.4</link> for an example).</para>
<para><?docpage num="223"?><indexterm id="iddle1695" significance="normal"><?indexkey C?><?primarykey cost(s)?><?secondarykey TRADEOFFS?><primary><emphasis role="strong">cost(s)</emphasis></primary><secondary>tradeoffs</secondary></indexterm><indexterm id="iddle1696" significance="normal"><?indexkey C?><?primarykey cost(s)?><?secondarykey TRADEOFFS?><?tertiarykey IN PERFORMANCE OPTIMIZATION STRATEGIES?><primary><emphasis role="strong">cost(s)</emphasis></primary><secondary>tradeoffs</secondary><tertiary>in performance optimization strategies</tertiary></indexterm><indexterm id="iddle1918" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PERFORMANCE TRADEOFFS?><primary><emphasis role="strong">design</emphasis></primary><secondary>performance tradeoffs</secondary></indexterm><indexterm id="iddle1919" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey PERFORMANCE TRADEOFFS?><?tertiarykey EVALUATION OF?><primary><emphasis role="strong">design</emphasis></primary><secondary>performance tradeoffs</secondary><tertiary>evaluation of</tertiary></indexterm><indexterm id="iddle2058" significance="normal"><?indexkey E?><?primarykey evaluation?><?secondarykey OF PERFORMANCE TRADEOFFS?><primary><emphasis role="strong">evaluation</emphasis></primary><secondary>of performance tradeoffs</secondary></indexterm><indexterm id="iddle2562" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey OPTIMIZATION?><?tertiarykey PREMATURE, AVOIDANCE OF?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>optimization</secondary><tertiary>premature, avoidance of</tertiary></indexterm><indexterm id="iddle2667" significance="normal"><?indexkey H?><?primarykey how much?><?secondarykey IMPORTANCE FOR SERVER APPLICATIONS?><primary sortas="how much"><emphasis role="strong">’how much’</emphasis></primary><secondary>importance for server applications</secondary></indexterm><indexterm id="iddle2943" significance="normal"><?indexkey L?><?primarykey layering?><primary><emphasis role="strong">layering</emphasis></primary></indexterm><indexterm id="iddle2944" significance="normal"><?indexkey L?><?primarykey layering?><?secondarykey THREE-TIER APPLICATION?><primary><emphasis role="strong">layering</emphasis></primary><secondary>three-tier application</secondary></indexterm><indexterm id="iddle2945" significance="normal"><?indexkey L?><?primarykey layering?><?secondarykey THREE-TIER APPLICATION?><?tertiarykey AS PERFORMANCE VS. SCALABILITY ILLUSTRATION?><primary><emphasis role="strong">layering</emphasis></primary><secondary>three-tier application</secondary><tertiary>as performance vs. scalability illustration</tertiary></indexterm><indexterm id="iddle3236" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey THREE-TIER APPLICATION?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>three-tier application</secondary></indexterm><indexterm id="iddle3237" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey THREE-TIER APPLICATION?><?tertiarykey PERFORMANCE VS. SCALABILITY?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>three-tier application</secondary><tertiary>performance vs. scalability</tertiary></indexterm><indexterm id="iddle3391" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey PERFORMANCE?><?tertiarykey PREMATURE, AVOIDANCE OF?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>performance</secondary><tertiary>premature, avoidance of</tertiary></indexterm><indexterm id="iddle3525" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey SCALABILITY VS?><?tertiarykey ISSUES, THREE-TIER APPLICATION MODEL AS ILLUSTRATION?><primary><emphasis role="strong">performance</emphasis></primary><secondary>scalability vs</secondary><tertiary>issues, three-tier application model as illustration</tertiary></indexterm><indexterm id="iddle3546" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TRADEOFFS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>tradeoffs</secondary></indexterm><indexterm id="iddle3547" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TRADEOFFS?><?tertiarykey EVALUATION OF?><primary><emphasis role="strong">performance</emphasis></primary><secondary>tradeoffs</secondary><tertiary>evaluation of</tertiary></indexterm><indexterm id="iddle3884" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey DETERMINATION?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>determination</secondary></indexterm><indexterm id="iddle3885" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey DETERMINATION?><?tertiarykey IMPORTANCE OF?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>determination</secondary><tertiary>importance of</tertiary></indexterm><indexterm id="iddle4048" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey TRADEOFFS?><primary><emphasis role="strong">safety</emphasis></primary><secondary>tradeoffs</secondary></indexterm><indexterm id="iddle4049" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey TRADEOFFS?><?tertiarykey IN PERFORMANCE OPTIMIZATION STRATEGIES?><primary><emphasis role="strong">safety</emphasis></primary><secondary>tradeoffs</secondary><tertiary>in performance optimization strategies</tertiary></indexterm><indexterm id="iddle4077" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey PERFORMANCE VS?><?tertiarykey THREE-TIER APPLICATION MODEL AS ILLUSTRATION?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>performance vs</secondary><tertiary>three-tier application model as illustration</tertiary></indexterm>The familiar three-tier application model—in which presentation, business logic, and persistence are separated and may be handled by different systems—illustrates how improvements in scalability often come at the expense of performance. A monolithic application where presentation, business logic, and persistence are intertwined would almost certainly provide better performance for the <emphasis>first</emphasis> unit of work than would a well-factored multitier implementation distributed over multiple systems. How could it not? The monolithic application would not have the network latency inherent in handing off tasks between tiers, nor would it have to pay the costs inherent in separating a computational process into distinct abstracted layers (such as queuing overhead, coordination overhead, and data copying).</para>
<para>However, when the monolithic system reaches its processing capacity, we could have a serious problem: it may be prohibitively difficult to significantly increase capacity. So we often accept the performance costs of longer service time or greater computing resources used per unit of work so that our application can scale to handle greater load by adding more resources.</para>
<para>Of the various aspects of performance, the “how much” aspects—scalability, throughput, and capacity—are usually of greater concern for server applications than the “how fast” aspects. (For interactive applications, latency tends to be more important, so that users need not wait for indications of progress and wonder what is going on.) This chapter focuses primarily on scalability rather than raw single-threaded performance.</para>
</section>
<section id="ch11lev2sec2" label="11.1.2" xreflabel="11.1.2">
<title id="ch11lev2sec2__title">Evaluating Performance Tradeoffs</title>
<para>Nearly all engineering decisions involve some form of tradeoff. Using thicker steel in a bridge span may increase its capacity and safety, but also its construction cost. While software engineering decisions don’t usually involve tradeoffs between money and risk to human life, we often have less information with which to make the right tradeoffs. For example, the “quicksort” algorithm is highly efficient for large data sets, but the less sophisticated “bubble sort” is actually more efficient for small data sets. If you are asked to implement an efficient sort routine, you need to know something about the sizes of data sets it will have to process, along with metrics that tell you whether you are trying to optimize average-case time, worst-case time, or predictability. Unfortunately, that information is often not part of the requirements given to the author of a library sort routine. This is one of the reasons why most optimizations are premature: <emphasis>they are often undertaken before a clear set of requirements is available</emphasis>.</para>
<sidebar float="1" id="ch11sb02" condition="223"><title/>
<para>Avoid premature optimization. First make it right, then make it fast—<emphasis>if</emphasis> it is not already fast enough.</para>
</sidebar>
<para>When making engineering decisions, sometimes you are trading one form of cost for another (service time versus memory consumption); sometimes you are trading cost for safety. Safety doesn’t necessarily mean risk to human lives, as <?docpage num="224"?><indexterm id="iddle1083" significance="normal"><?indexkey A?><?primarykey analysis?><primary><emphasis role="strong">analysis</emphasis></primary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle1084" significance="normal"><?indexkey A?><?primarykey analysis?><primary><emphasis role="strong">analysis</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle1085" significance="normal"><?indexkey A?><?primarykey analysis?><primary><emphasis role="strong">analysis</emphasis></primary><seealso> <link linkend="iddle4441" preference="0"><emphasis role="strong">static analysis tools</emphasis></link>.</seealso></indexterm><indexterm id="iddle1177" significance="normal"><?indexkey A?><?primarykey audit(ing)?><primary><emphasis role="strong">audit(ing)</emphasis></primary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle1200" significance="normal"><?indexkey B?><?primarykey bias?><primary><emphasis role="strong">bias</emphasis></primary><see> <link linkend="iddle4687" preference="0"><emphasis role="strong">testing</emphasis></link>, pitfalls.</see></indexterm><indexterm id="iddle1462" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey DEBUGGING?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>debugging</secondary></indexterm><indexterm id="iddle1463" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey DEBUGGING?><?tertiarykey COSTS VS. PERFORMANCE OPTIMIZATION VALUE?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>debugging</secondary><tertiary>costs vs. performance optimization value</tertiary></indexterm><indexterm id="iddle1687" significance="normal"><?indexkey C?><?primarykey cost(s)?><primary><emphasis role="strong">cost(s)</emphasis></primary><seealso> <link linkend="iddle1912" preference="0"><emphasis role="strong">design</emphasis>, of thread-safe classes, guidelines</link>.</seealso></indexterm><indexterm id="iddle1688" significance="normal"><?indexkey C?><?primarykey cost(s)?><primary><emphasis role="strong">cost(s)</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle1689" significance="normal"><?indexkey C?><?primarykey cost(s)?><primary><emphasis role="strong">cost(s)</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle1690" significance="normal"><?indexkey C?><?primarykey cost(s)?><primary><emphasis role="strong">cost(s)</emphasis></primary><seealso> <link linkend="iddle1929" preference="0"><emphasis role="strong">design</emphasis>, strategies</link>.</seealso></indexterm><indexterm id="iddle1691" significance="normal"><?indexkey C?><?primarykey cost(s)?><primary><emphasis role="strong">cost(s)</emphasis></primary><seealso> <link linkend="iddle1695" preference="0"><emphasis role="strong">cost(s)</emphasis>, tradeoffs</link>.</seealso></indexterm><indexterm id="iddle1823" significance="normal"><?indexkey D?><?primarykey debugging?><primary><emphasis role="strong">debugging</emphasis></primary><seealso> <link linkend="iddle1795" preference="0"><emphasis role="strong">deadlock(s)</emphasis>, analysis</link>.</seealso></indexterm><indexterm id="iddle1824" significance="normal"><?indexkey D?><?primarykey debugging?><primary><emphasis role="strong">debugging</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle1825" significance="normal"><?indexkey D?><?primarykey debugging?><primary><emphasis role="strong">debugging</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle1826" significance="normal"><?indexkey D?><?primarykey debugging?><primary><emphasis role="strong">debugging</emphasis></primary><seealso> <link linkend="iddle1810" preference="0"><emphasis role="strong">deadlock(s)</emphasis>, recovery</link>.</seealso></indexterm><indexterm id="iddle1827" significance="normal"><?indexkey D?><?primarykey debugging?><primary><emphasis role="strong">debugging</emphasis></primary><seealso> <link linkend="iddle1272" preference="0"><emphasis role="strong">buffer(s)</emphasis>, testing</link>.</seealso></indexterm><indexterm id="iddle1829" significance="normal"><?indexkey D?><?primarykey debugging?><?secondarykey CONCURRENCY?><primary><emphasis role="strong">debugging</emphasis></primary><secondary>concurrency</secondary></indexterm><indexterm id="iddle1830" significance="normal"><?indexkey D?><?primarykey debugging?><?secondarykey CONCURRENCY?><?tertiarykey COSTS VS. PERFORMANCE OPTIMIZATION VALUE?><primary><emphasis role="strong">debugging</emphasis></primary><secondary>concurrency</secondary><tertiary>costs vs. performance optimization value</tertiary></indexterm><indexterm id="iddle1891" significance="normal"><?indexkey D?><?primarykey design?><primary><emphasis role="strong">design</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle1892" significance="normal"><?indexkey D?><?primarykey design?><primary><emphasis role="strong">design</emphasis></primary><seealso> <link linkend="iddle1912" preference="0"><emphasis role="strong">design</emphasis>, of thread-safe classes, guidelines</link>.</seealso></indexterm><indexterm id="iddle1893" significance="normal"><?indexkey D?><?primarykey design?><primary><emphasis role="strong">design</emphasis></primary><seealso> <link linkend="iddle2244" preference="0"><emphasis role="strong">execution</emphasis>, policies</link>.</seealso></indexterm><indexterm id="iddle1894" significance="normal"><?indexkey D?><?primarykey design?><primary><emphasis role="strong">design</emphasis></primary><seealso> <link linkend="iddle4645" preference="0"><emphasis role="strong">task(s)</emphasis>, representation</link>.</seealso></indexterm><indexterm id="iddle1895" significance="normal"><?indexkey D?><?primarykey design?><primary><emphasis role="strong">design</emphasis></primary><seealso> <link linkend="iddle1929" preference="0"><emphasis role="strong">design</emphasis>, strategies</link>.</seealso></indexterm><indexterm id="iddle1954" significance="normal"><?indexkey D?><?primarykey documentation?><primary><emphasis role="strong">documentation</emphasis></primary><seealso> <link linkend="iddle1462" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, debugging</link>.</seealso></indexterm><indexterm id="iddle1955" significance="normal"><?indexkey D?><?primarykey documentation?><primary><emphasis role="strong">documentation</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle1956" significance="normal"><?indexkey D?><?primarykey documentation?><primary><emphasis role="strong">documentation</emphasis></primary><seealso> <link linkend="iddle2450" preference="0"><emphasis role="strong">good practices</emphasis></link>.</seealso></indexterm><indexterm id="iddle1957" significance="normal"><?indexkey D?><?primarykey documentation?><primary><emphasis role="strong">documentation</emphasis></primary><seealso> <link linkend="iddle1912" preference="0"><emphasis role="strong">design</emphasis>, of thread-safe classes, guidelines</link>.</seealso></indexterm><indexterm id="iddle1958" significance="normal"><?indexkey D?><?primarykey documentation?><primary><emphasis role="strong">documentation</emphasis></primary><seealso> <link linkend="iddle3567" preference="0"><emphasis role="strong">policy(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2055" significance="normal"><?indexkey E?><?primarykey evaluation?><primary><emphasis role="strong">evaluation</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle2056" significance="normal"><?indexkey E?><?primarykey evaluation?><primary><emphasis role="strong">evaluation</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle2057" significance="normal"><?indexkey E?><?primarykey evaluation?><primary><emphasis role="strong">evaluation</emphasis></primary><seealso> <link linkend="iddle1272" preference="0"><emphasis role="strong">buffer(s)</emphasis>, testing</link>.</seealso></indexterm><indexterm id="iddle2362" significance="normal"><?indexkey F?><?primarykey FindBugs code auditing tool?><primary><emphasis role="strong">FindBugs code auditing tool</emphasis></primary><seealso> <link linkend="iddle3254" preference="0"><emphasis role="strong">monitoring</emphasis>, tools</link>.</seealso></indexterm><indexterm id="iddle2385" significance="normal"><?indexkey F?><?primarykey fragility?><primary><emphasis role="strong">fragility</emphasis></primary><seealso> <link linkend="iddle1462" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, debugging</link>.</seealso></indexterm><indexterm id="iddle2386" significance="normal"><?indexkey F?><?primarykey fragility?><primary><emphasis role="strong">fragility</emphasis></primary><seealso> <link linkend="iddle1912" preference="0"><emphasis role="strong">design</emphasis>, of thread-safe classes, guidelines</link>.</seealso></indexterm><indexterm id="iddle2387" significance="normal"><?indexkey F?><?primarykey fragility?><primary><emphasis role="strong">fragility</emphasis></primary><seealso> <link linkend="iddle4005" preference="0"><emphasis role="strong">robustness</emphasis></link>.</seealso></indexterm><indexterm id="iddle2388" significance="normal"><?indexkey F?><?primarykey fragility?><primary><emphasis role="strong">fragility</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle2389" significance="normal"><?indexkey F?><?primarykey fragility?><primary><emphasis role="strong">fragility</emphasis></primary><seealso> <link linkend="iddle2574" preference="0"><emphasis role="strong">guidelines</emphasis>, scalability</link>.</seealso></indexterm><indexterm id="iddle2390" significance="normal"><?indexkey F?><?primarykey fragility?><primary><emphasis role="strong">fragility</emphasis></primary><seealso> <link linkend="iddle1272" preference="0"><emphasis role="strong">buffer(s)</emphasis>, testing</link>.</seealso></indexterm><indexterm id="iddle2450" significance="normal"><?indexkey G?><?primarykey good practices?><primary><emphasis role="strong">good practices</emphasis></primary><see> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</see></indexterm><indexterm id="iddle2451" significance="normal"><?indexkey G?><?primarykey good practices?><primary><emphasis role="strong">good practices</emphasis></primary><see> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</see></indexterm><indexterm id="iddle2452" significance="normal"><?indexkey G?><?primarykey good practices?><primary><emphasis role="strong">good practices</emphasis></primary><see> <link linkend="iddle2520" preference="0"><emphasis role="strong">guidelines</emphasis>, encapsulation</link>.</see></indexterm><indexterm id="iddle2453" significance="normal"><?indexkey G?><?primarykey good practices?><primary><emphasis role="strong">good practices</emphasis></primary><see> <link linkend="iddle1912" preference="0"><emphasis role="strong">design</emphasis>, of thread-safe classes, guidelines</link>.</see></indexterm><indexterm id="iddle2454" significance="normal"><?indexkey G?><?primarykey good practices?><primary><emphasis role="strong">good practices</emphasis></primary><see> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</see></indexterm><indexterm id="iddle2455" significance="normal"><?indexkey G?><?primarykey good practices?><primary><emphasis role="strong">good practices</emphasis></primary><see> <link linkend="iddle1929" preference="0"><emphasis role="strong">design</emphasis>, strategies</link>.</see></indexterm><indexterm id="iddle2498" significance="normal"><?indexkey G?><?primarykey guidelines?><primary><emphasis role="strong">guidelines</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle2499" significance="normal"><?indexkey G?><?primarykey guidelines?><primary><emphasis role="strong">guidelines</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle2500" significance="normal"><?indexkey G?><?primarykey guidelines?><primary><emphasis role="strong">guidelines</emphasis></primary><seealso> <link linkend="iddle3567" preference="0"><emphasis role="strong">policy(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2501" significance="normal"><?indexkey G?><?primarykey guidelines?><primary><emphasis role="strong">guidelines</emphasis></primary><seealso> <link linkend="iddle1929" preference="0"><emphasis role="strong">design</emphasis>, strategies</link>.</seealso></indexterm><indexterm id="iddle2553" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey MEASUREMENT?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>measurement</secondary></indexterm><indexterm id="iddle2554" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey MEASUREMENT?><?tertiarykey IMPORTANCE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>measurement</secondary><tertiary>importance</tertiary></indexterm><indexterm id="iddle2564" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle2565" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey PERFORMANCE?><?tertiarykey OPTIMIZATION QUESTIONS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>performance</secondary><tertiary>optimization questions</tertiary></indexterm><indexterm id="iddle2630" significance="normal"><?indexkey H?><?primarykey heap inspection tools?><primary><emphasis role="strong">heap inspection tools</emphasis></primary><seealso> <link linkend="iddle3254" preference="0"><emphasis role="strong">monitoring</emphasis>, tools</link>.</seealso></indexterm><indexterm id="iddle2671" significance="normal"><?indexkey I?><?primarykey I/O?><primary><emphasis role="strong">I/O</emphasis></primary><seealso> <link linkend="iddle3898" preference="0"><emphasis role="strong">resource(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2750" significance="normal"><?indexkey I?><?primarykey instrumentation?><primary><emphasis role="strong">instrumentation</emphasis></primary><seealso> <link linkend="iddle1795" preference="0"><emphasis role="strong">deadlock(s)</emphasis>, analysis</link>.</seealso></indexterm><indexterm id="iddle2751" significance="normal"><?indexkey I?><?primarykey instrumentation?><primary><emphasis role="strong">instrumentation</emphasis></primary><seealso> <link linkend="iddle2231" preference="0"><emphasis role="strong">exceptions</emphasis>, logging</link>.</seealso></indexterm><indexterm id="iddle2752" significance="normal"><?indexkey I?><?primarykey instrumentation?><primary><emphasis role="strong">instrumentation</emphasis></primary><seealso> <link linkend="iddle1713" preference="0"><emphasis role="strong">CPU utilization</emphasis>, monitoring</link>.</seealso></indexterm><indexterm id="iddle2753" significance="normal"><?indexkey I?><?primarykey instrumentation?><primary><emphasis role="strong">instrumentation</emphasis></primary><seealso> <link linkend="iddle3898" preference="0"><emphasis role="strong">resource(s)</emphasis></link>, management.</seealso></indexterm><indexterm id="iddle2754" significance="normal"><?indexkey I?><?primarykey instrumentation?><primary><emphasis role="strong">instrumentation</emphasis></primary><seealso> statistics.</seealso></indexterm><indexterm id="iddle2755" significance="normal"><?indexkey I?><?primarykey instrumentation?><primary><emphasis role="strong">instrumentation</emphasis></primary><seealso> <link linkend="iddle1272" preference="0"><emphasis role="strong">buffer(s)</emphasis>, testing</link>.</seealso></indexterm><indexterm id="iddle2867" significance="normal"><?indexkey I?><?primarykey iostat application?><primary><emphasis role="strong">iostat application</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle2868" significance="normal"><?indexkey I?><?primarykey iostat application?><primary><emphasis role="strong">iostat application</emphasis></primary><seealso> <link linkend="iddle3254" preference="0"><emphasis role="strong">monitoring</emphasis>, tools</link>.</seealso></indexterm><indexterm id="iddle3166" significance="normal"><?indexkey L?><?primarykey logging?><primary><emphasis role="strong">logging</emphasis></primary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle3183" significance="normal"><?indexkey M?><?primarykey measurement?><primary><emphasis role="strong">measurement</emphasis></primary></indexterm><indexterm id="iddle3184" significance="normal"><?indexkey M?><?primarykey measurement?><?secondarykey IMPORTANCE FOR EFFECTIVE OPTIMIZATION?><primary><emphasis role="strong">measurement</emphasis></primary><secondary>importance for effective optimization</secondary></indexterm><indexterm id="iddle3193" significance="normal"><?indexkey M?><?primarykey memory?><primary><emphasis role="strong">memory</emphasis></primary><seealso> <link linkend="iddle3898" preference="0"><emphasis role="strong">resource(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle3246" significance="normal"><?indexkey M?><?primarykey monitoring?><primary><emphasis role="strong">monitoring</emphasis></primary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle3247" significance="normal"><?indexkey M?><?primarykey monitoring?><primary><emphasis role="strong">monitoring</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle3248" significance="normal"><?indexkey M?><?primarykey monitoring?><primary><emphasis role="strong">monitoring</emphasis></primary><seealso> <link linkend="iddle2574" preference="0"><emphasis role="strong">guidelines</emphasis>, scalability</link>.</seealso></indexterm><indexterm id="iddle3249" significance="normal"><?indexkey M?><?primarykey monitoring?><primary><emphasis role="strong">monitoring</emphasis></primary><seealso> <link linkend="iddle1272" preference="0"><emphasis role="strong">buffer(s)</emphasis>, testing</link>.</seealso></indexterm><indexterm id="iddle3250" significance="normal"><?indexkey M?><?primarykey monitoring?><primary><emphasis role="strong">monitoring</emphasis></primary><seealso> <link linkend="iddle3254" preference="0"><emphasis role="strong">monitoring</emphasis>, tools</link>.</seealso></indexterm><indexterm id="iddle3344" significance="normal"><?indexkey O?><?primarykey object(s)?><primary><emphasis role="strong">object(s)</emphasis></primary><seealso> <link linkend="iddle3898" preference="0"><emphasis role="strong">resource(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle3392" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey PERFORMANCE?><?tertiarykey QUESTIONS ABOUT?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>performance</secondary><tertiary>questions about</tertiary></indexterm><indexterm id="iddle3469" significance="normal"><?indexkey P?><?primarykey perfbar application?><primary><emphasis role="strong">perfbar application</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle3470" significance="normal"><?indexkey P?><?primarykey perfbar application?><primary><emphasis role="strong">perfbar application</emphasis></primary><seealso> <link linkend="iddle3254" preference="0"><emphasis role="strong">monitoring</emphasis>, tools</link>.</seealso></indexterm><indexterm id="iddle3567" significance="normal"><?indexkey P?><?primarykey policy(s)?><primary><emphasis role="strong">policy(s)</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle3568" significance="normal"><?indexkey P?><?primarykey policy(s)?><primary><emphasis role="strong">policy(s)</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle3569" significance="normal"><?indexkey P?><?primarykey policy(s)?><primary><emphasis role="strong">policy(s)</emphasis></primary><seealso> <link linkend="iddle1912" preference="0"><emphasis role="strong">design</emphasis>, of thread-safe classes, guidelines</link>.</seealso></indexterm><indexterm id="iddle3570" significance="normal"><?indexkey P?><?primarykey policy(s)?><primary><emphasis role="strong">policy(s)</emphasis></primary><seealso> <link linkend="iddle3130" preference="0"><emphasis role="strong">lock(ing)</emphasis>, protocols</link>.</seealso></indexterm><indexterm id="iddle3571" significance="normal"><?indexkey P?><?primarykey policy(s)?><primary><emphasis role="strong">policy(s)</emphasis></primary><seealso> <link linkend="iddle1929" preference="0"><emphasis role="strong">design</emphasis>, strategies</link>.</seealso></indexterm><indexterm id="iddle3606" significance="normal"><?indexkey P?><?primarykey pool(s)?><primary><emphasis role="strong">pool(s)</emphasis></primary><seealso> <link linkend="iddle3898" preference="0"><emphasis role="strong">resource(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle3690" significance="normal"><?indexkey P?><?primarykey profiling?><primary><emphasis role="strong">profiling</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle3703" significance="normal"><?indexkey P?><?primarykey protocol(s)?><primary><emphasis role="strong">protocol(s)</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle3704" significance="normal"><?indexkey P?><?primarykey protocol(s)?><primary><emphasis role="strong">protocol(s)</emphasis></primary><seealso> <link linkend="iddle3567" preference="0"><emphasis role="strong">policy(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle3705" significance="normal"><?indexkey P?><?primarykey protocol(s)?><primary><emphasis role="strong">protocol(s)</emphasis></primary><seealso> <link linkend="iddle1929" preference="0"><emphasis role="strong">design</emphasis>, strategies</link>.</seealso></indexterm><indexterm id="iddle3742" significance="normal"><?indexkey Q?><?primarykey quality assurance?><primary><emphasis role="strong">quality assurance</emphasis></primary><seealso> <link linkend="iddle1272" preference="0"><emphasis role="strong">buffer(s)</emphasis>, testing</link>.</seealso></indexterm><indexterm id="iddle3880" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey CONCRETE?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>concrete</secondary></indexterm><indexterm id="iddle3881" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey CONCRETE?><?tertiarykey IMPORTANCE FOR EFFECTIVE PERFORMANCE OPTIMIZATION?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>concrete</secondary><tertiary>importance for effective performance optimization</tertiary></indexterm><indexterm id="iddle3898" significance="normal"><?indexkey R?><?primarykey resource(s)?><primary><emphasis role="strong">resource(s)</emphasis></primary><seealso> <link linkend="iddle5032" preference="0"><emphasis role="strong">utilization</emphasis>, CPU</link>.</seealso></indexterm><indexterm id="iddle3899" significance="normal"><?indexkey R?><?primarykey resource(s)?><primary><emphasis role="strong">resource(s)</emphasis></primary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle3900" significance="normal"><?indexkey R?><?primarykey resource(s)?><primary><emphasis role="strong">resource(s)</emphasis></primary><seealso> <link linkend="iddle1195" preference="0"><emphasis role="strong">barrier(s)</emphasis>, memory</link>.</seealso></indexterm><indexterm id="iddle3901" significance="normal"><?indexkey R?><?primarykey resource(s)?><primary><emphasis role="strong">resource(s)</emphasis></primary><seealso> <link linkend="iddle1646" preference="0"><emphasis role="strong">cooperation/cooperating</emphasis>, objects</link>.</seealso></indexterm><indexterm id="iddle3902" significance="normal"><?indexkey R?><?primarykey resource(s)?><primary><emphasis role="strong">resource(s)</emphasis></primary><seealso> <link linkend="iddle3355" preference="0"><emphasis role="strong">object(s)</emphasis>, pools</link>.</seealso></indexterm><indexterm id="iddle3903" significance="normal"><?indexkey R?><?primarykey resource(s)?><primary><emphasis role="strong">resource(s)</emphasis></primary><seealso> <link linkend="iddle3939" preference="0"><emphasis role="strong">resource(s)</emphasis>, utilization</link>.</seealso></indexterm><indexterm id="iddle3916" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle3917" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><seealso> <link linkend="iddle1272" preference="0"><emphasis role="strong">buffer(s)</emphasis>, testing</link>.</seealso></indexterm><indexterm id="iddle3918" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><seealso> <link linkend="iddle1951" preference="0"><emphasis role="strong">dining philosophers problem</emphasis></link>.</seealso></indexterm><indexterm id="iddle4005" significance="normal"><?indexkey R?><?primarykey robustness?><primary><emphasis role="strong">robustness</emphasis></primary><seealso> <link linkend="iddle2385" preference="0"><emphasis role="strong">fragility</emphasis></link>.</seealso></indexterm><indexterm id="iddle4006" significance="normal"><?indexkey R?><?primarykey robustness?><primary><emphasis role="strong">robustness</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle4010" significance="normal"><?indexkey R?><?primarykey rules?><primary><emphasis role="strong">rules</emphasis></primary><seealso> <link linkend="iddle1912" preference="0"><emphasis role="strong">design</emphasis>, of thread-safe classes, guidelines</link>.</seealso></indexterm><indexterm id="iddle4011" significance="normal"><?indexkey R?><?primarykey rules?><primary><emphasis role="strong">rules</emphasis></primary><seealso> <link linkend="iddle3567" preference="0"><emphasis role="strong">policy(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle4012" significance="normal"><?indexkey R?><?primarykey rules?><primary><emphasis role="strong">rules</emphasis></primary><seealso> <link linkend="iddle1929" preference="0"><emphasis role="strong">design</emphasis>, strategies</link>.</seealso></indexterm><indexterm id="iddle4120" significance="normal"><?indexkey S?><?primarykey semantics?><primary><emphasis role="strong">semantics</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle4121" significance="normal"><?indexkey S?><?primarykey semantics?><primary><emphasis role="strong">semantics</emphasis></primary><seealso> <link linkend="iddle4645" preference="0"><emphasis role="strong">task(s)</emphasis>, representation</link>.</seealso></indexterm><indexterm id="iddle4282" significance="normal"><?indexkey S?><?primarykey simplicity?><primary><emphasis role="strong">simplicity</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle4337" significance="normal"><?indexkey S?><?primarykey specification?><primary><emphasis role="strong">specification</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle4442" significance="normal"><?indexkey S?><?primarykey statistics gathering?><primary><emphasis role="strong">statistics gathering</emphasis></primary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle4451" significance="normal"><?indexkey S?><?primarykey strategies?><primary><emphasis role="strong">strategies</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle4452" significance="normal"><?indexkey S?><?primarykey strategies?><primary><emphasis role="strong">strategies</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle4453" significance="normal"><?indexkey S?><?primarykey strategies?><primary><emphasis role="strong">strategies</emphasis></primary><seealso> <link linkend="iddle1912" preference="0"><emphasis role="strong">design</emphasis>, of thread-safe classes, guidelines</link>.</seealso></indexterm><indexterm id="iddle4454" significance="normal"><?indexkey S?><?primarykey strategies?><primary><emphasis role="strong">strategies</emphasis></primary><seealso> <link linkend="iddle3567" preference="0"><emphasis role="strong">policy(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle4455" significance="normal"><?indexkey S?><?primarykey strategies?><primary><emphasis role="strong">strategies</emphasis></primary><seealso> <link linkend="iddle4645" preference="0"><emphasis role="strong">task(s)</emphasis>, representation</link>.</seealso></indexterm><indexterm id="iddle4667" significance="normal"><?indexkey T?><?primarykey techniques?><primary><emphasis role="strong">techniques</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle4668" significance="normal"><?indexkey T?><?primarykey techniques?><primary><emphasis role="strong">techniques</emphasis></primary><seealso> <link linkend="iddle1912" preference="0"><emphasis role="strong">design</emphasis>, of thread-safe classes, guidelines</link>.</seealso></indexterm><indexterm id="iddle4669" significance="normal"><?indexkey T?><?primarykey techniques?><primary><emphasis role="strong">techniques</emphasis></primary><seealso> <link linkend="iddle1929" preference="0"><emphasis role="strong">design</emphasis>, strategies</link>.</seealso></indexterm><indexterm id="iddle4687" significance="normal"><?indexkey T?><?primarykey testing?><primary><emphasis role="strong">testing</emphasis></primary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle4688" significance="normal"><?indexkey T?><?primarykey testing?><primary><emphasis role="strong">testing</emphasis></primary><seealso> <link linkend="iddle2231" preference="0"><emphasis role="strong">exceptions</emphasis>, logging</link>.</seealso></indexterm><indexterm id="iddle4689" significance="normal"><?indexkey T?><?primarykey testing?><primary><emphasis role="strong">testing</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle4690" significance="normal"><?indexkey T?><?primarykey testing?><primary><emphasis role="strong">testing</emphasis></primary><seealso> <link linkend="iddle1713" preference="0"><emphasis role="strong">CPU utilization</emphasis>, monitoring</link>.</seealso></indexterm><indexterm id="iddle4691" significance="normal"><?indexkey T?><?primarykey testing?><primary><emphasis role="strong">testing</emphasis></primary><seealso> <link linkend="iddle3695" preference="0"><emphasis role="strong">profiling</emphasis>, tools, quality assurance</link>.</seealso></indexterm><indexterm id="iddle4692" significance="normal"><?indexkey T?><?primarykey testing?><primary><emphasis role="strong">testing</emphasis></primary><seealso> statistics.</seealso></indexterm><indexterm id="iddle4937" significance="normal"><?indexkey T?><?primarykey tools?><primary><emphasis role="strong">tools</emphasis></primary><seealso> <link linkend="iddle2750" preference="0"><emphasis role="strong">instrumentation</emphasis></link>.</seealso></indexterm><indexterm id="iddle4938" significance="normal"><?indexkey T?><?primarykey tools?><primary><emphasis role="strong">tools</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle4945" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey MEASUREMENT?><?tertiarykey IMPORTANCE FOR EFFECTIVE PERFORMANCE OPTIMIZATION?><primary><emphasis role="strong">tools</emphasis></primary><secondary>measurement</secondary><tertiary>importance for effective performance optimization</tertiary></indexterm><indexterm id="iddle5109" significance="normal"><?indexkey V?><?primarykey vmstat application?><primary><emphasis role="strong">vmstat application</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle5110" significance="normal"><?indexkey V?><?primarykey vmstat application?><primary><emphasis role="strong">vmstat application</emphasis></primary><seealso> <link linkend="iddle3254" preference="0"><emphasis role="strong">monitoring</emphasis>, tools</link>.</seealso></indexterm>it did in the bridge example. Many performance optimizations come at the cost of readability or maintainability—the more “clever” or nonobvious code is, the harder it is to understand and maintain. Sometimes optimizations entail compromising good object-oriented design principles, such as breaking encapsulation; sometimes they involve greater risk of error, because faster algorithms are usually more complicated. (If you can’t spot the costs or risks, you probably haven’t thought it through carefully enough to proceed.)</para>
<para>Most performance decisions involve multiple variables and are highly situational. Before deciding that one approach is “faster” than another, ask yourself some questions:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>What do you mean by “faster”?</para></listitem>
<listitem><para>Under what conditions will this approach <emphasis>actually</emphasis> be faster? Under light or heavy load? With large or small data sets? Can you support your answer with measurements?</para></listitem>
<listitem><para>How often are these conditions likely to arise in your situation? Can you support your answer with measurements?</para></listitem>
<listitem><para>Is this code likely to be used in other situations where the conditions may be different?</para></listitem>
<listitem><para>What hidden costs, such as increased development or maintenance risk, are you trading for this improved performance? Is this a good tradeoff?</para></listitem>
</itemizedlist>
<para role="continued">These considerations apply to any performance-related engineering decision, but this is a book about concurrency. Why are we recommending such a conservative approach to optimization? <emphasis>The quest for performance is probably the single greatest source of concurrency bugs.</emphasis> The belief that synchronization was “too slow” led to many clever-looking but dangerous idioms for reducing synchronization (such as double-checked locking, discussed in <link linkend="ch16lev2sec8" preference="0">Section 16.2.4</link>), and is often cited as an excuse for not following the rules regarding synchronization. Because concurrency bugs are among the most difficult to track down and eliminate, however, anything that risks introducing them must be undertaken very carefully.</para>
<para>Worse, when you trade safety for performance, you may get neither. Especially when it comes to concurrency, the intuition of many developers about where a performance problem lies or which approach will be faster or more scalable is often incorrect. It is therefore imperative that any performance tuning exercise be accompanied by concrete performance requirements (so you know both when to tune and when to <emphasis>stop</emphasis> tuning) and with a measurement program in place using a realistic configuration and load profile. Measure again after tuning to verify that you’ve achieved the desired improvements. The safety and maintenance risks associated with many optimizations are bad enough—you don’t want to pay these costs if you don’t need to—and you definitely don’t want to pay them if you don’t even get the desired benefit.</para>
<sidebar float="1" id="ch11sb03" condition="224"><title/>
<para>Measure, don’t guess.</para>
</sidebar>
<para><?docpage num="225"?><indexterm id="iddle1077" significance="normal"><?indexkey A?><?primarykey Amdahl&rsquo;s law?><primary><emphasis role="strong">Amdahl’s law</emphasis></primary><seealso> <link linkend="iddle1465" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, errors</link>.</seealso></indexterm><indexterm id="iddle1078" significance="normal"><?indexkey A?><?primarykey Amdahl&rsquo;s law?><primary><emphasis role="strong">Amdahl’s law</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle1079" significance="normal"><?indexkey A?><?primarykey Amdahl&rsquo;s law?><primary><emphasis role="strong">Amdahl’s law</emphasis></primary><seealso> <link linkend="iddle3898" preference="0"><emphasis role="strong">resource(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1080" significance="normal"><?indexkey A?><?primarykey Amdahl&rsquo;s law?><primary><emphasis role="strong">Amdahl’s law</emphasis></primary><seealso> <link linkend="iddle4867" preference="0"><emphasis role="strong">throughput</emphasis></link>; ; <link linkend="iddle3939" preference="0"><emphasis role="strong">resource(s)</emphasis>, utilization</link>.</seealso></indexterm><indexterm id="iddle3186" significance="normal"><?indexkey M?><?primarykey measurement?><?secondarykey PROFILING TOOLS?><primary><emphasis role="strong">measurement</emphasis></primary><secondary>profiling tools</secondary></indexterm><indexterm id="iddle3189" significance="normal"><?indexkey M?><?primarykey measurement?><?secondarykey STRATEGIES AND TOOLS?><primary><emphasis role="strong">measurement</emphasis></primary><secondary>strategies and tools</secondary></indexterm><indexterm id="iddle3190" significance="normal"><?indexkey M?><?primarykey measurement?><?secondarykey STRATEGIES AND TOOLS?><?tertiarykey PROFILING TOOLS?><primary><emphasis role="strong">measurement</emphasis></primary><secondary>strategies and tools</secondary><tertiary>profiling tools</tertiary></indexterm><indexterm id="iddle3389" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle3390" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey PERFORMANCE?><?tertiarykey AMDAHL&rsquo;S LAW?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>performance</secondary><tertiary>Amdahl’s law</tertiary></indexterm><indexterm id="iddle3456" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey SERIALIZATION VS?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>serialization vs</secondary></indexterm><indexterm id="iddle3457" significance="normal"><?indexkey P?><?primarykey parallelizing/parallelism?><?secondarykey SERIALIZATION VS?><?tertiarykey AMDAHL&rsquo;S LAW?><primary><emphasis role="strong">parallelizing/parallelism</emphasis></primary><secondary>serialization vs</secondary><tertiary>Amdahl’s law</tertiary></indexterm><indexterm id="iddle3472" significance="normal"><?indexkey P?><?primarykey perfbar application?><?secondarykey PERFORMANCE MEASUREMENT USE?><primary><emphasis role="strong">perfbar application</emphasis></primary><secondary>performance measurement use</secondary></indexterm><indexterm id="iddle3513" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey OPTIMIZATION?><?tertiarykey AMDAHL&rsquo;S LAW?><primary><emphasis role="strong">performance</emphasis></primary><secondary>optimization</secondary><tertiary>Amdahl’s law</tertiary></indexterm><indexterm id="iddle3694" significance="normal"><?indexkey P?><?primarykey profiling?><?secondarykey TOOLS?><?tertiarykey PERFORMANCE MEASUREMENT?><primary><emphasis role="strong">profiling</emphasis></primary><secondary>tools</secondary><tertiary>performance measurement</tertiary></indexterm><indexterm id="iddle3939" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey UTILIZATION?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>utilization</secondary></indexterm><indexterm id="iddle3940" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey UTILIZATION?><?tertiarykey AMDAHL&rsquo;S LAW?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>utilization</secondary><tertiary>Amdahl’s law</tertiary></indexterm><indexterm id="iddle4180" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey PARALLELIZATION VS?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>parallelization vs</secondary></indexterm><indexterm id="iddle4181" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey PARALLELIZATION VS?><?tertiarykey AMDAHL&rsquo;S LAW?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>parallelization vs</secondary><tertiary>Amdahl’s law</tertiary></indexterm><indexterm id="iddle4185" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey SOURCES?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>sources</secondary></indexterm><indexterm id="iddle4186" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey SOURCES?><?tertiarykey IDENTIFICATION OF, PERFORMANCE IMPACT?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>sources</secondary><tertiary>identification of, performance impact</tertiary></indexterm><indexterm id="iddle4652" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey SERIALIZATION SOURCES?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>serialization sources</secondary></indexterm><indexterm id="iddle4653" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey SERIALIZATION SOURCES?><?tertiarykey IDENTIFYING?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>serialization sources</secondary><tertiary>identifying</tertiary></indexterm><indexterm id="iddle4951" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey PROFILING?><?tertiarykey PERFORMANCE MEASUREMENT?><primary><emphasis role="strong">tools</emphasis></primary><secondary>profiling</secondary><tertiary>performance measurement</tertiary></indexterm><indexterm id="iddle5030" significance="normal"><?indexkey U?><?primarykey utilization?><primary><emphasis role="strong">utilization</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle5031" significance="normal"><?indexkey U?><?primarykey utilization?><primary><emphasis role="strong">utilization</emphasis></primary><seealso> <link linkend="iddle3898" preference="0"><emphasis role="strong">resource(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle5032" significance="normal"><?indexkey U?><?primarykey utilization?><?secondarykey CPU?><primary><emphasis role="strong">utilization</emphasis></primary><secondary>CPU</secondary></indexterm><indexterm id="iddle5033" significance="normal"><?indexkey U?><?primarykey utilization?><?secondarykey CPU?><?tertiarykey AMDAHL&rsquo;S LAW?><primary><emphasis role="strong">utilization</emphasis></primary><secondary>CPU</secondary><tertiary>Amdahl’s law</tertiary></indexterm>There are sophisticated profiling tools on the market for measuring performance and tracking down performance bottlenecks, but you don’t have to spend a lot of money to figure out what your program is doing. For example, the free <literal>perfbar</literal> application can give you a good picture of how busy the CPUs are, and since your goal is usually to keep the CPUs busy, this is a very good way to evaluate whether you need performance tuning or how effective your tuning has been.</para>
</section>
</section>
<section id="ch11lev1sec2" condition="225" label="11.2" xreflabel="11.2"><?docpage num="225"?>
<title id="ch11lev1sec2__title">Amdahl’s Law</title>
<para>Some problems can be solved faster with more resources—the more workers available for harvesting crops, the faster the harvest can be completed. Other tasks are fundamentally serial—no number of additional workers will make the crops grow any faster. If one of our primary reasons for using threads is to harness the power of multiple processors, we must also ensure that the problem is amenable to parallel decomposition and that our program effectively exploits this potential for parallelization.</para>
<para>Most concurrent programs have a lot in common with farming, consisting of a mix of parallelizable and serial portions. <emphasis>Amdahl’s law</emphasis> describes how much a program can theoretically be sped up by additional computing resources, based on the proportion of parallelizable and serial components. If <emphasis>F</emphasis> is the fraction of the calculation that must be executed serially, then Amdahl’s law says that on a machine with <emphasis>N</emphasis> processors, we can achieve a speedup of at most:</para>
<mediaobject float="0">
<imageobject>
<imagedata depth="71" fileref="graphics/225equ01.gif" format="GIF" width="200"/></imageobject>

</mediaobject>
<para role="continued">As <emphasis>N</emphasis> approaches infinity, the maximum speedup converges to 1/<emphasis>F</emphasis>, meaning that a program in which fifty percent of the processing must be executed serially can be sped up only by a factor of two, regardless of how many processors are available, and a program in which ten percent must be executed serially can be sped up by at most a factor of ten. Amdahl’s law also quantifies the efficiency cost of serialization. With ten processors, a program with 10%serialization can achieve at most a speedup of 5.3 (at 53% utilization), and with 100 processors it can achieve at most a speedup of 9.2 (at 9% utilization). It takes a lot of inefficiently utilized CPUs to never get to that factor of ten.</para>
<para><link linkend="ch11fig01" preference="1">Figure 11.1</link> shows the maximum possible processor utilization for varying degrees of serial execution and numbers of processors. (Utilization is defined as the speedup divided by the number of processors.) It is clear that as processor counts increase, even a small percentage of serialized execution limits how much throughput can be increased with additional computing resources.</para>
<figure float="1" id="ch11fig01" label="11.1" xreflabel="11.1" condition="226">
<?docpage num="226"?>
<title id="ch11fig01__title">Maximum Utilization Under Amdahl’s Law for Various Serialization Percentages.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="306" fileref="graphics/11fig01.gif" format="GIF" width="495"/></imageobject>

</mediaobject>
</figure>
<para><link linkend="ch06" preference="0">Chapter 6</link> explored identifying logical boundaries for decomposing applications into tasks. But in order to predict what kind of speedup is possible from running your application on a multiprocessor system, you also need to identify the sources of serialization in your tasks.</para>
<para><?docpage num="226"?><indexterm id="iddle1777" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey SHARED?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>shared</secondary></indexterm><indexterm id="iddle1778" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey SHARED?><?tertiarykey AS SERIALIZATION SOURCE?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>shared</secondary><tertiary>as serialization source</tertiary></indexterm><indexterm id="iddle3986" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey HANDLING?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>handling</secondary></indexterm><indexterm id="iddle3987" significance="normal"><?indexkey R?><?primarykey result(s)?><?secondarykey HANDLING?><?tertiarykey AS SERIALIZATION SOURCE?><primary><emphasis role="strong">result(s)</emphasis></primary><secondary>handling</secondary><tertiary>as serialization source</tertiary></indexterm><indexterm id="iddle4229" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey DATA STRUCTURES?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>data structures</secondary></indexterm><indexterm id="iddle4230" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey DATA STRUCTURES?><?tertiarykey AS SERIALIZATION SOURCE?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>data structures</secondary><tertiary>as serialization source</tertiary></indexterm><indexterm id="iddle4272" significance="normal"><?indexkey S?><?primarykey side-effects?><primary><emphasis role="strong">side-effects</emphasis></primary></indexterm><indexterm id="iddle4273" significance="normal"><?indexkey S?><?primarykey side-effects?><?secondarykey AS SERIALIZATION SOURCE?><primary><emphasis role="strong">side-effects</emphasis></primary><secondary>as serialization source</secondary></indexterm><indexterm id="iddle5034" significance="normal"><?indexkey U?><?primarykey utilization?><?secondarykey CPU?><?tertiarykey AMDAHL&rsquo;S LAW?><primary><emphasis role="strong">utilization</emphasis></primary><secondary>CPU</secondary><tertiary>Amdahl’s law</tertiary></indexterm>Imagine an application where <emphasis>N</emphasis> threads execute <literal>doWork</literal> in <link linkend="ch11list01" preference="0">Listing 11.1</link>, fetching tasks from a shared work queue and processing them; assume that tasks do not depend on the results or side effects of other tasks. Ignoring for a moment how the tasks get onto the queue, how well will this application scale as we add processors? At first glance, it may appear that the application is completely parallelizable: tasks do not wait for each other, and the more processors available, the more tasks can be processed concurrently. However, there is a serial component as well—fetching the task from the work queue. The work queue is shared by all the worker threads, and it will require some amount of synchronization to maintain its integrity in the face of concurrent access. If locking is used to guard the state of the queue, then while one thread is dequeing a task, other threads that need to dequeue their next task must wait—and this is where task processing is serialized.</para>
<para>The processing time of a single task includes not only the time to execute the task <literal>Runnable</literal>, but also the time to dequeue the task from the shared work queue. If the work queue is a <literal>LinkedBlockingQueue</literal>, the dequeue operation may block less than with a synchronized <literal>LinkedList</literal> because <literal>LinkedBlockingQueue</literal> uses a more scalable algorithm, but accessing any shared data structure fundamentally introduces an element of serialization into a program.</para>
<para>This example also ignores another common source of serialization: result handling. All useful computations produce some sort of result or side effect—if not, they can be eliminated as dead code. Since <literal>Runnable</literal> provides for no explicit result handling, these tasks must have some sort of side effect, say writing their results to a log file or putting them in a data structure. Log files and result containers are usually shared by multiple worker threads and therefore are also a <?docpage num="227"?><indexterm id="iddle1028" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey SERIALIZED?><primary><emphasis role="strong">access</emphasis></primary><secondary>serialized</secondary></indexterm><indexterm id="iddle1029" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey SERIALIZED?><?tertiarykey WORKERTHREAD EXAMPLE?><primary><emphasis role="strong">access</emphasis></primary><secondary>serialized</secondary><tertiary><literal>WorkerThread</literal> example</tertiary></indexterm><indexterm id="iddle1082" significance="normal"><?indexkey A?><?primarykey Amdahl&rsquo;s law?><?secondarykey QUALITATIVE APPLICATION OF?><primary><emphasis role="strong">Amdahl’s law</emphasis></primary><secondary>qualitative application of</secondary></indexterm><indexterm id="iddle2220" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey WORKERTHREAD?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>WorkerThread</literal></secondary></indexterm><indexterm id="iddle2410" significance="normal"><?indexkey F?><?primarykey frameworks?><?secondarykey SERIALIZATION HIDDEN IN?><primary><emphasis role="strong">frameworks</emphasis></primary><secondary>serialization hidden in</secondary></indexterm><indexterm id="iddle2579" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SERIALIZATION SOURCES?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>serialization sources</secondary></indexterm><indexterm id="iddle3762" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey IMPLEMENTATIONS?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>implementations</secondary></indexterm><indexterm id="iddle3763" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey IMPLEMENTATIONS?><?tertiarykey SERIALIZATION DIFFERENCES?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>implementations</secondary><tertiary>serialization differences</tertiary></indexterm><indexterm id="iddle4078" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey QUEUE IMPLEMENTATIONS?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>queue implementations</secondary></indexterm><indexterm id="iddle4079" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey QUEUE IMPLEMENTATIONS?><?tertiarykey SERIALIZATION DIFFERENCES?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>queue implementations</secondary><tertiary>serialization differences</tertiary></indexterm><indexterm id="iddle4176" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey ACCESS?><?tertiarykey WORKERTHREAD?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>access</secondary><tertiary><literal>WorkerThread</literal></tertiary></indexterm><indexterm id="iddle4872" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey QUEUE IMPLEMENTATIONS?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>queue implementations</secondary></indexterm><indexterm id="iddle4873" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey QUEUE IMPLEMENTATIONS?><?tertiarykey SERIALIZATION DIFFERENCES?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>queue implementations</secondary><tertiary>serialization differences</tertiary></indexterm>source of serialization. If instead each thread maintains its own data structure for results that are merged after all the tasks are performed, then the final merge is a source of serialization.</para>
<example id="ch11list01" label="11.1" role="Listing" xreflabel="11.1" condition="227">
<title id="ch11list01__title">Serialized Access to a Task Queue.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class WorkerThread extends Thread {
    private final BlockingQueue&lt;Runnable&gt; queue;

    public WorkerThread(BlockingQueue&lt;Runnable&gt; queue) {
        this.queue = queue;
    }

    public void run() {
        while (true) {
            try {
                Runnable task = queue.take();
                task.run();
            } catch (InterruptedException e) {
                break;  /*  Allow thread to exit  */
            }
        }
    }
}
</programlisting>
</example>
<sidebar float="1" id="ch11sb04" condition="227"><title/>
<para>All concurrent applications have some sources of serialization; if you think yours does not, look again.</para>
</sidebar>
<section id="ch11lev2sec3" label="11.2.1" xreflabel="11.2.1">
<title id="ch11lev2sec3__title">Example: Serialization Hidden in Frameworks</title>
<para>To see how serialization can be hidden in the structure of an application, we can compare throughput as threads are added and infer differences in serialization based on observed differences in scalability. <link linkend="ch11fig02" preference="1">Figure 11.2</link> shows a simple application in which multiple threads repeatedly remove an element from a shared <literal>Queue</literal> and process it, similar to <link linkend="ch11list01" preference="0">Listing 11.1</link>. The processing step involves only thread-local computation. If a thread finds the queue is empty, it puts a batch of new elements on the queue so that other threads have something to process on their next iteration. Accessing the shared queue clearly entails some degree of serialization, but the processing step is entirely parallelizable since it involves no shared data.</para>
<figure float="1" id="ch11fig02" label="11.2" xreflabel="11.2" condition="228">
<?docpage num="228"?>
<title id="ch11fig02__title">Comparing Queue Implementations.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/11fig02_alt.gif"?><imagedata depth="255" fileref="graphics/11fig02.gif" format="GIF" role="stdwidth" width="500"/></imageobject></mediaobject>
</figure>
<para>The curves in <link linkend="ch11fig02" preference="1">Figure 11.2</link> compare throughput for two thread-safe <literal>Queue</literal> implementations: a <literal>LinkedList</literal> wrapped with <literal>synchronizedList</literal>, and a <literal>ConcurrentLinkedQueue</literal>. The tests were run on an 8-way Sparc V880 system running <?docpage num="228"?><indexterm id="iddle1608" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey THROUGHPUT IMPACT?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>throughput impact</secondary></indexterm><indexterm id="iddle1620" significance="normal"><?indexkey C?><?primarykey context switching?><?secondarykey THROUGHPUT IMPACT?><primary><emphasis role="strong">context switching</emphasis></primary><secondary>throughput impact</secondary></indexterm><indexterm id="iddle2471" significance="normal"><?indexkey G?><?primarykey granularity?><?secondarykey SERIALIZATION?><primary><emphasis role="strong">granularity</emphasis></primary><secondary>serialization</secondary></indexterm><indexterm id="iddle2472" significance="normal"><?indexkey G?><?primarykey granularity?><?secondarykey SERIALIZATION?><?tertiarykey THROUGHPUT IMPACT?><primary><emphasis role="strong">granularity</emphasis></primary><secondary>serialization</secondary><tertiary>throughput impact</tertiary></indexterm><indexterm id="iddle4082" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey SERIALIZATION IMPACT ON?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>serialization impact on</secondary></indexterm><indexterm id="iddle4177" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey GRANULARITY?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>granularity</secondary></indexterm><indexterm id="iddle4178" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey GRANULARITY?><?tertiarykey THROUGHPUT IMPACT?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>granularity</secondary><tertiary>throughput impact</tertiary></indexterm><indexterm id="iddle4182" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey SCALABILITY IMPACT?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>scalability impact</secondary></indexterm>Solaris. While each run represents the same amount of “work”, we can see that merely changing queue implementations can have a big impact on scalability.</para>
<para>The throughput of <literal>ConcurrentLinkedQueue</literal> continues to improve until it hits the number of processors and then remains mostly constant. On the other hand, the throughput of the synchronized <literal>LinkedList</literal> shows some improvement up to three threads, but then falls off as synchronization overhead increases. By the time it gets to four or five threads, contention is so heavy that every access to the queue lock is contended and throughput is dominated by context switching.</para>
<para>The difference in throughput comes from differing degrees of serialization between the two queue implementations. The synchronized <literal>LinkedList</literal> guards the entire queue state with a single lock that is held for the duration of the <literal>offer</literal> or <literal>remove</literal> call; <literal>ConcurrentLinkedQueue</literal> uses a sophisticated nonblocking queue algorithm (see <link linkend="ch15lev2sec7" preference="0">Section 15.4.2</link>) that uses atomic references to update individual link pointers. In one, the entire insertion or removal is serialized; in the other, only updates to individual pointers are serialized.</para>
</section>
<section id="ch11lev2sec4" label="11.2.2" xreflabel="11.2.2">
<title id="ch11lev2sec4__title">Applying Amdahl’s Law Qualitatively</title>
<para>Amdahl’s law quantifies the possible speedup when more computing resources are available, if we can accurately estimate the fraction of execution that is serialized. Although measuring serialization directly can be difficult, Amdahl’s law can still be useful without such measurement.</para>
<para>Since our mental models are influenced by our environment, many of us are used to thinking that a multiprocessor system has two or four processors, or maybe (if we’ve got a big budget) as many as a few dozen, because this is the technology that has been widely available in recent years. But as multicore CPUs <?docpage num="229"?><indexterm id="iddle1286" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey MISSES?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>misses</secondary></indexterm><indexterm id="iddle1287" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey MISSES?><?tertiarykey AS COST OF CONTEXT SWITCHING?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>misses</secondary><tertiary>as cost of context switching</tertiary></indexterm><indexterm id="iddle1611" significance="normal"><?indexkey C?><?primarykey context switching?><primary><emphasis role="strong">context switching</emphasis></primary><seealso> <link linkend="iddle1092" preference="0"><emphasis role="strong">analysis</emphasis>, performance</link>.</seealso></indexterm><indexterm id="iddle1612" significance="normal"><?indexkey C?><?primarykey context switching?><?secondarykey AS COST OF THREAD USE?><primary><emphasis role="strong">context switching</emphasis></primary><secondary>as cost of thread use</secondary></indexterm><indexterm id="iddle1692" significance="normal"><?indexkey C?><?primarykey cost(s)?><?secondarykey THREAD?><primary><emphasis role="strong">cost(s)</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle2467" significance="normal"><?indexkey G?><?primarykey granularity?><?secondarykey LOCK?><primary><emphasis role="strong">granularity</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle2468" significance="normal"><?indexkey G?><?primarykey granularity?><?secondarykey LOCK?><?tertiarykey AMDAHL&rsquo;S LAW INSIGHTS?><primary><emphasis role="strong">granularity</emphasis></primary><secondary>lock</secondary><tertiary>Amdahl’s law insights</tertiary></indexterm><indexterm id="iddle3101" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey GRANULARITY?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>granularity</secondary></indexterm><indexterm id="iddle3102" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey GRANULARITY?><?tertiarykey AMDAHL&rsquo;S LAW INSIGHTS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>granularity</secondary><tertiary>Amdahl’s law insights</tertiary></indexterm><indexterm id="iddle3147" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey SPLITTING?><?tertiarykey AMDAHL&rsquo;S LAW INSIGHTS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>splitting</secondary><tertiary>Amdahl’s law insights</tertiary></indexterm><indexterm id="iddle3152" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey STRIPING?><?tertiarykey AMDAHL&rsquo;S LAW INSIGHTS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>striping</secondary><tertiary>Amdahl’s law insights</tertiary></indexterm><indexterm id="iddle3887" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle3888" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey PERFORMANCE?><?tertiarykey AMDAHL&rsquo;S LAW INSIGHTS?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>performance</secondary><tertiary>Amdahl’s law insights</tertiary></indexterm><indexterm id="iddle4058" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey AMDAHL&rsquo;S LAW INSIGHTS?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>Amdahl’s law insights</secondary></indexterm><indexterm id="iddle4349" significance="normal"><?indexkey S?><?primarykey split(ing)?><?secondarykey LOCK?><?tertiarykey AMDAHL&rsquo;S LAW INSIGHTS?><primary><emphasis role="strong">split(ing)</emphasis></primary><secondary>lock</secondary><tertiary>Amdahl’s law insights</tertiary></indexterm><indexterm id="iddle4501" significance="normal"><?indexkey S?><?primarykey striping?><?secondarykey LOCK?><?tertiarykey AMDAHL&rsquo;S LAW INSIGHTS?><primary><emphasis role="strong">striping</emphasis></primary><secondary>lock</secondary><tertiary>Amdahl’s law insights</tertiary></indexterm><indexterm id="iddle4762" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey COSTS?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>costs</secondary></indexterm>become mainstream, systems will have hundreds or even thousands of processors. <footnote id="ch11fn03" label="3"><para>Market update: at this writing, Sun is shipping low-end server systems based on the 8-core Niagara processor, and Azul is shipping high-end server systems (96, 192, and 384-way) based on the 24-core Vega processor.</para></footnote> Algorithms that seem scalable on a four-way system may have hidden scalability bottlenecks that have just not yet been encountered.</para>
<para>When evaluating an algorithm, thinking “in the limit” about what would happen with hundreds or thousands of processors can offer some insight into where scaling limits might appear. For example, <link linkend="ch11lev2sec9" preference="0">Sections 11.4.2</link> and <link linkend="ch11lev2sec10" preference="0">11.4.3</link> discuss two techniques for reducing lock granularity: lock splitting (splitting one lock into two) and lock striping (splitting one lock into many). Looking at them through the lens of Amdahl’s law, we see that splitting a lock in two does not get us very far towards exploiting many processors, but lock striping seems much more promising because the size of the stripe set can be increased as processor count increases. (Of course, performance optimizations should always be considered in light of actual performance requirements; in some cases, splitting a lock in two may be enough to meet the requirements.)</para>
</section>
</section>
<section id="ch11lev1sec3" condition="229" label="11.3" xreflabel="11.3"><?docpage num="229"?>
<title id="ch11lev1sec3__title">Costs Introduced by Threads</title>
<para>Single-threaded programs incur neither scheduling nor synchronization overhead, and need not use locks to preserve the consistency of data structures. Scheduling and interthread coordination have performance costs; for threads to offer a performance improvement, the performance benefits of parallelization must outweigh the costs introduced by concurrency.</para>
<section id="ch11lev2sec5" label="11.3.1" xreflabel="11.3.1">
<title id="ch11lev2sec5__title">Context Switching</title>
<para>If the main thread is the only schedulable thread, it will almost never be scheduled out. On the other hand, if there are more runnable threads than CPUs, eventually the OS will preempt one thread so that another can use the CPU. This causes a <emphasis>context switch</emphasis>, which requires saving the execution context of the currently running thread and restoring the execution context of the newly scheduled thread.</para>
<para>Context switches are not free; thread scheduling requires manipulating shared data structures in the OS and JVM. The OS and JVMuse the same CPUs your program does; more CPU time spent in JVM and OS code means less is available for your program. But OS and JVM activity is not the only cost of context switches. When a new thread is switched in, the data it needs is unlikely to be in the local processor cache, so a context switch causes a flurry of cache misses, and thus threads run a little more slowly when they are first scheduled. This is one of the reasons that schedulers give each runnable thread a certain minimum time quantum even when many other threads are waiting: it amortizes the cost of the context switch and its consequences over more uninterrupted execution time, improving overall throughput (at some cost to responsiveness).</para>

<para><?docpage num="230"?></para><example id="ch11list02" label="11.2" role="Listing" xreflabel="11.2" condition="230">

<title id="ch11list02__title">Synchronization that has No Effect. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">synchronized (new Object()) {
    <emphasis>// do something</emphasis>
}
</programlisting>
</example>
<para><indexterm id="iddle1088" significance="normal"><?indexkey A?><?primarykey analysis?><?secondarykey ESCAPE?><primary><emphasis role="strong">analysis</emphasis></primary><secondary>escape</secondary></indexterm><indexterm id="iddle1195" significance="normal"><?indexkey B?><?primarykey barrier(s)?><?secondarykey MEMORY?><primary><emphasis role="strong">barrier(s)</emphasis></primary><secondary>memory</secondary></indexterm><indexterm id="iddle1212" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey CONTEXT SWITCHING IMPACT OF?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>context switching impact of</secondary></indexterm><indexterm id="iddle1281" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey FLUSHING?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>flushing</secondary></indexterm><indexterm id="iddle1282" significance="normal"><?indexkey C?><?primarykey cache/caching?><?secondarykey FLUSHING?><?tertiarykey AND MEMORY BARRIERS?><primary><emphasis role="strong">cache/caching</emphasis></primary><secondary>flushing</secondary><tertiary>and memory barriers</tertiary></indexterm><indexterm id="iddle1604" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey SYNCHRONIZATION?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>synchronization</secondary></indexterm><indexterm id="iddle2047" significance="normal"><?indexkey E?><?primarykey escape?><?secondarykey ANALYSIS?><primary><emphasis role="strong">escape</emphasis></primary><secondary>analysis</secondary></indexterm><indexterm id="iddle2334" significance="normal"><?indexkey F?><?primarykey fast path?><?secondarykey COSTS OF?><primary sortas="fast path"><emphasis role="strong">’fast path’ synchronization</emphasis></primary><secondary>costs of</secondary></indexterm><indexterm id="iddle2916" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey ESCAPE ANALYSIS?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>escape analysis</secondary></indexterm><indexterm id="iddle2925" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey SYNCHRONIZATION OPTIMIZATION BY?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>synchronization optimization by</secondary></indexterm><indexterm id="iddle3194" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey BARRIERS?><primary><emphasis role="strong">memory</emphasis></primary><secondary>barriers</secondary></indexterm><indexterm id="iddle3206" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey SYNCHRONIZATION?><primary><emphasis role="strong">memory</emphasis></primary><secondary>synchronization</secondary></indexterm><indexterm id="iddle3207" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey SYNCHRONIZATION?><?tertiarykey PERFORMANCE IMPACT OF?><primary><emphasis role="strong">memory</emphasis></primary><secondary>synchronization</secondary><tertiary>performance impact of</tertiary></indexterm><indexterm id="iddle3476" significance="normal"><?indexkey P?><?primarykey perfmon application?><?secondarykey PERFORMANCE MEASUREMENT USE?><primary><emphasis role="strong">perfmon application</emphasis></primary><secondary>performance measurement use</secondary></indexterm><indexterm id="iddle3509" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey MEMORY BARRIER IMPACT ON?><primary><emphasis role="strong">performance</emphasis></primary><secondary>memory barrier impact on</secondary></indexterm><indexterm id="iddle3854" significance="normal"><?indexkey R?><?primarykey reordering?><?secondarykey MEMORY?><primary><emphasis role="strong">reordering</emphasis></primary><secondary>memory</secondary></indexterm><indexterm id="iddle3855" significance="normal"><?indexkey R?><?primarykey reordering?><?secondarykey MEMORY?><?tertiarykey BARRIER IMPACT ON?><primary><emphasis role="strong">reordering</emphasis></primary><secondary>memory</secondary><tertiary>barrier impact on</tertiary></indexterm><indexterm id="iddle4546" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey CONTENDED?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>contended</secondary></indexterm><indexterm id="iddle4554" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey %?><?tertiarykey COSTS OF?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>’fast path’</secondary><tertiary>costs of</tertiary></indexterm><indexterm id="iddle4558" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey MEMORY?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>memory</secondary></indexterm><indexterm id="iddle4559" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey MEMORY?><?tertiarykey PERFORMANCE IMPACT OF?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>memory</secondary><tertiary>performance impact of</tertiary></indexterm><indexterm id="iddle4579" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey UNCONTENDED?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>uncontended</secondary></indexterm><indexterm id="iddle4946" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey MEASUREMENT?><?tertiarykey PERFORMANCE?><primary><emphasis role="strong">tools</emphasis></primary><secondary>measurement</secondary><tertiary>performance</tertiary></indexterm><indexterm id="iddle5006" significance="normal"><?indexkey U?><?primarykey uncontended?><primary><emphasis role="strong">uncontended</emphasis></primary></indexterm><indexterm id="iddle5007" significance="normal"><?indexkey U?><?primarykey uncontended?><?secondarykey SYNCHRONIZATION?><primary><emphasis role="strong">uncontended</emphasis></primary><secondary>synchronization</secondary></indexterm><indexterm id="iddle5112" significance="normal"><?indexkey V?><?primarykey vmstat application?><?secondarykey PERFORMANCE MEASUREMENT?><primary><emphasis role="strong">vmstat application</emphasis></primary><secondary>performance measurement</secondary></indexterm>When a thread blocks because it is waiting for a contended lock, the JVM usually suspends the thread and allows it to be switched out. If threads block frequently, they will be unable to use their full scheduling quantum. A program that does more blocking (blocking I/O, waiting for contended locks, or waiting on condition variables) incurs more context switches than one that is CPU-bound, increasing scheduling overhead and reducing throughput. (Nonblocking algorithms can also help reduce context switches; see <link linkend="ch15" preference="0">Chapter 15</link>.)</para>
<para>The actual cost of context switching varies across platforms, but a good rule of thumb is that a context switch costs the equivalent of 5,000 to 10,000 clock cycles, or several microseconds on most current processors.</para>
<para>The <literal>vmstat</literal> command on Unix systems and the <literal>perfmon</literal> tool on Windows systems report the number of context switches and the percentage of time spent in the kernel. High kernel usage (over 10%) often indicates heavy scheduling activity, which may be caused by blocking due to I/O or lock contention.</para>
</section>
<section id="ch11lev2sec6" label="11.3.2" xreflabel="11.3.2">
<title id="ch11lev2sec6__title">Memory Synchronization</title>
<para>The performance cost of synchronization comes from several sources. The visibility guarantees provided by <literal>synchronized</literal> and <literal>volatile</literal> may entail using special instructions called <emphasis>memory barriers</emphasis> that can flush or invalidate caches, flush hardware write buffers, and stall execution pipelines. Memory barriers may also have indirect performance consequences because they inhibit other compiler optimizations; most operations cannot be reordered with memory barriers.</para>
<para>When assessing the performance impact of synchronization, it is important to distinguish between <emphasis>contended</emphasis> and <emphasis>uncontended</emphasis> synchronization. The <literal>synchronized</literal> mechanism is optimized for the uncontended case (<literal>volatile</literal> is always uncontended), and at this writing, the performance cost of a “fast-path” uncontended synchronization ranges from 20 to 250 clock cycles for most systems. While this is certainly not zero, the effect of needed, uncontended synchronization is rarely significant in overall application performance, and the alternative involves compromising safety and potentially signing yourself (or your successor) up for some very painful bug hunting later.</para>
<para>Modern JVMs can reduce the cost of incidental synchronization by optimizing away locking that can be proven never to contend. If a lock object is accessible only to the current thread, the JVM is permitted to optimize away a lock acquisition because there is no way another thread could synchronize on the same lock. For example, the lock acquisition in <link linkend="ch11list02" preference="0">Listing 11.2</link> can always be eliminated by the JVM.</para>
<para>More sophisticated JVMs can use <emphasis>escape analysis</emphasis> to identify when a local object reference is never published to the heap and is therefore thread-local. In <literal>getStoogeNames</literal> <?docpage num="231"?><indexterm id="iddle1057" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey NONBLOCKING?><?tertiarykey BACKOFF IMPORTANCE FOR?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>nonblocking</secondary><tertiary>backoff importance for</tertiary></indexterm><indexterm id="iddle1182" significance="normal"><?indexkey B?><?primarykey backoff?><primary><emphasis role="strong">backoff</emphasis></primary></indexterm><indexterm id="iddle1183" significance="normal"><?indexkey B?><?primarykey backoff?><?secondarykey AND NONBLOCKING ALGORITHMS?><primary><emphasis role="strong">backoff</emphasis></primary><secondary>and nonblocking algorithms</secondary></indexterm><indexterm id="iddle1366" significance="normal"><?indexkey C?><?primarykey coarsening?><?secondarykey LOCK?><primary><emphasis role="strong">coarsening</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle1995" significance="normal"><?indexkey E?><?primarykey elision?><primary><emphasis role="strong">elision</emphasis></primary></indexterm><indexterm id="iddle1996" significance="normal"><?indexkey E?><?primarykey elision?><?secondarykey LOCK?><primary><emphasis role="strong">elision</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle2550" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey LOCK?><?tertiarykey CONTENTION, SCALABILITY IMPACT?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>lock</secondary><tertiary>contention, scalability impact</tertiary></indexterm><indexterm id="iddle2560" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey OPTIMIZATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>optimization</secondary></indexterm><indexterm id="iddle2561" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey OPTIMIZATION?><?tertiarykey LOCK CONTENTION IMPACT?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>optimization</secondary><tertiary>lock contention impact</tertiary></indexterm><indexterm id="iddle3071" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey COARSENING?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>coarsening</secondary></indexterm><indexterm id="iddle3090" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ELISION?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>elision</secondary></indexterm><indexterm id="iddle3304" significance="normal"><?indexkey N?><?primarykey nonblocking algorithms?><?secondarykey BACKOFF IMPORTANCE FOR?><primary><emphasis role="strong">nonblocking algorithms</emphasis></primary><secondary>backoff importance for</secondary></indexterm><indexterm id="iddle3386" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey LOCK CONTENTION?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>lock contention</secondary></indexterm><indexterm id="iddle3387" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey LOCK CONTENTION?><?tertiarykey IMPACT?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>lock contention</secondary><tertiary>impact</tertiary></indexterm>in <link linkend="ch11list03" preference="0">Listing 11.3</link>, the only reference to the <literal>List</literal> is the local variable <literal>stooges</literal>, and stack-confined variables are automatically thread-local. A naive execution of <literal>getStoogeNames</literal> would acquire and release the lock on the <literal>Vector</literal> four times, once for each call to <literal>add</literal> or <literal>toString</literal>. However, a smart runtime compiler can inline these calls and then see that <literal>stooges</literal> and its internal state never escape, and therefore that all four lock acquisitions can be eliminated.<footnote id="ch11fn04" label="4"><para>This compiler optimization, called <emphasis>lock elision</emphasis>, is performed by the IBM JVM and is expected in HotSpot as of Java 7.</para></footnote></para>
<example id="ch11list03" label="11.3" role="Listing" xreflabel="11.3" condition="231">
<title id="ch11list03__title">Candidate for Lock Elision.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public String getStoogeNames() {
    List&lt;String&gt; stooges = new Vector&lt;String&gt;();
    stooges.add("Moe");
    stooges.add("Larry");
    stooges.add("Curly");
    return stooges.toString();
}
</programlisting>
</example>
<para>Even without escape analysis, compilers can also perform <emphasis>lock coarsening</emphasis>, the merging of adjacent <literal>synchronized</literal> blocks using the same lock. For <literal>getStooge-Names</literal>, a JVM that performs lock coarsening might combine the three calls to <literal>add</literal> and the call to <literal>toString</literal> into a single lock acquisition and release, using heuristics on the relative cost of synchronization versus the instructions inside the <literal>synchronized</literal> block.<footnote id="ch11fn05" label="5"><para>A smart dynamic compiler can figure out that this method always returns the same string, and after the first execution recompile <literal>getStoogeNames</literal> to simply return the value returned by the first execution.</para></footnote> Not only does this reduce the synchronization overhead, but it also gives the optimizer a much larger block to work with, likely enabling other optimizations.</para>
<sidebar float="1" id="ch11sb05" condition="231"><title/>
<para>Don’t worry excessively about the cost of uncontended synchronization. The basic mechanism is already quite fast, and JVMs can perform additional optimizations that further reduce or eliminate the cost. Instead, focus optimization efforts on areas where lock contention actually occurs.</para>
</sidebar>
<para>Synchronization by one thread can also affect the performance of other threads. Synchronization creates traffic on the shared memory bus; this bus has a limited bandwidth and is shared across all processors. If threads must compete for synchronization bandwidth, all threads using synchronization will suffer.<footnote id="ch11fn06" label="6"><para>This aspect is sometimes used to argue against the use of nonblocking algorithms without some sort of backoff, because under heavy contention, nonblocking algorithms generate more synchronization traffic than lock-based ones. See <link linkend="ch15" preference="0">Chapter 15</link>.</para></footnote></para>
</section>
<section id="ch11lev2sec7" condition="232" label="11.3.3" xreflabel="11.3.3">
<?docpage num="232"?>
<title id="ch11lev2sec7__title">Blocking</title>
<para><indexterm id="iddle1227" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey SPIN-WAITING?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>spin-waiting</secondary></indexterm><indexterm id="iddle1233" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey THREADS, COSTS OF?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>threads, costs of</secondary></indexterm><indexterm id="iddle1593" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey LOCK?><?tertiarykey REDUCTION, STRATEGIES?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>lock</secondary><tertiary>reduction, strategies</tertiary></indexterm><indexterm id="iddle1594" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey LOCK?><?tertiarykey SCALABILITY IMPACT?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>lock</secondary><tertiary>scalability impact</tertiary></indexterm><indexterm id="iddle2576" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SCALABILITY?><?tertiarykey LOCKING IMPACT ON?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>scalability</secondary><tertiary>locking impact on</tertiary></indexterm><indexterm id="iddle3009" significance="normal"><?indexkey L?><?primarykey Little&rsquo;s law?><primary><emphasis role="strong">Little’s law</emphasis></primary></indexterm><indexterm id="iddle3010" significance="normal"><?indexkey L?><?primarykey Little&rsquo;s law?><?secondarykey LOCK CONTENTION COROLLARY?><primary><emphasis role="strong">Little’s law</emphasis></primary><secondary>lock contention corollary</secondary></indexterm><indexterm id="iddle3082" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONTENTION?><?tertiarykey REDUCTION, STRATEGIES?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>contention</secondary><tertiary>reduction, strategies</tertiary></indexterm><indexterm id="iddle3083" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONTENTION?><?tertiarykey SCALABILITY IMPACT OF?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>contention</secondary><tertiary>scalability impact of</tertiary></indexterm><indexterm id="iddle3388" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey LOCK CONTENTION?><?tertiarykey REDUCTION STRATEGIES?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>lock contention</secondary><tertiary>reduction strategies</tertiary></indexterm><indexterm id="iddle3516" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey OPTIMIZATION?><?tertiarykey REDUCTION STRATEGIES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>optimization</secondary><tertiary>reduction strategies</tertiary></indexterm><indexterm id="iddle4065" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey ENHANCEMENT?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>enhancement</secondary></indexterm><indexterm id="iddle4066" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey ENHANCEMENT?><?tertiarykey REDUCING LOCK CONTENTION?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>enhancement</secondary><tertiary>reducing lock contention</tertiary></indexterm><indexterm id="iddle4341" significance="normal"><?indexkey S?><?primarykey spin-waiting?><primary><emphasis role="strong">spin-waiting</emphasis></primary><seealso> <link linkend="iddle1208" preference="0"><emphasis role="strong">block(ing)</emphasis></link>.</seealso></indexterm><indexterm id="iddle4342" significance="normal"><?indexkey S?><?primarykey spin-waiting?><primary><emphasis role="strong">spin-waiting</emphasis></primary><seealso> <link linkend="iddle1278" preference="0">busy-waiting</link>.</seealso></indexterm><indexterm id="iddle4510" significance="normal"><?indexkey S?><?primarykey suspension, thread?><primary><emphasis role="strong">suspension, thread</emphasis></primary></indexterm><indexterm id="iddle4511" significance="normal"><?indexkey S?><?primarykey suspension, thread?><?secondarykey COSTS OF?><primary><emphasis role="strong">suspension, thread</emphasis></primary><secondary>costs of</secondary></indexterm><indexterm id="iddle4825" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SUSPENSION?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>suspension</secondary></indexterm><indexterm id="iddle4826" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SUSPENSION?><?tertiarykey COSTS OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>suspension</secondary><tertiary>costs of</tertiary></indexterm><indexterm id="iddle5142" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey SPIN-WAITING?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>spin-waiting</secondary></indexterm>Uncontended synchronization can be handled entirely within the JVM (<link linkend="biblio01_002" preference="0">Bacon et al., 1998</link>); contended synchronization may require OS activity, which adds to the cost. When locking is contended, the losing thread(s) must block. The JVM can implement blocking either via <emphasis>spin-waiting</emphasis> (repeatedly trying to acquire the lock until it succeeds) or by <emphasis>suspending</emphasis> the blocked thread through the operating system. Which is more efficient depends on the relationship between context switch overhead and the time until the lock becomes available; spin-waiting is preferable for short waits and suspension is preferable for long waits. Some JVMs choose between the two adaptively based on profiling data of past wait times, but most just suspend threads waiting for a lock.</para>
<para>Suspending a thread because it could not get a lock, or because it blocked on a condition wait or blocking I/O operation, entails two additional context switches and all the attendant OS and cache activity: the blocked thread is switched out before its quantum has expired, and is then switched back in later after the lock or other resource becomes available. (Blocking due to lock contention also has a cost for the thread holding the lock: when it releases the lock, it must then ask the OS to resume the blocked thread.)</para>
</section>
</section>
<section id="ch11lev1sec4" condition="232" label="11.4" xreflabel="11.4"><?docpage num="232"?><?docpage num="233"?>
<title id="ch11lev1sec4__title">Reducing Lock Contention</title>
<para>We’ve seen that serialization hurts scalability and that context switches hurt performance. Contended locking causes both, so reducing lock contention can improve both performance and scalability.</para>
<para>Access to resources guarded by an exclusive lock is serialized—only one thread at a time may access it. Of course, we use locks for good reasons, such as preventing data corruption, but this safety comes at a price. Persistent contention for a lock limits scalability.</para>
<sidebar float="1" id="ch11sb06" condition="232"><title/>
<para>The principal threat to scalability in concurrent applications is the exclusive resource lock.</para>
</sidebar>
<para>Two factors influence the likelihood of contention for a lock: how often that lock is requested and how long it is held once acquired.<footnote id="ch11fn07" label="7"><para>This is a corollary of <emphasis>Little’s law</emphasis>, a result from queueing theory that says “the average number of customers in a stable system is equal to their average arrival rate multiplied by their average time in the system”. (<link linkend="biblio01_023" preference="0">Little, 1961</link>)</para></footnote> If the product of these factors is sufficiently small, then most attempts to acquire the lock will be uncontended, and lock contention will not pose a significant scalability impediment. If, however, the lock is in sufficiently high demand, threads will block waiting for it; in the extreme case, processors will sit idle even though there is plenty of work to do.</para>
<sidebar float="1" id="ch11sb07" condition="232"><title/>
<para><?docpage num="233"?><indexterm id="iddle2078" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey ATTRIBUTESTORE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>AttributeStore</literal></secondary></indexterm><indexterm id="iddle2548" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey LOCK?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle2549" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey LOCK?><?tertiarykey CONTENTION, REDUCTION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>lock</secondary><tertiary>contention, reduction</tertiary></indexterm><indexterm id="iddle3080" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONTENTION?><?tertiarykey REDUCTION, GUIDELINES?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>contention</secondary><tertiary>reduction, guidelines</tertiary></indexterm><indexterm id="iddle3145" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey SCOPE?><?tertiarykey NARROWING, AS LOCK CONTENTION REDUCTION STRATEGY?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>scope</secondary><tertiary>narrowing, as lock contention reduction strategy</tertiary></indexterm><indexterm id="iddle3290" significance="normal"><?indexkey N?><?primarykey narrowing?><primary><emphasis role="strong">narrowing</emphasis></primary></indexterm><indexterm id="iddle3291" significance="normal"><?indexkey N?><?primarykey narrowing?><?secondarykey LOCK SCOPE?><primary><emphasis role="strong">narrowing</emphasis></primary><secondary>lock scope</secondary></indexterm><indexterm id="iddle3292" significance="normal"><?indexkey N?><?primarykey narrowing?><?secondarykey LOCK SCOPE?><?tertiarykey AS LOCK CONTENTION REDUCTION STRATEGY?><primary><emphasis role="strong">narrowing</emphasis></primary><secondary>lock scope</secondary><tertiary>as lock contention reduction strategy</tertiary></indexterm><indexterm id="iddle4071" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey LOCK SCOPE IMPACT ON?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>lock scope impact on</secondary></indexterm><indexterm id="iddle4109" significance="normal"><?indexkey S?><?primarykey scope/scoped?><?secondarykey LOCK?><primary><emphasis role="strong">scope/scoped</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle4110" significance="normal"><?indexkey S?><?primarykey scope/scoped?><?secondarykey LOCK?><?tertiarykey NARROWING, AS LOCK CONTENTION REDUCTION STRATEGY?><primary><emphasis role="strong">scope/scoped</emphasis></primary><secondary>lock</secondary><tertiary>narrowing, as lock contention reduction strategy</tertiary></indexterm><indexterm id="iddle4907" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey LOCK SCOPE?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>lock scope</secondary></indexterm><indexterm id="iddle4908" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey LOCK SCOPE?><?tertiarykey NARROWING, AS LOCK CONTENTION REDUCTION STRATEGY?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>lock scope</secondary><tertiary>narrowing, as lock contention reduction strategy</tertiary></indexterm>There are three ways to reduce lock contention:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Reduce the duration for which locks are held;</para></listitem>
<listitem><para>Reduce the frequency with which locks are requested; or</para></listitem>
<listitem><para>Replace exclusive locks with coordination mechanisms that permit greater concurrency.</para></listitem>
</itemizedlist>
</sidebar>
<section id="ch11lev2sec8" label="11.4.1" xreflabel="11.4.1">
<title id="ch11lev2sec8__title">Narrowing Lock Scope (“Get in, Get Out”)</title>
<para>An effective way to reduce the likelihood of contention is to hold locks as briefly as possible. This can be done by moving code that doesn’t require the lock out of <literal>synchronized</literal> blocks, especially for expensive operations and potentially blocking operations such as I/O.</para>
<para>It is easy to see how holding a “hot” lock for too long can limit scalability; we saw an example of this in <literal>SynchronizedFactorizer</literal> in <link linkend="ch02" preference="0">Chapter 2</link>. If an operation holds a lock for 2 milliseconds and every operation requires that lock, throughput can be no greater than 500 operations per second, no matter how many processors are available. Reducing the time the lock is held to 1 millisecond improves the lock-induced throughput limit to 1000 operations per second.<footnote id="ch11fn08" label="8"><para>Actually, this calculation <emphasis>understates</emphasis> the cost of holding locks for too long because it doesn’t take into account the context switch overhead generated by increased lock contention.</para></footnote></para>
<para><literal>AttributeStore</literal> in <link linkend="ch11list04" preference="0">Listing 11.4</link> shows an example of holding a lock longer than necessary. The <literal>userLocationMatches</literal> method looks up the user’s location in a <literal>Map</literal> and uses regular expression matching to see if the resulting value matches the supplied pattern. The entire <literal>userLocationMatches</literal> method is <literal>synchronized</literal>, but the only portion of the code that actually needs the lock is the call to <literal>Map.get</literal>.</para>
<example id="ch11list04" label="11.4" role="Listing" xreflabel="11.4" condition="232">
<title id="ch11list04__title">Holding a Lock Longer than Necessary.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class AttributeStore {
    @GuardedBy("this") private final Map&lt;String, String&gt;
            attributes = new HashMap&lt;String, String&gt;();

    public <emphasis role="strong">synchronized</emphasis>  boolean userLocationMatches(String name,
                                                     String regexp) {
        String key = "users." + name + ".location";
        String location = attributes.get(key);
        if (location == null)
            return false;
        else
            return Pattern.matches(regexp, location);
    }
}
</programlisting>
</example>
<para><?docpage num="234"?><indexterm id="iddle1081" significance="normal"><?indexkey A?><?primarykey Amdahl&rsquo;s law?><?secondarykey LOCK SCOPE REDUCTION ADVANTAGE?><primary><emphasis role="strong">Amdahl’s law</emphasis></primary><secondary>lock scope reduction advantage</secondary></indexterm><indexterm id="iddle1161" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey LOSS?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>loss</secondary></indexterm><indexterm id="iddle1162" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey LOSS?><?tertiarykey RISK OF LOCK SCOPE REDUCTION?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>loss</secondary><tertiary>risk of lock scope reduction</tertiary></indexterm><indexterm id="iddle1860" significance="normal"><?indexkey D?><?primarykey delegation?><?secondarykey ADVANTAGES?><?tertiarykey FOR CLASS MAINTENANCE SAFETY?><primary><emphasis role="strong">delegation</emphasis></primary><secondary>advantages</secondary><tertiary>for class maintenance safety</tertiary></indexterm><indexterm id="iddle1861" significance="normal"><?indexkey D?><?primarykey delegation?><?secondarykey THREAD SAFETY?><primary><emphasis role="strong">delegation</emphasis></primary><secondary>thread safety</secondary></indexterm><indexterm id="iddle2082" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BETTERATTRIBUTESTORE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BetterAttributeStore</literal></secondary></indexterm><indexterm id="iddle4491" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey THREAD SAFETY DELEGATION?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>thread safety delegation</secondary></indexterm><indexterm id="iddle4735" significance="normal"><?indexkey T?><?primarykey thread safety?><?secondarykey DELEGATION OF?><primary><emphasis role="strong">thread safety</emphasis></primary><secondary>delegation of</secondary></indexterm><literal>BetterAttributeStore</literal> in <link linkend="ch11list05" preference="0">Listing 11.5</link> rewrites <literal>AttributeStore</literal> to reduce significantly the lock duration. The first step is to construct the <literal>Map</literal> key associated with the user’s location, a string of the form <literal>users.</literal><emphasis>name</emphasis><literal>.location</literal>. This entails instantiating a <literal>StringBuilder</literal> object, appending several strings to it, and instantiating the result as a <literal>String</literal>. After the location has been retrieved, the regular expression is matched against the resulting location string. Because constructing the key string and processing the regular expression do not access shared state, they need not be executed with the lock held. <literal>BetterAttributeStore</literal> factors these steps out of the <literal>synchronized</literal> block, thus reducing the time the lock is held.</para>
<example id="ch11list05" label="11.5" role="Listing" xreflabel="11.5" condition="234">
<title id="ch11list05__title">Reducing Lock Duration.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class BetterAttributeStore {
    @GuardedBy("this") private final Map&lt;String, String&gt;
            attributes = new HashMap&lt;String, String&gt;();

    public boolean userLocationMatches(String name, String regexp) {
        String key = "users." + name + ".location";
        String location;
        <emphasis role="strong">synchronized (this)</emphasis> {
            location = attributes.get(key);
        }
        if (location == null)
            return false;
        else
            return Pattern.matches(regexp, location);
    }
}
</programlisting>
</example>
<para>Reducing the scope of the lock in <literal>userLocationMatches</literal> substantially reduces the number of instructions that are executed with the lock held. By Amdahl’s law, this removes an impediment to scalability because the amount of serialized code is reduced.</para>
<para>Because <literal>AttributeStore</literal> has only one state variable, <literal>attributes</literal>, we can improve it further by the technique of <emphasis>delegating thread safety</emphasis> (<link linkend="ch04lev1sec3" preference="0">Section 4.3</link>). By replacing <literal>attributes</literal> with a thread-safe <literal>Map</literal> (a <literal>Hashtable</literal>, <literal>synchronizedMap</literal>, or <literal>ConcurrentHashMap</literal>), <literal>AttributeStore</literal> can delegate all its thread safety obligations to the underlying thread-safe collection. This eliminates the need for explicit synchronization in <literal>AttributeStore</literal>, reduces the lock scope to the duration of the <literal>Map</literal> access, and removes the risk that a future maintainer will undermine thread safety by forgetting to acquire the appropriate lock before accessing <literal>attributes</literal>.</para>
<para>While shrinking <literal>synchronized</literal> blocks can improve scalability, a <literal>synchronized</literal> block can be <emphasis>too</emphasis> small—operations that need to be atomic (such updating multiple variables that participate in an invariant) must be contained in a single <literal>synchronized</literal> <?docpage num="235"?><?docpage num="236"?><indexterm id="iddle1367" significance="normal"><?indexkey C?><?primarykey coarsening?><?secondarykey LOCK?><primary><emphasis role="strong">coarsening</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle1808" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey LOCK SPLITTING AS RISK FACTOR FOR?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>lock splitting as risk factor for</secondary></indexterm><indexterm id="iddle2469" significance="normal"><?indexkey G?><?primarykey granularity?><?secondarykey LOCK?><?tertiarykey REDUCTION OF?><primary><emphasis role="strong">granularity</emphasis></primary><secondary>lock</secondary><tertiary>reduction of</tertiary></indexterm><indexterm id="iddle2730" significance="normal"><?indexkey I?><?primarykey independent/independence?><?secondarykey STATE VARIABLES?><?tertiarykey LOCK SPLITTING USE WITH?><primary><emphasis role="strong">independent/independence</emphasis></primary><secondary>state variables</secondary><tertiary>lock splitting use with</tertiary></indexterm><indexterm id="iddle3073" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey COARSENING?><?tertiarykey IMPACT ON SPLITTING SYNCHRONIZED BLOCKS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>coarsening</secondary><tertiary>impact on splitting synchronized blocks</tertiary></indexterm><indexterm id="iddle3103" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey GRANULARITY?><?tertiarykey REDUCTION OF?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>granularity</secondary><tertiary>reduction of</tertiary></indexterm><indexterm id="iddle3146" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey SPLITTING?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>splitting</secondary></indexterm><indexterm id="iddle3148" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey SPLITTING?><?tertiarykey AS LOCK GRANULARITY REDUCTION STRATEGY?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>splitting</secondary><tertiary>as lock granularity reduction strategy</tertiary></indexterm><indexterm id="iddle4348" significance="normal"><?indexkey S?><?primarykey split(ing)?><?secondarykey LOCK?><primary><emphasis role="strong">split(ing)</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle4350" significance="normal"><?indexkey S?><?primarykey split(ing)?><?secondarykey LOCK?><?tertiarykey AS LOCK GRANULARITY REDUCTION STRATEGY?><primary><emphasis role="strong">split(ing)</emphasis></primary><secondary>lock</secondary><tertiary>as lock granularity reduction strategy</tertiary></indexterm><indexterm id="iddle4434" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey VARIABLES?><?tertiarykey INDEPENDENT, LOCK SPLITTING?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>variables</secondary><tertiary>independent, lock splitting</tertiary></indexterm><indexterm id="iddle4473" significance="normal"><?indexkey S?><?primarykey strategies?><?secondarykey LOCK SPLITTING?><primary><emphasis role="strong">strategies</emphasis></primary><secondary>lock splitting</secondary></indexterm><indexterm id="iddle5059" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey STATE?><?tertiarykey INDEPENDENT, LOCK SPLITTING USE WITH?><primary><emphasis role="strong">variables</emphasis></primary><secondary>state</secondary><tertiary>independent, lock splitting use with</tertiary></indexterm>block. And because the cost of synchronization is nonzero, breaking one <literal>synchronized</literal> block into multiple <literal>synchronized</literal> blocks (correctness permitting) at some point becomes counterproductive in terms of performance.<footnote id="ch11fn09" label="9"><para>If the JVM performs lock coarsening, it may undo the splitting of <literal>synchronized</literal> blocks anyway.</para></footnote> The ideal balance is of course platform-dependent, but in practice it makes sense to worry about the size of a <literal>synchronized</literal> block only when you can move “substantial” computation or blocking operations out of it.</para>
</section>
<section id="ch11lev2sec9" label="11.4.2" xreflabel="11.4.2">
<title id="ch11lev2sec9__title">Reducing Lock Granularity</title>
<para>The other way to reduce the fraction of time that a lock is held (and therefore the likelihood that it will be contended) is to have threads ask for it less often. This can be accomplished by <emphasis>lock splitting</emphasis> and <emphasis>lock striping</emphasis>, which involve using separate locks to guard multiple independent state variables previously guarded by a single lock. These techniques reduce the granularity at which locking occurs, potentially allowing greater scalability—but using more locks also increases the risk of deadlock.</para>
<para>As a thought experiment, imagine what would happen if there was <emphasis>only one</emphasis> lock for the entire application instead of a separate lock for each object. Then execution of all <literal>synchronized</literal> blocks, regardless of their lock, would be serialized. With many threads competing for the global lock, the chance that two threads want the lock at the same time increases, resulting in more contention. So if lock requests were instead distributed over a <emphasis>larger</emphasis> set of locks, there would be less contention. Fewer threads would be blocked waiting for locks, thus increasing scalability.</para>
<para>If a lock guards more than one <emphasis>independent</emphasis> state variable, you may be able to improve scalability by splitting it into multiple locks that each guard different variables. This results in each lock being requested less often.</para>
<para><literal>ServerStatus</literal> in <link linkend="ch11list06" preference="0">Listing 11.6</link> shows a portion of the monitoring interface for a database server that maintains the set of currently logged-on users and the set of currently executing queries. As a user logs on or off or query execution begins or ends, the <literal>ServerStatus</literal> object is updated by calling the appropriate <literal>add</literal> or <literal>remove</literal> method. The two types of information are completely independent; <literal>ServerStatus</literal> could even be split into two separate classes with no loss of functionality.</para>
<para>Instead of guarding both <literal>users</literal> and <literal>queries</literal> with the <literal>ServerStatus</literal> lock, we can instead guard each with a separate lock, as shown in <link linkend="ch11list07" preference="0">Listing 11.7</link>. After splitting the lock, each new finer-grained lock will see less locking traffic than the original coarser lock would have. (Delegating to a thread-safe <literal>Set</literal> implementation for <literal>users</literal> and <literal>queries</literal> instead of using explicit synchronization would implicitly provide lock splitting, as each <literal>Set</literal> would use a different lock to guard its state.)</para>
<para>Splitting a lock into two offers the greatest possibility for improvement when the lock is experiencing moderate but not heavy contention. Splitting locks that are experiencing little contention yields little net improvement in performance or throughput, although it might increase the load threshold at which performance starts to degrade due to contention. Splitting locks experiencing moderate contention <?docpage num="237"?><?docpage num="238"?><indexterm id="iddle2177" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SERVERSTATUS?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ServerStatus</literal></secondary></indexterm><indexterm id="iddle3149" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey SPLITTING?><?tertiarykey SERVERSTATUS EXAMPLES?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>splitting</secondary><tertiary><literal>ServerStatus</literal> examples</tertiary></indexterm><indexterm id="iddle4351" significance="normal"><?indexkey S?><?primarykey split(ing)?><?secondarykey LOCK?><?tertiarykey SERVERSTATUS EXAMPLES?><primary><emphasis role="strong">split(ing)</emphasis></primary><secondary>lock</secondary><tertiary><literal>ServerStatus</literal> examples</tertiary></indexterm><indexterm id="iddle1380" significance="normal"><?indexkey C?><?primarykey collections?><?secondarykey LOCK STRIPING USE?><primary><emphasis role="strong">collections</emphasis></primary><secondary>lock striping use</secondary></indexterm><indexterm id="iddle1747" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey CONTENTION AVOIDANCE?><primary><emphasis role="strong">data</emphasis></primary><secondary>contention avoidance</secondary></indexterm><indexterm id="iddle1748" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey CONTENTION AVOIDANCE?><?tertiarykey AND SCALABILITY?><primary><emphasis role="strong">data</emphasis></primary><secondary>contention avoidance</secondary><tertiary>and scalability</tertiary></indexterm><indexterm id="iddle2340" significance="normal"><?indexkey F?><?primarykey fields?><?secondarykey HOT FIELDS?><primary><emphasis role="strong">fields</emphasis></primary><secondary>hot fields</secondary></indexterm><indexterm id="iddle2341" significance="normal"><?indexkey F?><?primarykey fields?><?secondarykey HOT FIELDS?><?tertiarykey AVOIDING?><primary><emphasis role="strong">fields</emphasis></primary><secondary>hot fields</secondary><tertiary>avoiding</tertiary></indexterm><indexterm id="iddle2629" significance="normal"><?indexkey H?><?primarykey hashcodes/hashtables?><?secondarykey LOCK STRIPING USE?><primary><emphasis role="strong">hashcodes/hashtables</emphasis></primary><secondary>lock striping use</secondary></indexterm><indexterm id="iddle2653" significance="normal"><?indexkey H?><?primarykey hot fields?><primary><emphasis role="strong">hot fields</emphasis></primary></indexterm><indexterm id="iddle2654" significance="normal"><?indexkey H?><?primarykey hot fields?><?secondarykey AVOIDANCE?><primary><emphasis role="strong">hot fields</emphasis></primary><secondary>avoidance</secondary></indexterm><indexterm id="iddle2655" significance="normal"><?indexkey H?><?primarykey hot fields?><?secondarykey AVOIDANCE?><?tertiarykey SCALABILITY ADVANTAGES?><primary><emphasis role="strong">hot fields</emphasis></primary><secondary>avoidance</secondary><tertiary>scalability advantages</tertiary></indexterm><indexterm id="iddle2837" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><?secondarykey RECURSION USE?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><secondary>recursion use</secondary></indexterm><indexterm id="iddle3114" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><?tertiarykey RECURSION USE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary><tertiary>recursion use</tertiary></indexterm><indexterm id="iddle3151" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey STRIPING?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>striping</secondary></indexterm><indexterm id="iddle3154" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey STRIPPING?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>stripping</secondary></indexterm><indexterm id="iddle3803" significance="normal"><?indexkey R?><?primarykey recursion?><?secondarykey INTRINSIC LOCK ACQUISITION?><primary><emphasis role="strong">recursion</emphasis></primary><secondary>intrinsic lock acquisition</secondary></indexterm><indexterm id="iddle4068" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey HOT FIELD IMPACT ON?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>hot field impact on</secondary></indexterm><indexterm id="iddle4499" significance="normal"><?indexkey S?><?primarykey striping?><?secondarykey LOCK?><primary><emphasis role="strong">striping</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle4500" significance="normal"><?indexkey S?><?primarykey striping?><?secondarykey LOCK?><primary><emphasis role="strong">striping</emphasis></primary><secondary>lock</secondary></indexterm>might actually turn them into mostly uncontended locks, which is the most desirable outcome for both performance and scalability.</para>
<example id="ch11list06" label="11.6" role="Listing" xreflabel="11.6" condition="236">
<?docpage num="236"?>
<title id="ch11list06__title">Candidate for Lock Splitting.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ServerStatus {
    @GuardedBy("this") public final Set&lt;String&gt; users;
    @GuardedBy("this") public final Set&lt;String&gt; queries;
    ...
    public synchronized void addUser(String u) { users.add(u); }
    public synchronized void addQuery(String q) { queries.add(q); }
    public synchronized void removeUser(String u) {
        users.remove(u);
    }
    public synchronized void removeQuery(String q) {
        queries.remove(q);
    }
}
</programlisting>
</example>
<example id="ch11list07" label="11.7" role="Listing" xreflabel="11.7" condition="236">
<?docpage num="236"?>
<title id="ch11list07__title"><literal>ServerStatus</literal> Refactored to Use Split Locks.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ServerStatus {
    @GuardedBy("users") public final Set&lt;String&gt; users;
    @GuardedBy("queries") public final Set&lt;String&gt; queries;
    ...
    public void addUser(String u) {
        <emphasis role="strong">synchronized</emphasis>  (users) {
            users.add(u);
        }
    }

    public void addQuery(String q) {
        <emphasis role="strong">synchronized</emphasis>  (queries) {
            queries.add(q);
        }
    }
    <emphasis>// remove methods similarly refactored to use split locks</emphasis>
}
</programlisting>
</example>
</section>
<section id="ch11lev2sec10" label="11.4.3" xreflabel="11.4.3">
<title id="ch11lev2sec10__title">Lock Striping</title>
<para>Splitting a heavily contended lock into two is likely to result in two heavily contended locks. While this will produce a small scalability improvement by enabling two threads to execute concurrently instead of one, it still does not dramatically improve prospects for concurrency on a system with many processors. The lock splitting example in the <literal>ServerStatus</literal> classes does not offer any obvious opportunity for splitting the locks further.</para>
<para>Lock splitting can sometimes be extended to partition locking on a variablesized set of independent objects, in which case it is called <emphasis>lock striping</emphasis>. For example, the implementation of <literal>ConcurrentHashMap</literal> uses an array of 16 locks, each of which guards 1/16 of the hash buckets; bucket <emphasis>N</emphasis> is guarded by lock <emphasis>N</emphasis> mod 16. Assuming the hash function provides reasonable spreading characteristics and keys are accessed uniformly, this should reduce the demand for any given lock by approximately a factor of 16. It is this technique that enables <literal>ConcurrentHashMap</literal> to support up to 16 concurrent writers. (The number of locks could be increased to provide even better concurrency under heavy access on high-processor-count systems, but the number of stripes should be increased beyond the default of 16 only when you have evidence that concurrent writers are generating enough contention to warrant raising the limit.)</para>
<para>One of the downsides of lock striping is that locking the collection for exclusive access is more difficult and costly than with a single lock. Usually an operation can be performed by acquiring at most one lock, but occasionally you need to lock the entire collection, as when <literal>ConcurrentHashMap</literal> needs to expand the map and rehash the values into a larger set of buckets. This is typically done by acquiring all of the locks in the stripe set.<footnote id="ch11fn10" label="10"><para>The only way to acquire an arbitrary set of intrinsic locks is via recursion.</para></footnote></para>
<para><literal>StripedMap</literal> in <link linkend="ch11list08" preference="0">Listing 11.8</link> illustrates implementing a hash-based map using lock striping. There are <literal>N_LOCKS</literal> locks, each guarding a subset of the buckets. Most methods, like <literal>get</literal>, need acquire only a single bucket lock. Some methods may need to acquire all the locks but, as in the implementation for <literal>clear</literal>, may not need to acquire them all simultaneously.<footnote id="ch11fn11" label="11"><para>Clearing the <literal>Map</literal> in this way is not atomic, so there is not necessarily a time when the <literal>Striped-Map</literal> is actually empty if other threads are concurrently adding elements; making the operation atomic would require acquiring all the locks at once. However, for concurrent collections that clients typically cannot lock for exclusive access, the result of methods like <literal>size</literal> or <literal>isEmpty</literal> may be out of date by the time they return anyway, so this behavior, while perhaps somewhat surprising, is usually acceptable.</para></footnote></para>
</section>
<section id="ch11lev2sec11" label="11.4.4" xreflabel="11.4.4">
<title id="ch11lev2sec11__title">Avoiding Hot Fields</title>
<para>Lock splitting and lock striping can improve scalability because they enable different threads to operate on different data (or different portions of the same data structure) without interfering with each other. A program that would benefit from lock splitting necessarily exhibits contention for a <emphasis>lock</emphasis> more often than for the <emphasis>data</emphasis> <?docpage num="239"?><indexterm id="iddle2186" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey STRIPEDMAP?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>StripedMap</literal></secondary></indexterm><indexterm id="iddle1138" significance="normal"><?indexkey A?><?primarykey atomic variables?><?secondarykey AND LOCK CONTENTION?><primary><emphasis role="strong">atomic variables</emphasis></primary><secondary>and lock contention</secondary></indexterm><indexterm id="iddle2342" significance="normal"><?indexkey F?><?primarykey fields?><?secondarykey HOT FIELDS?><?tertiarykey UPDATING, ATOMIC VARIABLE ADVANTAGES?><primary><emphasis role="strong">fields</emphasis></primary><secondary>hot fields</secondary><tertiary>updating, atomic variable advantages</tertiary></indexterm><indexterm id="iddle2466" significance="normal"><?indexkey G?><?primarykey granularity?><?secondarykey ATOMIC VARIABLE ADVANTAGES?><primary><emphasis role="strong">granularity</emphasis></primary><secondary>atomic variable advantages</secondary></indexterm><indexterm id="iddle2656" significance="normal"><?indexkey H?><?primarykey hot fields?><?secondarykey UPDATING?><primary><emphasis role="strong">hot fields</emphasis></primary><secondary>updating</secondary></indexterm><indexterm id="iddle2657" significance="normal"><?indexkey H?><?primarykey hot fields?><?secondarykey UPDATING?><?tertiarykey ATOMIC VARIABLE ADVANTAGES?><primary><emphasis role="strong">hot fields</emphasis></primary><secondary>updating</secondary><tertiary>atomic variable advantages</tertiary></indexterm><indexterm id="iddle3094" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey EXCLUSIVE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>exclusive</secondary></indexterm><indexterm id="iddle3095" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey EXCLUSIVE?><?tertiarykey ALTERNATIVE TO?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>exclusive</secondary><tertiary>alternative to</tertiary></indexterm><indexterm id="iddle3259" significance="normal"><?indexkey M?><?primarykey multiple-reader, single-writer locking?><primary><emphasis role="strong">multiple-reader, single-writer locking</emphasis></primary></indexterm><indexterm id="iddle3260" significance="normal"><?indexkey M?><?primarykey multiple-reader, single-writer locking?><?secondarykey AND LOCK CONTENTION REDUCTION?><primary><emphasis role="strong">multiple-reader, single-writer locking</emphasis></primary><secondary>and lock contention reduction</secondary></indexterm><indexterm id="iddle3526" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey SCALABILITY VS?><?tertiarykey LOCK GRANULARITY REDUCTION?><primary><emphasis role="strong">performance</emphasis></primary><secondary>scalability vs</secondary><tertiary>lock granularity reduction</tertiary></indexterm><indexterm id="iddle3797" significance="normal"><?indexkey R?><?primarykey ReadWriteLock?><?secondarykey EXCLUSIVE LOCKING VS?><primary><emphasis role="strong">ReadWriteLock</emphasis></primary><secondary>exclusive locking vs</secondary></indexterm><indexterm id="iddle4075" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey PERFORMANCE VS?><?tertiarykey LOCK GRANULARITY REDUCTION?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>performance vs</secondary><tertiary>lock granularity reduction</tertiary></indexterm>guarded by that lock. If a lock guards two independent variables <emphasis>X</emphasis> and <emphasis>Y</emphasis>, and thread <emphasis>A</emphasis> wants to access <emphasis>X</emphasis> while <emphasis>B</emphasis> wants to access <emphasis>Y</emphasis> (as would be the case if one thread called <literal>addUser</literal> while another called <literal>addQuery</literal> in <literal>ServerStatus</literal>), then the two threads are not contending for any data, even though they are contending for a lock.</para>
<example id="ch11list08" label="11.8" role="Listing" xreflabel="11.8" condition="238">
<?docpage num="238"?>
<title id="ch11list08__title">Hash-based Map Using Lock Striping.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class StripedMap {
    <emphasis>// Synchronization policy: buckets[n] guarded by locks[n%N_LOCKS]</emphasis>
    private static final int N_LOCKS = 16;
    private final Node[] buckets;
    private final Object[] locks;

    private static class Node { ... }

    public StripedMap(int numBuckets) {
        buckets = new Node[numBuckets];
        locks = new Object[N_LOCKS];
        for (int i = 0; i &lt; N_LOCKS; i++)
            locks[i] = new Object();
    }

    private final int hash(Object key) {
        return Math.abs(key.hashCode() % buckets.length);
    }

    public Object get(Object key) {
        int hash = hash(key);
        synchronized (locks[hash % N_LOCKS]) {
            for (Node m = buckets[hash]; m != null; m = m.next)
                if (m.key.equals(key))
                    return m.value;
        }
        return null;
    }

    public void clear() {
        for (int i = 0; i &lt; buckets.length; i++) {
            synchronized (locks[i % N_LOCKS]) {
                buckets[i] = null;
            }
        }
    }
    ...
}
</programlisting>
</example>
<para>Lock granularity cannot be reduced when there are variables that are required for every operation. This is yet another area where raw performance and scalability are often at odds with each other; common optimizations such as caching frequently computed values can introduce “hot fields” that limit scalability.</para>
<para>If you were implementing <literal>HashMap</literal>, you would have a choice of how <literal>size</literal> computes the number of entries in the <literal>Map</literal>. The simplest approach is to count the number of entries every time it is called. A common optimization is to update a separate counter as entries are added or removed; this slightly increases the cost of a <literal>put</literal> or <literal>remove</literal> operation to keep the counter up-to-date, but reduces the cost of the <literal>size</literal> operation from <emphasis>O</emphasis>(<emphasis>n</emphasis>) to <emphasis>O</emphasis>(1).</para>
<para>Keeping a separate count to speed up operations like <literal>size</literal> and <literal>isEmpty</literal> works fine for a single-threaded or fully synchronized implementation, but makes it much harder to improve the scalability of the implementation because every operation that modifies the map must now update the shared counter. Even if you use lock striping for the hash chains, synchronizing access to the counter reintroduces the scalability problems of exclusive locking. What looked like a performance optimization—caching the results of the <literal>size</literal> operation—has turned into a scalability liability. In this case, the counter is called a <emphasis>hot field</emphasis> because every mutative operation needs to access it.</para>
<para><literal>ConcurrentHashMap</literal> avoids this problem by having <literal>size</literal> enumerate the stripes and add up the number of elements in each stripe, instead of maintaining a global count. To avoid enumerating every element, <literal>ConcurrentHashMap</literal> maintains a separate count field for each stripe, also guarded by the stripe lock.<footnote id="ch11fn12" label="12"><para>If <literal>size</literal> is called frequently compared to mutative operations, striped data structures can optimize for this by caching the collection size in a <literal>volatile</literal> whenever <literal>size</literal> is called and invalidating the cache (setting it to -1) whenever the collection is modified. If the cached value is nonnegative on entry to <literal>size</literal>, it is accurate and can be returned; otherwise it is recomputed.</para></footnote></para>
</section>
<section id="ch11lev2sec12" label="11.4.5" xreflabel="11.4.5">
<title id="ch11lev2sec12__title">Alternatives to Exclusive Locks</title>
<para>A third technique for mitigating the effect of lock contention is to forego the use of exclusive locks in favor of a more concurrency-friendly means of managing shared state. These include using the concurrent collections, read-write locks, immutable objects and atomic variables.</para>
<para><literal>ReadWriteLock</literal> (see <link linkend="ch13" preference="0">Chapter 13</link>) enforces a multiple-reader, single-writer locking discipline: more than one reader can access the shared resource concurrently so long as none of them wants to modify it, but writers must acquire the lock excusively. For read-mostly data structures, <literal>ReadWriteLock</literal> can offer greater concurrency than exclusive locking; for read-only data structures, immutability can eliminate the need for locking entirely.</para>
<para>Atomic variables (see <link linkend="ch15" preference="0">Chapter 15</link>) offer a means of reducing the cost of updating “hot fields” such as statistics counters, sequence generators, or the reference <?docpage num="240"?><indexterm id="iddle1090" significance="normal"><?indexkey A?><?primarykey analysis?><?secondarykey LOCK CONTENTION?><primary><emphasis role="strong">analysis</emphasis></primary><secondary>lock contention</secondary></indexterm><indexterm id="iddle1091" significance="normal"><?indexkey A?><?primarykey analysis?><?secondarykey LOCK CONTENTION?><?tertiarykey THREAD DUMP USE?><primary><emphasis role="strong">analysis</emphasis></primary><secondary>lock contention</secondary><tertiary>thread dump use</tertiary></indexterm><indexterm id="iddle1591" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey LOCK?><?tertiarykey MEASUREMENT?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>lock</secondary><tertiary>measurement</tertiary></indexterm><indexterm id="iddle1713" significance="normal"><?indexkey C?><?primarykey CPU utilization?><?secondarykey MONITORING?><primary><emphasis role="strong">CPU utilization</emphasis></primary><secondary>monitoring</secondary></indexterm><indexterm id="iddle2684" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey UTILIZATION MEASUREMENT TOOLS?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>utilization measurement tools</secondary></indexterm><indexterm id="iddle2869" significance="normal"><?indexkey I?><?primarykey iostat application?><?secondarykey I/O MEASUREMENT?><primary><emphasis role="strong">iostat application</emphasis></primary><secondary>I/O measurement</secondary></indexterm><indexterm id="iddle3078" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONTENTION?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>contention</secondary></indexterm><indexterm id="iddle3079" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONTENTION?><?tertiarykey MEASUREMENT?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>contention</secondary><tertiary>measurement</tertiary></indexterm><indexterm id="iddle3187" significance="normal"><?indexkey M?><?primarykey measurement?><?secondarykey PROFILING TOOLS?><?tertiarykey LOCK CONTENTION?><primary><emphasis role="strong">measurement</emphasis></primary><secondary>profiling tools</secondary><tertiary>lock contention</tertiary></indexterm><indexterm id="iddle3251" significance="normal"><?indexkey M?><?primarykey monitoring?><?secondarykey CPU UTILIZATION?><primary><emphasis role="strong">monitoring</emphasis></primary><secondary>CPU utilization</secondary></indexterm><indexterm id="iddle3257" significance="normal"><?indexkey M?><?primarykey mpstat application?><primary><emphasis role="strong">mpstat application</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle3258" significance="normal"><?indexkey M?><?primarykey mpstat application?><primary><emphasis role="strong">mpstat application</emphasis></primary><seealso> <link linkend="iddle3254" preference="0"><emphasis role="strong">monitoring</emphasis>, tools</link>.</seealso></indexterm><indexterm id="iddle3473" significance="normal"><?indexkey P?><?primarykey perfmon application?><primary><emphasis role="strong">perfmon application</emphasis></primary><seealso> <link linkend="iddle2553" preference="0"><emphasis role="strong">guidelines</emphasis>, measurement</link>.</seealso></indexterm><indexterm id="iddle3474" significance="normal"><?indexkey P?><?primarykey perfmon application?><primary><emphasis role="strong">perfmon application</emphasis></primary><seealso> <link linkend="iddle3254" preference="0"><emphasis role="strong">monitoring</emphasis>, tools</link>.</seealso></indexterm><indexterm id="iddle3475" significance="normal"><?indexkey P?><?primarykey perfmon application?><?secondarykey I/O MEASUREMENT?><primary><emphasis role="strong">perfmon application</emphasis></primary><secondary>I/O measurement</secondary></indexterm><indexterm id="iddle3692" significance="normal"><?indexkey P?><?primarykey profiling?><?secondarykey TOOLS?><primary><emphasis role="strong">profiling</emphasis></primary><secondary>tools</secondary></indexterm><indexterm id="iddle3693" significance="normal"><?indexkey P?><?primarykey profiling?><?secondarykey TOOLS?><?tertiarykey LOCK CONTENTION DETECTION?><primary><emphasis role="strong">profiling</emphasis></primary><secondary>tools</secondary><tertiary>lock contention detection</tertiary></indexterm><indexterm id="iddle4064" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey CPU UTILIZATION MONITORING?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>CPU utilization monitoring</secondary></indexterm><indexterm id="iddle4770" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey DUMPS?><?tertiarykey LOCK CONTENTION ANALYSIS USE?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>dumps</secondary><tertiary>lock contention analysis use</tertiary></indexterm><indexterm id="iddle4943" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey MEASUREMENT?><primary><emphasis role="strong">tools</emphasis></primary><secondary>measurement</secondary></indexterm><indexterm id="iddle4944" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey MEASUREMENT?><?tertiarykey I/O UTILIZATION?><primary><emphasis role="strong">tools</emphasis></primary><secondary>measurement</secondary><tertiary>I/O utilization</tertiary></indexterm><indexterm id="iddle4949" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey PROFILING?><primary><emphasis role="strong">tools</emphasis></primary><secondary>profiling</secondary></indexterm><indexterm id="iddle4950" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey PROFILING?><?tertiarykey LOCK CONTENTION DETECTION?><primary><emphasis role="strong">tools</emphasis></primary><secondary>profiling</secondary><tertiary>lock contention detection</tertiary></indexterm><indexterm id="iddle5111" significance="normal"><?indexkey V?><?primarykey vmstat application?><?secondarykey CPU UTILIZATION MEASUREMENT?><primary><emphasis role="strong">vmstat application</emphasis></primary><secondary>CPU utilization measurement</secondary></indexterm>to the first node in a linked data structure. (We used <literal>AtomicLong</literal> to maintain the hit counter in the servlet examples in <link linkend="ch02" preference="0">Chapter 2</link>.) The atomic variable classes provide very fine-grained (and thereforemore scalable) atomic operations on integers or object references, and are implemented using low-level concurrency primitives (such as compare-and-swap) provided by most modern processors. If your class has a small number of hot fields that do not participate in invariants with other variables, replacing them with atomic variables may improve scalability. (Changing your algorithm to have fewer hot fields might improve scalability even more—atomic variables reduce the cost of updating hot fields, but they don’t eliminate it.)</para>
</section>
<section id="ch11lev2sec13" label="11.4.6" xreflabel="11.4.6">
<title id="ch11lev2sec13__title">Monitoring CPU Utilization</title>
<para>When testing for scalability, the goal is usually to keep the processors fully utilized. Tools like <literal>vmstat</literal> and <literal>mpstat</literal> on Unix systems or <literal>perfmon</literal> on Windows systems can tell you just how “hot” the processors are running.</para>
<para>If the CPUs are asymmetrically utilized (some CPUs are running hot but others are not) your first goal should be to find increased parallelism in your program. Asymmetric utilization indicates that most of the computation is going on in a small set of threads, and your application will not be able to take advantage of additional processors.</para>
<para>If the CPUs are not fully utilized, you need to figure out why. There are several likely causes:</para>
<itemizedlist mark="none" spacing="normal">
<listitem><formalpara><title><emphasis role="strong"><?design?>Insufficent load.</emphasis></title><para>It may be that the application being tested is just not subjected to enough load. You can test for this by increasing the load and measuring changes in utilization, response time, or service time. Generating enough load to saturate an application can require substantial computer power; the problem may be that the client systems, not the system being tested, are running at capacity.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>I/O-bound.</emphasis></title><para>You can determine whether an application is disk-bound using <literal>iostat</literal> or <literal>perfmon</literal>, and whether it is bandwidth-limited by monitoring traffic levels on your network.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Externally bound.</emphasis></title><para>If your application depends on external services such as a database or web service, the bottleneck may not be in your code. You can test for this by using a profiler or database administration tools to determine how much time is being spent waiting for answers from the external service.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Lock contention.</emphasis></title><para>Profiling tools can tell you how much lock contention your application is experiencing and which locks are “hot”. You can often get the same information without a profiler through random sampling, triggering a few thread dumps and looking for threads contending for locks. If a thread is blocked waiting for a lock, the appropriate stack frame in the thread dump indicates “waiting to lock monitor . . . ” Locks that are mostly uncontended rarely show up in a thread dump; a heavily contended lock will almost always have at least one thread waiting to acquire it and so will frequently appear in thread dumps.</para></formalpara></listitem>
</itemizedlist>
<para role="continued"><?docpage num="241"?><indexterm id="iddle1074" significance="normal"><?indexkey A?><?primarykey allocation?><?secondarykey OBJECT POOL USE?><primary><emphasis role="strong">allocation</emphasis></primary><secondary>object pool use</secondary></indexterm><indexterm id="iddle1075" significance="normal"><?indexkey A?><?primarykey allocation?><?secondarykey OBJECT POOL USE?><?tertiarykey DISADVANTAGES OF?><primary><emphasis role="strong">allocation</emphasis></primary><secondary>object pool use</secondary><tertiary>disadvantages of</tertiary></indexterm><indexterm id="iddle1473" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey OBJECT POOL DISADVANTAGES?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>object pool disadvantages</secondary></indexterm><indexterm id="iddle3355" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey POOLS?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>pools</secondary></indexterm><indexterm id="iddle3356" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey POOLS?><?tertiarykey APPROPRIATE USES?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>pools</secondary><tertiary>appropriate uses</tertiary></indexterm><indexterm id="iddle3358" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey POOLS?><?tertiarykey DISADVANTAGES OF?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>pools</secondary><tertiary>disadvantages of</tertiary></indexterm><indexterm id="iddle3527" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey SCALABILITY VS?><?tertiarykey OBJECT POOLING ISSUES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>scalability vs</secondary><tertiary>object pooling issues</tertiary></indexterm><indexterm id="iddle3607" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey OBJECT?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>object</secondary></indexterm><indexterm id="iddle3608" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey OBJECT?><?tertiarykey APPROPRIATE USES?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>object</secondary><tertiary>appropriate uses</tertiary></indexterm><indexterm id="iddle3610" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey OBJECT?><?tertiarykey DISADVANTAGES OF?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>object</secondary><tertiary>disadvantages of</tertiary></indexterm><indexterm id="iddle4076" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey PERFORMANCE VS?><?tertiarykey OBJECT POOLING ISSUES?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>performance vs</secondary><tertiary>object pooling issues</tertiary></indexterm><indexterm id="iddle5113" significance="normal"><?indexkey V?><?primarykey vmstat application?><?secondarykey THREAD UTILIZATION MEASUREMENT?><primary><emphasis role="strong">vmstat application</emphasis></primary><secondary>thread utilization measurement</secondary></indexterm>If your application is keeping the CPUs sufficiently hot, you can use monitoring tools to infer whether it would benefit from additional CPUs. A program with only four threads may be able to keep a 4-way system fully utilized, but is unlikely to see a performance boost if moved to an 8-way system since there would need to be waiting runnable threads to take advantage of the additional processors. (You may also be able to reconfigure the program to divide its workload over more threads, such as adjusting a thread pool size.) One of the columns reported by <literal>vmstat</literal> is the number of threads that are runnable but not currently running because a CPU is not available; if CPU utilization is high and there are always runnable threads waiting for a CPU, your application would probably benefit from more processors.</para>
</section>
<section id="ch11lev2sec14" label="11.4.7" xreflabel="11.4.7">
<title id="ch11lev2sec14__title">Just Say No to Object Pooling</title>
<para>In early JVM versions, object allocation and garbage collection were slow,<footnote id="ch11fn13" label="13"><para>As was everything else—synchronization, graphics, JVM startup, reflection—predictably so in the first version of an experimental technology.</para></footnote> but their performance has improved substantially since then. In fact, allocation in Java is now faster than <literal>malloc</literal> is in C: the common code path for <literal>new Object</literal> in HotSpot 1.4.x and 5.0 is approximately ten machine instructions.</para>
<para>To work around “slow” object lifecycles, many developers turned to object pooling, where objects are recycled instead of being garbage collected and allocated anew when needed. Even taking into account its reduced garbage collection overhead, object pooling has been shown to be a performance loss<footnote id="ch11fn14" label="14"><para>In addition to being a loss in terms of CPU cycles, object pooling has a number of other problems, among them the challenge of setting pool sizes correctly (too small, and pooling has no effect; too large, and it puts pressure on the garbage collector, retaining memory that could be used more effectively for something else); the risk that an object will not be properly reset to its newly allocated state, introducing subtle bugs; the risk that a thread will return an object to the pool but continue using it; and that it makes more work for generational garbage collectors by encouraging a pattern of old-to-young references.</para></footnote> for all but the most expensive objects (and a serious loss for light- and medium-weight objects) in single-threaded programs (<link linkend="biblio01_009" preference="0">Click, 2005</link>).</para>
<para>In concurrent applications, pooling fares even worse. When threads allocate new objects, very little inter-thread coordination is required, as allocators typically use thread-local allocation blocks to eliminate most synchronization on heap data structures. But if those threads instead request an object from a pool, some synchronization is necessary to coordinate access to the pool data structure, creating the possibility that a thread will block. Because blocking a thread due to lock contention is hundreds of times more expensive than an allocation, even a small amount of pool-induced contention would be a scalability bottleneck. (Even an uncontended synchronization is usually more expensive than allocating an object.) This is yet another technique intended as a performance optimization but that turned into a scalability hazard. Pooling has its uses,<footnote id="ch11fn15" label="15"><para>In constrained environments, such as some J2ME or RTSJ targets, object pooling may still be required for effective memory management or to manage responsiveness.</para></footnote> but is of limited utility as a performance optimization.</para>
<sidebar float="1" id="ch11sb08" condition="241"><title/>
<para><?docpage num="242"?><indexterm id="iddle1071" significance="normal"><?indexkey A?><?primarykey allocation?><primary><emphasis role="strong">allocation</emphasis></primary></indexterm><indexterm id="iddle1072" significance="normal"><?indexkey A?><?primarykey allocation?><?secondarykey ADVANTAGES VS. SYNCHRONIZATION?><primary><emphasis role="strong">allocation</emphasis></primary><secondary>advantages vs. synchronization</secondary></indexterm><indexterm id="iddle1481" significance="normal"><?indexkey C?><?primarykey ConcurrentHashMap?><?secondarykey PERFORMANCE ADVANTAGES OF?><primary><emphasis role="strong">ConcurrentHashMap</emphasis></primary><secondary>performance advantages of</secondary></indexterm><indexterm id="iddle2502" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey ALLOCATION VS. SYNCHRONIZATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>allocation vs. synchronization</secondary></indexterm><indexterm id="iddle2625" significance="normal"><?indexkey H?><?primarykey hashcodes/hashtables?><?secondarykey CONCURRENTHASHMAP?><?tertiarykey PERFORMANCE ADVANTAGES OF?><primary><emphasis role="strong">hashcodes/hashtables</emphasis></primary><secondary><literal>ConcurrentHashMap</literal></secondary><tertiary>performance advantages of</tertiary></indexterm><indexterm id="iddle3180" significance="normal"><?indexkey M?><?primarykey Map?><?secondarykey CONCURRENTHASHMAP AS CONCURRENT REPLACEMENT?><?tertiarykey PERFORMANCE ADVANTAGES?><primary><emphasis role="strong">Map</emphasis></primary><secondary><literal>ConcurrentHashMap</literal> as concurrent replacement</secondary><tertiary>performance advantages</tertiary></indexterm><indexterm id="iddle4063" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey CONCURRENTHASHMAP ADVANTAGES?><primary><emphasis role="strong">scalability</emphasis></primary><secondary><literal>ConcurrentHashMap</literal> advantages</secondary></indexterm><indexterm id="iddle4536" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey ALLOCATION ADVANTAGES VS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>allocation advantages vs</secondary></indexterm>Allocating objects is usually cheaper than synchronizing.</para>
</sidebar>
</section>
</section>
<section id="ch11lev1sec5" condition="241" label="11.5" xreflabel="11.5"><?docpage num="241"?><?docpage num="242"?>
<title id="ch11lev1sec5__title">Example: Comparing Map Performance</title>
<para>The single-threaded performance of <literal>ConcurrentHashMap</literal> is slightly better than that of a synchronized <literal>HashMap</literal>, but it is in concurrent use that it really shines. The implementation of <literal>ConcurrentHashMap</literal> assumes the most common operation is retrieving a value that already exists, and is therefore optimized to provide highest performance and concurrency for successful <literal>get</literal> operations.</para>
<para>The major scalability impediment for the synchronized <literal>Map</literal> implementations is that there is a single lock for the entire map, so only one thread can access the map at a time. On the other hand, <literal>ConcurrentHashMap</literal> does no locking for most successful read operations, and uses lock striping for write operations and those few read operations that do require locking. As a result, multiple threads can access the <literal>Map</literal> concurrently without blocking.</para>
<para><link linkend="ch11fig03" preference="1">Figure 11.3</link> illustrates the differences in scalability between several <literal>Map</literal> implementations: <literal>ConcurrentHashMap</literal>, <literal>ConcurrentSkipListMap</literal>, and <literal>HashMap</literal> and <literal>TreeMap</literal> wrapped with <literal>synchronizedMap</literal>. The first two are thread-safe by design; the latter two are made thread-safe by the synchronized wrapper. In each run, <emphasis>N</emphasis> threads concurrently execute a tight loop that selects a random key and attempts to retrieve the value corresponding to that key. If the value is not present, it is added to the <literal>Map</literal> with probability <emphasis>p</emphasis> = .6, and if it is present, is removed with probability <emphasis>p</emphasis> = .02. The tests were run under a pre-release build of Java 6 on an 8-way Sparc V880, and the graph displays throughput normalized to the onethread case for <literal>ConcurrentHashMap</literal>. (The scalability gap between the concurrent and synchronized collections is even larger on Java 5.0.)</para>
<para>The data for <literal>ConcurrentHashMap</literal> and <literal>ConcurrentSkipListMap</literal> shows that they scale well to large numbers of threads; throughput continues to improve as threads are added. While the numbers of threads in <link linkend="ch11fig03" preference="1">Figure 11.3</link> may not seem large, this test program generates more contention per thread than a typical application because it does little other than pound on the <literal>Map</literal>; a real program would do additional thread-local work in each iteration.</para>
<figure float="1" id="ch11fig03" label="11.3" xreflabel="11.3" condition="243">
<?docpage num="243"?>
<title id="ch11fig03__title">Comparing Scalability of <literal>Map</literal> Implementations.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/11fig03_alt.gif"?><imagedata depth="229" fileref="graphics/11fig03.gif" format="GIF" role="stdwidth" width="500"/></imageobject></mediaobject>
</figure>
<para>The numbers for the synchronized collections are not as encouraging. Performance for the one-thread case is comparable to <literal>ConcurrentHashMap</literal>, but once the load transitions from mostly uncontended to mostly contended—which happens here at two threads—the synchronized collections suffer badly. This is common behavior for code whose scalability is limited by lock contention. So long as contention is low, time per operation is dominated by the time to actually do the work and throughput may improve as threads are added. Once contention becomes significant, time per operation is dominated by context switch and scheduling delays, and adding more threads has little effect on throughput.</para>
</section>
<section id="ch11lev1sec6" condition="243" label="11.6" xreflabel="11.6">
<?docpage num="243"?>
<title id="ch11lev1sec6__title">Reducing Context Switch Overhead</title>
<para><indexterm id="iddle1615" significance="normal"><?indexkey C?><?primarykey context switching?><?secondarykey MESSAGE LOGGING?><primary><emphasis role="strong">context switching</emphasis></primary><secondary>message logging</secondary></indexterm><indexterm id="iddle1616" significance="normal"><?indexkey C?><?primarykey context switching?><?secondarykey MESSAGE LOGGING?><?tertiarykey REDUCTION STRATEGIES?><primary><emphasis role="strong">context switching</emphasis></primary><secondary>message logging</secondary><tertiary>reduction strategies</tertiary></indexterm><indexterm id="iddle1618" significance="normal"><?indexkey C?><?primarykey context switching?><?secondarykey REDUCTION?><primary><emphasis role="strong">context switching</emphasis></primary><secondary>reduction</secondary></indexterm><indexterm id="iddle2674" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey MESSAGE LOGGING?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>message logging</secondary></indexterm><indexterm id="iddle2675" significance="normal"><?indexkey I?><?primarykey I/O?><?secondarykey MESSAGE LOGGING?><?tertiarykey REDUCTION STRATEGIES?><primary><emphasis role="strong">I/O</emphasis></primary><secondary>message logging</secondary><tertiary>reduction strategies</tertiary></indexterm><indexterm id="iddle4188" significance="normal"><?indexkey S?><?primarykey server?><?secondarykey APPLICATIONS?><primary><emphasis role="strong">server</emphasis></primary><secondary>applications</secondary></indexterm><indexterm id="iddle4189" significance="normal"><?indexkey S?><?primarykey server?><?secondarykey APPLICATIONS?><?tertiarykey CONTEXT SWITCH REDUCTION?><primary><emphasis role="strong">server</emphasis></primary><secondary>applications</secondary><tertiary>context switch reduction</tertiary></indexterm>Many tasks involve operations that may block; transitioning between the running and blocked states entails a context switch. One source of blocking in server applications is generating log messages in the course of processing requests; to illustrate how throughput can be improved by reducing context switches, we’ll analyze the scheduling behavior of two logging approaches.</para>
<para>Most logging frameworks are thin wrappers around <literal>println</literal>; when you have something to log, just write it out right then and there. Another approach was shown in <literal>LogWriter</literal> on page 152: the logging is performed in a dedicated background thread instead of by the requesting thread. From the developer’s perspective, both approaches are roughly equivalent. But there may be a difference in performance, depending on the volume of logging activity, how many threads are doing logging, and other factors such as the cost of context switching.<footnote id="ch11fn16" label="16"><para>Building a logger that moves the I/O to another thread may improve performance, but it also introduces a number of design complications, such as interruption (what happens if a thread blocked in a logging operation is interrupted?), service guarantees (does the logger guarantee that a successfully queued log message will be logged prior to service shutdown?), saturation policy (what happens when the producers log messages faster than the logger thread can handle them?), and service lifecycle (how do we shut down the logger, and how do we communicate the service state to producers?).</para></footnote></para>
<para>The service time for a logging operation includes whatever computation is associated with the I/O stream classes; if the I/O operation blocks, it also includes the duration for which the thread is blocked. The operating system will deschedule the blocked thread until the I/O completes, and probably a little longer. When the I/O completes, other threads are probably active and will be allowed to finish out their scheduling quanta, and threads may already be waiting ahead of us on <?docpage num="244"?><indexterm id="iddle2615" significance="normal"><?indexkey H?><?primarykey happens-before?><?secondarykey PUBLICATION CONSEQUENCES?><primary><emphasis role="strong">happens-before</emphasis></primary><secondary>publication consequences</secondary></indexterm><indexterm id="iddle3414" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey PARTIAL?><?tertiarykey HAPPENS-BEFORE, PUBLICATION CONSEQUENCES?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>partial</secondary><tertiary>happens-before, publication consequences</tertiary></indexterm><indexterm id="iddle3461" significance="normal"><?indexkey P?><?primarykey partial ordering?><?secondarykey HAPPENS-BEFORE?><primary><emphasis role="strong">partial ordering</emphasis></primary><secondary>happens-before</secondary></indexterm><indexterm id="iddle3462" significance="normal"><?indexkey P?><?primarykey partial ordering?><?secondarykey HAPPENS-BEFORE?><?tertiarykey AND PUBLICATION?><primary><emphasis role="strong">partial ordering</emphasis></primary><secondary>happens-before</secondary><tertiary>and publication</tertiary></indexterm><indexterm id="iddle3724" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey JMM SUPPORT?><primary><emphasis role="strong">publication</emphasis></primary><secondary>JMM support</secondary></indexterm><indexterm id="iddle4190" significance="normal"><?indexkey S?><?primarykey server?><?secondarykey APPLICATIONS?><?tertiarykey CONTEXT SWITCH REDUCTION?><primary><emphasis role="strong">server</emphasis></primary><secondary>applications</secondary><tertiary>context switch reduction</tertiary></indexterm>the scheduling queue—further adding to service time. Alternatively, if multiple threads are logging simultaneously, theremay be contention for the output stream lock, in which case the result is the same as with blocking I/O—the thread blocks waiting for the lock and gets switched out. Inline logging involves I/O and locking, which can lead to increased context switching and therefore increased service times.</para>
<para>Increasing request service time is undesirable for several reasons. First, service time affects quality of service: longer service times mean someone is waiting longer for a result. But more significantly, longer service times in this case mean more lock contention. The “get in, get out” principle of <link linkend="ch11lev2sec8" preference="0">Section 11.4.1</link> tells us that we should hold locks as briefly as possible, because the longer a lock is held, the more likely that lock will be contended. If a thread blocks waiting for I/O while holding a lock, another thread is more likely to want the lock while the first thread is holding it. Concurrent systems perform much better when most lock acquisitions are uncontended, because contended lock acquisition means more context switches. A coding style that encourages more context switches thus yields lower overall throughput.</para>
<para>Moving the I/O out of the request-processing thread is likely to shorten the mean service time for request processing. Threads calling <literal>log</literal> no longer block waiting for the output stream lock or for I/O to complete; they need only queue the message and can then return to their task. On the other hand, we’ve introduced the possibility of contention for the message queue, but the <literal>put</literal> operation is lighter-weight than the logging I/O (which might require system calls) and so is less likely to block in actual use (as long as the queue is not full). Because the request thread is now less likely to block, it is less likely to be context-switched out in the middle of a request. What we’ve done is turned a complicated and uncertain code path involving I/O and possible lock contention into a straight-line code path.</para>
<para>To some extent, we are just moving the work around, moving the I/O to a thread where its cost isn’t perceived by the user (which may in itself be a win). But by moving <emphasis>all</emphasis> the logging I/O to a single thread, we also eliminate the chance of contention for the output stream and thus eliminate a source of blocking. This improves overall throughput because fewer resources are consumed in scheduling, context switching, and lock management.</para>
<para>Moving the I/O from many request-processing threads to a single logger thread is similar to the difference between a bucket brigade and a collection of individuals fighting a fire. In the “hundred guys running around with buckets” approach, you have a greater chance of contention at the water source and at the fire (resulting in overall less water delivered to the fire), plus greater inefficiency because each worker is continuously switching modes (filling, running, dumping, running, etc.). In the bucket-brigade approach, the flow of water from the source to the burning building is constant, less energy is expended transporting the water to the fire, and each worker focuses on doing one job continuously. Just as interruptions are disruptive and productivity-reducing to humans, blocking and context switching are disruptive to threads.</para>
</section>



<section id="ch11lev1sec7" condition="245" label="" xreflabel="">
<?docpage num="245"?><?docpage num="246"?>
<title id="ch11lev1sec7__title">Summary</title>
<para>Because one of the most common reasons to use threads is to exploit multiple processors, in discussing the performance of concurrent applications, we are usually more concerned with throughput or scalability than we are with raw service time. Amdahl’s law tells us that the scalability of an application is driven by the proportion of code that must be executed serially. Since the primary source of serialization in Java programs is the exclusive resource lock, scalability can often be improved by spending less time holding locks, either by reducing lock granularity, reducing the duration for which locks are held, or replacing exclusive locks with nonexclusive or nonblocking alternatives.</para>
</section>

</chapter>

<chapter id="ch12" label="12" xreflabel="12" condition="247">
<?docpage num="247"?>
<title id="ch12__title">Testing Concurrent Programs</title>


<para><indexterm id="iddle1479" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey TESTING?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>testing</secondary></indexterm><indexterm id="iddle1678" significance="normal"><?indexkey C?><?primarykey correctness?><?secondarykey TESTING?><?tertiarykey GOALS?><primary><emphasis role="strong">correctness</emphasis></primary><secondary>testing</secondary><tertiary>goals</tertiary></indexterm><indexterm id="iddle2310" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey MODES?><primary><emphasis role="strong">failure</emphasis></primary><secondary>modes</secondary></indexterm><indexterm id="iddle2311" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey MODES?><?tertiarykey TESTING FOR?><primary><emphasis role="strong">failure</emphasis></primary><secondary>modes</secondary><tertiary>testing for</tertiary></indexterm><indexterm id="iddle2632" significance="normal"><?indexkey H?><?primarykey Heisenbugs?><primary><emphasis role="strong">Heisenbugs</emphasis></primary></indexterm><indexterm id="iddle3536" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TESTING?><primary><emphasis role="strong">performance</emphasis></primary><secondary>testing</secondary></indexterm><indexterm id="iddle3672" significance="normal"><?indexkey P?><?primarykey probability?><?secondarykey DETERMINISM VS?><primary><emphasis role="strong">probability</emphasis></primary><secondary>determinism vs</secondary></indexterm><indexterm id="iddle3673" significance="normal"><?indexkey P?><?primarykey probability?><?secondarykey DETERMINISM VS?><?tertiarykey IN CONCURRENT PROGRAMS?><primary><emphasis role="strong">probability</emphasis></primary><secondary>determinism vs</secondary><tertiary>in concurrent programs</tertiary></indexterm><indexterm id="iddle4047" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey TESTING?><?tertiarykey GOALS?><primary><emphasis role="strong">safety</emphasis></primary><secondary>testing</secondary><tertiary>goals</tertiary></indexterm><indexterm id="iddle4693" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey CONCURRENT PROGRAMS?><primary><emphasis role="strong">testing</emphasis></primary><secondary>concurrent programs</secondary></indexterm><indexterm id="iddle4709" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><?tertiarykey TIMING AND SYNCHRONIZATION ARTIFACTS?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary><tertiary>timing and synchronization artifacts</tertiary></indexterm><indexterm id="iddle4714" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey SAFETY?><?tertiarykey CRITERIA?><primary><emphasis role="strong">testing</emphasis></primary><secondary>safety</secondary><tertiary>criteria</tertiary></indexterm>Concurrent programs employ similar design principles and patterns to sequential programs. The difference is that concurrent programs have a degree of nondeterminism that sequential programs do not, increasing the number of potential interactions and failure modes that must be planned for and analyzed.</para>
<para>Similarly, testing concurrent programs uses and extends ideas from testing sequential ones. The same techniques for testing correctness and performance in sequential programs can be applied to concurrent programs, but with concurrent programs the space of things that can go wrong is much larger. The major challenge in constructing tests for concurrent programs is that potential failures may be rare probabalistic occurrences rather than deterministic ones; tests that disclose such failures must be more extensive and run for longer than typical sequential tests.</para>
<para>Most tests of concurrent classes fall into one or both of the classic categories of <emphasis>safety</emphasis> and <emphasis>liveness</emphasis>. In <link linkend="ch01" preference="0">Chapter 1</link>, we defined safety as “nothing bad ever happens” and liveness as “something good eventually happens”.</para>
<para>Tests of safety, which verify that a class’s behavior conforms to its specification, usually take the form of testing invariants. For example, in a linked list implementation that caches the size of the list every time it is modified, one safety test would be to compare the cached count against the actual number of elements in the list. In a single-threaded program this is easy, since the list contents do not change while you are testing its properties. But in a concurrent program, such a test is likely to be fraught with races unless you can observe the count field and count the elements in a single atomic operation. This can be done by locking the list for exclusive access, employing some sort of “atomic snapshot” feature provided by the implementation, or by using “test points” provided by the implementation that let tests assert invariants or execute test code atomically.</para>
<para>In this book, we’ve used timing diagrams to depict “unlucky” interactions that could cause failures in incorrectly constructed classes; test programs attempt to search enough of the state space that such bad luck eventually occurs. Unfortunately, test code can introduce timing or synchronization artifacts that can mask bugs that might otherwise manifest themselves.<footnote id="ch12fn01" label="1"><para>Bugs that disappear when you add debugging or test code are playfully called <emphasis>Heisenbugs</emphasis>.</para></footnote></para>
<para><?docpage num="248"?><indexterm id="iddle1266" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey BOUNDEDBUFFER EXAMPLE?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary><literal>BoundedBuffer</literal> example</secondary></indexterm><indexterm id="iddle2086" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BoundedBuffer</literal></secondary></indexterm><indexterm id="iddle4140" significance="normal"><?indexkey S?><?primarykey Semaphore?><?secondarykey EXAMPLE USE?><primary><emphasis role="strong">Semaphore</emphasis></primary><secondary>example use</secondary></indexterm><indexterm id="iddle1211" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey BOUNDED COLLECTIONS?><?tertiarykey TESTING?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>bounded collections</secondary><tertiary>testing</tertiary></indexterm><indexterm id="iddle1268" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey BOUNDEDBUFFER EXAMPLE?><?tertiarykey TEST CASE DEVELOPMENT FOR?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary><literal>BoundedBuffer</literal> example</secondary><tertiary>test case development for</tertiary></indexterm><indexterm id="iddle1272" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey TESTING?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary>testing</secondary></indexterm><indexterm id="iddle1677" significance="normal"><?indexkey C?><?primarykey correctness?><?secondarykey TESTING?><primary><emphasis role="strong">correctness</emphasis></primary><secondary>testing</secondary></indexterm><indexterm id="iddle1702" significance="normal"><?indexkey C?><?primarykey counting semaphores?><?secondarykey PERMITS, THREAD RELATIONSHIPS?><primary><emphasis role="strong">counting semaphores</emphasis></primary><secondary>permits, thread relationships</secondary></indexterm><indexterm id="iddle1779" significance="normal"><?indexkey D?><?primarykey data structure(s)?><?secondarykey TESTING INSERTION AND REMOVAL HANDLING?><primary><emphasis role="strong">data structure(s)</emphasis></primary><secondary>testing insertion and removal handling</secondary></indexterm><indexterm id="iddle2085" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BoundedBuffer</literal></secondary></indexterm><indexterm id="iddle3029" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey TESTING?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>testing</secondary></indexterm><indexterm id="iddle3030" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey TESTING?><?tertiarykey CRITERIA?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>testing</secondary><tertiary>criteria</tertiary></indexterm><indexterm id="iddle3537" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TESTING?><?tertiarykey CRITERIA?><primary><emphasis role="strong">performance</emphasis></primary><secondary>testing</secondary><tertiary>criteria</tertiary></indexterm><indexterm id="iddle3949" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey AS PERFORMANCE TESTING CRITERIA?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>as performance testing criteria</secondary></indexterm><indexterm id="iddle4059" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey AS PERFORMANCE TESTING CRITERIA?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>as performance testing criteria</secondary></indexterm><indexterm id="iddle4141" significance="normal"><?indexkey S?><?primarykey Semaphore?><?secondarykey IN BOUNDEDBUFFER EXAMPLE?><primary><emphasis role="strong">Semaphore</emphasis></primary><secondary>in <literal>BoundedBuffer</literal> example</secondary></indexterm><indexterm id="iddle4151" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey COUNTING?><?tertiarykey PERMITS, THREAD RELATIONSHIPS?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>counting</secondary><tertiary>permits, thread relationships</tertiary></indexterm><indexterm id="iddle4697" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey LIVENESS?><primary><emphasis role="strong">testing</emphasis></primary><secondary>liveness</secondary></indexterm><indexterm id="iddle4698" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey LIVENESS?><?tertiarykey CRITERIA?><primary><emphasis role="strong">testing</emphasis></primary><secondary>liveness</secondary><tertiary>criteria</tertiary></indexterm><indexterm id="iddle4700" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PERFORMANCE?><?tertiarykey CRITERIA?><primary><emphasis role="strong">testing</emphasis></primary><secondary>performance</secondary><tertiary>criteria</tertiary></indexterm><indexterm id="iddle4707" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><?tertiarykey PROGRESS QUANTIFICATION?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary><tertiary>progress quantification</tertiary></indexterm><indexterm id="iddle4708" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><?tertiarykey PROVING A NEGATIVE?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary><tertiary>proving a negative</tertiary></indexterm><indexterm id="iddle4712" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PROGRAM CORRECTNESS?><primary><emphasis role="strong">testing</emphasis></primary><secondary>program correctness</secondary></indexterm><indexterm id="iddle4868" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey AS PERFORMANCE TESTING CRITERIA?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>as performance testing criteria</secondary></indexterm><indexterm id="iddle5010" significance="normal"><?indexkey U?><?primarykey unit tests?><?secondarykey ISSUES?><primary><emphasis role="strong">unit tests</emphasis></primary><secondary>issues</secondary></indexterm>Liveness properties present their own testing challenges. Liveness tests include tests of progress and nonprogress, which are hard to quantify—how do you verify that a method is blocking and not merely running slowly? Similarly, how do you test that an algorithm does <emphasis>not</emphasis> deadlock? How long should you wait before you declare it to have failed?</para>
<para>Related to liveness tests are performance tests. Performance can be measured in a number of ways, including:</para>
<formalpara><title><emphasis role="strong"><?design?>Throughput:</emphasis></title><para>the rate at which a set of concurrent tasks is completed;</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Responsiveness:</emphasis></title><para>the delay between a request for and completion of some action (also called <emphasis>latency</emphasis>); or</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Scalability:</emphasis></title><para>the improvement in throughput (or lack thereof) as more resources (usually CPUs) are made available.</para></formalpara>



<section id="ch12lev1sec1" condition="248" label="12.1" xreflabel="12.1"><?docpage num="248"?><?docpage num="249"?>
<title id="ch12lev1sec1__title">Testing for Correctness</title>
<para>Developing unit tests for a concurrent class starts with the same analysis as for a sequential class—identifying invariants and postconditions that are amenable to mechanical checking. If you are lucky, many of these are present in the specification; the rest of the time, writing tests is an adventure in iterative specification discovery.</para>
<para>As a concrete illustration, we’re going to build a set of test cases for a bounded buffer. <link linkend="ch12list01" preference="0">Listing 12.1</link> shows our <literal>BoundedBuffer</literal> implementation, using <literal>Semaphore</literal> to implement the required bounding and blocking.</para>
<para><literal>BoundedBuffer</literal> implements a fixed-length array-based queue with blocking <literal>put</literal> and <literal>take</literal> methods controlled by a pair of counting semaphores. The <literal>availableItems</literal> semaphore represents the number of elements that can be <emphasis>removed</emphasis> from the buffer, and is initially zero (since the buffer is initially empty). Similarly, <literal>availableSpaces</literal> represents how many items can be <emphasis>inserted</emphasis> into the buffer, and is initialized to the size of the buffer.</para>
<para>A <literal>take</literal> operation first requires that a permit be obtained from <literal>availableItems</literal>. This succeeds immediately if the buffer is nonempty, and otherwise blocks until the buffer becomes nonempty. Once a permit is obtained, the next element from the buffer is removed and a permit is released to the <literal>availableSpaces</literal> semaphore.<footnote id="ch12fn02" label="2"><para>In a counting semaphore, the permits are not represented explicitly or associated with an owning thread; a <literal>release</literal> operation creates a permit and an <literal>acquire</literal> operation consumes one.</para></footnote> The <literal>put</literal> operation is defined conversely, so that on exit from either the <literal>put</literal> or <literal>take</literal> methods, the sum of the counts of both semaphores always equals the bound. (In practice, if you need a bounded buffer you should use <literal>ArrayBlockingQueue</literal> or <literal>LinkedBlockingQueue</literal> rather than rolling your own, but the technique used here illustrates how insertions and removals can be controlled in other data structures as well.)</para>
<example id="ch12list01" label="12.1" role="Listing" xreflabel="12.1" condition="249">
<?docpage num="249"?>
<title id="ch12list01__title">Bounded Buffer Using <literal>Semaphore</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class BoundedBuffer&lt;E&gt; {
    private final Semaphore availableItems, availableSpaces;
    @GuardedBy("this") private final E[] items;
    @GuardedBy("this") private int putPosition = 0, takePosition = 0;

    public BoundedBuffer(int capacity) {
        availableItems = new Semaphore(0);
        availableSpaces = new Semaphore(capacity);
        items = (E[]) new Object[capacity];
    }
    public boolean isEmpty() {
        return availableItems.availablePermits() == 0;
    }
    public boolean isFull() {
        return availableSpaces.availablePermits() == 0;
    }

    public void put(E x) throws InterruptedException {
        availableSpaces.acquire();
        doInsert(x);
        availableItems.release();
    }
    public E take() throws InterruptedException {
        availableItems.acquire();
        E item = doExtract();
        availableSpaces.release();
        return item;
    }

    private <emphasis role="strong">synchronized</emphasis> void doInsert(E x) {
        int i = putPosition;
        items[i] = x;
        putPosition = (++i == items.length)? 0 : i;
    }
    private <emphasis role="strong">synchronized</emphasis> E doExtract() {
        int i = takePosition;
        E x = items[i];
        items[i] = null;
        takePosition = (++i == items.length)? 0 : i;
        return x;
    }
}
</programlisting>
</example>
<section id="ch12lev2sec1" condition="250" label="12.1.1" xreflabel="12.1.1">
<?docpage num="250"?>
<title id="ch12lev2sec1__title">Basic Unit Tests</title>
<para><indexterm id="iddle1218" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey OPERATIONS?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>operations</secondary></indexterm><indexterm id="iddle1219" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey OPERATIONS?><?tertiarykey TESTING?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>operations</secondary><tertiary>testing</tertiary></indexterm><indexterm id="iddle1269" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey BOUNDEDBUFFERTEST EXAMPLE?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary><literal>BoundedBufferTest</literal> example</secondary></indexterm><indexterm id="iddle1899" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey CONCURRENCY TESTING?><primary><emphasis role="strong">design</emphasis></primary><secondary>concurrency testing</secondary></indexterm><indexterm id="iddle2089" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BOUNDEDBUFFERTEST?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BoundedBufferTest</literal></secondary></indexterm><indexterm id="iddle2845" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey BOUNDEDBUFFER EXAMPLE?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary><literal>BoundedBuffer</literal> example</secondary></indexterm><indexterm id="iddle3882" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey CONCURRENCY TESTING?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>concurrency testing</secondary></indexterm><indexterm id="iddle3883" significance="normal"><?indexkey R?><?primarykey requirements?><?secondarykey CONCURRENCY TESTING?><?tertiarykey TCK EXAMPLE?><primary><emphasis role="strong">requirements</emphasis></primary><secondary>concurrency testing</secondary><tertiary>TCK example</tertiary></indexterm><indexterm id="iddle4170" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey TESTS, VALUE IN CONCURRENCY TESTING?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>tests, value in concurrency testing</secondary></indexterm><indexterm id="iddle4663" significance="normal"><?indexkey T?><?primarykey TCK (Technology Compatibility Kit)?><primary><emphasis role="strong">TCK (Technology Compatibility Kit)</emphasis></primary></indexterm><indexterm id="iddle4664" significance="normal"><?indexkey T?><?primarykey TCK (Technology Compatibility Kit)?><?secondarykey CONCURRENCY TESTING REQUIREMENTS?><primary><emphasis role="strong">TCK (Technology Compatibility Kit)</emphasis></primary><secondary>concurrency testing requirements</secondary></indexterm><indexterm id="iddle5008" significance="normal"><?indexkey U?><?primarykey unit tests?><primary><emphasis role="strong">unit tests</emphasis></primary></indexterm><indexterm id="iddle5009" significance="normal"><?indexkey U?><?primarykey unit tests?><?secondarykey FOR BOUNDEDBUFFER EXAMPLE?><primary><emphasis role="strong">unit tests</emphasis></primary><secondary>for <literal>BoundedBuffer</literal> example</secondary></indexterm>The most basic unit tests for <literal>BoundedBuffer</literal> are similar to what we’d use in a sequential context—create a bounded buffer, call its methods, and assert postconditions and invariants. Some invariants that quickly come to mind are that a freshly created buffer should identify itself as empty, and also as not full. A similar but slightly more complicated safety test is to insert <emphasis>N</emphasis> elements into a buffer with capacity <emphasis>N</emphasis> (which should succeed without blocking), and test that the buffer recognizes that it is full (and not empty). JUnit test methods for these properties are shown in <link linkend="ch12list02" preference="0">Listing 12.2</link>.</para>
<example id="ch12list02" label="12.2" role="Listing" xreflabel="12.2" condition="250">
<title id="ch12list02__title">Basic Unit Tests for <literal>BoundedBuffer</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">class BoundedBufferTest extends TestCase {
    void testIsEmptyWhenConstructed() {
        BoundedBuffer&lt;Integer&gt; bb = new BoundedBuffer&lt;Integer&gt;(10);
        assertTrue(bb.isEmpty());
        assertFalse(bb.isFull());
    }

    void testIsFullAfterPuts() throws InterruptedException {
        BoundedBuffer&lt;Integer&gt; bb = new BoundedBuffer&lt;Integer&gt;(10);
        for (int i = 0; i &lt; 10; i++)
            bb.put(i);
        assertTrue(bb.isFull());
        assertFalse(bb.isEmpty());
    }
}
</programlisting>
</example>
<para>These simple test methods are entirely sequential. Including a set of sequential tests in your test suite is often helpful, since they can disclose when a problem is <emphasis>not</emphasis> related to concurrency issues before you start looking for data races.</para>
</section>
<section id="ch12lev2sec2" label="12.1.2" xreflabel="12.1.2">
<title id="ch12lev2sec2__title">Testing Blocking Operations</title>
<para>Tests of essential concurrency properties require introducing more than one thread. Most testing frameworks are not very concurrency-friendly: they rarely include facilities to create threads or monitor them to ensure that they do not die unexpectedly. If a helper thread created by a test case discovers a failure, the framework usually does not know with which test the thread is associated, so some work may be required to relay success or failure information back to the main test runner thread so it can be reported.</para>
<para>For the conformance tests for <literal>java.util.concurrent</literal>, it was important that failures be clearly associated with a specific test. Hence the JSR 166 Expert Group created a base class<footnote id="ch12fn03" label="3"><para><literal><ulink url="http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/tck/JSR166TestCase.java">http://gee.cs.oswego.edu/cgi-bin/viewcvs.cgi/jsr166/src/test/tck/JSR166TestCase.java</ulink></literal></para></footnote> that provided methods to relay and report failures during <?docpage num="251"?><indexterm id="iddle2800" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey BLOCKING TEST USE?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>blocking test use</secondary></indexterm><indexterm id="iddle4723" significance="normal"><?indexkey T?><?primarykey Thread?><?secondarykey GETSTATE?><primary><emphasis role="strong">Thread</emphasis></primary><secondary><literal>getState</literal></secondary></indexterm><indexterm id="iddle4724" significance="normal"><?indexkey T?><?primarykey Thread?><?secondarykey GETSTATE?><?tertiarykey USE PRECAUTIONS?><primary><emphasis role="strong">Thread</emphasis></primary><secondary><literal>getState</literal></secondary><tertiary>use precautions</tertiary></indexterm><literal>tearDown</literal>, following the convention that every test must wait until all the threads it created terminate. You may not need to go to such lengths; the key requirements are that it be clear whether the tests passed and that failure information is reported somewhere for use in diagnosing the problem.</para>
<para>If a method is supposed to block under certain conditions, then a test for that behavior should succeed only if the thread does <emphasis>not</emphasis> proceed. Testing that a method blocks is similar to testing that a method throws an exception; if the method returns normally, the test has failed.</para>
<para>Testing that a method blocks introduces an additional complication: once the method successfully blocks, you have to convince it somehow to unblock. The obvious way to do this is via interruption—start a blocking activity in a separate thread, wait until the thread blocks, interrupt it, and then assert that the blocking operation completed. Of course, this requires your blocking methods to respond to interruption by returning early or throwing <literal>InterruptedException</literal>.</para>
<para>The “wait until the thread blocks” part is easier said than done; in practice, you have to make an arbitrary decision about how long the few instructions being executed could possibly take, and wait longer than that. You should be prepared to increase this value if you are wrong (in which case you will see spurious test failures).</para>
<para><link linkend="ch12list03" preference="0">Listing 12.3</link> shows an approach to testing blocking operations. It creates a “taker” thread that attempts to <literal>take</literal> an element from an empty buffer. If <literal>take</literal> succeeds, it registers failure. The test runner thread starts the taker thread, waits a long time, and then interrupts it. If the taker thread has correctly blocked in the <literal>take</literal> operation, it will throw <literal>InterruptedException</literal>, and the <literal>catch</literal> block for this exception treats this as success and lets the thread exit. The main test runner thread then attempts to <literal>join</literal> with the taker thread and verifies that the join returned successfully by calling <literal>Thread.isAlive</literal>; if the taker thread responded to the interrupt, the <literal>join</literal> should complete quickly.</para>
<para>The timed <literal>join</literal> ensures that the test completes even if <literal>take</literal> gets stuck in some unexpected way. This test method tests several properties of <literal>take</literal>—not only that it blocks but that, when interrupted, it throws <literal>InterruptedException</literal>. This is one of the few cases in which it is appropriate to subclass <literal>Thread</literal> explicitly instead of using a <literal>Runnable</literal> in a pool: in order to test proper termination with <literal>join</literal>. The same approach can be used to test that the taker thread unblocks after an element is placed in the queue by the main thread.</para>
<para>It is tempting to use <literal>Thread.getState</literal> to verify that the thread is actually blocked on a condition wait, but this approach is not reliable. There is nothing that requires a blocked thread <emphasis>ever</emphasis> to enter the <literal>WAITING</literal> or <literal>TIMED_WAITING</literal> states, since the JVM can choose to implement blocking by spin-waiting instead. Similarly, because spurious wakeups from <literal>Object.wait</literal> or <literal>Condition.await</literal> are permitted (see <link linkend="ch14" preference="0">Chapter 14</link>), a thread in the <literal>WAITING</literal> or <literal>TIMED_WAITING</literal> state may temporarily transition to <literal>RUNNABLE</literal> even if the condition for which it is waiting is not yet true. Even ignoring these implementation options, it may take some time for the target thread to settle into a blocking state. <emphasis>The result of Thread.getState should not be used for concurrency control, and is of limited usefulness for testing—its primary utility is as a source of debugging information.</emphasis></para>

<para><?docpage num="252"?></para><example id="ch12list03" label="12.3" role="Listing" xreflabel="12.3" condition="252">

<title id="ch12list03__title">Testing Blocking and Responsiveness to Interruption.</title>
<programlisting format="linespecific" linenumbering="unnumbered">void testTakeBlocksWhenEmpty() {
    final BoundedBuffer&lt;Integer&gt; bb = new BoundedBuffer&lt;Integer&gt;(10);
    Thread taker = new Thread() {
        public void run() {
            try {
                int unused = bb.take();
                fail();  // if we get here, it's an error
            } catch (InterruptedException success) { }
        }};
    try {
        taker.start();
        Thread.sleep(LOCKUP_DETECT_TIMEOUT);
        taker.interrupt();
        taker.join(LOCKUP_DETECT_TIMEOUT);
        assertFalse(taker.isAlive());
    } catch (Exception unexpected) {
        fail();
    }
}
</programlisting>
</example>
</section>
<section id="ch12lev2sec3" label="12.1.3" xreflabel="12.1.3">
<title id="ch12lev2sec3__title">Testing Safety</title>
<para><indexterm id="iddle2573" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey SAFETY?><?tertiarykey TESTING?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>safety</secondary><tertiary>testing</tertiary></indexterm><indexterm id="iddle3688" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey SAFETY TESTING?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>safety testing</secondary></indexterm><indexterm id="iddle4046" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey TESTING?><primary><emphasis role="strong">safety</emphasis></primary><secondary>testing</secondary></indexterm><indexterm id="iddle4713" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey SAFETY?><primary><emphasis role="strong">testing</emphasis></primary><secondary>safety</secondary></indexterm><indexterm id="iddle4717" significance="normal"><?indexkey T?><?primarykey testTakeBlocksWhenEmpty example?><primary><emphasis role="strong">testTakeBlocksWhenEmpty example</emphasis></primary></indexterm>The tests in <link linkend="ch12list02" preference="0">Listings 12.2</link> and <link linkend="ch12list03" preference="0">12.3</link> test important properties of the bounded buffer, but are unlikely to disclose errors stemming from data races. To test that a concurrent class performs correctly under unpredictable concurrent access, we need to set up multiple threads performing <literal>put</literal> and <literal>take</literal> operations over some amount of time and then somehow test that nothing went wrong.</para>
<para>Constructing tests to disclose safety errors in concurrent classes is a chicken-and-egg problem: the test programs themselves are concurrent programs. Developing good concurrent tests can be more difficult than developing the classes they test.</para>
<sidebar float="1" id="ch12sb01" condition="252"><title/>
<para>The challenge to constructing effective safety tests for concurrent classes is identifying easily checked properties that will, with high probability, fail if something goes wrong, while at the same time not letting the failureauditing code limit concurrency artificially. It is best if checking the test property does not require any synchronization.</para>
</sidebar>
<para>One approach that works well with classes used in producer-consumer designs (like <literal>BoundedBuffer</literal>) is to check that everything put into a queue or buffer comes out of it, and that nothing else does. A naive implementation of this approach would insert the element into a “shadow” list when it is put on the queue, <?docpage num="253"?><indexterm id="iddle1340" significance="normal"><?indexkey C?><?primarykey checksums?><primary><emphasis role="strong">checksums</emphasis></primary></indexterm><indexterm id="iddle1341" significance="normal"><?indexkey C?><?primarykey checksums?><?secondarykey SAFETY TESTING USE?><primary><emphasis role="strong">checksums</emphasis></primary><secondary>safety testing use</secondary></indexterm><indexterm id="iddle3401" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey CHECKSUMS?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>checksums</secondary></indexterm><indexterm id="iddle3402" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey CHECKSUMS?><?tertiarykey SAFETY TESTING USE?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>checksums</secondary><tertiary>safety testing use</tertiary></indexterm><indexterm id="iddle3790" significance="normal"><?indexkey R?><?primarykey random(ness)?><?secondarykey TEST DATA GENERATION USE?><primary><emphasis role="strong">random(ness)</emphasis></primary><secondary>test data generation use</secondary></indexterm>remove it from the list when it is removed from the queue, and assert that the shadow list is empty when the test has finished. But this approach would distort the scheduling of the test threads because modifying the shadow list would require synchronization and possibly blocking.</para>
<para>A better approach is to compute checksums of the elements that are enqueued and dequeued using an order-sensitive checksum function, and compare them. If they match, the test passes. This approach works best when there is a single producer putting elements into the buffer and a single consumer taking them out, because it can test not only that the right elements (probably) came out but that they came out in the right order.</para>
<para>Extending this approach to a multiple-producer, multiple-consumer situation requires using a checksum function that is <emphasis>insensitive</emphasis> to the order in which the elements are combined, so that multiple checksums can be combined after the test. Otherwise, synchronizing access to a shared checksum field could become a concurrency bottleneck or distort the timing of the test. (Any commutative operation, such as addition or XOR, meets these requirements.)</para>
<para>To ensure that your test actually tests what you think it does, it is important that the checksums themselves not be guessable by the compiler. It would be a bad idea to use consecutive integers as your test data because then the result would always be the same, and a smart compiler could conceivably just precompute it.</para>
<para>To avoid this problem, test data should be generated randomly, but many otherwise effective tests are compromised by a poor choice of random number generator (RNG). Random number generation can create couplings between classes and timing artifacts because most random number generator classes are threadsafe and therefore introduce additional synchronization.<footnote id="ch12fn04" label="4"><para>Many benchmarks are, unbeknownst to their developers or users, simply tests of how great a concurrency bottleneck the RNG is.</para></footnote> Giving each thread its own RNG allows a non-thread-safe RNG to be used.</para>
<para>Rather than using a general-purpose RNG, it is better to use simple pseudorandom functions. You don’t need high-quality randomness; all you need is enough randomness to ensure the numbers change from run to run. The <literal>xor-Shift</literal> function in <link linkend="ch12list04" preference="0">Listing 12.4</link> (<link linkend="biblio01_025" preference="0">Marsaglia, 2003</link>) is among the cheapest mediumquality random number functions. Starting it off with values based on <literal>hashCode</literal> and <literal>nanoTime</literal> makes the sums both unguessable and almost always different for each run.</para>
<example id="ch12list04" label="12.4" role="Listing" xreflabel="12.4" condition="253">
<title id="ch12list04__title">Medium-quality Random Number Generator Suitable for Testing.</title>
<programlisting format="linespecific" linenumbering="unnumbered">static int xorShift(int y) {
    y ^= (y &lt;&lt; 6);
    y ^= (y &gt;&gt;&gt; 21);
    y ^= (y &lt;&lt; 7);
    return y;
}
</programlisting>
</example>
<para><?docpage num="254"?><indexterm id="iddle1743" significance="normal"><?indexkey C?><?primarykey CyclicBarrier?><?secondarykey TESTING USE?><primary><emphasis role="strong">CyclicBarrier</emphasis></primary><secondary>testing use</secondary></indexterm><indexterm id="iddle2161" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PUTTAKETEST?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>PutTakeTest</literal></secondary></indexterm><indexterm id="iddle2600" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey TESTING?><?tertiarykey TIMING-SENSITIVE DATA RACES?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>testing</secondary><tertiary>timing-sensitive data races</tertiary></indexterm><indexterm id="iddle4678" significance="normal"><?indexkey T?><?primarykey termination?><?secondarykey SAFETY TEST?><primary><emphasis role="strong">termination</emphasis></primary><secondary>safety test</secondary></indexterm><indexterm id="iddle4679" significance="normal"><?indexkey T?><?primarykey termination?><?secondarykey SAFETY TEST?><?tertiarykey CRITERIA FOR?><primary><emphasis role="strong">termination</emphasis></primary><secondary>safety test</secondary><tertiary>criteria for</tertiary></indexterm><indexterm id="iddle4789" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey OVERHEAD?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>overhead</secondary></indexterm><indexterm id="iddle4790" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey OVERHEAD?><?tertiarykey IN SAFETY TESTING, STRATEGIES FOR MITIGATING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>overhead</secondary><tertiary>in safety testing, strategies for mitigating</tertiary></indexterm><literal>PutTakeTest</literal> in <link linkend="ch12list05" preference="0">Listings 12.5</link> and <link linkend="ch12list06" preference="0">12.6</link> starts <emphasis>N</emphasis> producer threads that generate elements and enqueue them, and <emphasis>N</emphasis> consumer threads that dequeue them. Each thread updates the checksum of the elements as they go in or out, using a perthread checksum that is combined at the end of the test run so as to add no more synchronization or contention than required to test the buffer.</para>
<para>Depending on your platform, creating and starting a thread can be a moderately heavyweight operation. If your thread is short-running and you start a number of threads in a loop, the threads run sequentially rather than concurrently in the worst case. Even in the not-quite-worst case, the fact that the first thread has a head start on the others means that you may get fewer interleavings than expected: the first thread runs by itself for some amount of time, and then the first two threads run concurrently for some amount of time, and only eventually are all the threads running concurrently. (The same thing happens at the end of the run: the threads that got a head start also finish early.)</para>
<para>We presented a technique for mitigating this problem in <link linkend="ch05lev2sec10" preference="0">Section 5.5.1</link>, using a <literal>CountDownLatch</literal> as a starting gate and another as a finish gate. Another way to get the same effect is to use a <literal>CyclicBarrier</literal>, initialized with the number of worker threads plus one, and have the worker threads and the test driver wait at the barrier at the beginning and end of their run. This ensures that all threads are up and running before any start working. <literal>PutTakeTest</literal> uses this technique to coordinate starting and stopping the worker threads, creating more potential concurrent interleavings. We still can’t guarantee that the scheduler won’t run each thread to completion sequentially, but making the runs long enough reduces the extent to which scheduling distorts our results.</para>
<para>The final trick employed by <literal>PutTakeTest</literal> is to use a deterministic termination criterion so that no additional inter-thread coordination is needed to figure out when the test is finished. The <literal>test</literal> method starts exactly as many producers as consumers and each of them <literal>put</literal>s or <literal>take</literal>s the same number of elements, so the total number of items added and removed is the same.</para>
<para>Tests like <literal>PutTakeTest</literal> tend to be good at finding safety violations. For example, a common error in implementing semaphore-controlled buffers is to forget that the code actually doing the insertion and extraction requires mutual exclusion (using <literal>synchronized</literal> or <literal>ReentrantLock</literal>). A sample run of <literal>PutTakeTest</literal> with a version of <literal>BoundedBuffer</literal> that omits making <literal>doInsert</literal> and <literal>doExtract synchronized</literal> fails fairly quickly. Running <literal>PutTakeTest</literal> with a few dozen threads iterating a few million times on buffers of various capacity on various systems increases our confidence about the lack of data corruption in <literal>put</literal> and <literal>take</literal>.</para>
<sidebar float="1" id="ch12sb02" condition="254"><title/>
<para>Tests should be run on multiprocessor systems to increase the diversity of potential interleavings. However, having more than a few CPUs does not necessarily make tests more effective. To maximize the chance of detecting timing-sensitive data races, there should be more active threads than CPUs, so that at any given time some threads are running and some are switched out, thus reducing the predicatability of interactions between threads.</para>
</sidebar>

<para><?docpage num="255"?></para><example id="ch12list05" label="12.5" role="Listing" xreflabel="12.5" condition="255">

<title id="ch12list05__title">Producer-consumer Test Program for <literal>BoundedBuffer</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class PutTakeTest {
    private static final ExecutorService pool
            = Executors.newCachedThreadPool();
    private final AtomicInteger putSum = new AtomicInteger(0);
    private final AtomicInteger takeSum = new AtomicInteger(0);
    private final CyclicBarrier barrier;
    private final BoundedBuffer&lt;Integer&gt; bb;
    private final int nTrials, nPairs;

    public static void main(String[] args) {
        new PutTakeTest(10, 10, 100000).test(); // <emphasis>sample parameters</emphasis>
        pool.shutdown();
    }

    PutTakeTest(int capacity, int npairs, int ntrials) {
        this.bb = new BoundedBuffer&lt;Integer&gt;(capacity);
        this.nTrials = ntrials;
        this.nPairs = npairs;
        this.barrier = new CyclicBarrier(npairs*  2 + 1);
    }

    void test() {
        try {
            for (int i = 0; i &lt;  nPairs; i++) {
                pool.execute(new Producer());
                pool.execute(new Consumer());
            }
            barrier.await(); // <emphasis>wait for all threads to be ready</emphasis>
            barrier.await(); // <emphasis>wait for all threads to finish</emphasis>
            assertEquals(putSum.get(), takeSum.get());
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

    class Producer implements Runnable {  /*  <emphasis>Listing 12.6</emphasis>  */ }

    class Consumer implements Runnable {  /*  <emphasis>Listing 12.6</emphasis>  */ }
}
</programlisting>
</example>

<para><?docpage num="256"?></para><example id="ch12list06" label="12.6" role="Listing" xreflabel="12.6" condition="256">

<title id="ch12list06__title">Producer and Consumer Classes Used in <literal>PutTakeTest</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">/* <emphasis>inner classes of PutTakeTest (Listing 12.5)</emphasis>  */
class Producer implements Runnable {
    public void run() {
        try {
            int seed = (this.hashCode() ^ (int)System.nanoTime());
            int sum = 0;
            barrier.await();
            for (int i = nTrials; i &gt; 0; --i) {
                bb.put(seed);
                sum += seed;
                seed = xorShift(seed);
            }
            putSum.getAndAdd(sum);
            barrier.await();
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }
}

class Consumer implements Runnable {
    public void run() {
        try {
            barrier.await();
            int sum = 0;
            for (int i = nTrials; i &gt; 0; --i) {
                sum += bb.take();
            }
            takeSum.getAndAdd(sum);
            barrier.await();
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }
}
</programlisting>
</example>
<para><?docpage num="257"?><indexterm id="iddle2103" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CONSUMER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Consumer</literal></secondary></indexterm><indexterm id="iddle2160" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PRODUCER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Producer</literal></secondary></indexterm><indexterm id="iddle1293" significance="normal"><?indexkey C?><?primarykey callbacks?><primary><emphasis role="strong">callbacks</emphasis></primary></indexterm><indexterm id="iddle1294" significance="normal"><?indexkey C?><?primarykey callbacks?><?secondarykey TESTING USE?><primary><emphasis role="strong">callbacks</emphasis></primary><secondary>testing use</secondary></indexterm><indexterm id="iddle1986" significance="normal"><?indexkey E?><?primarykey Effective Java Programming Language Guide?><primary><emphasis role="strong"><emphasis>Effective Java Programming Language Guide</emphasis></emphasis></primary></indexterm><indexterm id="iddle2631" significance="normal"><?indexkey H?><?primarykey heap inspection tools?><?secondarykey MEASURING MEMORY USAGE?><primary><emphasis role="strong">heap inspection tools</emphasis></primary><secondary>measuring memory usage</secondary></indexterm><indexterm id="iddle2846" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey CALLBACK TESTING?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>callback testing</secondary></indexterm><indexterm id="iddle2951" significance="normal"><?indexkey L?><?primarykey leakage?><?secondarykey RESOURCE?><primary><emphasis role="strong">leakage</emphasis></primary><secondary>resource</secondary></indexterm><indexterm id="iddle2952" significance="normal"><?indexkey L?><?primarykey leakage?><?secondarykey RESOURCE?><?tertiarykey TESTING FOR?><primary><emphasis role="strong">leakage</emphasis></primary><secondary>resource</secondary><tertiary>testing for</tertiary></indexterm><indexterm id="iddle3198" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey DEPLETION?><?tertiarykey TESTING FOR?><primary><emphasis role="strong">memory</emphasis></primary><secondary>depletion</secondary><tertiary>testing for</tertiary></indexterm><indexterm id="iddle3342" significance="normal"><?indexkey N?><?primarykey nulling out memory references?><primary><emphasis role="strong">nulling out memory references</emphasis></primary></indexterm><indexterm id="iddle3343" significance="normal"><?indexkey N?><?primarykey nulling out memory references?><?secondarykey TESTING USE?><primary><emphasis role="strong">nulling out memory references</emphasis></primary><secondary>testing use</secondary></indexterm><indexterm id="iddle3896" significance="normal"><?indexkey R?><?primarykey resource exhaustion, preventing?><?secondarykey TESTING STRATEGIES?><primary><emphasis role="strong">resource exhaustion, preventing</emphasis></primary><secondary>testing strategies</secondary></indexterm><indexterm id="iddle3914" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey LEAKAGE?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>leakage</secondary></indexterm><indexterm id="iddle3915" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey LEAKAGE?><?tertiarykey TESTING FOR?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>leakage</secondary><tertiary>testing for</tertiary></indexterm><indexterm id="iddle3927" significance="normal"><?indexkey R?><?primarykey resource(s)?><?secondarykey MANAGEMENT?><?tertiarykey TESTING?><primary><emphasis role="strong">resource(s)</emphasis></primary><secondary>management</secondary><tertiary>testing</tertiary></indexterm><indexterm id="iddle4680" significance="normal"><?indexkey T?><?primarykey termination?><?secondarykey SAFETY TEST?><?tertiarykey CRITERIA FOR?><primary><emphasis role="strong">termination</emphasis></primary><secondary>safety test</secondary><tertiary>criteria for</tertiary></indexterm><indexterm id="iddle4783" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey LEAKAGE?><?tertiarykey TESTING FOR?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>leakage</secondary><tertiary>testing for</tertiary></indexterm><indexterm id="iddle4942" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey HEAP INSPECTION?><primary><emphasis role="strong">tools</emphasis></primary><secondary>heap inspection</secondary></indexterm>In tests that run until they complete a fixed number of operations, it is possible that the test case will never finish if the code being tested encounters an exception due to a bug. The most common way to handle this is to have the test framework abort tests that do not terminate within a certain amount of time; how long to wait should be determined empirically, and failures must then be analyzed to ensure that the problem wasn’t just that you didn’t wait long enough. (This problem is not unique to testing concurrent classes; sequential tests must also distinguish between long-running and infinite loops.)</para>
</section>
<section id="ch12lev2sec4" label="12.1.4" xreflabel="12.1.4">
<title id="ch12lev2sec4__title">Testing Resource Management</title>
<para>The tests so far have been concerned with a class’s adherence to its specification—that it does what it is supposed to do. A secondary aspect to test is that it does <emphasis>not</emphasis> do things it is <emphasis>not</emphasis> supposed to do, such as leak resources. Any object that holds or manages other objects should not continue to maintain references to those objects longer than necessary. Such storage leaks prevent garbage collectors from reclaiming memory (or threads, file handles, sockets, database connections, or other limited resources) and can lead to resource exhaustion and application failure.</para>
<para>Resource management issues are especially important for classes like <literal>BoundedBuffer</literal>—the entire reason for bounding a buffer is to prevent application failure due to resource exhaustion when producers get too far ahead of consumers. Bounding causes overly productive producers to block rather than continue to create work that will consume more and more memory or other resources.</para>
<para>Undesirable memory retention can be easily tested with heap-inspection tools that measure application memory usage; a variety of commercial and open-source heap-profiling tools can do this. The <literal>testLeak</literal> method in <link linkend="ch12list07" preference="0">Listing 12.7</link> contains placeholders for a heap-inspection tool to snapshot the heap, which forces a garbage collection<footnote id="ch12fn05" label="5"><para>Technically, it is impossible to <emphasis>force</emphasis> a garbage collection; <literal>System.gc</literal> only <emphasis>suggests</emphasis> to the JVM that this might be a good time to perform a garbage collection. HotSpot can be instructed to ignore <literal>System.gc</literal> calls with <literal>-XX:+DisableExplicitGC</literal>.</para></footnote> and then records information about the heap size and memory usage.</para>
<para>The <literal>testLeak</literal> method inserts several large objects into a bounded buffer and then removes them; memory usage at heap snapshot #2 should be approximately the same as at heap snapshot #1. On the other hand, if <literal>doExtract</literal> forgot to null out the reference to the returned element (<literal>items[i]=null</literal>), the reported memory usage at the two snapshots would definitely not be the same. (This is one of the few times where explicit nulling is necessary; most of the time, it is either not helpful or actually harmful [EJ Item 5].)</para>
</section>
<section id="ch12lev2sec5" label="12.1.5" xreflabel="12.1.5">
<title id="ch12lev2sec5__title">Using Callbacks</title>
<para>Callbacks to client-provided code can be helpful in constructing test cases; callbacks are often made at known points in an object’s lifecycle that are good opportunities to assert invariants. For example, <literal>ThreadPoolExecutor</literal> makes calls to the task <literal>Runnable</literal>s and to the <literal>ThreadFactory</literal>.</para>

<para><?docpage num="258"?></para><example id="ch12list07" label="12.7" role="Listing" xreflabel="12.7" condition="258">

<title id="ch12list07__title">Testing for Resource Leaks.</title>
<programlisting format="linespecific" linenumbering="unnumbered">class Big { double[] data = new double[100000]; }

void testLeak() throws InterruptedException {
     BoundedBuffer&lt;Big&gt; bb = new BoundedBuffer&lt;Big&gt;(CAPACITY);
     int heapSize1 =  /* snapshot heap */ ;
     for (int i = 0; i &lt; CAPACITY; i++)
         bb.put(new Big());
     for (int i = 0; i &lt; CAPACITY; i++)
         bb.take();
     int heapSize2 =  /* snapshot heap */ ;
     assertTrue(Math.abs(heapSize1-heapSize2) &lt; THRESHOLD);
}
</programlisting>
</example>
<para><indexterm id="iddle2084" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BIG?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Big</literal></secondary></indexterm><indexterm id="iddle2198" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey TESTINGTHREADFACTORY?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>TestingThreadFactory</literal></secondary></indexterm><indexterm id="iddle2756" significance="normal"><?indexkey I?><?primarykey instrumentation?><?secondarykey OF THREAD CREATION?><primary><emphasis role="strong">instrumentation</emphasis></primary><secondary>of thread creation</secondary></indexterm><indexterm id="iddle2757" significance="normal"><?indexkey I?><?primarykey instrumentation?><?secondarykey OF THREAD CREATION?><?tertiarykey THREAD POOL TESTING USE?><primary><emphasis role="strong">instrumentation</emphasis></primary><secondary>of thread creation</secondary><tertiary>thread pool testing use</tertiary></indexterm><indexterm id="iddle3624" significance="normal"><?indexkey P?><?primarykey pool(s)?><?secondarykey THREAD?><?tertiarykey CALLBACK USE IN TESTING?><primary><emphasis role="strong">pool(s)</emphasis></primary><secondary>thread</secondary><tertiary>callback use in testing</tertiary></indexterm><indexterm id="iddle4716" significance="normal"><?indexkey T?><?primarykey testPoolExample example?><primary><emphasis role="strong">testPoolExample example</emphasis></primary></indexterm><indexterm id="iddle4798" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey POOLS?><?tertiarykey CALLBACK USE IN TESTING?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>pools</secondary><tertiary>callback use in testing</tertiary></indexterm>Testing a thread pool involves testing a number of elements of execution policy: that additional threads are created when they are supposed to, but not when they are not supposed to; that idle threads get reaped when they are supposed to, etc. Constructing a comprehensive test suite that covers all the possibilities is a major effort, but many of them can be tested fairly simply individually.</para>
<para>We can instrument thread creation by using a custom thread factory. <literal>TestingThreadFactory</literal> in <link linkend="ch12list08" preference="0">Listing 12.8</link> maintains a count of created threads; test cases can then verify the number of threads created during a test run. <literal>TestingThreadFactory</literal> could be extended to return a custom <literal>Thread</literal> that also records when the thread terminates, so that test cases can verify that threads are reaped in accordance with the execution policy.</para>
<example id="ch12list08" label="12.8" role="Listing" xreflabel="12.8" condition="258">
<title id="ch12list08__title">Thread Factory for Testing <literal>ThreadPoolExecutor</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">class TestingThreadFactory implements ThreadFactory {
    public final AtomicInteger numCreated = new AtomicInteger();
    private final ThreadFactory factory
            = Executors.defaultThreadFactory();

    public Thread newThread(Runnable r) {
        numCreated.incrementAndGet();
        return factory.newThread(r);
    }
}
</programlisting>
</example>
<para>If the core pool size is smaller than the maximum size, the thread pool should grow as demand for execution increases. Submitting long-running tasks to the pool makes the number of executing tasks stay constant for long enough to make a few assertions, such as testing that the pool is expanded as expected, as shown in <link linkend="ch12list09" preference="0">Listing 12.9</link>.</para>

<para><?docpage num="259"?></para><example id="ch12list09" label="12.9" role="Listing" xreflabel="12.9" condition="259">

<title id="ch12list09__title">Test Method to Verify Thread Pool Expansion.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public void testPoolExpansion() throws InterruptedException {
    int MAX_SIZE = 10;
    ExecutorService exec = Executors.newFixedThreadPool(MAX_SIZE);

    for (int i = 0; i &lt; 10*  MAX_SIZE; i++)
        exec.execute(new Runnable() {
            public void run() {
                try {
                    Thread.sleep(Long.MAX_VALUE);
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            }
        });
    for (int i = 0;
         i &lt; 20 &amp;&amp; threadFactory.numCreated.get() &lt; MAX_SIZE;
         i++)
        Thread.sleep(100);
    assertEquals(threadFactory.numCreated.get(), MAX_SIZE);
    exec.shutdownNow();
}
</programlisting>
</example>
</section>
<section id="ch12lev2sec6" label="12.1.6" xreflabel="12.1.6">
<title id="ch12lev2sec6__title">Generating More Interleavings</title>
<para><indexterm id="iddle1101" significance="normal"><?indexkey A?><?primarykey AOP (aspect-oriented programming)?><primary><emphasis role="strong">AOP (aspect-oriented programming)</emphasis></primary></indexterm><indexterm id="iddle1102" significance="normal"><?indexkey A?><?primarykey AOP (aspect-oriented programming)?><?secondarykey IN TESTING?><primary><emphasis role="strong">AOP (aspect-oriented programming)</emphasis></primary><secondary>in testing</secondary></indexterm><indexterm id="iddle2770" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey GENERATING?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>generating</secondary></indexterm><indexterm id="iddle2771" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey GENERATING?><?tertiarykey TESTING USE?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>generating</secondary><tertiary>testing use</tertiary></indexterm><indexterm id="iddle2890" significance="normal"><?indexkey J?><?primarykey Java Language Specification, The?><primary><emphasis role="strong"><emphasis>Java Language Specification, The</emphasis></emphasis></primary></indexterm>Since many of the potential failures in concurrent code are low-probability events, testing for concurrency errors is a numbers game, but there are some things you can do to improve your chances. We’ve already mentioned how running on multiprocessor systems with fewer processors than active threads can generate more interleavings than either a single-processor system or one with many processors. Similarly, testing on a variety of systems with different processor counts, operating systems, and processor architectures can disclose problems that might not occur on all systems.</para>
<para>A useful trick for increasing the number of interleavings, and therefore more effectively exploring the state space of your programs, is to use <literal>Thread.yield</literal> to encourage more context switches during operations that access shared state. (The effectiveness of this technique is platform-specific, since the JVM is free to treat <literal>Thread.yield</literal> as a no-op [JLS 17.9]; using a short but nonzero sleep would be slower but more reliable.) The method in <link linkend="ch12list10" preference="0">Listing 12.10</link> transfers credits from one account to another; between the two update operations, invariants such as “sum of all accounts equals zero” do not hold. By sometimes yielding in the middle of an operation, you may activate timing-sensitive bugs in code that does not use adequate synchronization to access state. The inconvenience of adding these calls for testing and removing them for production can be reduced by adding them using aspect-oriented programming (AOP) tools.</para>

<para><?docpage num="260"?></para><example id="ch12list10" label="12.10" role="Listing" xreflabel="12.10" condition="260">

<title id="ch12list10__title">Using <literal>Thread.yield</literal> to Generate More Interleavings.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public synchronized void transferCredits(Account from,
                                         Account to,
                                         int amount) {
    from.setBalance(from.getBalance() - amount);
    if (random.nextInt(1000) &gt; THRESHOLD)
        Thread.yield();
    to.setBalance(to.getBalance() + amount);
}
</programlisting>
</example>
</section>
</section>
<section id="ch12lev1sec2" condition="260" label="12.2" xreflabel="12.2"><?docpage num="260"?><?docpage num="261"?><?docpage num="262"?>
<title id="ch12lev1sec2__title">Testing for Performance</title>
<para><indexterm id="iddle1193" significance="normal"><?indexkey B?><?primarykey barrier(s)?><?secondarykey %?><primary><emphasis role="strong">barrier(s)</emphasis></primary><secondary>-based timer</secondary></indexterm><indexterm id="iddle1744" significance="normal"><?indexkey C?><?primarykey CyclicBarrier?><?secondarykey TESTING USE?><primary><emphasis role="strong">CyclicBarrier</emphasis></primary><secondary>testing use</secondary></indexterm><indexterm id="iddle2162" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey PUTTAKETEST?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>PutTakeTest</literal></secondary></indexterm><indexterm id="iddle2417" significance="normal"><?indexkey F?><?primarykey functionality?><?secondarykey TESTS?><primary><emphasis role="strong">functionality</emphasis></primary><secondary>tests</secondary></indexterm><indexterm id="iddle2418" significance="normal"><?indexkey F?><?primarykey functionality?><?secondarykey TESTS?><?tertiarykey VS. PERFORMANCE TESTS?><primary><emphasis role="strong">functionality</emphasis></primary><secondary>tests</secondary><tertiary>vs. performance tests</tertiary></indexterm><indexterm id="iddle3538" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TESTING?><?tertiarykey GOALS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>testing</secondary><tertiary>goals</tertiary></indexterm><indexterm id="iddle4309" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey AS PERFORMANCE TESTING GOAL?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>as performance testing goal</secondary></indexterm><indexterm id="iddle4695" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey FUNCTIONALITY?><primary><emphasis role="strong">testing</emphasis></primary><secondary>functionality</secondary></indexterm><indexterm id="iddle4696" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey FUNCTIONALITY?><?tertiarykey VS. PERFORMANCE TESTS?><primary><emphasis role="strong">testing</emphasis></primary><secondary>functionality</secondary><tertiary>vs. performance tests</tertiary></indexterm><indexterm id="iddle4699" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PERFORMANCE?><primary><emphasis role="strong">testing</emphasis></primary><secondary>performance</secondary></indexterm><indexterm id="iddle4701" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PERFORMANCE?><?tertiarykey GOALS?><primary><emphasis role="strong">testing</emphasis></primary><secondary>performance</secondary><tertiary>goals</tertiary></indexterm><indexterm id="iddle4912" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey MEASURING?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>measuring</secondary></indexterm><indexterm id="iddle4913" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey MEASURING?><?tertiarykey IN PERFORMANCE TESTING?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>measuring</secondary><tertiary>in performance testing</tertiary></indexterm><indexterm id="iddle5021" significance="normal"><?indexkey U?><?primarykey usage scenarios?><primary><emphasis role="strong">usage scenarios</emphasis></primary></indexterm><indexterm id="iddle5022" significance="normal"><?indexkey U?><?primarykey usage scenarios?><?secondarykey PERFORMANCE TESTING USE?><primary><emphasis role="strong">usage scenarios</emphasis></primary><secondary>performance testing use</secondary></indexterm>Performance tests are often extended versions of functionality tests. In fact, it is almost always worthwhile to include some basic functionality testing within performance tests to ensure that you are not testing the performance of broken code.</para>
<para>While there is definitely overlap between performance and functionality tests, they have different goals. Performance tests seek to measure end-to-end performance metrics for representative use cases. Picking a reasonable set of usage scenarios is not always easy; ideally, tests should reflect how the objects being tested are actually used in your application.</para>
<para>In some cases an appropriate test scenario is obvious. Bounded buffers are nearly always used in producer-consumer designs, so it is sensible to measure the throughput of producers feeding data to consumers. We can easily extend <literal>PutTakeTest</literal> to become a performance test for this scenario.</para>
<para>A common secondary goal of performance testing is to select sizings empirically for various bounds—numbers of threads, buffer capacities, and so on. While these values might turn out to be sensitive enough to platform characteristics (such as processor type or even processor stepping level, number of CPUs, or memory size) to require dynamic configuration, it is equally common that reasonable choices for these values work well across a wide range of systems.</para>
<section id="ch12lev2sec7" label="12.2.1" xreflabel="12.2.1">
<title id="ch12lev2sec7__title">Extending PutTakeTest to Add Timing</title>
<para>The primary extension we have to make to <literal>PutTakeTest</literal> is to measure the time taken for a run. Rather than attempting to measure the time for a single operation, we get a more accurate measure by timing the entire run and dividing by the number of operations to get a per-operation time. We are already using a <literal>CyclicBarrier</literal> to start and stop the worker threads, so we can extend this by using a barrier action that measures the start and end time, as shown in <link linkend="ch12list11" preference="0">Listing 12.11</link>.</para>
<para>We can modify the initialization of the barrier to use this barrier action by using the constructor for <literal>CyclicBarrier</literal> that accepts a barrier action:</para>
<example id="ch12list11" label="12.11" role="Listing" xreflabel="12.11" condition="260">
<title id="ch12list11__title">Barrier-based Timer.</title>
<programlisting format="linespecific" linenumbering="unnumbered">this.timer = new BarrierTimer();
this.barrier = new CyclicBarrier(npairs * 2 + 1, timer);
<?docpage num="261"?>public class BarrierTimer implements Runnable {
    private boolean started;
    private long startTime, endTime;

    public synchronized void run() {
        long t = System.nanoTime();
        if (!started) {
            started = true;
            startTime = t;
        } else
            endTime = t;
    }
    public synchronized void clear() {
        started = false;
    }
    public synchronized long getTime() {
        return endTime - startTime;
    }
}
</programlisting>
</example>
<para><indexterm id="iddle1246" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey BUFFERS?><?tertiarykey SCALABILITY TESTING?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>buffers</secondary><tertiary>scalability testing</tertiary></indexterm><indexterm id="iddle1247" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey BUFFERS?><?tertiarykey SIZE DETERMINATION?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>buffers</secondary><tertiary>size determination</tertiary></indexterm><indexterm id="iddle1264" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey BOUNDED?><?tertiarykey SCALABILITY TESTING?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary>bounded</secondary><tertiary>scalability testing</tertiary></indexterm><indexterm id="iddle1265" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey BOUNDED?><?tertiarykey SIZE DETERMINATION?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary>bounded</secondary><tertiary>size determination</tertiary></indexterm><indexterm id="iddle1270" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey CAPACITIES?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary>capacities</secondary></indexterm><indexterm id="iddle1271" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey CAPACITIES?><?tertiarykey COMPARISON TESTING?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary>capacities</secondary><tertiary>comparison testing</tertiary></indexterm><indexterm id="iddle1712" significance="normal"><?indexkey C?><?primarykey CPU utilization?><?secondarykey IMPACT ON PERFORMANCE TESTING?><primary><emphasis role="strong">CPU utilization</emphasis></primary><secondary>impact on performance testing</secondary></indexterm><indexterm id="iddle2080" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BARRIERTIMER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BarrierTimer</literal></secondary></indexterm><indexterm id="iddle2205" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey TIMEDPUTTAKETEST?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>TimedPutTakeTest</literal></secondary></indexterm><indexterm id="iddle3471" significance="normal"><?indexkey P?><?primarykey perfbar application?><?secondarykey CPU PERFORMANCE MEASURE?><primary><emphasis role="strong">perfbar application</emphasis></primary><secondary>CPU performance measure</secondary></indexterm><indexterm id="iddle3687" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey PERFORMANCE TESTING?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>performance testing</secondary></indexterm><indexterm id="iddle4086" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey TESTING?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>testing</secondary></indexterm><indexterm id="iddle4310" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey BOUNDED BUFFERS?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>bounded buffers</secondary></indexterm><indexterm id="iddle4311" significance="normal"><?indexkey S?><?primarykey size(ing)?><?secondarykey BOUNDED BUFFERS?><?tertiarykey DETERMINATION OF?><primary><emphasis role="strong">size(ing)</emphasis></primary><secondary>bounded buffers</secondary><tertiary>determination of</tertiary></indexterm><indexterm id="iddle4870" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey PRODUCER-CONSUMER HANDOFF?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>producer-consumer handoff</secondary></indexterm><indexterm id="iddle4871" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey PRODUCER-CONSUMER HANDOFF?><?tertiarykey TESTING?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>producer-consumer handoff</secondary><tertiary>testing</tertiary></indexterm>The modified <literal>test</literal> method using the barrier-based timer is shown in <link linkend="ch12list12" preference="0">Listing 12.12</link>.</para>
<para>We can learn several things from running <literal>TimedPutTakeTest</literal>. One is the throughput of the producer-consumer handoff operation for various combinations of parameters; another is how the bounded buffer scales with different numbers of threads; a third is how we might select the bound size. Answering these questions requires running the test for various combinations of parameters, so we’ll need amain test driver, shown in <link linkend="ch12list13" preference="0">Listing 12.13</link>.</para>
<para><link linkend="ch12fig01" preference="1">Figure 12.1</link> shows some sample results on a 4-way machine, using buffer capacities of 1, 10, 100, and 1000. We see immediately that a buffer size of one causes very poor throughput; this is because each thread can make only a tiny bit of progress before blocking and waiting for another thread. Increasing buffer size to ten helps dramatically, but increases past ten offer diminishing returns.</para>
<figure float="1" id="ch12fig01" label="12.1" xreflabel="12.1" condition="263">
<?docpage num="263"?>
<title id="ch12fig01__title"><literal>TimedPutTakeTest</literal> with Various Buffer Capacities.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/12fig01_alt.gif"?><imagedata depth="302" fileref="graphics/12fig01.gif" format="GIF" role="stdwidth" width="500"/></imageobject></mediaobject>
</figure>
<para>It may be somewhat puzzling at first that adding a lot more threads degrades performance only slightly. The reason is hard to see from the data, but easy to see on a CPU performance meter such as <literal>perfbar</literal> while the test is running: even with many threads, not much computation is going on, and most of it is spent blocking and unblocking threads. So there is plenty of CPU slack for more threads to do the same thing without hurting performance very much.</para>
<para>However, be careful about concluding from this data that you can always add more threads to a producer-consumer program that uses a bounded buffer. This test is fairly artificial in how it simulates the <emphasis>application</emphasis>; the producers do almost no work to generate the item placed on the queue, and the consumers do almost no work with the item retrieved. If the worker threads in a real producer-consumer <?docpage num="263"?><indexterm id="iddle1973" significance="normal"><?indexkey D?><?primarykey driver program?><primary><emphasis role="strong">driver program</emphasis></primary></indexterm><indexterm id="iddle1974" significance="normal"><?indexkey D?><?primarykey driver program?><?secondarykey FOR TIMEDPUTTAKETEST EXAMPLE?><primary><emphasis role="strong">driver program</emphasis></primary><secondary>for <literal>TimedPutTakeTest</literal> example</secondary></indexterm><indexterm id="iddle4686" significance="normal"><?indexkey T?><?primarykey test example method?><primary><emphasis role="strong">test example method</emphasis></primary></indexterm><indexterm id="iddle1050" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey COMPARING PERFORMANCE?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>comparing performance</secondary></indexterm><indexterm id="iddle1076" significance="normal"><?indexkey A?><?primarykey allocation?><?secondarykey SCALABILITY ADVANTAGES?><primary><emphasis role="strong">allocation</emphasis></primary><secondary>scalability advantages</secondary></indexterm><indexterm id="iddle1123" significance="normal"><?indexkey A?><?primarykey ArrayBlockingQueue?><?secondarykey PERFORMANCE ADVANTAGES OVER BOUNDEDBUFFER?><primary><emphasis role="strong">ArrayBlockingQueue</emphasis></primary><secondary>performance advantages over <literal>BoundedBuffer</literal></secondary></indexterm><indexterm id="iddle1585" significance="normal"><?indexkey C?><?primarykey contention/contended?><primary><emphasis role="strong">contention/contended</emphasis></primary></indexterm><indexterm id="iddle1586" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey AS PERFORMANCE INHIBITING FACTOR?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>as performance inhibiting factor</secondary></indexterm><indexterm id="iddle2988" significance="normal"><?indexkey L?><?primarykey linked lists?><?secondarykey LINKEDBLOCKINGQUEUE?><?tertiarykey PERFORMANCE ADVANTAGES?><primary><emphasis role="strong">linked lists</emphasis></primary><secondary><literal>LinkedBlockingQueue</literal></secondary><tertiary>performance advantages</tertiary></indexterm><indexterm id="iddle4056" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey ALGORITHM?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>algorithm</secondary></indexterm><indexterm id="iddle4057" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey ALGORITHM?><?tertiarykey COMPARISON TESTING?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>algorithm</secondary><tertiary>comparison testing</tertiary></indexterm><indexterm id="iddle4498" significance="normal"><?indexkey S?><?primarykey striping?><primary><emphasis role="strong">striping</emphasis></primary><seealso> <link linkend="iddle3078" preference="0"><emphasis role="strong">lock(ing)</emphasis>, contention</link>.</seealso></indexterm>application do some nontrivial work to produce and consume items (as is generally the case), then this slack would disappear and the effects of having too many threads could be very noticeable. The primary purpose of this test is to measure what constraints the producer-consumer handoff via the bounded buffer imposes on overall throughput.</para>
<example id="ch12list12" label="12.12" role="Listing" xreflabel="12.12" condition="262">
<?docpage num="262"?>
<title id="ch12list12__title">Testing with a Barrier-based Timer.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public void test() {
    try {
        timer.clear();
        for (int i = 0; i &lt; nPairs; i++) {
            pool.execute(new Producer());
            pool.execute(new Consumer());
        }
        barrier.await();
        barrier.await();
        long nsPerItem = timer.getTime() / (nPairs*  (long)nTrials);
        System.out.print("Throughput: " + nsPerItem + " ns/item");
        assertEquals(putSum.get(), takeSum.get());
    } catch (Exception e) {
        throw new RuntimeException(e);
    }
}
</programlisting>
</example>
<example id="ch12list13" label="12.13" role="Listing" xreflabel="12.13" condition="262">
<?docpage num="262"?>
<title id="ch12list13__title">Driver Programfor <literal>TimedPutTakeTest</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public static void main(String[] args) throws Exception {
    int tpt = 100000;  // <emphasis>trials per thread</emphasis>
    for (int cap = 1; cap &lt;= 1000; cap*= 10) {
        System.out.println("Capacity: " + cap);
        for (int pairs = 1; pairs &lt;= 128; pairs*= 2) {
            TimedPutTakeTest t =
                new TimedPutTakeTest(cap, pairs, tpt);
            System.out.print("Pairs: " + pairs + "\t");
            t.test();
            System.out.print("\t");
            Thread.sleep(1000);
            t.test();
            System.out.println();
            Thread.sleep(1000);
        }
    }
    pool.shutdown();
}
</programlisting>
</example>
</section>
<section id="ch12lev2sec8" label="12.2.2" xreflabel="12.2.2">
<title id="ch12lev2sec8__title">Comparing Multiple Algorithms</title>
<para>While <literal>BoundedBuffer</literal> is a fairly solid implementation that performs reasonably well, it turns out to be no match for either <literal>ArrayBlockingQueue</literal> or <literal>LinkedBlockingQueue</literal> (which explains why this buffer algorithm wasn’t selected for inclusion in the class library). The <literal>java.util.concurrent</literal> algorithms have been selected and tuned, in part using tests just like those described here, to be as efficient as we know how to make them, while still offering a wide range of functionality.<footnote id="ch12fn06" label="6"><para>You might be able to outperform them if you both are a concurrency expert and can give up some of the provided functionality.</para></footnote> The main reason <literal>BoundedBuffer</literal> fares poorly is that <literal>put</literal> and <literal>take</literal> each have multiple operations that could encouter contention—acquire a semaphore, acquire a lock, release a semaphore. Other implementation approaches have fewer points at which they might contend with another thread.</para>
<para><link linkend="ch12fig02" preference="1">Figure 12.2</link> shows comparative throughput on a dual hyperthreaded machine for all three classes with 256-element buffers, using a variant of <literal>TimedPutTakeTest</literal>. This test suggests that <literal>LinkedBlockingQueue</literal> scales better than <literal>ArrayBlockingQueue</literal>. This may seem odd at first: a linked queue must allocate a link node object for each insertion, and hence seems to be doing more work than the array-based queue. However, even though it has more allocation and <?docpage num="264"?><indexterm id="iddle1402" significance="normal"><?indexkey C?><?primarykey completion?><?secondarykey TASK?><primary><emphasis role="strong">completion</emphasis></primary><secondary>task</secondary></indexterm><indexterm id="iddle1403" significance="normal"><?indexkey C?><?primarykey completion?><?secondarykey TASK?><?tertiarykey MEASURING SERVICE TIME VARIANCE?><primary><emphasis role="strong">completion</emphasis></primary><secondary>task</secondary><tertiary>measuring service time variance</tertiary></indexterm><indexterm id="iddle2473" significance="normal"><?indexkey G?><?primarykey granularity?><?secondarykey TIMER?><primary><emphasis role="strong">granularity</emphasis></primary><secondary>timer</secondary></indexterm><indexterm id="iddle2474" significance="normal"><?indexkey G?><?primarykey granularity?><?secondarykey TIMER?><?tertiarykey MEASUREMENT IMPACT?><primary><emphasis role="strong">granularity</emphasis></primary><secondary>timer</secondary><tertiary>measurement impact</tertiary></indexterm><indexterm id="iddle3188" significance="normal"><?indexkey M?><?primarykey measurement?><?secondarykey RESPONSIVENESS?><primary><emphasis role="strong">measurement</emphasis></primary><secondary>responsiveness</secondary></indexterm><indexterm id="iddle3649" significance="normal"><?indexkey P?><?primarykey predictability?><?secondarykey MEASURING?><primary><emphasis role="strong">predictability</emphasis></primary><secondary>measuring</secondary></indexterm><indexterm id="iddle3744" significance="normal"><?indexkey Q?><?primarykey quality of service?><primary><emphasis role="strong">quality of service</emphasis></primary></indexterm><indexterm id="iddle3745" significance="normal"><?indexkey Q?><?primarykey quality of service?><?secondarykey MEASURING?><primary><emphasis role="strong">quality of service</emphasis></primary><secondary>measuring</secondary></indexterm><indexterm id="iddle3957" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey MEASURING?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>measuring</secondary></indexterm><indexterm id="iddle4614" significance="normal"><?indexkey T?><?primarykey task(s)?><?secondarykey COMPLETION?><?tertiarykey SERVICE TIME VARIANCE RELATIONSHIP TO?><primary><emphasis role="strong">task(s)</emphasis></primary><secondary>completion</secondary><tertiary>service time variance relationship to</tertiary></indexterm><indexterm id="iddle4901" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey GRANULARITY?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>granularity</secondary></indexterm><indexterm id="iddle4902" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey GRANULARITY?><?tertiarykey MEASUREMENT IMPACT?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>granularity</secondary><tertiary>measurement impact</tertiary></indexterm><indexterm id="iddle5069" significance="normal"><?indexkey V?><?primarykey variance?><primary><emphasis role="strong">variance</emphasis></primary></indexterm><indexterm id="iddle5070" significance="normal"><?indexkey V?><?primarykey variance?><?secondarykey SERVICE TIME?><primary><emphasis role="strong">variance</emphasis></primary><secondary>service time</secondary></indexterm>GC overhead, a linked queue allows more concurrent access by <literal>put</literal>s and <literal>take</literal>s than an array-based queue because the best linked queue algorithms allow the head and tail to be updated independently. Because allocation is usually threadlocal, algorithms that can reduce contention by doing more allocation usually scale better. (This is another instance in which intuition based on traditional performance tuning runs counter to what is needed for scalability.)</para>
<figure float="1" id="ch12fig02" label="12.2" xreflabel="12.2" condition="264">

<title id="ch12fig02__title">Comparing Blocking Queue Implementations.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/12fig02_alt.gif"?><imagedata depth="255" fileref="graphics/12fig02.gif" format="GIF" role="stdwidth" width="500"/></imageobject></mediaobject>
</figure>
</section>
<section id="ch12lev2sec9" label="12.2.3" xreflabel="12.2.3">
<title id="ch12lev2sec9__title">Measuring Responsiveness</title>
<para>So far we have focused on measuring throughput, which is usually the most important performance metric for concurrent programs. But sometimes it is more important to know how long an individual action might take to complete, and in this case we want to measure the <emphasis>variance</emphasis> of service time. Sometimes it makes sense to allow a longer average service time if it lets us obtain a smaller variance; predictability is a valuable performance characteristic too. Measuring variance allows us to estimate the answers to quality-of-service questions like “What percentage of operations will succeed in under 100 milliseconds?”</para>
<para>Histograms of task completion times are normally the best way to visualize variance in service time. Variances are only slightly more difficult to measure than averages—you need to keep track of per-task completion times in addition to aggregate completion time. Since timer granularity can be a factor in measuring individual task time (an individual task may take less than or close to the smallest “timer tick”, which would distort measurements of task duration), to avoid measurement artifacts we can measure the run time of small batches of <literal>put</literal> and <literal>take</literal> operations instead.</para>
<para><?docpage num="265"?><indexterm id="iddle2324" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey NONFAIR SEMAPHORES VS. FAIR?><primary><emphasis role="strong">fairness</emphasis></primary><secondary>nonfair semaphores vs. fair</secondary></indexterm><indexterm id="iddle2325" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey NONFAIR SEMAPHORES VS. FAIR?><?tertiarykey PERFORMANCE MEASUREMENT?><primary><emphasis role="strong">fairness</emphasis></primary><secondary>nonfair semaphores vs. fair</secondary><tertiary>performance measurement</tertiary></indexterm><indexterm id="iddle3308" significance="normal"><?indexkey N?><?primarykey nonfair semaphores?><primary><emphasis role="strong">nonfair semaphores</emphasis></primary></indexterm><indexterm id="iddle3309" significance="normal"><?indexkey N?><?primarykey nonfair semaphores?><?secondarykey ADVANTAGES OF?><primary><emphasis role="strong">nonfair semaphores</emphasis></primary><secondary>advantages of</secondary></indexterm><indexterm id="iddle4153" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey FAIR VS. NONFAIR?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>fair vs. nonfair</secondary></indexterm><indexterm id="iddle4154" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey FAIR VS. NONFAIR?><?tertiarykey PERFORMANCE COMPARISON?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>fair vs. nonfair</secondary><tertiary>performance comparison</tertiary></indexterm><indexterm id="iddle4155" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey NONFAIR?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>nonfair</secondary></indexterm><indexterm id="iddle4156" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey NONFAIR?><?tertiarykey ADVANTAGES OF?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>nonfair</secondary><tertiary>advantages of</tertiary></indexterm><link linkend="ch12fig03" preference="1">Figure 12.3</link> shows the per-task completion times of a variant of <literal>TimedPutTakeTest</literal> using a buffer size of 1000 in which each of 256 concurrent tasks iterates only 1000 items for nonfair (shaded bars) and fair semaphores (open bars). (<link linkend="ch13lev1sec3" preference="0">Section 13.3</link> explains fair versus nonfair queueing for locks and semaphores.) Completion times for nonfair semaphores range from 104 to 8,714 ms, a factor of over eighty. It is possible to reduce this range by forcing more fairness in concurrency control; this is easy to do in <literal>BoundedBuffer</literal> by initializing the semaphores to fair mode. As <link linkend="ch12fig03" preference="1">Figure 12.3</link> shows, this succeeds in greatly reducing the variance (now ranging only from 38,194 to 38,207 ms), but unfortunately also greatly reduces the throughput. (A longer-running test with more typical kinds of tasks would probably show an even larger throughput reduction.)</para>
<figure float="1" id="ch12fig03" label="12.3" xreflabel="12.3" condition="265">

<title id="ch12fig03__title">Completion Time Histogram for <literal>TimedPutTakeTest</literal> with Default (Nonfair) and Fair Semaphores.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/12fig03_alt.gif"?><imagedata depth="260" fileref="graphics/12fig03.gif" format="GIF" role="stdwidth" width="500"/></imageobject></mediaobject>
</figure>
<para>We saw before that very small buffer sizes cause heavy context switching and poor throughput even in nonfair mode, because nearly every operation involves a context switch. As an indication that the cost of fairness results primarily from blocking threads, we can rerun this test with a buffer size of one and see that nonfair semaphores now perform comparably to fair semaphores. <link linkend="ch12fig04" preference="1">Figure 12.4</link> shows that fairness doesn’t make the average much worse or the variance much better in this case.</para>
<figure float="1" id="ch12fig04" label="12.4" xreflabel="12.4" condition="266">
<?docpage num="266"?>
<title id="ch12fig04__title">Completion Time Histogram for <literal>TimedPutTakeTest</literal> with Single-item Buffers.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/12fig04_alt.gif"?><imagedata depth="304" fileref="graphics/12fig04.gif" format="GIF" role="stdwidth" width="500"/></imageobject></mediaobject>
</figure>
<para>So, unless threads are continually blocking anyway because of tight synchronization requirements, nonfair semaphores provide much better throughput and fair semaphores provides lower variance. Because the results are so dramatically different, <literal>Semaphore</literal> forces its clients to decide which of the two factors to optimize for.</para>
</section>
</section>
<section id="ch12lev1sec3" condition="266" label="12.3" xreflabel="12.3">
<?docpage num="266"?>
<title id="ch12lev1sec3__title">Avoiding Performance Testing Pitfalls</title>
<para><indexterm id="iddle2441" significance="normal"><?indexkey G?><?primarykey garbage collection?><primary><emphasis role="strong">garbage collection</emphasis></primary></indexterm><indexterm id="iddle2442" significance="normal"><?indexkey G?><?primarykey garbage collection?><?secondarykey AS PERFORMANCE TESTING PITFALL?><primary><emphasis role="strong">garbage collection</emphasis></primary><secondary>as performance testing pitfall</secondary></indexterm><indexterm id="iddle3539" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TESTING?><?tertiarykey PITFALLS, AVOIDING?><primary><emphasis role="strong">performance</emphasis></primary><secondary>testing</secondary><tertiary>pitfalls, avoiding</tertiary></indexterm><indexterm id="iddle4702" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary></indexterm><indexterm id="iddle4703" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><?tertiarykey AVOIDING?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary><tertiary>avoiding</tertiary></indexterm><indexterm id="iddle4706" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><?tertiarykey GARBAGE COLLECTION?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary><tertiary>garbage collection</tertiary></indexterm>In theory, developing performance tests is easy—find a typical usage scenario, write a program that executes that scenario many times, and time it. In practice, you have to watch out for a number of coding pitfalls that prevent performance tests from yielding meaningful results.</para>
<section id="ch12lev2sec10" label="12.3.1" xreflabel="12.3.1">
<title id="ch12lev2sec10__title">Garbage Collection</title>
<para>The timing of garbage collection is unpredictable, so there is always the possibility that the garbage collector will run during a measured test run. If a test program performs <emphasis>N</emphasis> iterations and triggers no garbage collection but iteration <emphasis>N</emphasis> + 1would trigger a garbage collection, a small variation in the size of the run could have a big (but spurious) effect on the measured time per iteration.</para>
<para>There are two strategies for preventing garbage collection from biasing your results. One is to ensure that garbage collection does not run at all during your test (you can invoke the JVM with <literal>-verbose:gc</literal> to find out); alternatively, you can make sure that the garbage collector runs a number of times during your run so that the test program adequately reflects the cost of ongoing allocation and garbage collection. The latter strategy is often better—it requires a longer test and is more likely to reflect real-world performance.</para>
<para>Most producer-consumer applications involve a fair amount of allocation and garbage collection—producers allocate new objects that are used and discarded by consumers. Running the bounded buffer test for long enough to incur multiple garbage collections yields more accurate results.</para>
</section>
<section id="ch12lev2sec11" condition="267" label="12.3.2" xreflabel="12.3.2">
<?docpage num="267"?>
<title id="ch12lev2sec11__title">Dynamic Compilation</title>
<para><indexterm id="iddle1392" significance="normal"><?indexkey C?><?primarykey compilation?><primary><emphasis role="strong">compilation</emphasis></primary></indexterm><indexterm id="iddle1393" significance="normal"><?indexkey C?><?primarykey compilation?><?secondarykey DYNAMIC?><primary><emphasis role="strong">compilation</emphasis></primary><secondary>dynamic</secondary></indexterm><indexterm id="iddle1394" significance="normal"><?indexkey C?><?primarykey compilation?><?secondarykey DYNAMIC?><?tertiarykey AND PERFORMANCE TESTING?><primary><emphasis role="strong">compilation</emphasis></primary><secondary>dynamic</secondary><tertiary>and performance testing</tertiary></indexterm><indexterm id="iddle1976" significance="normal"><?indexkey D?><?primarykey dynamic?><?secondarykey COMPILATION?><primary><emphasis role="strong">dynamic</emphasis></primary><secondary>compilation</secondary></indexterm><indexterm id="iddle1977" significance="normal"><?indexkey D?><?primarykey dynamic?><?secondarykey COMPILATION?><?tertiarykey AS PERFORMANCE TESTING PITFALL?><primary><emphasis role="strong">dynamic</emphasis></primary><secondary>compilation</secondary><tertiary>as performance testing pitfall</tertiary></indexterm><indexterm id="iddle2658" significance="normal"><?indexkey H?><?primarykey HotSpot JVM?><primary><emphasis role="strong">HotSpot JVM</emphasis></primary></indexterm><indexterm id="iddle2659" significance="normal"><?indexkey H?><?primarykey HotSpot JVM?><?secondarykey DYNAMIC COMPILATION USE?><primary><emphasis role="strong">HotSpot JVM</emphasis></primary><secondary>dynamic compilation use</secondary></indexterm><indexterm id="iddle4705" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><?tertiarykey DYNAMIC COMPILATION?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary><tertiary>dynamic compilation</tertiary></indexterm><indexterm id="iddle4899" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey DYNAMIC COMPILATION?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>dynamic compilation</secondary></indexterm><indexterm id="iddle4900" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey DYNAMIC COMPILATION?><?tertiarykey AS PERFORMANCE TESTING PITFALL?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>dynamic compilation</secondary><tertiary>as performance testing pitfall</tertiary></indexterm>Writing and interpreting performance benchmarks for dynamically compiled languages like Java is far more difficult than for statically compiled languages like C or C++. The HotSpot JVM (and other modern JVMs) uses a combination of bytecode interpretation and dynamic compilation. When a class is first loaded, the JVM executes it by interpreting the bytecode. At some point, if a method is run often enough, the dynamic compiler kicks in and converts it to machine code; when compilation completes, it switches from interpretation to direct execution.</para>
<para>The timing of compilation is unpredictable. Your timing tests should run only after all code has been compiled; there is no value in measuring the speed of the interpreted code since most programs run long enough that all frequently executed code paths are compiled. Allowing the compiler to run during a measured test run can bias test results in two ways: compilation consumes CPU resources, and measuring the run time of a combination of interpreted and compiled code is not a meaningful performance metric. <link linkend="ch12fig05" preference="1">Figure 12.5</link> shows how this can bias your results. The three timelines represent the execution of the same number of iterations: timeline <emphasis>A</emphasis> represents all interpreted execution, <emphasis>B</emphasis> represents compilation halfway through the run, and <emphasis>C</emphasis> represents compilation early in the run. The point at which compilation runs seriously affects the measured per-operation runtime.<footnote id="ch12fn07" label="7"><para>The JVMmay choose to perform compilation in the application thread or in the background thread; each can bias timing results in different ways.</para></footnote></para>
<figure float="1" id="ch12fig05" label="12.5" xreflabel="12.5" condition="267">

<title id="ch12fig05__title">Results Biased by Dynamic Compilation.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="190" fileref="graphics/12fig05.gif" format="GIF" width="500"/></imageobject>

</mediaobject>
</figure>
<para>Code may also be decompiled (reverting to interpreted execution) and recompiled for various reasons, such as loading a class that invalidates assumptions made by prior compilations, or gathering sufficient profiling data to decide that a code path should be recompiled with different optimizations.</para>
<para>One way to to prevent compilation from biasing your results is to run your program for a long time (at least several minutes) so that compilation and interpreted execution represent a small fraction of the total run time. Another approach is to use an unmeasured “warm-up” run, in which your code is executed enough to be fully compiled when you actually start timing. On HotSpot, running your program with <literal>-XX:+PrintCompilation</literal> prints out a message when <?docpage num="268"?><indexterm id="iddle1434" significance="normal"><?indexkey C?><?primarykey computation?><?secondarykey THREAD-LOCAL?><primary><emphasis role="strong">computation</emphasis></primary><secondary>thread-local</secondary></indexterm><indexterm id="iddle1435" significance="normal"><?indexkey C?><?primarykey computation?><?secondarykey THREAD-LOCAL?><?tertiarykey AND PERFORMANCE TESTING?><primary><emphasis role="strong">computation</emphasis></primary><secondary>thread-local</secondary><tertiary>and performance testing</tertiary></indexterm><indexterm id="iddle1609" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey UNREALISTIC DEGREES OF?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>unrealistic degrees of</secondary></indexterm><indexterm id="iddle1610" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey UNREALISTIC DEGREES OF?><?tertiarykey AS PERFORMANCE TESTING PITFALL?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>unrealistic degrees of</secondary><tertiary>as performance testing pitfall</tertiary></indexterm><indexterm id="iddle2914" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><seealso> <link linkend="iddle1714" preference="0"><emphasis role="strong">CPU utilization</emphasis>, optimization</link>.</seealso></indexterm><indexterm id="iddle3256" significance="normal"><?indexkey M?><?primarykey monomorphic call transformation?><primary><emphasis role="strong">monomorphic call transformation</emphasis></primary></indexterm><indexterm id="iddle3380" significance="normal"><?indexkey O?><?primarykey optimization?><primary><emphasis role="strong">optimization</emphasis></primary></indexterm><indexterm id="iddle3381" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey COMPILER?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>compiler</secondary></indexterm><indexterm id="iddle3382" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey COMPILER?><?tertiarykey AS PERFORMANCE TESTING PITFALL?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>compiler</secondary><tertiary>as performance testing pitfall</tertiary></indexterm><indexterm id="iddle4710" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><?tertiarykey UNREALISTIC CODE PATH SAMPLING?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary><tertiary>unrealistic code path sampling</tertiary></indexterm><indexterm id="iddle4711" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><?tertiarykey UNREALISTIC CONTENTION?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary><tertiary>unrealistic contention</tertiary></indexterm><indexterm id="iddle4839" significance="normal"><?indexkey T?><?primarykey thread-local?><?secondarykey COMPUTATION?><primary><emphasis role="strong">thread-local</emphasis></primary><secondary>computation</secondary></indexterm><indexterm id="iddle4840" significance="normal"><?indexkey T?><?primarykey thread-local?><?secondarykey COMPUTATION?><?tertiarykey ROLE IN ACCURATE PERFORMANCE TESTING?><primary><emphasis role="strong">thread-local</emphasis></primary><secondary>computation</secondary><tertiary>role in accurate performance testing</tertiary></indexterm><indexterm id="iddle4986" significance="normal"><?indexkey T?><?primarykey tuning?><primary><emphasis role="strong">tuning</emphasis></primary><seealso> <link linkend="iddle1714" preference="0"><emphasis role="strong">CPU utilization</emphasis>, optimization</link>.</seealso></indexterm>dynamic compilation runs, so you can verify that this is prior to, rather than during, measured test runs.</para>
<para>Running the same test several times in the same JVM instance can be used to validate the testing methodology. The first group of results should be discarded as warm-up; seeing inconsistent results in the remaining groups suggests that the test should be examined further to determine why the timing results are not repeatable.</para>
<para>The JVM uses various background threads for housekeeping tasks. When measuring multiple <emphasis>unrelated</emphasis> computationally intensive activities in a single run, it is a good idea to place explicit pauses between the measured trials to give the JVM a chance to catch up with background tasks with minimal interference from measured tasks. (When measuring multiple related activities, however, such as multiple runs of the same test, excluding JVM background tasks in this way may give unrealistically optimistic results.)</para>
</section>
<section id="ch12lev2sec12" label="12.3.3" xreflabel="12.3.3">
<title id="ch12lev2sec12__title">Unrealistic Sampling of Code Paths</title>
<para>Runtime compilers use profiling information to help optimize the code being compiled. The JVM is permitted to use information specific to the execution in order to produce better code, which means that compiling method <emphasis>M</emphasis> in one program may generate different code than compiling <emphasis>M</emphasis> in another. In some cases, the JVM may make optimizations based on assumptions that may only be true temporarily, and later back them out by invalidating the compiled code if they become untrue.<footnote id="ch12fn08" label="8"><para>For example, the JVM can use <emphasis>monomorphic call transformation</emphasis> to convert a virtual method call to a direct method call if no classes currently loaded override that method, but it invalidates the compiled code if a class is subsequently loaded that overrides the method.</para></footnote></para>
<para>As a result, it is important that your test programs not only adequately approximate the usage patterns of a typical application, but also approximate the set of code paths used by such an application. Otherwise, a dynamic compiler could make special optimizations to a purely single-threaded test program that could not be applied in real applications containing at least occasional parallelism. Therefore, tests of multithreaded performance should normally be mixed with tests of single-threaded performance, even if you want to measure only singlethreaded performance. (This issue does not arise in <literal>TimedPutTakeTest</literal> because even the smallest test case uses two threads.)</para>
</section>
<section id="ch12lev2sec13" label="12.3.4" xreflabel="12.3.4">
<title id="ch12lev2sec13__title">Unrealistic Degrees of Contention</title>
<para>Concurrent applications tend to interleave two very different sorts of work: accessing shared data, such as fetching the next task from a shared work queue, and thread-local computation (executing the task, assuming the task itself does not access shared data). Depending on the relative proportions of the two types of work, the application will experience different levels of contention and exhibit different performance and scaling behaviors.</para>
<para>If <emphasis>N</emphasis> threads are fetching tasks from a shared work queue and executing them, and the tasks are compute-intensive and long-running (and do not access shared <?docpage num="269"?><indexterm id="iddle1787" significance="normal"><?indexkey D?><?primarykey dead-code elimination?><primary><emphasis role="strong">dead-code elimination</emphasis></primary></indexterm><indexterm id="iddle1788" significance="normal"><?indexkey D?><?primarykey dead-code elimination?><?secondarykey AND PERFORMANCE TESTING?><primary><emphasis role="strong">dead-code elimination</emphasis></primary><secondary>and performance testing</secondary></indexterm><indexterm id="iddle4704" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey PITFALLS?><?tertiarykey DEAD CODE ELIMINATION?><primary><emphasis role="strong">testing</emphasis></primary><secondary>pitfalls</secondary><tertiary>dead code elimination</tertiary></indexterm>data very much), there will be almost no contention; throughput is dominated by the availability of CPU resources. On the other hand, if the tasks are very short-lived, there will be a lot of contention for the work queue and throughput is dominated by the cost of synchronization.</para>
<para>To obtain realistic results, concurrent performance tests should try to approximate the thread-local computation done by a typical application in addition to the concurrent coordination under study. If the the work done for each task in an application is significantly different in nature or scope from the test program, it is easy to arrive at unwarranted conclusions about where the performance bottlenecks lie. We saw in <link linkend="ch11lev1sec5" preference="0">Section 11.5</link> that, for lock-based classes such as the synchronized <literal>Map</literal> implementations, whether access to the lock is mostly contended or mostly uncontended can have a dramatic effect on throughput. The tests in that section do nothing but pound on the <literal>Map</literal>; even with two threads, all attempts to access the <literal>Map</literal> are contended. However, if an application did a significant amount of thread-local computation for each time it accesses the shared data structure, the contention level might be low enough to offer good performance.</para>
<para>In this regard, <literal>TimedPutTakeTest</literal> may be a poor model for some applications. Since the worker threads do not do very much, throughput is dominated by coordination overhead, and this is not necessarily the case in all applications that exchange data between producers and consumers via bounded buffers.</para>
</section>
<section id="ch12lev2sec14" label="12.3.5" xreflabel="12.3.5">
<title id="ch12lev2sec14__title">Dead Code Elimination</title>
<para>One of the challenges of writing good benchmarks (in any language) is that optimizing compilers are adept at spotting and eliminating dead code—code that has no effect on the outcome. Since benchmarks often don’t compute anything, they are an easy target for the optimizer. Most of the time, it is a good thing when the optimizer prunes dead code from a program, but for a benchmark this is a big problem because then you are measuring less execution than you think. If you’re lucky, the optimizer will prune away your <emphasis>entire</emphasis> program, and then it will be obvious that your data is bogus. If you’re unlucky, dead-code elimination will just speed up your program by some factor that <emphasis>could</emphasis> be explained by other means.</para>
<para>Dead-code elimination is a problem in benchmarking statically compiled languages too, but detecting that the compiler has eliminated a good chunk of your benchmark is a lot easier because you can look at the machine code and see that a part of your program is missing. With dynamically compiled languages, that information is not easily accessible.</para>
<para>Many microbenchmarks perform much “better” when run with HotSpot’s <literal>-server</literal> compiler than with <literal>-client</literal>, not just because the server compiler can produce more efficient code, but also because it is more adept at optimizing dead code. Unfortunately, the dead-code elimination that made such short work of your benchmark won’t do quite as well with code that actually does something. But you should still prefer <literal>-server</literal> to <literal>-client</literal> for both production and testing on multiprocessor systems—you just have to write your tests so that they are not susceptible to dead-code elimination.</para>
<sidebar float="1" id="ch12sb03" condition="269"><title/>
<para><?docpage num="270"?><indexterm id="iddle2598" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey TESTING?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>testing</secondary></indexterm><indexterm id="iddle2599" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey TESTING?><?tertiarykey EFFECTIVE PERFORMANCE TESTS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>testing</secondary><tertiary>effective performance tests</tertiary></indexterm><indexterm id="iddle3743" significance="normal"><?indexkey Q?><?primarykey quality assurance?><?secondarykey STRATEGIES?><primary><emphasis role="strong">quality assurance</emphasis></primary><secondary>strategies</secondary></indexterm><indexterm id="iddle4715" significance="normal"><?indexkey T?><?primarykey testing?><?secondarykey STRATEGIES?><primary><emphasis role="strong">testing</emphasis></primary><secondary>strategies</secondary></indexterm>Writing effective performance tests requires tricking the optimizer into not optimizing away your benchmark as dead code. This requires every computed result to be used somehow by your program—in a way that does not require synchronization or substantial computation.</para>
</sidebar>
<para>In <literal>PutTakeTest</literal>, we compute the checksum of elements added to and removed from the queue and combine these checksums across all the threads, but this could still be optimized away if we do not actually <emphasis>use</emphasis> the checksum value. We happen to need it to verify the correctness of the algorithm, but you can ensure that a value is used by printing it out. However, you should avoid doing I/O while the test is actually running, so as not to distort the run time measurement.</para>
<para>A cheap trick for preventing a calculation from being optimized away without introducing too much overhead is to compute the <literal>hashCode</literal> of the field of some derived object, compare it to an arbitrary value such as the current value of <literal>System. nanoTime</literal>, and print a useless and ignorable message if they happen to match:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">if (foo.x.hashCode() == System.nanoTime())
    System.out.print(" ");
</programlisting>
</informalexample>
<para>The comparison will rarely succeed, and if it does, its only effect will be to insert a harmless space character into the output. (The <literal>print</literal> method buffers output until <literal>println</literal> is called, so in the rare case that <literal>hashCode</literal> and <literal>System.nanoTime</literal> are equal no I/O is actually performed.)</para>
<para>Not only should every computed result be used, but results should also be unguessable. Otherwise, a smart dynamic optimizing compiler is allowed to replace actions with precomputed results. We addressed this in the construction of <literal>PutTakeTest</literal>, but any test program whose input is static data is vulnerable to this optimization.</para>
</section>
</section>
<section id="ch12lev1sec4" condition="269" label="12.4" xreflabel="12.4"><?docpage num="269"?><?docpage num="270"?>
<title id="ch12lev1sec4__title">Complementary Testing Approaches</title>
<para>While we’d like to believe that an effective testing program should “find all the bugs”, this is an unrealistic goal. NASA devotes more of its engineering resources to testing (it is estimated they employ 20 testers for each developer) than any commercial entity could afford to—and the code produced is still not free of defects. In complex programs, no amount of testing can find all coding errors.</para>
<para>The goal of testing is not so much to <emphasis>find errors</emphasis> as it is to <emphasis>increase confidence</emphasis> that the code works as expected. Since it is unrealistic to assume you can find all the bugs, the goal of a quality assurance (QA) plan should be to achieve the greatest possible confidence given the testing resources available. More things can go wrong in a concurrent program than in a sequential one, and therefore more testing is required to achieve the same level of confidence. So far we’ve focused primarily on techniques for constructing effective unit and performance tests. Testing is critically important for building confidence that concurrent classes behave correctly, but should be only one of the QA metholologies you employ.</para>
<para><?docpage num="271"?><indexterm id="iddle1273" significance="normal"><?indexkey B?><?primarykey bug pattern(s)?><primary><emphasis role="strong">bug pattern(s)</emphasis></primary><seealso> <link linkend="iddle1462" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, debugging</link>.</seealso></indexterm><indexterm id="iddle1274" significance="normal"><?indexkey B?><?primarykey bug pattern(s)?><primary><emphasis role="strong">bug pattern(s)</emphasis></primary><seealso> <link linkend="iddle1943" preference="0"><emphasis role="strong">design patterns</emphasis></link>.</seealso></indexterm><indexterm id="iddle1275" significance="normal"><?indexkey B?><?primarykey bug pattern(s)?><primary><emphasis role="strong">bug pattern(s)</emphasis></primary><seealso> <link linkend="iddle1272" preference="0"><emphasis role="strong">buffer(s)</emphasis>, testing</link>.</seealso></indexterm><indexterm id="iddle1276" significance="normal"><?indexkey B?><?primarykey bug pattern(s)?><primary><emphasis role="strong">bug pattern(s)</emphasis></primary></indexterm><indexterm id="iddle1277" significance="normal"><?indexkey B?><?primarykey bug pattern(s)?><?secondarykey DETECTOR?><primary><emphasis role="strong">bug pattern(s)</emphasis></primary><secondary>detector</secondary></indexterm><indexterm id="iddle1369" significance="normal"><?indexkey C?><?primarykey code review?><primary><emphasis role="strong">code review</emphasis></primary></indexterm><indexterm id="iddle1370" significance="normal"><?indexkey C?><?primarykey code review?><?secondarykey AS QUALITY ASSURANCE STRATEGY?><primary><emphasis role="strong">code review</emphasis></primary><secondary>as quality assurance strategy</secondary></indexterm><indexterm id="iddle2363" significance="normal"><?indexkey F?><?primarykey FindBugs code auditing tool?><?secondarykey AS STATIC ANALYSIS TOOL EXAMPLE?><primary><emphasis role="strong">FindBugs code auditing tool</emphasis></primary><secondary>as static analysis tool example</secondary></indexterm><indexterm id="iddle3840" significance="normal"><?indexkey R?><?primarykey release?><?secondarykey LOCK?><?tertiarykey UNRELEASED LOCK BUG PATTERN?><primary><emphasis role="strong">release</emphasis></primary><secondary>lock</secondary><tertiary>unreleased lock bug pattern</tertiary></indexterm><indexterm id="iddle4441" significance="normal"><?indexkey S?><?primarykey static analysis tools?><primary><emphasis role="strong">static analysis tools</emphasis></primary></indexterm><indexterm id="iddle4556" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey INCONSISTENT?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>inconsistent</secondary></indexterm><indexterm id="iddle4557" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey INCONSISTENT?><?tertiarykey AS CONCURRENCY BUG PATTERN?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>inconsistent</secondary><tertiary>as concurrency bug pattern</tertiary></indexterm><indexterm id="iddle4953" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey STATIC ANALYSIS?><primary><emphasis role="strong">tools</emphasis></primary><secondary>static analysis</secondary></indexterm>Different QA methodologies are more effective at finding some types of defects and less effective at finding others. By employing complementary testing methodologies such as code review and static analysis, you can achieve greater confidence than you could with any single approach.</para>
<section id="ch12lev2sec15" label="12.4.1" xreflabel="12.4.1">
<title id="ch12lev2sec15__title">Code Review</title>
<para>As effective and important as unit and stress tests are for finding concurrency bugs, they are no substitute for rigorous code review by multiple people. (On the other hand, code review is no substitute for testing either.) You can and should design tests to maximize their chances of discovering safety errors, and you should run them frequently, but you should not neglect to have concurrent code reviewed carefully by someone besides its author. Even concurrency experts make mistakes; taking the time to have someone else review the code is almost always worthwhile. Expert concurrent programmers are better at finding subtle races than are most test programs. (Also, platform issues such as JVM implementation details or processor memory models can prevent bugs from showing up on particular hardware or software configurations.) Code review also has other benefits; not only can it find errors, but it often improves the quality of comments describing the implementation details, thus reducing future maintenence cost and risk.</para>
</section>
<section id="ch12lev2sec16" label="12.4.2" xreflabel="12.4.2">
<title id="ch12lev2sec16__title">Static Analysis Tools</title>
<para>As of this writing, <emphasis>static analysis tools</emphasis> are rapidly emerging as an effective complement to formal testing and code review. Static code analysis is the process of analyzing code without executing it, and code auditing tools can analyze classes to look for instances of common <emphasis>bug patterns</emphasis>. Static analysis tools such as the open-source FindBugs<footnote id="ch12fn09" label="9"><para><literal><ulink url="http://findbugs.sourceforge.net">http://findbugs.sourceforge.net</ulink></literal></para></footnote> contain <emphasis>bug-pattern detectors</emphasis> for many common coding errors, many of which can easily be missed by testing or code review.</para>
<para>Static analysis tools produce a list of warnings that must be examined by hand to determine whether they represent actual errors. Historically, tools like <literal>lint</literal> produced so many false warnings as to scare developers away, but tools like FindBugs have been tuned to produce many fewer false alarms. Static analysis tools are still somewhat primitive (especially in their integration with development tools and lifecycle), but they are already effective enough to be a valuable addition to the testing process.</para>
<para>As of this writing, FindBugs includes detectors for the following concurrencyrelated bug patterns, and more are being added all the time:</para>
<formalpara><title><emphasis role="strong"><?design?>Inconsistent synchronization.</emphasis></title><para>Many objects follow the synchronization policy of guarding all variables with the object’s intrinsic lock. If a field is accessed frequently but not always with the <literal>this</literal> lock held, this may indicate that the synchronization policy is not being consistently followed.</para></formalpara>
<para>Analysis tools must guess at the synchronization policy because Java classes do not have formal concurrency specifications. In the future, if annotations <?docpage num="272"?><indexterm id="iddle1572" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey STARTING THREAD FROM?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary>starting thread from</secondary></indexterm><indexterm id="iddle1573" significance="normal"><?indexkey C?><?primarykey construction/constructors?><?secondarykey STARTING THREAD FROM?><?tertiarykey AS CONCURRENCY BUG PATTERN?><primary><emphasis role="strong">construction/constructors</emphasis></primary><secondary>starting thread from</secondary><tertiary>as concurrency bug pattern</tertiary></indexterm><indexterm id="iddle1970" significance="normal"><?indexkey D?><?primarykey double-checked locking (DCL)?><?secondarykey AS CONCURRENCY BUG PATTERN?><primary><emphasis role="strong">double-checked locking (DCL)</emphasis></primary><secondary>as concurrency bug pattern</secondary></indexterm><indexterm id="iddle3088" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey DOUBLE-CHECKED?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>double-checked</secondary></indexterm><indexterm id="iddle3089" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey DOUBLE-CHECKED?><?tertiarykey AS CONCURRENCY BUG PATTERN?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>double-checked</secondary><tertiary>as concurrency bug pattern</tertiary></indexterm><indexterm id="iddle3159" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey UNRELEASED?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>unreleased</secondary></indexterm><indexterm id="iddle3160" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey UNRELEASED?><?tertiarykey AS CONCURRENCY BUG PATTERN?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>unreleased</secondary><tertiary>as concurrency bug pattern</tertiary></indexterm><indexterm id="iddle3324" significance="normal"><?indexkey N?><?primarykey notification?><?secondarykey ERRORS?><primary><emphasis role="strong">notification</emphasis></primary><secondary>errors</secondary></indexterm><indexterm id="iddle3325" significance="normal"><?indexkey N?><?primarykey notification?><?secondarykey ERRORS?><?tertiarykey AS CONCURRENCY BUG PATTERN?><primary><emphasis role="strong">notification</emphasis></primary><secondary>errors</secondary><tertiary>as concurrency bug pattern</tertiary></indexterm><indexterm id="iddle5136" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey CONDITION?><?tertiarykey ERRORS, AS CONCURRENCY BUG PATTERN?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>condition</secondary><tertiary>errors, as concurrency bug pattern</tertiary></indexterm>such as <literal>@GuardedBy</literal> are standardized, auditing tools could interpret annotations rather than having to guess at the relationship between variables and locks, thus improving the quality of analysis.</para>
<formalpara><title><emphasis role="strong"><?design?>Invoking <literal>Thread.run</literal>.</emphasis></title><para><literal>Thread</literal> implements <literal>Runnable</literal> and therefore has a <literal>run</literal> method. However, it is almost always a mistake to call <literal>Thread.run</literal> directly; usually the programmer meant to call <literal>Thread.start</literal>.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Unreleased lock.</emphasis></title><para>Unlike intrinsic locks, explicit locks (see <link linkend="ch13" preference="0">Chapter 13</link>) are not automatically released when control exits the scope in which they were acquired. The standard idiom is to release the lock from a <literal>finally</literal> block; otherwise the lock can remain unreleased in the event of an <literal>Exception</literal>.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Empty <literal>synchronized</literal> block.</emphasis></title><para>While empty <literal>synchronized</literal> blocks do have semantics under the Java Memory Model, they are frequently used incorrectly, and there are usually better solutions to whatever problem the developer was trying to solve.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Double-checked locking.</emphasis></title><para>Double-checked locking is a broken idiom for reducing synchronization overhead in lazy initialization (see <link linkend="ch16lev2sec8" preference="0">Section 16.2.4</link>) that involves reading a shared mutable field without appropriate synchronization.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Starting a thread from a constructor.</emphasis></title><para>Starting a thread from a constructor introduces the risk of subclassing problems, and can allow the <literal>this</literal> reference to escape the constructor.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Notification errors.</emphasis></title><para>The <literal>notify</literal> and <literal>notifyAll</literal> methods indicate that an object’s state may have changed in a way that would unblock threads that are waiting on the associated condition queue. These methods should be called only when the state associated with the condition queue has changed. A <literal>synchronized</literal> block that calls <literal>notify</literal> or <literal>notifyAll</literal> but does not modify any state is likely to be an error. (See <link linkend="ch14" preference="0">Chapter 14</link>.)</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Condition wait errors.</emphasis></title><para>When waiting on a condition queue, <literal>Object.wait</literal> or <literal>Condition. await</literal> should be called in a loop, with the appropriate lock held, after testing some state predicate (see <link linkend="ch14" preference="0">Chapter 14</link>). Calling <literal>Object.wait</literal> or <literal>Condition.await</literal> without the lock held, not in a loop, or without testing some state predicate is almost certainly an error.</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Misuse of <literal>Lock</literal> and <literal>Condition</literal>.</emphasis></title><para>Using a <literal>Lock</literal> as the lock argument for a <literal>synchronized</literal> block is likely to be a typo, as is calling <literal>Condition.wait</literal> instead of <literal>await</literal> (though the latter would likely be caught in testing, since it would throw an <literal>IllegalMonitorStateException</literal> the first time it was called).</para></formalpara>
<formalpara><title><emphasis role="strong"><?design?>Sleeping or waiting while holding a lock.</emphasis></title><para>Calling <literal>Thread.sleep</literal> with a lock held can prevent other threads from making progress for a long time and is therefore a potentially serious liveness hazard. Calling <literal>Object.wait</literal> or <literal>Condition.await</literal> with two locks held poses a similar hazard.</para></formalpara>
<formalpara><?docpage num="273"?><title><emphasis role="strong"><?design?>Spin loops.</emphasis></title><para><indexterm id="iddle1103" significance="normal"><?indexkey A?><?primarykey AOP (aspect-oriented programming)?><?secondarykey IN TESTING?><primary><emphasis role="strong">AOP (aspect-oriented programming)</emphasis></primary><secondary>in testing</secondary></indexterm><indexterm id="iddle3254" significance="normal"><?indexkey M?><?primarykey monitoring?><?secondarykey TOOLS?><primary><emphasis role="strong">monitoring</emphasis></primary><secondary>tools</secondary></indexterm><indexterm id="iddle3255" significance="normal"><?indexkey M?><?primarykey monitoring?><?secondarykey TOOLS?><?tertiarykey FOR QUALITY ASSURANCE?><primary><emphasis role="strong">monitoring</emphasis></primary><secondary>tools</secondary><tertiary>for quality assurance</tertiary></indexterm><indexterm id="iddle3695" significance="normal"><?indexkey P?><?primarykey profiling?><?secondarykey TOOLS?><?tertiarykey QUALITY ASSURANCE?><primary><emphasis role="strong">profiling</emphasis></primary><secondary>tools</secondary><tertiary>quality assurance</tertiary></indexterm><indexterm id="iddle4344" significance="normal"><?indexkey S?><?primarykey spin-waiting?><?secondarykey AS CONCURRENCY BUG PATTERN?><primary><emphasis role="strong">spin-waiting</emphasis></primary><secondary>as concurrency bug pattern</secondary></indexterm><indexterm id="iddle4847" significance="normal"><?indexkey T?><?primarykey ThreadInfo?><primary><emphasis role="strong">ThreadInfo</emphasis></primary></indexterm><indexterm id="iddle4848" significance="normal"><?indexkey T?><?primarykey ThreadInfo?><?secondarykey AND TESTING?><primary><emphasis role="strong">ThreadInfo</emphasis></primary><secondary>and testing</secondary></indexterm><indexterm id="iddle4947" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey MONITORING?><primary><emphasis role="strong">tools</emphasis></primary><secondary>monitoring</secondary></indexterm><indexterm id="iddle4948" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey MONITORING?><?tertiarykey QUALITY ASSURANCE USE?><primary><emphasis role="strong">tools</emphasis></primary><secondary>monitoring</secondary><tertiary>quality assurance use</tertiary></indexterm><indexterm id="iddle4952" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey PROFILING?><?tertiarykey QUALITY ASSURANCE USE?><primary><emphasis role="strong">tools</emphasis></primary><secondary>profiling</secondary><tertiary>quality assurance use</tertiary></indexterm><indexterm id="iddle5143" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey SPIN-WAITING?><?tertiarykey AS CONCURRENCY BUG PATTERN?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>spin-waiting</secondary><tertiary>as concurrency bug pattern</tertiary></indexterm>Code that does nothing but spin (busy wait) checking a field for an expected value can waste CPU time and, if the field is not volatile, is not guaranteed to terminate. Latches or condition waits are often a better technique when waiting for a state transition to occur.</para></formalpara>
</section>
<section id="ch12lev2sec17" label="12.4.3" xreflabel="12.4.3">
<title id="ch12lev2sec17__title">Aspect-oriented Testing Techniques</title>
<para>As of this writing, aspect-oriented programming (AOP) techniques have only limited applicability to concurrency, because most popular AOP tools do not yet support pointcuts at synchronization points. However, AOP can be applied to assert invariants or some aspects of compliance with synchronization policies. For example, (<link linkend="biblio01_020" preference="0">Laddad, 2003</link>) provides an example of using an aspect to wrap all calls to non-thread-safe Swing methods with the assertion that the call is occurring in the event thread. As it requires no code changes, this technique is easy to apply and can disclose subtle publication and thread-confinement errors.</para>
</section>
<section id="ch12lev2sec18" label="12.4.4" xreflabel="12.4.4">
<title id="ch12lev2sec18__title">Profilers and Monitoring Tools</title>
<para>Most commercial profiling tools have some support for threads. They vary in feature set and effectiveness, but can often provide insight into what your program is doing (although profiling tools are usually intrusive and can substantially affect program timing and behavior). Most offer a display showing a timeline for each thread with different colors for the various thread states (runnable, blocked waiting for a lock, blocked waiting for I/O, etc.). Such a display can show how effectively your program is utilizing the available CPU resources, and if it is doing badly, where to look for the cause. (Many profilers also claim features for identifying which locks are causing contention, but in practice these features are often a blunter instrument than is desired for analyzing a program’s locking behavior.)</para>
<para>The built-in JMX agent also offers some limited features for monitoring thread behavior. The <literal>ThreadInfo</literal> class includes the thread’s current state and, if the thread is blocked, the lock or condition queue on which it is blocked. If the “thread contention monitoring” feature is enabled (it is disabled by default because of its performance impact), <literal>ThreadInfo</literal> also includes the number of times that the thread has blocked waiting for a lock or notification, and the cumulative amount of time it has spent waiting.</para>
</section>
</section>



<section id="ch12lev1sec5" condition="273" label="" xreflabel=""><?docpage num="273"?>
<title id="ch12lev1sec5__title">Summary</title>
<para>Testing concurrent programs for correctness can be extremely challenging because many of the possible failure modes of concurrent programs are low-probability events that are sensitive to timing, load, and other hard-to-reproduce conditions. Further, the testing infrastructure can introduce additional synchronization or timing constraints that can mask concurrency problems in the code being tested. Testing concurrent programs for performance can be equally challenging; Java programs are more difficult to test than programs written in statically compiled languages like C, because timing measurements can be affected by dynamic compilation, garbage collection, and adaptive optimization.</para>
<para><?docpage num="274"?>To have the best chance of finding latent bugs before they occur in production, combine traditional testing techniques (being careful to avoid the pitfalls discussed here) with code reviews and automated analysis tools. Each of these techniques finds problems that the others are likely to miss.</para>
</section>

</chapter>

</part>

<part id="part04" label="IV" xreflabel="IV" condition="275">
<?docpage num="275"?><?docpage num="276"?>
<title id="part04__title">Advanced Topics</title>
<chapter id="ch13" label="13" xreflabel="13" condition="277">
<?docpage num="277"?>
<title id="ch13__title">Explicit Locks</title>


<para><indexterm id="iddle1034" significance="normal"><?indexkey A?><?primarykey acquisition of locks?><primary><emphasis role="strong">acquisition of locks</emphasis></primary><see> locks, acquisition.</see></indexterm><indexterm id="iddle1365" significance="normal"><?indexkey C?><?primarykey coarsening?><primary><emphasis role="strong">coarsening</emphasis></primary><seealso> <link linkend="iddle2879" preference="0"><emphasis role="strong">iterators/iteration</emphasis>, locking</link>.</seealso></indexterm><indexterm id="iddle1754" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey SHARING?><?tertiarykey ACCESS COORDINATION?><primary><emphasis role="strong">data</emphasis></primary><secondary>sharing</secondary><tertiary>access coordination</tertiary></indexterm><indexterm id="iddle2281" significance="normal"><?indexkey E?><?primarykey explicit locks?><primary><emphasis role="strong">explicit locks</emphasis></primary></indexterm><indexterm id="iddle2359" significance="normal"><?indexkey F?><?primarykey finally block?><primary><emphasis role="strong">finally block</emphasis></primary><seealso> interruptions.</seealso></indexterm><indexterm id="iddle2360" significance="normal"><?indexkey F?><?primarykey finally block?><primary><emphasis role="strong">finally block</emphasis></primary><seealso> <link linkend="iddle2879" preference="0"><emphasis role="strong">iterators/iteration</emphasis>, locking</link>.</seealso></indexterm><indexterm id="iddle2834" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><?secondarykey EXPLICIT LOCKS VS?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><secondary>explicit locks vs</secondary></indexterm><indexterm id="iddle3039" significance="normal"><?indexkey L?><?primarykey Lock?><primary><emphasis role="strong">Lock</emphasis></primary></indexterm><indexterm id="iddle3040" significance="normal"><?indexkey L?><?primarykey Lock?><primary><emphasis role="strong">Lock</emphasis></primary></indexterm><indexterm id="iddle3099" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey EXPLICIT?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>explicit</secondary></indexterm><indexterm id="iddle3110" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><?tertiarykey EXPLICIT LOCKS VS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary><tertiary>explicit locks vs</tertiary></indexterm><indexterm id="iddle3210" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey VISIBILITY?><?tertiarykey REENTRANTLOCK EFFECT?><primary><emphasis role="strong">memory</emphasis></primary><secondary>visibility</secondary><tertiary><literal>ReentrantLock</literal> effect</tertiary></indexterm><indexterm id="iddle3286" significance="normal"><?indexkey M?><?primarykey mutexes (mutual exclusion locks)?><?secondarykey REENTRANTLOCK CAPABILITIES?><primary><emphasis role="strong">mutexes (mutual exclusion locks)</emphasis></primary><secondary>ReentrantLock capabilities</secondary></indexterm><indexterm id="iddle3810" significance="normal"><?indexkey R?><?primarykey reentrant/reentrancy?><?secondarykey REENTRANTLOCK?><primary><emphasis role="strong">reentrant/reentrancy</emphasis></primary><secondary><literal>ReentrantLock</literal></secondary></indexterm><indexterm id="iddle3815" significance="normal"><?indexkey R?><?primarykey ReentrantLock?><?secondarykey LOCK IMPLEMENTATION?><primary><emphasis role="strong">ReentrantLock</emphasis></primary><secondary><literal>Lock</literal> implementation</secondary></indexterm><indexterm id="iddle4225" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey DATA?><?tertiarykey ACCESS COORDINATION, EXPLICIT LOCK USE?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>data</secondary><tertiary>access coordination, explicit lock use</tertiary></indexterm><indexterm id="iddle4570" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey REENTRANTLOCK CAPABILITIES?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary><literal>ReentrantLock</literal> capabilities</secondary></indexterm><indexterm id="iddle5106" significance="normal"><?indexkey V?><?primarykey visibility?><?secondarykey MEMORY?><?tertiarykey REENTRANTLOCK CAPABILITIES?><primary><emphasis role="strong">visibility</emphasis></primary><secondary>memory</secondary><tertiary>ReentrantLock capabilities</tertiary></indexterm>Before Java 5.0, the only mechanisms for coordinating access to shared data were <literal>synchronized</literal> and <literal>volatile</literal>. Java 5.0 adds another option: <literal>ReentrantLock</literal>. Contrary to what some have written, <literal>ReentrantLock</literal> is not a replacement for intrinsic locking, but rather an alternative with advanced features for when intrinsic locking proves too limited.</para>



<section id="ch13lev1sec1" condition="277" label="13.1" xreflabel="13.1"><?docpage num="277"?>
<title id="ch13lev1sec1__title">Lock and ReentrantLock</title>
<para>The <literal>Lock</literal> interface, shown in <link linkend="ch13list01" preference="0">Listing 13.1</link>, defines a number of abstract locking operations. Unlike intrinsic locking, <literal>Lock</literal> offers a choice of unconditional, polled, timed, and interruptible lock acquisition, and all lock and unlock operations are explicit. <literal>Lock</literal> implementations must provide the same memory-visibility semantics as intrinsic locks, but can differ in their locking semantics, scheduling algorithms, ordering guarantees, and performance characteristics. (<literal>Lock.newCondition</literal> is covered in <link linkend="ch14" preference="0">Chapter 14</link>.)</para>
<example id="ch13list01" label="13.1" role="Listing" xreflabel="13.1" condition="277">
<title id="ch13list01__title"><literal>Lock</literal> Interface.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface Lock {
    void lock();
    void lockInterruptibly() throws InterruptedException;
    boolean tryLock();
    boolean tryLock(long timeout, TimeUnit unit)
        throws InterruptedException;
    void unlock();
    Condition newCondition();
}
</programlisting>
</example>
<para><literal>ReentrantLock</literal> implements <literal>Lock</literal>, providing the same mutual exclusion and memory-visibility guarantees as <literal>synchronized</literal>. Acquiring a <literal>ReentrantLock</literal> has the same memory semantics as entering a <literal>synchronized</literal> block, and releasing a <literal>ReentrantLock</literal> has the same memory semantics as exiting a <literal>synchronized</literal> block. <?docpage num="278"?><indexterm id="iddle2361" significance="normal"><?indexkey F?><?primarykey finally block?><?secondarykey IMPORTANCE WITH EXPLICIT LOCKS?><primary><emphasis role="strong">finally block</emphasis></primary><secondary>importance with explicit locks</secondary></indexterm><indexterm id="iddle2365" significance="normal"><?indexkey F?><?primarykey FindBugs code auditing tool?><?secondarykey UNRELEASED LOCK DETECTOR?><primary><emphasis role="strong">FindBugs code auditing tool</emphasis></primary><secondary>unreleased lock detector</secondary></indexterm><indexterm id="iddle3136" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey REENTRANT?><?tertiarykey SEMANTICS, REENTRANTLOCK CAPABILITIES?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>reentrant</secondary><tertiary>semantics, <literal>ReentrantLock</literal> capabilities</tertiary></indexterm><indexterm id="iddle3140" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey RELEASE?><?tertiarykey INTRINSIC LOCKING DISADVANTAGES?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>release</secondary><tertiary>intrinsic locking disadvantages</tertiary></indexterm><indexterm id="iddle3808" significance="normal"><?indexkey R?><?primarykey reentrant/reentrancy?><?secondarykey LOCKING SEMANTICS?><?tertiarykey REENTRANTLOCK CAPABILITIES?><primary><emphasis role="strong">reentrant/reentrancy</emphasis></primary><secondary>locking semantics</secondary><tertiary><literal>ReentrantLock</literal> capabilities</tertiary></indexterm><indexterm id="iddle3838" significance="normal"><?indexkey R?><?primarykey release?><?secondarykey LOCK?><?tertiarykey INTRINSIC LOCKING DISADVANTAGES?><primary><emphasis role="strong">release</emphasis></primary><secondary>lock</secondary><tertiary>intrinsic locking disadvantages</tertiary></indexterm><indexterm id="iddle4129" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey REENTRANT LOCKING?><?tertiarykey REENTRANTLOCK CAPABILITIES?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>reentrant locking</secondary><tertiary><literal>ReentrantLock</literal> capabilities</tertiary></indexterm>(Memory visibility is covered in <link linkend="ch03lev1sec1" preference="0">Section 3.1</link> and in <link linkend="ch16" preference="0">Chapter 16</link>.) And, like <literal>synchronized</literal>, <literal>ReentrantLock</literal> offers reentrant locking semantics (see <link linkend="ch02lev2sec6" preference="0">Section 2.3.2</link>). <literal>ReentrantLock</literal> supports all of the lock-acquisition modes defined by <literal>Lock</literal>, providing more flexibility for dealing with lock unavailability than does <literal>synchronized</literal>.</para>
<para>Why create a new locking mechanism that is so similar to intrinsic locking? Intrinsic locking works fine in most situations but has some functional limitations—it is not possible to interrupt a thread waiting to acquire a lock, or to attempt to acquire a lock without being willing to wait for it forever. Intrinsic locks also must be released in the same block of code in which they are acquired; this simplifies coding and interacts nicely with exception handling, but makes non-blockstructured locking disciplines impossible. None of these are reasons to abandon <literal>synchronized</literal>, but in some cases a more flexible locking mechanism offers better liveness or performance.</para>
<para><link linkend="ch13list02" preference="0">Listing 13.2</link> shows the canonical form for using a <literal>Lock</literal>. This idiomis somewhat more complicated than using intrinsic locks: the lock <emphasis>must</emphasis> be released in a <literal>finally</literal> block. Otherwise, the lock would never be released if the guarded code were to throw an exception. When using locking, you must also consider what happens if an exception is thrown out of the <literal>try</literal> block; if it is possible for the object to be left in an inconsistent state, additional <literal>try-catch</literal> or <literal>try-finally</literal> blocks may be needed. (You should always consider the effect of exceptions when using any form of locking, including intrinsic locking.)</para>
<para>Failing to use <literal>finally</literal> to release a <literal>Lock</literal> is a ticking time bomb. When it goes off, you will have a hard time tracking down its origin as there will be no record of where or when the <literal>Lock</literal> should have been released. This is one reason not to use <literal>ReentrantLock</literal> as a blanket substitute for <literal>synchronized</literal>: it is more “dangerous” because it doesn’t automatically clean up the lock when control leaves the guarded block. While remembering to release the lock from a <literal>finally</literal> block is not all that difficult, it is also not impossible to forget.<footnote id="ch13fn01" label="1"><para>FindBugs has an “unreleased lock” detector identifying when a <literal>Lock</literal> is not released in all code paths out of the block in which it was acquired.</para></footnote></para>
<example id="ch13list02" label="13.2" role="Listing" xreflabel="13.2" condition="278">
<title id="ch13list02__title">Guarding Object State Using <literal>ReentrantLock</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">Lock lock = new ReentrantLock();
...
lock.lock();
try {
    <emphasis>// update object state</emphasis>
    <emphasis>// catch exceptions and restore invariants if necessary</emphasis>
} finally {
    lock.unlock();
}
</programlisting>
</example>
<section id="ch13lev2sec1" condition="279" label="13.1.1" xreflabel="13.1.1">
<?docpage num="279"?>
<title id="ch13lev2sec1__title">Polled and Timed Lock Acquisition</title>
<para><indexterm id="iddle1813" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey RECOVERY?><?tertiarykey POLLED AND TIMED LOCK ACQUISITION USE?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>recovery</secondary><tertiary>polled and timed lock acquisition use</tertiary></indexterm><indexterm id="iddle4984" significance="normal"><?indexkey T?><?primarykey tryLock?><?secondarykey DEADLOCK AVOIDANCE?><primary><emphasis role="strong">tryLock</emphasis></primary><secondary>deadlock avoidance</secondary></indexterm><indexterm id="iddle1302" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey INTERRUPTIBLE LOCK ACQUISITION?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>interruptible lock acquisition</secondary></indexterm><indexterm id="iddle1318" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey TIMED LOCKS USE?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>timed locks use</secondary></indexterm><indexterm id="iddle1448" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1812" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey RECOVERY?><?tertiarykey POLLED AND TIMED LOCK ACQUISITION USE?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>recovery</secondary><tertiary>polled and timed lock acquisition use</tertiary></indexterm><indexterm id="iddle2804" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey LOCK ACQUISITION USE?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>lock acquisition use</secondary></indexterm><indexterm id="iddle3052" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><?tertiarykey INTERRUPTIBLE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary><tertiary>interruptible</tertiary></indexterm><indexterm id="iddle3055" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><?tertiarykey POLLED?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary><tertiary>polled</tertiary></indexterm><indexterm id="iddle3058" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><?tertiarykey TIMED?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary><tertiary>timed</tertiary></indexterm><indexterm id="iddle3098" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey EXCLUSIVE?><?tertiarykey TIMED LOCK USE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>exclusive</secondary><tertiary>timed lock use</tertiary></indexterm><indexterm id="iddle3605" significance="normal"><?indexkey P?><?primarykey polling?><?secondarykey LOCK ACQUISITION?><primary><emphasis role="strong">polling</emphasis></primary><secondary>lock acquisition</secondary></indexterm><indexterm id="iddle3670" significance="normal"><?indexkey P?><?primarykey probability?><primary><emphasis role="strong">probability</emphasis></primary></indexterm><indexterm id="iddle3671" significance="normal"><?indexkey P?><?primarykey probability?><?secondarykey DEADLOCK AVOIDANCE USE WITH TIMED AND POLLED LOCKS?><primary><emphasis role="strong">probability</emphasis></primary><secondary>deadlock avoidance use with timed and polled locks</secondary></indexterm><indexterm id="iddle4175" significance="normal"><?indexkey S?><?primarykey serialized/serialization?><?secondarykey ACCESS?><?tertiarykey TIMED LOCK USE?><primary><emphasis role="strong">serialized/serialization</emphasis></primary><secondary>access</secondary><tertiary>timed lock use</tertiary></indexterm><indexterm id="iddle4685" significance="normal"><?indexkey T?><?primarykey termination?><?secondarykey TIMED LOCKS USE?><primary><emphasis role="strong">termination</emphasis></primary><secondary>timed locks use</secondary></indexterm><indexterm id="iddle4906" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey LOCK ACQUISITION?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>lock acquisition</secondary></indexterm>The timed and polled lock-acqusition modes provided by <literal>tryLock</literal> allow more sophisticated error recovery than unconditional acquisition. With intrinsic locks, a deadlock is fatal—the only way to recover is to restart the application, and the only defense is to construct your program so that inconsistent lock ordering is impossible. Timed and polled locking offer another option: probabalistic deadlock avoidance.</para>
<para>Using timed or polled lock acquisition (<literal>tryLock</literal>) lets you regain control if you cannot acquire all the required locks, release the ones you did acquire, and try again (or at least log the failure and do something else). <link linkend="ch13list03" preference="0">Listing 13.3</link> shows an alternate way of addressing the dynamic ordering deadlock from <link linkend="ch10lev2sec2" preference="0">Section 10.1.2</link>: use <literal>tryLock</literal> to attempt to acquire both locks, but back off and retry if they cannot both be acquired. The sleep time has a fixed component and a random component to reduce the likelihood of livelock. If the locks cannot be acquired within the specified time, <literal>transferMoney</literal> returns a failure status so that the operation can fail gracefully. (See [CPJ 2.5.1.2] and [CPJ 2.5.1.3] for more examples of using polled locks for deadlock avoidance.)</para>
<para>Timed locks are also useful in implementing activities that manage a time budget (see <link linkend="ch06lev2sec15" preference="0">Section 6.3.7</link>). When an activity with a time budget calls a blocking method, it can supply a timeout corresponding to the remaining time in the budget. This lets activities terminate early if they cannot deliver a result within the desired time. With intrinsic locks, there is no way to cancel a lock acquisition once it is started, so intrinsic locks put the ability to implement time-budgeted activities at risk.</para>
<para>The travel portal example in <link linkend="ch06list17" preference="0">Listing 6.17</link> on page <link linkend="ch06list17" preference="0" role="pageref">134</link> creates a separate task for each car-rental company from which it was soliciting bids. Soliciting a bid probably involves some sort of network-based request mechanism, such as a web service request. But soliciting a bid might also require exclusive access to a scarce resource, such as a direct communications line to the company.</para>
<para>We saw one way to ensure serialized access to a resource in <link linkend="ch09lev1sec5" preference="0">Section 9.5</link>: a single-threaded executor. Another approach is to use an exclusive lock to guard access to the resource. The code in <link linkend="ch13list04" preference="0">Listing 13.4</link> tries to send a message on a shared communications line guarded by a <literal>Lock</literal>, but fails gracefully if it cannot do so within its time budget. The timed <literal>tryLock</literal> makes it practical to incorporate exclusive locking into such a time-limited activity.</para>
</section>
<section id="ch13lev2sec2" label="13.1.2" xreflabel="13.1.2">
<title id="ch13lev2sec2__title">Interruptible Lock Acquisition</title>
<para>Just as timed lock acquisition allows exclusive locking to be used within timelimited activities, interruptible lock acquisition allows locking to be used within cancellable activities. <link linkend="ch07lev2sec6" preference="0">Section 7.1.6</link> identified several mechanisms, such as acquiring an intrinsic lock, that are not responsive to interruption. These noninterruptible blocking mechanisms complicate the implementation of cancellable tasks. The <literal>lockInterruptibly</literal> method allows you to try to acquire a lock while remaining responsive to interruption, and its inclusion in <literal>Lock</literal> avoids creating another category of non-interruptible blocking mechanisms.</para>

<para><?docpage num="280"?></para><example id="ch13list03" label="13.3" role="Listing" xreflabel="13.3" condition="280">

<title id="ch13list03__title">Avoiding Lock-ordering Deadlock Using <literal>Trylock</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public boolean transferMoney(Account fromAcct,
                             Account toAcct,
                             DollarAmount amount,
                             long timeout,
                             TimeUnit unit)
        throws InsufficientFundsException, InterruptedException {
    long fixedDelay = getFixedDelayComponentNanos(timeout, unit);
    long randMod = getRandomDelayModulusNanos(timeout, unit);
    long stopTime = System.nanoTime() + unit.toNanos(timeout);

    while (true) {
        if (fromAcct.lock.tryLock()) {
            try {
                if (toAcct.lock.tryLock()) {
                    try {
                        if (fromAcct.getBalance().compareTo(amount)
                                &lt; 0)
                            throw new InsufficientFundsException();
                        else {
                            fromAcct.debit(amount);
                            toAcct.credit(amount);
                            return true;
                        }
                    } finally {
                        toAcct.lock.unlock();
                    }
                 }
             } finally {
                 fromAcct.lock.unlock();
             }
         }
         if (System.nanoTime() &gt; stopTime)
             return false;
         NANOSECONDS.sleep(fixedDelay + rnd.nextLong() % randMod);
     }
}
</programlisting>
</example>

<para><?docpage num="281"?></para><example id="ch13list04" label="13.4" role="Listing" xreflabel="13.4" condition="281">

<title id="ch13list04__title">Locking with a Time Budget.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public boolean trySendOnSharedLine(String message,
                                   long timeout, TimeUnit unit)
                                   throws InterruptedException {
    long nanosToLock = unit.toNanos(timeout)
                     - estimatedNanosToSend(message);
    if (!lock.tryLock(nanosToLock, NANOSECONDS))
        return false;
    try {
        return sendOnSharedLine(message);
    } finally {
        lock.unlock();
    }
}
</programlisting>
</example>
<para><indexterm id="iddle1303" significance="normal"><?indexkey C?><?primarykey cancellation?><?secondarykey INTERRUPTIBLE LOCK ACQUISITION?><primary><emphasis role="strong">cancellation</emphasis></primary><secondary>interruptible lock acquisition</secondary></indexterm><indexterm id="iddle3120" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey NON-BLOCK-STRUCTURED?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>non-block-structured</secondary></indexterm><indexterm id="iddle4157" significance="normal"><?indexkey S?><?primarykey sendOnSharedLine example?><primary><emphasis role="strong">sendOnSharedLine example</emphasis></primary></indexterm><indexterm id="iddle4985" significance="normal"><?indexkey T?><?primarykey trySendOnSharedLine example?><primary><emphasis role="strong">trySendOnSharedLine example</emphasis></primary></indexterm>The canonical structure of interruptible lock acquisition is slightly more complicated than normal lock acquisition, as two <literal>try</literal> blocks are needed. (If the interruptible lock acquisition can throw <literal>InterruptedException</literal>, the standard <literal>try-finally</literal> locking idiom works.) <link linkend="ch13list05" preference="0">Listing 13.5</link> uses <literal>lockInterruptibly</literal> to implement <literal>sendOnSharedLine</literal> from <link linkend="ch13list04" preference="0">Listing 13.4</link> so that we can call it from a cancellable task. The timed <literal>tryLock</literal> is also responsive to interruption and so can be used when you need both timed and interruptible lock acquisition.</para>
<example id="ch13list05" label="13.5" role="Listing" xreflabel="13.5" condition="281">
<title id="ch13list05__title">Interruptible Lock Acquisition.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public boolean sendOnSharedLine(String message)
        throws InterruptedException {
    lock.lockInterruptibly();
    try {
        return cancellableSendOnSharedLine(message);
    } finally {
        lock.unlock();
    }
}

private boolean cancellableSendOnSharedLine(String message)
    throws InterruptedException { ... }
</programlisting>
</example>
</section>
<section id="ch13lev2sec3" label="13.1.3" xreflabel="13.1.3">
<title id="ch13lev2sec3__title">Non-block-structured Locking</title>
<para>With intrinsic locks, acquire-release pairs are block-structured—a lock is always released in the same basic block in which it was acquired, regardless of how control exits the block. Automatic lock release simplifies analysis and prevents potential coding errors, but sometimes a more flexible locking discipline is needed.</para>
<para><?docpage num="282"?><indexterm id="iddle1449" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1587" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey INTRINSIC LOCKS VS. REENTRANTLOCK?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>intrinsic locks vs. <literal>ReentrantLock</literal></secondary></indexterm><indexterm id="iddle1588" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey INTRINSIC LOCKS VS. REENTRANTLOCK?><?tertiarykey PERFORMANCE CONSIDERATIONS?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>intrinsic locks vs. <literal>ReentrantLock</literal></secondary><tertiary>performance considerations</tertiary></indexterm><indexterm id="iddle2611" significance="normal"><?indexkey H?><?primarykey hand-over-hand locking?><primary><emphasis role="strong">hand-over-hand locking</emphasis></primary></indexterm><indexterm id="iddle2838" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><?secondarykey REENTRANTLOCK VS?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><secondary><literal>ReentrantLock</literal> vs</secondary></indexterm><indexterm id="iddle3084" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey COUPLING?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>coupling</secondary></indexterm><indexterm id="iddle3104" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey HAND-OVER-HAND?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>hand-over-hand</secondary></indexterm><indexterm id="iddle3115" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><?tertiarykey REENTRANTLOCK VS., PERFORMANCE CONSIDERATIONS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary><tertiary><literal>ReentrantLock</literal> vs., performance considerations</tertiary></indexterm><indexterm id="iddle3138" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey RELEASE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>release</secondary></indexterm><indexterm id="iddle3139" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey RELEASE?><?tertiarykey IN HAND-OVER-HAND LOCKING?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>release</secondary><tertiary>in hand-over-hand locking</tertiary></indexterm><indexterm id="iddle3521" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey REENTRANTLOCK VS. INTRINSIC LOCKS?><primary><emphasis role="strong">performance</emphasis></primary><secondary><literal>ReentrantLock</literal> vs. intrinsic locks</secondary></indexterm><indexterm id="iddle3813" significance="normal"><?indexkey R?><?primarykey ReentrantLock?><?secondarykey INTRINSIC LOCKS VS?><primary><emphasis role="strong">ReentrantLock</emphasis></primary><secondary>intrinsic locks vs</secondary></indexterm><indexterm id="iddle3814" significance="normal"><?indexkey R?><?primarykey ReentrantLock?><?secondarykey INTRINSIC LOCKS VS?><?tertiarykey PERFORMANCE?><primary><emphasis role="strong">ReentrantLock</emphasis></primary><secondary>intrinsic locks vs</secondary><tertiary>performance</tertiary></indexterm><indexterm id="iddle3836" significance="normal"><?indexkey R?><?primarykey release?><?secondarykey LOCK?><primary><emphasis role="strong">release</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle3837" significance="normal"><?indexkey R?><?primarykey release?><?secondarykey LOCK?><?tertiarykey IN HAND-OVER-HAND LOCKING?><primary><emphasis role="strong">release</emphasis></primary><secondary>lock</secondary><tertiary>in hand-over-hand locking</tertiary></indexterm><indexterm id="iddle4069" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey INTRINSIC LOCKS VS. REENTRANTLOCK?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>intrinsic locks vs. <literal>ReentrantLock</literal></secondary></indexterm><indexterm id="iddle4070" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey INTRINSIC LOCKS VS. REENTRANTLOCK?><?tertiarykey PERFORMANCE?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>intrinsic locks vs. <literal>ReentrantLock</literal></secondary><tertiary>performance</tertiary></indexterm>In <link linkend="ch11" preference="0">Chapter 11</link>, we saw how reducing lock granularity can enhance scalability. Lock striping allows different hash chains in a hash-based collection to use different locks. We can apply a similar principle to reduce locking granularity in a linked list by using a separate lock for <emphasis>each link node</emphasis>, allowing different threads to operate independently on different portions of the list. The lock for a given node guards the link pointers and the data stored in that node, so when traversing or modifying the list we must hold the lock on one node until we acquire the lock on the next node; only then can we release the lock on the first node. An example of this technique, called <emphasis>hand-over-hand locking</emphasis> or <emphasis>lock coupling</emphasis>, appears in [CPJ 2.5.1.4].</para>
</section>
</section>
<section id="ch13lev1sec2" condition="282" label="13.2" xreflabel="13.2"><?docpage num="282"?>
<title id="ch13lev1sec2__title">Performance Considerations</title>
<para>When <literal>ReentrantLock</literal> was added in Java 5.0, it offered far better contended performance than intrinsic locking. For synchronization primitives, contended performance is the key to scalability: if more resources are expended on lock management and scheduling, fewer are available for the application. A better lock implementation makes fewer system calls, forces fewer context switches, and initiates less memory-synchronization traffic on the shared memory bus, operations that are time-consuming and divert computing resources from the program.</para>
<para>Java 6 uses an improved algorithm for managing intrinsic locks, similar to that used by <literal>ReentrantLock</literal>, that closes the scalability gap considerably. <link linkend="ch13fig01" preference="1">Figure 13.1</link> shows the performance difference between intrinsic locks and <literal>ReentrantLock</literal> on Java 5.0 and on a prerelease build of Java 6 on a four-way Opteron system running Solaris. The curves represent the “speedup” of <literal>ReentrantLock</literal> over intrinsic locking on a single JVM version. On Java 5.0, <literal>ReentrantLock</literal> offers considerably better throughput, but on Java 6, the two are quite close.<footnote id="ch13fn02" label="2"><para>Though this particular graph doesn’t show it, the scalability difference between Java 5.0 and Java 6 really does come from improvement in intrinsic locking, rather than from regression in <literal>Reentrant-Lock</literal>.</para></footnote> The test program is the same one used in <link linkend="ch11lev1sec5" preference="0">Section 11.5</link>, this time comparing the throughput of a <literal>HashMap</literal> guarded by an intrinsic lock and by a <literal>ReentrantLock</literal>.</para>

<para><?docpage num="283"?></para><figure float="1" id="ch13fig01" label="13.1" xreflabel="13.1" condition="283">

<title id="ch13fig01__title">Intrinsic Locking Versus <literal>ReentrantLock</literal> Performance on Java 5.0 and Java 6.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/13fig01_alt.gif"?><imagedata depth="283" fileref="graphics/13fig01.gif" format="GIF" role="stdwidth" width="500"/></imageobject></mediaobject>
</figure>
<para><indexterm id="iddle1184" significance="normal"><?indexkey B?><?primarykey barging?><primary><emphasis role="strong">barging</emphasis></primary><seealso> <link linkend="iddle2319" preference="0"><emphasis role="strong">fairness</emphasis></link>.</seealso></indexterm><indexterm id="iddle1185" significance="normal"><?indexkey B?><?primarykey barging?><primary><emphasis role="strong">barging</emphasis></primary><seealso> <link linkend="iddle3124" preference="0"><emphasis role="strong">lock(ing)</emphasis>, ordering</link>.</seealso></indexterm><indexterm id="iddle1186" significance="normal"><?indexkey B?><?primarykey barging?><primary><emphasis role="strong">barging</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle2322" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey FAIR LOCK?><primary><emphasis role="strong">fairness</emphasis></primary><secondary>fair lock</secondary></indexterm><indexterm id="iddle2323" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey NONFAIR LOCK?><primary><emphasis role="strong">fairness</emphasis></primary><secondary>nonfair lock</secondary></indexterm><indexterm id="iddle2328" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey REENTRANTLOCK OPTIONS?><primary><emphasis role="strong">fairness</emphasis></primary><secondary><literal>ReentrantLock</literal> options</secondary></indexterm><indexterm id="iddle3137" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey REENTRANTLOCK FAIRNESS OPTIONS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary><literal>ReentrantLock</literal> fairness options</secondary></indexterm><indexterm id="iddle4982" significance="normal"><?indexkey T?><?primarykey tryLock?><primary><emphasis role="strong">tryLock</emphasis></primary></indexterm><indexterm id="iddle4983" significance="normal"><?indexkey T?><?primarykey tryLock?><?secondarykey BARGING USE?><primary><emphasis role="strong">tryLock</emphasis></primary><secondary>barging use</secondary></indexterm>On Java 5.0, the performance of intrinsic locking drops dramatically in going from one thread (no contention) to more than one thread; the performance of <literal>ReentrantLock</literal> drops far less, showing its better scalability. But on Java 6, it is a different story—intrinsic locks no longer fall apart under contention, and the two scale fairly similarly.</para>
<para>Graphs like <link linkend="ch13fig01" preference="1">Figure 13.1</link> remind us that statements of the form “<emphasis>X</emphasis> is faster than <emphasis>Y</emphasis>” are at best short-lived. Performance and scalability are sensitive to platform factors such as CPU, processor count, cache size, and JVM characteristics, all of which can change over time. <footnote id="ch13fn03" label="3"><para>When we started this book, <literal>ReentrantLock</literal> seemed the last word in lock scalability. Less than a year later, intrinsic locking gives it a good run for its money. Performance is not just a moving target, it can be a fast-moving target.</para></footnote></para>
<sidebar float="1" id="ch13sb01" condition="283"><title/>
<para>Performance is a moving target; yesterday’s benchmark showing that <emphasis>X</emphasis> is faster than <emphasis>Y</emphasis> may already be out of date today.</para>
</sidebar>
</section>
<section id="ch13lev1sec3" condition="283" label="13.3" xreflabel="13.3"><?docpage num="283"?>
<title id="ch13lev1sec3__title">Fairness</title>
<para>The <literal>ReentrantLock</literal> constructor offers a choice of two <emphasis>fairness</emphasis> options: create a <emphasis>nonfair</emphasis> lock (the default) or a <emphasis>fair</emphasis> lock. Threads acquire a fair lock in the order in which they requested it, whereas a nonfair lock permits <emphasis>barging</emphasis>: threads requesting a lock can jump ahead of the queue of waiting threads if the lock happens to be available when it is requested. (<literal>Semaphore</literal> also offers the choice of fair or nonfair acquisition ordering.) Nonfair <literal>ReentrantLock</literal>s do not go out of their way to promote barging—they simply don’t prevent a thread from barging if it shows up at the right time. With a fair lock, a newly requesting thread is queued if the lock is held by another thread or if threads are queued waiting for the lock; with a nonfair lock, the thread is queued only if the lock is currently held.<footnote id="ch13fn04" label="4"><para>The polled <literal>tryLock</literal> always barges, even for fair locks.</para></footnote></para>
<para>Wouldn’t we want all locks to be fair? After all, fairness is good and unfairness is bad, right? (Just ask your kids.) When it comes to locking, though, fairness has a significant performance cost because of the overhead of suspending and resuming threads. In practice, a statistical fairness guarantee—promising that a blocked thread will <emphasis>eventually</emphasis> acquire the lock—is often good enough, and is far less expensive to deliver. Some algorithms rely on fair queueing to ensure their <?docpage num="284"?><indexterm id="iddle1188" significance="normal"><?indexkey B?><?primarykey barging?><?secondarykey PERFORMANCE ADVANTAGES OF?><primary><emphasis role="strong">barging</emphasis></primary><secondary>performance advantages of</secondary></indexterm><indexterm id="iddle3493" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey FAIR VS. NONFAIR LOCKING?><primary><emphasis role="strong">performance</emphasis></primary><secondary>fair vs. nonfair locking</secondary></indexterm>correctness, but these are unusual. In most cases, the performance benefits of nonfair locks outweigh the benefits of fair queueing.</para>
<para><link linkend="ch13fig02" preference="1">Figure 13.2</link> shows another run of the <literal>Map</literal> performance test, this time comparing <literal>HashMap</literal> wrapped with fair and nonfair <literal>ReentrantLock</literal>s on a four-way Opteron system running Solaris, plotted on a log scale.<footnote id="ch13fn05" label="5"><para>The graph for <literal>ConcurrentHashMap</literal> is fairly wiggly in the region between four and eight threads. These variations almost certainly come from measurement noise, which could be introduced by coincidental interactions with the hash codes of the elements, thread scheduling, map resizing, garbage collection or other memory-system effects, or by the OS deciding to run some periodic housekeeping task around the time that test case ran. The reality is that there are all sorts of variations in performance tests that usually aren’t worth bothering to control. We made no attempt to clean up our graphs artificially, because real-world performance measurements are also full of noise.</para></footnote> The fairness penalty is nearly two orders of magnitude. <emphasis>Don’t pay for fairness if you don’t need it.</emphasis></para>
<figure float="1" id="ch13fig02" label="13.2" xreflabel="13.2" condition="284">

<title id="ch13fig02__title">Fair Versus Nonfair Lock Performance.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/13fig02_alt.gif"?><imagedata depth="261" fileref="graphics/13fig02.gif" format="GIF" width="500"/></imageobject></mediaobject>
</figure>
<para>One reason barging locks perform so much better than fair locks under heavy contention is that there can be a significant delay between when a suspended thread is resumed and when it actually runs. Let’s say thread <emphasis>A</emphasis> holds a lock and thread <emphasis>B</emphasis> asks for that lock. Since the lock is busy, <emphasis>B</emphasis> is suspended. When <emphasis>A</emphasis> releases the lock, <emphasis>B</emphasis> is resumed so it can try again. In the meantime, though, if thread <emphasis>C</emphasis> requests the lock, there is a good chance that <emphasis>C</emphasis> can acquire the lock, use it, and release it before <emphasis>B</emphasis> even finishes waking up. In this case, everyone wins: <emphasis>B</emphasis> gets the lock no later than it otherwise would have, <emphasis>C</emphasis> gets it much earlier, and throughput is improved.</para>
<para>Fair locks tend to work best when they are held for a relatively long time or when the mean time between lock requests is relatively long. In these cases, the condition under which barging provides a throughput advantage—when the lock is unheld but a thread is currently waking up to claim it—is less likely to hold.</para>
<para><?docpage num="285"?><indexterm id="iddle1834" significance="normal"><?indexkey D?><?primarykey debugging?><?secondarykey THREAD DUMPS?><primary><emphasis role="strong">debugging</emphasis></primary><secondary>thread dumps</secondary></indexterm><indexterm id="iddle1835" significance="normal"><?indexkey D?><?primarykey debugging?><?secondarykey THREAD DUMPS?><?tertiarykey INTRINSIC LOCK ADVANTAGE OVER REENTRANTLOCK?><primary><emphasis role="strong">debugging</emphasis></primary><secondary>thread dumps</secondary><tertiary>intrinsic lock advantage over <literal>ReentrantLock</literal></tertiary></indexterm><indexterm id="iddle2543" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INTRINSIC LOCKS VS. REENTRANTLOCK?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>intrinsic locks vs. <literal>ReentrantLock</literal></secondary></indexterm><indexterm id="iddle2833" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><?secondarykey ADVANTAGES OF?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><secondary>advantages of</secondary></indexterm><indexterm id="iddle3109" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><?tertiarykey ADVANTAGES OF?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary><tertiary>advantages of</tertiary></indexterm><indexterm id="iddle4769" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey DUMPS?><?tertiarykey INTRINSIC LOCK ADVANTAGE OVER REENTRANTLOCK?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>dumps</secondary><tertiary>intrinsic lock advantage over <literal>ReentrantLock</literal></tertiary></indexterm>Like the default <literal>ReentrantLock</literal>, intrinsic locking offers no deterministic fairness guarantees, but the statistical fairness guarantees of most locking implementations are good enough for almost all situations. The language specification does not require the JVM to implement intrinsic locks fairly, and no production JVMs do. <literal>ReentrantLock</literal> does not depress lock fairness to new lows—it only makes explicit something that was present all along.</para>
</section>
<section id="ch13lev1sec4" condition="285" label="13.4" xreflabel="13.4"><?docpage num="285"?>
<title id="ch13lev1sec4__title">Choosing Between Synchronized and ReentrantLock</title>
<para><literal>ReentrantLock</literal> provides the same locking and memory semantics as intrinsic locking, as well as additional features such as timed lock waits, interruptible lock waits, fairness, and the ability to implement non-block-structured locking. The performance of <literal>ReentrantLock</literal> appears to dominate that of intrinsic locking, winning slightly on Java 6 and dramatically on Java 5.0. So why not deprecate <literal>synchronized</literal> and encourage all new concurrent code to use <literal>ReentrantLock</literal>? Some authors have in fact suggested this, treating <literal>synchronized</literal> as a “legacy” construct. But this is taking a good thing <emphasis>way</emphasis> too far.</para>
<para>Intrinsic locks still have significant advantages over explicit locks. The notation is familiar and compact, and many existing programs already use intrinsic locking—and mixing the two could be confusing and error-prone. <literal>Reentrant-Lock</literal> is definitely a more dangerous tool than synchronization; if you forget to wrap the <literal>unlock</literal> call in a <literal>finally</literal> block, your code will probably appear to run properly, but you’ve created a time bomb that may well hurt innocent bystanders. Save <literal>ReentrantLock</literal> for situations in which you need something <literal>ReentrantLock</literal> provides that intrinsic locking doesn’t.</para>
<sidebar float="1" id="ch13sb02" condition="285"><title/>
<para><literal>ReentrantLock</literal> is an advanced tool for situations where intrinsic locking is not practical. Use it if you need its advanced features: timed, polled, or interruptible lock acquisition, fair queueing, or non-block-structured locking. Otherwise, prefer <literal>synchronized</literal>.</para>
</sidebar>
<para>Under Java 5.0, intrinsic locking has another advantage over <literal>ReentrantLock</literal>: thread dumps show which call frames acquired which locks and can detect and identify deadlocked threads. The JVM knows nothing about which threads hold <literal>ReentrantLock</literal>s and therefore cannot help in debugging threading problems using <literal>ReentrantLock</literal>. This disparity is addressed in Java 6 by providing a management and monitoring interface with which locks can register, enabling locking information for <literal>ReentrantLock</literal>s to appear in thread dumps and through other management and debugging interfaces. The availability of this information for debugging is a substantial, if mostly temporary, advantage for <literal>synchronized</literal>; locking information in thread dumps has saved many programmers from utter consternation. The non-block-structured nature of <literal>ReentrantLock</literal> still means that lock acquisitions cannot be tied to specific stack frames, as they can with intrinsic locks.</para>
<para><?docpage num="286"?><indexterm id="iddle1368" significance="normal"><?indexkey C?><?primarykey coarsening?><?secondarykey LOCK?><primary><emphasis role="strong">coarsening</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle1478" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey READ-WRITE LOCK ADVANTAGES?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>read-write lock advantages</secondary></indexterm><indexterm id="iddle1997" significance="normal"><?indexkey E?><?primarykey elision?><?secondarykey LOCK?><?tertiarykey JVM OPTIMIZATION?><primary><emphasis role="strong">elision</emphasis></primary><secondary>lock</secondary><tertiary>JVM optimization</tertiary></indexterm><indexterm id="iddle2920" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey OPTIMIZATIONS?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>optimizations</secondary></indexterm><indexterm id="iddle3072" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey COARSENING?><?tertiarykey AS JVM OPTIMIZATION?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>coarsening</secondary><tertiary>as JVM optimization</tertiary></indexterm><indexterm id="iddle3091" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ELISION?><?tertiarykey AS JVM OPTIMIZATION?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>elision</secondary><tertiary>as JVM optimization</tertiary></indexterm><indexterm id="iddle3132" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey READ-WRITE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>read-write</secondary></indexterm><indexterm id="iddle3261" significance="normal"><?indexkey M?><?primarykey multiple-reader, single-writer locking?><?secondarykey READ-WRITE LOCKS?><primary><emphasis role="strong">multiple-reader, single-writer locking</emphasis></primary><secondary>read-write locks</secondary></indexterm><indexterm id="iddle3385" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey JVM?><?tertiarykey STRATEGIES?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>JVM</secondary><tertiary>strategies</tertiary></indexterm><indexterm id="iddle3520" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey READ-WRITE LOCK ADVANTAGES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>read-write lock advantages</secondary></indexterm><indexterm id="iddle3795" significance="normal"><?indexkey R?><?primarykey read-write locks?><primary><emphasis role="strong">read-write locks</emphasis></primary></indexterm><indexterm id="iddle3796" significance="normal"><?indexkey R?><?primarykey ReadWriteLock?><primary><emphasis role="strong">ReadWriteLock</emphasis></primary></indexterm>Future performance improvements are likely to favor <literal>synchronized</literal> over <literal>ReentrantLock</literal>. Because <literal>synchronized</literal> is built into the JVM, it can perform optimizations such as lock elision for thread-confined lock objects and lock coarsening to eliminate synchronization with intrinsic locks (see <link linkend="ch11lev2sec6" preference="0">Section 11.3.2</link>); doing this with library-based locks seems far less likely. Unless you are deploying on Java 5.0 for the foreseeable future and you have a <emphasis>demonstrated</emphasis> need for <literal>ReentrantLock</literal>’s scalability benefits on that platform, it is not a good idea to choose <literal>ReentrantLock</literal> over <literal>synchronized</literal> for performance reasons.</para>
</section>
<section id="ch13lev1sec5" condition="286" label="13.5" xreflabel="13.5"><?docpage num="286"?>
<title id="ch13lev1sec5__title">Read-write Locks</title>
<para><literal>ReentrantLock</literal> implements a standard mutual-exclusion lock: at most one thread at a time can hold a <literal>ReentrantLock</literal>. But mutual exclusion is frequently a stronger locking discipline than needed to preserve data integrity, and thus limits concurrency more than necessary. Mutual exclusion is a conservative locking strategy that prevents writer/writer and writer/reader overlap, but also prevents reader/reader overlap. In many cases, data structures are “read-mostly”—they are mutable and are sometimes modified, but most accesses involve only reading. In these cases, it would be nice to relax the locking requirements to allow multiple readers to access the data structure at once. As long as each thread is guaranteed an up-to-date view of the data and no other thread modifies the data while the readers are viewing it, there will be no problems. This is what read-write locks allow: a resource can be accessed by multiple readers or a single writer at a time, but not both.</para>
<para><literal>ReadWriteLock</literal>, shown in <link linkend="ch13list06" preference="0">Listing 13.6</link>, exposes two <literal>Lock</literal> objects—one for reading and one for writing. To read data guarded by a <literal>ReadWriteLock</literal> you must first acquire the read lock, and to modify data guarded by a <literal>ReadWriteLock</literal> you must first acquire the write lock. While there may appear to be two separate locks, the read lock and write lock are simply different views of an integrated read-write lock object.</para>
<example id="ch13list06" label="13.6" role="Listing" xreflabel="13.6" condition="286">
<title id="ch13list06__title"><literal>ReadWriteLock</literal> Interface.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface ReadWriteLock {
    Lock readLock();
    Lock writeLock();
}
</programlisting>
</example>
<para>The locking strategy implemented by read-write locks allows multiple simultaneous readers but only a single writer. Like <literal>Lock</literal>, <literal>ReadWriteLock</literal> admits multiple implementations that can vary in performance, scheduling guarantees, acquisition preference, fairness, or locking semantics.</para>
<para>Read-write locks are a performance optimization designed to allow greater concurrency in certain situations. In practice, read-write locks can improve performance for frequently accessed read-mostly data structures on multiprocessor systems; under other conditions they perform slightly worse than exclusive locks <?docpage num="287"?><indexterm id="iddle1187" significance="normal"><?indexkey B?><?primarykey barging?><?secondarykey AND READ-WRITE LOCKS?><primary><emphasis role="strong">barging</emphasis></primary><secondary>and read-write locks</secondary></indexterm><indexterm id="iddle1971" significance="normal"><?indexkey D?><?primarykey downgrading?><primary><emphasis role="strong">downgrading</emphasis></primary></indexterm><indexterm id="iddle1972" significance="normal"><?indexkey D?><?primarykey downgrading?><?secondarykey READ-WRITE LOCK IMPLEMENTATION STRATEGY?><primary><emphasis role="strong">downgrading</emphasis></primary><secondary>read-write lock implementation strategy</secondary></indexterm><indexterm id="iddle2329" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey REENTRANTREADWRITELOCK?><primary><emphasis role="strong">fairness</emphasis></primary><secondary><literal>ReentrantReadWriteLock</literal></secondary></indexterm><indexterm id="iddle3133" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey READ-WRITE?><?tertiarykey IMPLEMENTATION STRATEGIES?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>read-write</secondary><tertiary>implementation strategies</tertiary></indexterm><indexterm id="iddle3141" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey RELEASE?><?tertiarykey PREFERENCE, IN READ-WRITE LOCK IMPLEMENTATION?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>release</secondary><tertiary>preference, in read-write lock implementation</tertiary></indexterm><indexterm id="iddle3806" significance="normal"><?indexkey R?><?primarykey reentrant/reentrancy?><?secondarykey AND READ-WRITE LOCKS?><primary><emphasis role="strong">reentrant/reentrancy</emphasis></primary><secondary>and read-write locks</secondary></indexterm><indexterm id="iddle3820" significance="normal"><?indexkey R?><?primarykey ReentrantReadWriteLock?><?secondarykey REENTRANT LOCKING SEMANTICS?><primary><emphasis role="strong">ReentrantReadWriteLock</emphasis></primary><secondary>reentrant locking semantics</secondary></indexterm><indexterm id="iddle3839" significance="normal"><?indexkey R?><?primarykey release?><?secondarykey LOCK?><?tertiarykey PREFERENCES IN READ-WRITE LOCK IMPLEMENTATION?><primary><emphasis role="strong">release</emphasis></primary><secondary>lock</secondary><tertiary>preferences in read-write lock implementation</tertiary></indexterm><indexterm id="iddle4130" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey REENTRANT LOCKING?><?tertiarykey REENTRANTREADWRITELOCK CAPABILITIES?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>reentrant locking</secondary><tertiary><literal>ReentrantReadWriteLock</literal> capabilities</tertiary></indexterm><indexterm id="iddle5019" significance="normal"><?indexkey U?><?primarykey upgrading?><primary><emphasis role="strong">upgrading</emphasis></primary></indexterm><indexterm id="iddle5020" significance="normal"><?indexkey U?><?primarykey upgrading?><?secondarykey READ-WRITE LOCKS?><primary><emphasis role="strong">upgrading</emphasis></primary><secondary>read-write locks</secondary></indexterm>due to their greater complexity. Whether they are an improvement in any given situation is best determined via profiling; because <literal>ReadWriteLock</literal> uses <literal>Lock</literal> for the read and write portions of the lock, it is relatively easy to swap out a readwrite lock for an exclusive one if profiling determines that a read-write lock is not a win.</para>
<para>The interaction between the read and write locks allows for a number of possible implementations. Some of the implementation options for a <literal>ReadWriteLock</literal> are:</para>
<itemizedlist mark="none" spacing="normal">
<listitem><formalpara><title><emphasis role="strong"><?design?>Release preference.</emphasis></title><para>When a writer releases the write lock and both readers and writers are queued up, who should be given preference—readers, writers, or whoever asked first?</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Reader barging.</emphasis></title><para>If the lock is held by readers but there are waiting writers, should newly arriving readers be granted immediate access, or should they wait behind the writers? Allowing readers to barge ahead of writers enhances concurrency but runs the risk of starving writers.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Reentrancy.</emphasis></title><para>Are the read and write locks reentrant?</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Downgrading.</emphasis></title><para>If a thread holds the write lock, can it acquire the read lock without releasing the write lock? This would let a writer “downgrade” to a read lock without letting other writers modify the guarded resource in the meantime.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Upgrading.</emphasis></title><para>Can a read lock be upgraded to a write lock in preference to other waiting readers or writers? Most read-write lock implementations do not support upgrading, because without an explicit upgrade operation it is deadlock-prone. (If two readers simultaneously attempt to upgrade to a write lock, neither will release the read lock.)</para></formalpara></listitem>
</itemizedlist>
<para role="continued"><literal>ReentrantReadWriteLock</literal> provides reentrant locking semantics for both locks. Like <literal>ReentrantLock</literal>, a <literal>ReentrantReadWriteLock</literal> can be constructed as nonfair (the default) or fair. With a fair lock, preference is given to the thread that has been waiting the longest; if the lock is held by readers and a thread requests the write lock, no more readers are allowed to acquire the read lock until the writer has been serviced and releases the write lock. With a nonfair lock, the order in which threads are granted access is unspecified. Downgrading from writer to reader is permitted; upgrading from reader to writer is not (attempting to do so results in deadlock).</para>
<para>Like <literal>ReentrantLock</literal>, thewrite lock in <literal>ReentrantReadWriteLock</literal> has a unique owner and can be released only by the thread that acquired it. In Java 5.0, the read lock behaves more like a <literal>Semaphore</literal> than a lock, maintaining only the count of active readers, not their identities. This behavior was changed in Java 6 to keep track also of which threads have been granted the read lock. <footnote id="ch13fn06" label="6"><para>One reason for this change is that under Java 5.0, the lock implementation cannot distinguish between a thread requesting the read lock for the first time and a reentrant lock request, which would make fair read-write locks deadlock-prone.</para></footnote></para>
<para><?docpage num="288"?><indexterm id="iddle2167" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey READWRITEMAP?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ReadWriteMap</literal></secondary></indexterm>Read-write locks can improve concurrency when locks are typically held for a moderately long time and most operations do not modify the guarded resources. <literal>ReadWriteMap</literal> in <link linkend="ch13list07" preference="0">Listing 13.7</link> uses a <literal>ReentrantReadWriteLock</literal> to wrap a <literal>Map</literal> so that it can be shared safely by multiple readers and still prevent reader-writer or writer-writer conflicts.<footnote id="ch13fn07" label="7"><para><literal>ReadWriteMap</literal> does not implement <literal>Map</literal> because implementing the view methods such as <literal>entrySet</literal> and <literal>values</literal> would be difficult and the “easy” methods are usually sufficient.</para></footnote> In reality, <literal>ConcurrentHashMap</literal>’s performance is so good that you would probably use it rather than this approach if all you needed was a concurrent hash-based map, but this technique would be useful if you want to provide more concurrent access to an alternate <literal>Map</literal> implementation such as <literal>LinkedHashMap</literal>.</para>
<example id="ch13list07" label="13.7" role="Listing" xreflabel="13.7" condition="288">
<title id="ch13list07__title">Wrapping a <literal>Map</literal> with a Read-write Lock.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class ReadWriteMap&lt;K,V&gt; {
    private final Map&lt;K,V&gt; map;
    private final ReadWriteLock lock = new ReentrantReadWriteLock();
    private final Lock r = lock.readLock();
    private final Lock w = lock.writeLock();

    public ReadWriteMap(Map&lt;K,V&gt; map) {
        this.map = map;
    }

    public V put(K key, V value) {
        <emphasis role="strong">w.lock();</emphasis>
        try {
            return map.put(key, value);
        } finally {
            <emphasis role="strong">w.unlock();</emphasis>
        }
    }
    <emphasis>// Do the same for remove(), putAll(), clear()</emphasis>

    public V get(Object key) {
        <emphasis role="strong">r.lock();</emphasis>
        try {
            return map.get(key);
        } finally {
            <emphasis role="strong">r.unlock();</emphasis>
        }
    }
    <emphasis>// Do the same for other read-only Map methods</emphasis>
}
</programlisting>
</example>
<para><link linkend="ch13fig03" preference="1">Figure 13.3</link> shows a throughput comparison between an <literal>ArrayList</literal> wrapped <?docpage num="289"?>with a <literal>ReentrantLock</literal> and with a <literal>ReadWriteLock</literal> on a four-way Opteron system running Solaris. The test program used here is similar to the <literal>Map</literal> performance test we’ve been using throughout the book—each operation randomly selects a value and searches for it in the collection, and a small percentange of operations modify the contents of the collection.</para>
<figure float="1" id="ch13fig03" label="13.3" xreflabel="13.3" condition="289">

<title id="ch13fig03__title">Read-write Lock Performance.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/13fig03_alt.gif"?><imagedata depth="252" fileref="graphics/13fig03.gif" format="GIF" width="500"/></imageobject></mediaobject>
</figure>
</section>



<section id="ch13lev1sec6" condition="289" label="" xreflabel=""><?docpage num="289"?><?docpage num="290"?>
<title id="ch13lev1sec6__title">Summary</title>
<para>Explicit <literal>Lock</literal>s offer an extended feature set compared to intrinsic locking, including greater flexibility in dealing with lock unavailability and greater control over queueing behavior. But <literal>ReentrantLock</literal> is not a blanket substitute for <literal>synchronized</literal>; use it only when you need features that <literal>synchronized</literal> lacks.</para>
<para>Read-write locks allow multiple readers to access a guarded object concurrently, offering the potential for improved scalability when accessing read-mostly data structures.</para>
</section>

</chapter>

<chapter id="ch14" label="14" xreflabel="14" condition="291">
<?docpage num="291"?>
<title id="ch14__title">Building Custom Synchronizers</title>


<para><indexterm id="iddle1228" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey STATE-DEPENDENT ACTIONS?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>state-dependent actions</secondary></indexterm><indexterm id="iddle18731" significance="normal"><?indexkey D?><?primarykey dependencies?><primary><emphasis role="strong">dependencies</emphasis></primary></indexterm><indexterm id="iddle1873" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey STATE?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle1874" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey STATE?><?tertiarykey BLOCKING OPERATIONS?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>state</secondary><tertiary>blocking operations</tertiary></indexterm><indexterm id="iddle1875" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey STATE?><?tertiarykey CLASSES?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>state</secondary><tertiary>classes</tertiary></indexterm><indexterm id="iddle1876" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey STATE?><?tertiarykey CLASSES, BUILDING?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>state</secondary><tertiary>classes, building</tertiary></indexterm><indexterm id="iddle1877" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey STATE?><?tertiarykey MANAGING?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>state</secondary><tertiary>managing</tertiary></indexterm><indexterm id="iddle3645" significance="normal"><?indexkey P?><?primarykey precondition(s)?><?secondarykey STATE-BASED?><primary><emphasis role="strong">precondition(s)</emphasis></primary><secondary>state-based</secondary></indexterm><indexterm id="iddle3646" significance="normal"><?indexkey P?><?primarykey precondition(s)?><?secondarykey STATE-BASED?><?tertiarykey IN STATE-DEPENDENT CLASSES?><primary><emphasis role="strong">precondition(s)</emphasis></primary><secondary>state-based</secondary><tertiary>in state-dependent classes</tertiary></indexterm><indexterm id="iddle4387" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey DEPENDENT?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>dependent</secondary></indexterm><indexterm id="iddle4388" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey DEPENDENT?><?tertiarykey CLASSES?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>dependent</secondary><tertiary>classes</tertiary></indexterm><indexterm id="iddle4389" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey DEPENDENT?><?tertiarykey CLASSES, BUILDING?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>dependent</secondary><tertiary>classes, building</tertiary></indexterm><indexterm id="iddle4391" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey DEPENDENT?><?tertiarykey OPERATIONS, BLOCKING STRATEGIES?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>dependent</secondary><tertiary>operations, blocking strategies</tertiary></indexterm><indexterm id="iddle4393" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey DEPENDENT?><?tertiarykey OPERATIONS, MANAGING?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>dependent</secondary><tertiary>operations, managing</tertiary></indexterm><indexterm id="iddle4594" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><?secondarykey BUILDING?><?tertiarykey WITH CONDITION QUEUES?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary><secondary>building</secondary><tertiary>with condition queues</tertiary></indexterm>The class libraries include a number of <emphasis>state-dependent</emphasis> classes—those having operations with <emphasis>state-based preconditions</emphasis>—such as <literal>FutureTask</literal>, <literal>Semaphore</literal>, and <literal>BlockingQueue</literal>. For example, you cannot remove an item from an empty queue or retrieve the result of a task that has not yet finished; before these operations can proceed, you must wait until the queue enters the “nonempty” state or the task enters the “completed” state.</para>
<para>The easiest way to construct a state-dependent class is usually to build on top of an existing state-dependent library class; we did this in <literal>ValueLatch</literal> on page <link linkend="ch08list15" preference="0" role="pageref">187</link>, using a <literal>CountDownLatch</literal> to provide the required blocking behavior. But if the library classes do not provide the functionality you need, you can also build your own synchronizers using the low-level mechanisms provided by the language and libraries, including intrinsic <emphasis>condition queues</emphasis>, explicit <literal>Condition</literal> objects, and the <literal>AbstractQueuedSynchronizer</literal> framework. This chapter explores the various options for implementing state dependence and the rules for using the state dependence mechanisms provided by the platform.</para>



<section id="ch14lev1sec1" condition="291" label="14.1" xreflabel="14.1"><?docpage num="291"?>
<title id="ch14lev1sec1__title">Managing State Dependence</title>
<para>In a single-threaded program, if a state-based precondition (like “the connection pool is nonempty”) does not hold when a method is called, it will never become true. Therefore, classes in sequential programs can be coded to fail when their preconditions do not hold. But in a concurrent program, state-based conditions can change through the actions of other threads: a pool that was empty a few instructions ago can become nonempty because another thread returned an element. State-dependent methods on concurrent objects can sometimes get away with failing when their preconditions are not met, but there is often a better alternative: wait for the precondition to become true.</para>
<para>State-dependent operations that <emphasis>block</emphasis> until the operation can proceed are more convenient and less error-prone than those that simply fail. The built-in condition queue mechanism enables threads to block until an object has entered a state that allows progress and to wake blocked threads when they may be able to make further progress. We cover the details of condition queues in <link linkend="ch14lev1sec2" preference="0">Section 14.2</link>, but to <?docpage num="292"?><?docpage num="293"?><indexterm id="iddle1122" significance="normal"><?indexkey A?><?primarykey ArrayBlockingQueue?><?secondarykey AS BOUNDED BUFFER EXAMPLE?><primary><emphasis role="strong">ArrayBlockingQueue</emphasis></primary><secondary>as bounded buffer example</secondary></indexterm><indexterm id="iddle1232" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey STATE-DEPENDENT ACTIONS?><?tertiarykey STRUCTURE?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>state-dependent actions</secondary><tertiary>structure</tertiary></indexterm><indexterm id="iddle1244" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey BUFFERS?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>buffers</secondary></indexterm><indexterm id="iddle1245" significance="normal"><?indexkey B?><?primarykey bound(ed)?><?secondarykey BUFFERS?><?tertiarykey BLOCKING OPERATIONS?><primary><emphasis role="strong">bound(ed)</emphasis></primary><secondary>buffers</secondary><tertiary>blocking operations</tertiary></indexterm><indexterm id="iddle1262" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey BOUNDED?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary>bounded</secondary></indexterm><indexterm id="iddle1263" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey BOUNDED?><?tertiarykey BLOCKING STATE-DEPENDENT OPERATIONS WITH?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary>bounded</secondary><tertiary>blocking state-dependent operations with</tertiary></indexterm><indexterm id="iddle1987" significance="normal"><?indexkey E?><?primarykey Effective Java Programming Language Guide?><primary><emphasis role="strong"><emphasis>Effective Java Programming Language Guide</emphasis></emphasis></primary></indexterm><indexterm id="iddle2117" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey GRUMPYBOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>GrumpyBoundedBuffer</literal></secondary></indexterm><indexterm id="iddle2224" significance="normal"><?indexkey E?><?primarykey exceptions?><?secondarykey AND PRECONDITION FAILURE?><primary><emphasis role="strong">exceptions</emphasis></primary><secondary>and precondition failure</secondary></indexterm><indexterm id="iddle2312" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey PRECONDITION?><primary><emphasis role="strong">failure</emphasis></primary><secondary>precondition</secondary></indexterm><indexterm id="iddle2313" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey PRECONDITION?><?tertiarykey BOUNDED BUFFER HANDLING OF?><primary><emphasis role="strong">failure</emphasis></primary><secondary>precondition</secondary><tertiary>bounded buffer handling of</tertiary></indexterm><indexterm id="iddle2314" significance="normal"><?indexkey F?><?primarykey failure?><?secondarykey PRECONDITION?><?tertiarykey PROPAGATION TO CALLERS?><primary><emphasis role="strong">failure</emphasis></primary><secondary>precondition</secondary><tertiary>propagation to callers</tertiary></indexterm><indexterm id="iddle3105" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey IN BLOCKING ACTIONS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>in blocking actions</secondary></indexterm><indexterm id="iddle3642" significance="normal"><?indexkey P?><?primarykey precondition(s)?><?secondarykey FAILURE?><primary><emphasis role="strong">precondition(s)</emphasis></primary><secondary>failure</secondary></indexterm><indexterm id="iddle3643" significance="normal"><?indexkey P?><?primarykey precondition(s)?><?secondarykey FAILURE?><?tertiarykey BOUNDED BUFFER HANDLING OF?><primary><emphasis role="strong">precondition(s)</emphasis></primary><secondary>failure</secondary><tertiary>bounded buffer handling of</tertiary></indexterm><indexterm id="iddle3644" significance="normal"><?indexkey P?><?primarykey precondition(s)?><?secondarykey FAILURE?><?tertiarykey PROPAGATION TO CALLERS?><primary><emphasis role="strong">precondition(s)</emphasis></primary><secondary>failure</secondary><tertiary>propagation to callers</tertiary></indexterm><indexterm id="iddle3682" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey BOUNDED BUFFER USE?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>bounded buffer use</secondary></indexterm>motivate the value of an efficient condition wait mechanism, we first show how state dependence might be (painfully) tackled using polling and sleeping.</para>
<para>A blocking state-dependent action takes the form shown in <link linkend="ch14list01" preference="0">Listing 14.1</link>. The pattern of locking is somewhat unusual in that the lock is released and reacquired in the middle of the operation. The state variables that make up the precondition must be guarded by the object’s lock, so that they can remain constant while the precondition is tested. But if the precondition does not hold, the lock must be released so another thread can modify the object state—otherwise the precondition will never become true. The lock must then be reacquired before testing the precondition again.</para>
<example id="ch14list01" label="14.1" role="Listing" xreflabel="14.1" condition="292">
<title id="ch14list01__title">Structure of Blocking State-dependent Actions.</title>
<programlisting format="linespecific" linenumbering="unnumbered">    acquire lock on object state
    while (precondition does not hold) {
        release lock
        wait until precondition might hold
        optionally fail if interrupted or timeout expires
        reacquire lock
    }
    perform action
    release lock
</programlisting>
</example>
<para>Bounded buffers such as <literal>ArrayBlockingQueue</literal> are commonly used in producer-consumer designs. A bounded buffer provides <emphasis>put</emphasis> and <emphasis>take</emphasis> operations, each of which has preconditions: you cannot take an element from an empty buffer, nor put an element into a full buffer. State dependent operations can deal with precondition failure by throwing an exception or returning an error status (making it the caller’s problem), or by blocking until the object transitions to the right state.</para>
<para>We’re going to develop several implementations of a bounded buffer that take different approaches to handling precondition failure. Each extends <literal>BaseBoundedBuffer</literal> in <link linkend="ch14list02" preference="0">Listing 14.2</link>, which implements a classic array-based circular buffer where the buffer state variables (<literal>buf</literal>, <literal>head</literal>, <literal>tail</literal>, and <literal>count</literal>) are guarded by the buffer’s intrinsic lock. It provides synchronized <literal>doPut</literal> and <literal>doTake</literal> methods that are used by subclasses to implement the <literal>put</literal> and <literal>take</literal> operations; the underlying state is hidden from the subclasses.</para>
<section id="ch14lev2sec1" label="14.1.1" xreflabel="14.1.1">
<title id="ch14lev2sec1__title">Example: Propagating Precondition Failure to Callers</title>
<para><literal>GrumpyBoundedBuffer</literal> in <link linkend="ch14list03" preference="0">Listing 14.3</link> is a crude first attempt at implementing a bounded buffer. The <literal>put</literal> and <literal>take</literal> methods are <literal>synchronized</literal> to ensure exclusive access to the buffer state, since both employ check-then-act logic in accessing the buffer.</para>
<para>While this approach is easy enough to implement, it is annoying to use. Exceptions are supposed to be for exceptional conditions [EJ Item 39]. “Buffer is <?docpage num="294"?><indexterm id="iddle2081" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BASEBOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BaseBoundedBuffer</literal></secondary></indexterm><indexterm id="iddle2118" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey GRUMPYBOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>GrumpyBoundedBuffer</literal></secondary></indexterm><indexterm id="iddle3403" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey FIFO?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>FIFO</secondary></indexterm><indexterm id="iddle3404" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey FIFO?><?tertiarykey IMPACT OF CALLER STATE DEPENDENCE HANDLING ON?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>FIFO</secondary><tertiary>impact of caller state dependence handling on</tertiary></indexterm>full” is not an exceptional condition for a bounded buffer any more than “red” is an exceptional condition for a traffic signal. The simplification in implementing the buffer (forcing the caller to manage the state dependence) is more than made up for by the substantial complication in using it, since now the caller must be prepared to catch exceptions and possibly retry for every buffer operation.<footnote id="ch14fn01" label="1"><para>Pushing the state dependence back to the caller also makes it nearly impossible to do things like preserve FIFO ordering; by forcing the caller to retry, you lose the information of who arrived first.</para></footnote> A well-structured call to <literal>take</literal> is shown in <link linkend="ch14list04" preference="0">Listing 14.4</link>—not very pretty, especially if <literal>put</literal> and <literal>take</literal> are called throughout the program.</para>
<example id="ch14list02" label="14.2" role="Listing" xreflabel="14.2" condition="293">
<?docpage num="293"?>
<title id="ch14list02__title">Base Class for Bounded Buffer Implementations.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public abstract class BaseBoundedBuffer&lt;V&gt; {
    @GuardedBy("this") private final V[] buf;
    @GuardedBy("this") private int tail;
    @GuardedBy("this") private int head;
    @GuardedBy("this") private int count;

    protected BaseBoundedBuffer(int capacity) {
        this.buf = (V[]) new Object[capacity];
    }

    protected synchronized final void doPut(V v) {
        buf[tail] = v;
        if (++tail == buf.length)
            tail = 0;
        ++count;
    }

    protected synchronized final V doTake() {
        V v = buf[head];
        buf[head] = null;
        if (++head == buf.length)
            head = 0;
        --count;
        return v;
    }

    public synchronized final boolean isFull() {
        return count == buf.length;
    }

    public synchronized final boolean isEmpty() {
        return count == 0;
    }
}
</programlisting>
</example>
<example id="ch14list03" label="14.3" role="Listing" xreflabel="14.3" condition="294">
<title id="ch14list03__title">Bounded Buffer that Balks When Preconditions are Not Met.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class GrumpyBoundedBuffer&lt;V&gt; extends BaseBoundedBuffer&lt;V&gt; {
    public GrumpyBoundedBuffer(int size) { super(size); }

    public <emphasis role="strong">synchronized</emphasis>  void put(V v) throws BufferFullException {
        <emphasis role="strong">if (isFull())</emphasis>
            <emphasis role="strong">throw new BufferFullException();</emphasis>
        doPut(v);
    }

    public <emphasis role="strong">synchronized</emphasis>  V take() throws BufferEmptyException {
        <emphasis role="strong">if (isEmpty())</emphasis>
               <emphasis role="strong">throw new BufferEmptyException();</emphasis>
        return doTake();
    }
}
</programlisting>
</example>
<example id="ch14list04" label="14.4" role="Listing" xreflabel="14.4" condition="294">
<title id="ch14list04__title">Client Logic for Calling <literal>GrumpyBoundedBuffer</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">while (true) {
    try {
        V item = buffer.take();
        <emphasis>// use item</emphasis>
        break;
    } catch (BufferEmptyException e) {
        Thread.sleep(SLEEP_GRANULARITY);
    }
}
</programlisting>
</example>
<para>A variant of this approach is to return an error value when the buffer is in the wrong state. This is a minor improvement in that it doesn’t abuse the exception mechanism by throwing an exception that really means “sorry, try again”, <?docpage num="295"?><indexterm id="iddle1229" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey STATE-DEPENDENT ACTIONS?><?tertiarykey AND POLLING?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>state-dependent actions</secondary><tertiary>and polling</tertiary></indexterm><indexterm id="iddle1230" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey STATE-DEPENDENT ACTIONS?><?tertiarykey AND SLEEPING?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>state-dependent actions</secondary><tertiary>and sleeping</tertiary></indexterm><indexterm id="iddle1278" significance="normal"><?indexkey B?><?primarykey busy-waiting?><primary>busy-waiting</primary><seealso> <link linkend="iddle1227" preference="0"><emphasis role="strong">block(ing)</emphasis>, spin-waiting</link>.</seealso></indexterm><indexterm id="iddle1716" significance="normal"><?indexkey C?><?primarykey CPU utilization?><?secondarykey SPIN-WAITING IMPACT ON?><primary><emphasis role="strong">CPU utilization</emphasis></primary><secondary>spin-waiting impact on</secondary></indexterm><indexterm id="iddle2181" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SLEEPYBOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SleepyBoundedBuffer</literal></secondary></indexterm><indexterm id="iddle3602" significance="normal"><?indexkey P?><?primarykey polling?><primary><emphasis role="strong">polling</emphasis></primary></indexterm><indexterm id="iddle3603" significance="normal"><?indexkey P?><?primarykey polling?><?secondarykey BLOCKING STATE-DEPENDENT ACTIONS?><primary><emphasis role="strong">polling</emphasis></primary><secondary>blocking state-dependent actions</secondary></indexterm><indexterm id="iddle3970" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey SLEEPING IMPACT ON?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>sleeping impact on</secondary></indexterm><indexterm id="iddle4320" significance="normal"><?indexkey S?><?primarykey sleeping?><primary><emphasis role="strong">sleeping</emphasis></primary></indexterm><indexterm id="iddle4321" significance="normal"><?indexkey S?><?primarykey sleeping?><?secondarykey BLOCKING STATE-DEPENDENT ACTIONS?><primary><emphasis role="strong">sleeping</emphasis></primary><secondary>blocking state-dependent actions</secondary></indexterm><indexterm id="iddle4322" significance="normal"><?indexkey S?><?primarykey sleeping?><?secondarykey BLOCKING STATE-DEPENDENT ACTIONS?><?tertiarykey BLOCKING STATE-DEPENDENT ACTIONS?><primary><emphasis role="strong">sleeping</emphasis></primary><secondary>blocking state-dependent actions</secondary><tertiary>blocking state-dependent actions</tertiary></indexterm><indexterm id="iddle4343" significance="normal"><?indexkey S?><?primarykey spin-waiting?><primary><emphasis role="strong">spin-waiting</emphasis></primary></indexterm><indexterm id="iddle5132" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey BUSY-WAITING?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>busy-waiting</secondary></indexterm>but it does not address the fundamental problem: that callers must deal with precondition failures themselves.<footnote id="ch14fn02" label="2"><para><literal>Queue</literal> offers both of these options—<literal>poll</literal> returns <literal>null</literal> if the queue is empty, and <literal>remove</literal> throws an exception—but <literal>Queue</literal> is not intended for use in producer-consumer designs. <literal>BlockingQueue</literal>, whose operations block until the queue is in the right state to proceed, is a better choice when producers and consumers will execute concurrently.</para></footnote></para>
<para>The client code in <link linkend="ch14list04" preference="0">Listing 14.4</link> is not the only way to implement the retry logic. The caller could retry the <literal>take</literal> immediately, without sleeping—an approach known as <emphasis>busy waiting</emphasis> or <emphasis>spin waiting</emphasis>. This could consume quite a lot of CPU time if the buffer state does not change for a while. On the other hand, if the caller decides to sleep so as not to consume so much CPU time, it could easily “oversleep” if the buffer state changes shortly after the call to <literal>sleep</literal>. So the client code is left with the choice between the poor CPU usage of spinning and the poor responsiveness of sleeping. (Somewhere between busy waiting and sleeping would be calling <literal>Thread.yield</literal> in each iteration, which is a hint to the scheduler that this would be a reasonable time to let another thread run. If you are waiting for another thread to do something, that something might happen faster if you yield the processor rather than consuming your full scheduling quantum.)</para>
</section>
<section id="ch14lev2sec2" label="14.1.2" xreflabel="14.1.2">
<title id="ch14lev2sec2__title">Example: Crude Blocking by Polling and Sleeping</title>
<para><literal>SleepyBoundedBuffer</literal> in <link linkend="ch14list05" preference="0">Listing 14.5</link> attempts to spare callers the inconvenience of implementing the retry logic on each call by encapsulating the same crude “poll and sleep” retry mechanism within the <literal>put</literal> and <literal>take</literal> operations. If the buffer is empty, <literal>take</literal> sleeps until another thread puts some data into the buffer; if the buffer is full, <literal>put</literal> sleeps until another thread makes room by removing some data. This approach encapsulates precondition management and simplifies using the buffer—definitely a step in the right direction.</para>
<para>The implementation of <literal>SleepyBoundedBuffer</literal> is more complicated than the previous attempt.<footnote id="ch14fn03" label="3"><para>We will spare you the details of Snow White’s other five bounded buffer implementations, especially <literal>SneezyBoundedBuffer</literal>.</para></footnote> The buffer code must test the appropriate state condition with the buffer lock held, because the variables that represent the state condition are guarded by the buffer lock. If the test fails, the executing thread sleeps for a while, first releasing the lock so other threads can access the buffer.<footnote id="ch14fn04" label="4"><para>It is usually a bad idea for a thread to go to sleep or otherwise block with a lock held, but in this case is even worse because the desired condition (buffer is full/empty) can never become true if the lock is not released!</para></footnote> Once the thread wakes up, it reacquires the lock and tries again, alternating between sleeping and testing the state condition until the operation can proceed.</para>
<para>From the perspective of the caller, this works nicely—if the operation can proceed immediately, it does, and otherwise it blocks—and the caller need not deal with the mechanics of failure and retry. Choosing the sleep granularity is a tradeoff between responsiveness and CPU usage; the smaller the sleep granularity, the more responsive, but also the more CPU resources consumed. <link linkend="ch14fig01" preference="1">Figure 14.1</link> shows how sleep granularity can affect responsiveness: there may be a delay between when buffer space becomes available and when the thread wakes up and checks again.</para>
<figure float="1" id="ch14fig01" label="14.1" xreflabel="14.1" condition="297">
<?docpage num="297"?>
<title id="ch14fig01__title">Thread Oversleeping Because the Condition Became True Just After It Went to Sleep.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="124" fileref="graphics/14fig01.gif" format="GIF" width="492"/></imageobject>

</mediaobject>
</figure>

<para><?docpage num="296"?></para><example id="ch14list05" label="14.5" role="Listing" xreflabel="14.5" condition="296">

<title id="ch14list05__title">Bounded Buffer Using Crude Blocking.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class SleepyBoundedBuffer&lt;V&gt; extends BaseBoundedBuffer&lt;V&gt; {
    public SleepyBoundedBuffer(int size) { super(size); }

    public void put(V v) throws InterruptedException {
        while (true) {
            synchronized (this) {
                if (<emphasis role="strong">!isFull()</emphasis>) {
                    doPut(v);
                    return;
                }
            }
            <emphasis role="strong">Thread.sleep</emphasis>(SLEEP_GRANULARITY);
        }
    }

    public V take() throws InterruptedException {
        while (true) {
            synchronized (this) {
                if (<emphasis role="strong">!isEmpty()</emphasis>)
                    return doTake();
            }
            <emphasis role="strong">Thread.sleep</emphasis>(SLEEP_GRANULARITY);
        }
    }
}
</programlisting>
</example>
<para><indexterm id="iddle1231" significance="normal"><?indexkey B?><?primarykey block(ing)?><?secondarykey STATE-DEPENDENT ACTIONS?><?tertiarykey CONDITION QUEUES?><primary><emphasis role="strong">block(ing)</emphasis></primary><secondary>state-dependent actions</secondary><tertiary>condition queues</tertiary></indexterm><indexterm id="iddle15051" significance="normal"><?indexkey C?><?primarykey condition?><primary><emphasis role="strong">condition</emphasis></primary></indexterm><indexterm id="iddle1505" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey QUEUES?><?tertiarykey BLOCKING STATE-DEPENDENT OPERATIONS USE?><primary><emphasis role="strong">condition</emphasis></primary><secondary>queues</secondary><tertiary>blocking state-dependent operations use</tertiary></indexterm><indexterm id="iddle1879" significance="normal"><?indexkey D?><?primarykey dependencies?><?secondarykey STATE?><?tertiarykey OPERATIONS, CONDITION QUEUE HANDLING?><primary><emphasis role="strong">dependencies</emphasis></primary><secondary>state</secondary><tertiary>operations, condition queue handling</tertiary></indexterm><indexterm id="iddle2182" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SLEEPYBOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SleepyBoundedBuffer</literal></secondary></indexterm><indexterm id="iddle3758" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey CONDITION?><?tertiarykey BLOCKING STATE-DEPENDENT OPERATIONS USE?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>condition</secondary><tertiary>blocking state-dependent operations use</tertiary></indexterm><indexterm id="iddle4392" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey DEPENDENT?><?tertiarykey OPERATIONS, CONDITION QUEUE HANDLING?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>dependent</secondary><tertiary>operations, condition queue handling</tertiary></indexterm><literal>SleepyBoundedBuffer</literal> also creates another requirement for the caller—dealing with <literal>InterruptedException</literal>. When a method blocks waiting for a condition to become true, the polite thing to do is to provide a cancellation mechanism (see <link linkend="ch07" preference="0">Chapter 7</link>). Like most well-behaved blocking library methods, <literal>SleepyBounded-Buffer</literal> supports cancellation through interruption, returning early and throwing <literal>InterruptedException</literal> if interrupted.</para>
<para>These attempts to synthesize a blocking operation from polling and sleeping were fairly painful. It would be nice to have a way of suspending a thread but ensuring that it is awakened promptly when a certain condition (such as the buffer being no longer full) becomes true. This is exactly what <emphasis>condition queues</emphasis> do.</para>
</section>
<section id="ch14lev2sec3" label="14.1.3" xreflabel="14.1.3">
<title id="ch14lev2sec3__title">Condition Queues to the Rescue</title>
<para>Condition queues are like the “toast is ready” bell on your toaster. If you are listening for it, you are notified promptly when your toast is ready and can drop what you are doing (or not, maybe you want to finish the newspaper first) and <?docpage num="297"?><indexterm id="iddle1267" significance="normal"><?indexkey B?><?primarykey buffer(s)?><?secondarykey BOUNDEDBUFFER EXAMPLE?><?tertiarykey CONDITION QUEUE USE?><primary><emphasis role="strong">buffer(s)</emphasis></primary><secondary><literal>BoundedBuffer</literal> example</secondary><tertiary>condition queue use</tertiary></indexterm><indexterm id="iddle1371" significance="normal"><?indexkey C?><?primarykey collections?><primary><emphasis role="strong">collections</emphasis></primary><seealso> hashtables.</seealso></indexterm><indexterm id="iddle1372" significance="normal"><?indexkey C?><?primarykey collections?><primary><emphasis role="strong">collections</emphasis></primary><seealso> <link linkend="iddle3001" preference="0"><emphasis role="strong">lists</emphasis></link>.</seealso></indexterm><indexterm id="iddle1373" significance="normal"><?indexkey C?><?primarykey collections?><primary><emphasis role="strong">collections</emphasis></primary><seealso> <link linkend="iddle5140" preference="0"><emphasis role="strong">wait(s)</emphasis>, sets</link>.</seealso></indexterm><indexterm id="iddle1503" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey QUEUES?><primary><emphasis role="strong">condition</emphasis></primary><secondary>queues</secondary><seealso> <link linkend="iddle4585" preference="0"><emphasis role="strong">synchronizer(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1507" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey QUEUES?><?tertiarykey INTRINSIC?><primary><emphasis role="strong">condition</emphasis></primary><secondary>queues</secondary><tertiary>intrinsic</tertiary></indexterm><indexterm id="iddle1581" significance="normal"><?indexkey C?><?primarykey containers?><primary><emphasis role="strong">containers</emphasis></primary><seealso> <link linkend="iddle1460" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, collections</link>.</seealso></indexterm><indexterm id="iddle1613" significance="normal"><?indexkey C?><?primarykey context switching?><?secondarykey CONDITION QUEUES ADVANTAGES?><primary><emphasis role="strong">context switching</emphasis></primary><secondary>condition queues advantages</secondary></indexterm><indexterm id="iddle1711" significance="normal"><?indexkey C?><?primarykey CPU utilization?><?secondarykey CONDITION QUEUES ADVANTAGES?><primary><emphasis role="strong">CPU utilization</emphasis></primary><secondary>condition queues advantages</secondary></indexterm><indexterm id="iddle1887" significance="normal"><?indexkey D?><?primarykey deques?><primary><emphasis role="strong">deques</emphasis></primary><seealso> <link linkend="iddle1460" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, collections</link>.</seealso></indexterm><indexterm id="iddle1888" significance="normal"><?indexkey D?><?primarykey deques?><primary><emphasis role="strong">deques</emphasis></primary><seealso> <link linkend="iddle4229" preference="0"><emphasis role="strong">shared/sharing</emphasis>, data structures</link>.</seealso></indexterm><indexterm id="iddle1889" significance="normal"><?indexkey D?><?primarykey deques?><primary><emphasis role="strong">deques</emphasis></primary><seealso> <link linkend="iddle1222" preference="0"><emphasis role="strong">block(ing)</emphasis>, queues, and thread pool management</link>.</seealso></indexterm><indexterm id="iddle2087" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BoundedBuffer</literal></secondary></indexterm><indexterm id="iddle2326" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey QUEUING?><primary><emphasis role="strong">fairness</emphasis></primary><secondary>queuing</secondary></indexterm><indexterm id="iddle2327" significance="normal"><?indexkey F?><?primarykey fairness?><?secondarykey QUEUING?><?tertiarykey INTRINSIC CONDITION QUEUES?><primary><emphasis role="strong">fairness</emphasis></primary><secondary>queuing</secondary><tertiary>intrinsic condition queues</tertiary></indexterm><indexterm id="iddle2623" significance="normal"><?indexkey H?><?primarykey hashcodes/hashtables?><primary><emphasis role="strong">hashcodes/hashtables</emphasis></primary><seealso> <link linkend="iddle1460" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, collections</link>.</seealso></indexterm><indexterm id="iddle2824" significance="normal"><?indexkey I?><?primarykey intrinsic condition queues?><primary><emphasis role="strong">intrinsic condition queues</emphasis></primary></indexterm><indexterm id="iddle2835" significance="normal"><?indexkey I?><?primarykey intrinsic locks?><?secondarykey INTRINSIC CONDITION QUEUE RELATIONSHIP TO?><primary><emphasis role="strong">intrinsic locks</emphasis></primary><secondary>intrinsic condition queue relationship to</secondary></indexterm><indexterm id="iddle3001" significance="normal"><?indexkey L?><?primarykey lists?><primary><emphasis role="strong">lists</emphasis></primary><seealso> <link linkend="iddle1460" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, collections</link>.</seealso></indexterm><indexterm id="iddle3111" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey INTRINSIC?><?tertiarykey INTRINSIC CONDITION QUEUE RELATIONSHIP TO?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>intrinsic</secondary><tertiary>intrinsic condition queue relationship to</tertiary></indexterm><indexterm id="iddle3396" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey TECHNIQUES?><?tertiarykey CONDITION QUEUES USE?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>techniques</secondary><tertiary>condition queues use</tertiary></indexterm><indexterm id="iddle3757" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey CONDITION?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>condition</secondary></indexterm><indexterm id="iddle3759" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey CONDITION?><?tertiarykey INTRINSIC?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>condition</secondary><tertiary>intrinsic</tertiary></indexterm><indexterm id="iddle3950" significance="normal"><?indexkey R?><?primarykey responsiveness?><?secondarykey CONDITION QUEUES ADVANTAGES?><primary><emphasis role="strong">responsiveness</emphasis></primary><secondary>condition queues advantages</secondary></indexterm><indexterm id="iddle4212" significance="normal"><?indexkey S?><?primarykey set(s)?><primary><emphasis role="strong">set(s)</emphasis></primary><seealso> <link linkend="iddle1460" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, collections</link>.</seealso></indexterm><indexterm id="iddle4964" significance="normal"><?indexkey T?><?primarykey tree(s)?><primary><emphasis role="strong">tree(s)</emphasis></primary><seealso> <link linkend="iddle1460" preference="0"><emphasis role="strong">concurrent/concurrency</emphasis>, collections</link>.</seealso></indexterm><indexterm id="iddle5140" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey SETS?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>sets</secondary></indexterm>get your toast. If you are not listening for it (perhaps you went outside to get the newspaper), you could miss the notification, but on return to the kitchen you can observe the state of the toaster and either retrieve the toast if it is finished or start listening for the bell again if it is not.</para>
<para>A <emphasis>condition queue</emphasis> gets its name because it gives a group of threads—called the <emphasis>wait set</emphasis>—a way to wait for a specific condition to become true. Unlike typical queues in which the elements are data items, the elements of a condition queue are the threads waiting for the condition.</para>
<para>Just as each Java object can act as a lock, each object can also act as a condition queue, and the <literal>wait</literal>, <literal>notify</literal>, and <literal>notifyAll</literal> methods in <literal>Object</literal> constitute the API for intrinsic condition queues. An object’s intrinsic lock and its intrinsic condition queue are related: in order to call any of the condition queue methods on object <emphasis>X</emphasis>, you must hold the lock on <emphasis>X</emphasis>. This is because the mechanism for waiting for state-based conditions is necessarily tightly bound to the mechanism for preserving state consistency: you cannot wait for a condition unless you can examine the state, and you cannot release another thread from a condition wait unless you can modify the state.</para>
<para><literal>Object.wait</literal> atomically releases the lock and asks the OS to suspend the current thread, allowing other threads to acquire the lock and therefore modify the object state. Upon waking, it reacquires the lock before returning. Intuitively, calling <literal>wait</literal> means “I want to go to sleep, but wake me when something interesting happens”, and calling the notification methods means “something interesting happened”.</para>
<para><literal>BoundedBuffer</literal> in <link linkend="ch14list06" preference="0">Listing 14.6</link> implements a bounded buffer using <literal>wait</literal> and <literal>notifyAll</literal>. This is simpler than the sleeping version, and is both more efficient (waking up less frequently if the buffer state does not change) and more responsive (waking up promptly when an interesting state change happens). This is a big improvement, but note that the introduction of condition queues didn’t change the semantics compared to the sleeping version. It is simply an optimization in several dimensions: CPU efficiency, context-switch overhead, and responsiveness. Condition queues don’t let you do anything you can’t do with sleeping and polling<footnote id="ch14fn05" label="5"><para>This is notquite true; a <emphasis>fair</emphasis> condition queue can guarantee the relative order in which threads are released from the wait set. Intrinsic condition queues, like intrinsic locks, do not offer fair queueing; explicit <literal>Condition</literal>s offer a choice of fair or nonfair queueing.</para></footnote>, but they make it a lot easier and more efficient to express and manage state dependence.</para>

<para><?docpage num="298"?></para><example id="ch14list06" label="14.6" role="Listing" xreflabel="14.6" condition="298">

<title id="ch14list06__title">Bounded Buffer Using Condition Queues.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class BoundedBuffer&lt;V&gt; extends BaseBoundedBuffer&lt;V&gt; {
    <emphasis>// CONDITION PREDICATE: not-full (!isFull())</emphasis>
    <emphasis>// CONDITION PREDICATE: not-empty (!isEmpty())</emphasis>

    public BoundedBuffer(int size) { super(size); }

    <emphasis>// BLOCKS-UNTIL: not-full</emphasis>
    public  <emphasis role="strong">synchronized</emphasis>  void put(V v) throws InterruptedException {
        <emphasis role="strong">while (isFull())</emphasis>
            <emphasis role="strong">wait();</emphasis>
        doPut(v);
        <emphasis role="strong">notifyAll();</emphasis>
    }

    <emphasis>// BLOCKS-UNTIL: not-empty</emphasis>
    public  <emphasis role="strong">synchronized</emphasis>  V take() throws InterruptedException {
        <emphasis role="strong">while (isEmpty())</emphasis>
            <emphasis role="strong">wait();</emphasis>
        V v = doTake();
        <emphasis role="strong">notifyAll();</emphasis>
        return v;
    }
}
</programlisting>
</example>
<para><indexterm id="iddle1509" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey QUEUES?><?tertiarykey USING?><primary><emphasis role="strong">condition</emphasis></primary><secondary>queues</secondary><tertiary>using</tertiary></indexterm><indexterm id="iddle2088" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey BOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>BoundedBuffer</literal></secondary></indexterm><indexterm id="iddle3330" significance="normal"><?indexkey N?><?primarykey notify?><?secondarykey EFFICIENCY OF?><primary><emphasis role="strong"><literal>notify</literal></emphasis></primary><secondary>efficiency of</secondary></indexterm><indexterm id="iddle3772" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey USING?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>using</secondary></indexterm><literal>BoundedBuffer</literal> is finally good enough to use—it is easy to use and manages state dependence sensibly.<footnote id="ch14fn06" label="6"><para><literal>ConditionBoundedBuffer</literal> in <link linkend="ch14lev1sec3" preference="0">Section 14.3</link> is even better: it is more efficient because it can use single notification instead of <literal>notifyAll</literal>.</para></footnote> A production version should also include timed versions of <literal>put</literal> and <literal>take</literal>, so that blocking operations can time out if they cannot complete within a time budget. The timed version of <literal>Object.wait</literal> makes this easy to implement.</para>
</section>
</section>
<section id="ch14lev1sec2" condition="298" label="14.2" xreflabel="14.2"><?docpage num="298"?>
<title id="ch14lev1sec2__title">Using Condition Queues</title>
<para>Condition queues make it easier to build efficient and responsive state-dependent classes, but they are still easy to use incorrectly; there are a lot of rules regarding their proper use that are not enforced by the compiler or platform. (This is one of the reasons to build on top of classes like <literal>LinkedBlockingQueue</literal>, <literal>CountDown-Latch</literal>, <literal>Semaphore</literal>, and <literal>FutureTask</literal> when you can; if you can get away with it, it is a lot easier.)</para>
<section id="ch14lev2sec4" condition="299" label="14.2.1" xreflabel="14.2.1">
<?docpage num="299"?><?docpage num="300"?>
<title id="ch14lev2sec4__title">The Condition Predicate</title>
<para><indexterm id="iddle1499" significance="normal"><?indexkey C?><?primarykey condition?><primary><emphasis role="strong">condition</emphasis></primary></indexterm><indexterm id="iddle15001" significance="normal"><?indexkey C?><?primarykey condition?><primary><emphasis role="strong">condition</emphasis></primary></indexterm><indexterm id="iddle1500" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey PREDICATE?><primary><emphasis role="strong">condition</emphasis></primary><secondary>predicate</secondary></indexterm><indexterm id="iddle1501" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey PREDICATE?><primary><emphasis role="strong">condition</emphasis></primary><secondary>predicate</secondary></indexterm><indexterm id="iddle1512" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey WAITS?><primary><emphasis role="strong">condition</emphasis></primary><secondary>waits</secondary></indexterm><indexterm id="iddle1513" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey WAITS?><?tertiarykey AND CONDITION PREDICATE?><primary><emphasis role="strong">condition</emphasis></primary><secondary>waits</secondary><tertiary>and condition predicate</tertiary></indexterm><indexterm id="iddle1901" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey CONDITION QUEUES?><primary><emphasis role="strong">design</emphasis></primary><secondary>condition queues</secondary></indexterm><indexterm id="iddle1902" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey CONDITION QUEUES?><?tertiarykey AND CONDITION PREDICATE?><primary><emphasis role="strong">design</emphasis></primary><secondary>condition queues</secondary><tertiary>and condition predicate</tertiary></indexterm><indexterm id="iddle2508" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey CONDITION PREDICATE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>condition predicate</secondary></indexterm><indexterm id="iddle2509" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey CONDITION PREDICATE?><?tertiarykey DOCUMENTATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>condition predicate</secondary><tertiary>documentation</tertiary></indexterm><indexterm id="iddle3163" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey WAIT?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary><literal>wait</literal></secondary></indexterm><indexterm id="iddle3164" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey WAIT?><?tertiarykey AND CONDITION PREDICATE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary><literal>wait</literal></secondary><tertiary>and condition predicate</tertiary></indexterm><indexterm id="iddle3641" significance="normal"><?indexkey P?><?primarykey precondition(s)?><?secondarykey CONDITION PREDICATE AS?><primary><emphasis role="strong">precondition(s)</emphasis></primary><secondary>condition predicate as</secondary></indexterm><indexterm id="iddle4430" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey VARIABLES?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>variables</secondary></indexterm><indexterm id="iddle4431" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey VARIABLES?><?tertiarykey CONDITION PREDICATE USE?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>variables</secondary><tertiary>condition predicate use</tertiary></indexterm><indexterm id="iddle5055" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey STATE?><primary><emphasis role="strong">variables</emphasis></primary><secondary>state</secondary></indexterm><indexterm id="iddle5056" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey STATE?><?tertiarykey CONDITION PREDICATE USE?><primary><emphasis role="strong">variables</emphasis></primary><secondary>state</secondary><tertiary>condition predicate use</tertiary></indexterm><indexterm id="iddle5133" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey CONDITION?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>condition</secondary></indexterm><indexterm id="iddle5134" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey CONDITION?><?tertiarykey AND CONDITION PREDICATE?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>condition</secondary><tertiary>and condition predicate</tertiary></indexterm>The key to using condition queues correctly is identifying the <emphasis>condition predicates</emphasis> that the object may wait for. It is the condition predicate that causes much of the confusion surrounding <literal>wait</literal> and <literal>notify</literal>, because it has no instantiation in the API and nothing in either the language specification or the JVM implementation ensures its correct use. In fact, it is not mentioned directly at all in the language specification or the Javadoc. But without it, condition waits would not work.</para>
<para><emphasis>The condition predicate is the precondition that makes an operation state-dependent in the first place.</emphasis> In a bounded buffer, <literal>take</literal> can proceed only if the buffer is not empty; otherwise it must wait. For <literal>take</literal>, the condition predicate is “the buffer is not empty”, which <literal>take</literal> must test for before proceeding. Similarly, the condition predicate for <literal>put</literal> is “the buffer is not full”. Condition predicates are expressions constructed from the state variables of the class; <literal>BaseBoundedBuffer</literal> tests for “buffer not empty” by comparing <literal>count</literal> to zero, and tests for “buffer not full” by comparing <literal>count</literal> to the buffer size.</para>
<sidebar float="1" id="ch14sb01" condition="299"><title/>
<para>Document the condition predicate(s) associated with a condition queue and the operations that wait on them.</para>
</sidebar>
<para>There is an important three-way relationship in a condition wait involving locking, the <literal>wait</literal> method, and a condition predicate. The condition predicate involves state variables, and the state variables are guarded by a lock, so before testing the condition predicate, we must hold that lock. The lock object and the condition queue object (the object on which <literal>wait</literal> and <literal>notify</literal> are invoked) must also be the same object.</para>
<para>In <literal>BoundedBuffer</literal>, the buffer state is guarded by the buffer lock and the buffer object is used as the condition queue. The <literal>take</literal> method acquires the buffer lock and then tests the condition predicate (that the buffer is nonempty). If the buffer is indeed nonempty, it removes the first element, which it can do because it still holds the lock guarding the buffer state.</para>
<para>If the condition predicate is not true (the buffer is empty), <literal>take</literal> must wait until another thread puts an object in the buffer. It does this by calling <literal>wait</literal> on the buffer’s intrinsic condition queue, which requires holding the lock on the condition queue object. As careful design would have it, <literal>take</literal> already holds that lock, which it needed to test the condition predicate (and if the condition predicate was true, to modify the buffer state in the same atomic operation). The <literal>wait</literal> method releases the lock, blocks the current thread, and waits until the specified timeout expires, the thread is interrupted, or the thread is awakened by a notification. After the thread wakes up, <literal>wait</literal> reacquires the lock before returning. A thread waking up from <literal>wait</literal> gets no special priority in reacquiring the lock; it contends for the lock just like any other thread attempting to enter a <literal>synchronized</literal> block.</para>
<sidebar float="1" id="ch14sb02" condition="299"><title/>
<para><?docpage num="300"?><indexterm id="iddle1517" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey WAITS?><?tertiarykey WAKING UP FROM, CONDITION QUEUE HANDLING?><primary><emphasis role="strong">condition</emphasis></primary><secondary>waits</secondary><tertiary>waking up from, condition queue handling</tertiary></indexterm><indexterm id="iddle2510" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey CONDITION PREDICATE?><?tertiarykey LOCK AND CONDITION QUEUE RELATIONSHIP?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>condition predicate</secondary><tertiary>lock and condition queue relationship</tertiary></indexterm><indexterm id="iddle3686" significance="normal"><?indexkey P?><?primarykey producer-consumer pattern?><?secondarykey PATHOLOGICAL WAITING CONDITIONS?><primary><emphasis role="strong">producer-consumer pattern</emphasis></primary><secondary>pathological waiting conditions</secondary></indexterm><indexterm id="iddle5139" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey CONDITION?><?tertiarykey WAKING UP FROM, CONDITION QUEUE HANDLING?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>condition</secondary><tertiary>waking up from, condition queue handling</tertiary></indexterm><indexterm id="iddle5151" significance="normal"><?indexkey W?><?primarykey waking up?><?secondarykey CONDITION QUEUE HANDLING?><primary><emphasis role="strong">waking up</emphasis></primary><secondary>condition queue handling</secondary></indexterm>Every call to <literal>wait</literal> is implicitly associated with a specific <emphasis>condition predicate</emphasis>. When calling <literal>wait</literal> regarding a particular condition predicate, the caller must already hold the lock associated with the condition queue, and that lock must also guard the state variables from which the condition predicate is composed.</para>
</sidebar>
</section>
<section id="ch14lev2sec5" label="14.2.2" xreflabel="14.2.2">
<title id="ch14lev2sec5__title">Waking Up Too Soon</title>
<para>As if the three-way relationship among the lock, the condition predicate, and the condition queue were not complicated enough, that <literal>wait</literal> returns does not necessarily mean that the condition predicate the thread is waiting for has become true.</para>
<para><emphasis>A single intrinsic condition queue may be used with more than one condition predicate.</emphasis> When your thread is awakened because someone called <literal>notifyAll</literal>, that doesn’t mean that the condition predicate <emphasis>you</emphasis> were waiting for is now true. (This is like having your toaster and coffee maker share a single bell; when it rings, you still have to look to see which device raised the signal.)<footnote id="ch14fn07" label="7"><para>This situation actually describes Tim’s kitchen pretty well; so many devices beep that when you hear one, you have to inspect the toaster, the microwave, the coffee maker, and several others to determine the cause of the signal.</para></footnote> Additionally, <literal>wait</literal> is even allowed to return “spuriously”—not in response to any thread calling <literal>notify</literal>.<footnote id="ch14fn08" label="8"><para>To push the breakfast analogy way too far, this is like a toaster with a loose connection that makes the bell go off when the toast is ready but also sometimes when it is not ready.</para></footnote></para>
<para>When control re-enters the code calling <literal>wait</literal>, it has reacquired the lock associated with the condition queue. Is the condition predicate now true? Maybe. It might have been true at the time the notifying thread called <literal>notifyAll</literal>, but could have become false again by the time <emphasis>you</emphasis> reacquire the lock. Other threads may have acquired the lock and changed the object’s state between when your thread was awakened and when <literal>wait</literal> reacquired the lock. Or maybe it hasn’t been true at all since you called <literal>wait</literal>. You don’t know why another thread called <literal>notify</literal> or <literal>notifyAll</literal>; maybe it was because <emphasis>another</emphasis> condition predicate associated with the same condition queue became true. Multiple condition predicates per condition queue are quite common—<literal>BoundedBuffer</literal> uses the same condition queue for both the “not full” and “not empty” predicates.<footnote id="ch14fn09" label="9"><para>It is actually possible for threads to be waiting for both “not full” and “not empty” at the same time! This can happen when the number of producers/consumers exceeds the buffer capacity.</para></footnote></para>
<para>For all these reasons, when you wake up from <literal>wait</literal> you must test the condition predicate <emphasis>again</emphasis>, and go back to waiting (or fail) if it is not yet true. Since you can wake up repeatedly without your condition predicate being true, you must therefore always call <literal>wait</literal> from within a loop, testing the condition predicate in each iteration. The canonical form for a condition wait is shown in <link linkend="ch14list07" preference="0">Listing 14.7</link>.</para>

<para><?docpage num="301"?></para><example id="ch14list07" label="14.7" role="Listing" xreflabel="14.7" condition="301">

<title id="ch14list07__title">Canonical Form for State-dependent Methods.</title>
<programlisting format="linespecific" linenumbering="unnumbered">void stateDependentMethod() throws InterruptedException {
    <emphasis>// condition predicate must be guarded by lock</emphasis>
    synchronized(lock) {
        while (!conditionPredicate())
            lock.wait();
        <emphasis>// object is now in desired state</emphasis>
    }
}
</programlisting>
</example>
<sidebar float="1" id="ch14sb03" condition="301"><title/>
<para><indexterm id="iddle1514" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey WAITS?><?tertiarykey CANONICAL FORM?><primary><emphasis role="strong">condition</emphasis></primary><secondary>waits</secondary><tertiary>canonical form</tertiary></indexterm><indexterm id="iddle2511" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey CONDITION WAIT USAGE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>condition wait usage</secondary></indexterm><indexterm id="iddle2637" significance="normal"><?indexkey H?><?primarykey hijacked signal?><primary><emphasis role="strong">hijacked signal</emphasis></primary><see> <link linkend="iddle3213" preference="0"><emphasis role="strong">missed signals</emphasis></link>.</see></indexterm><indexterm id="iddle3213" significance="normal"><?indexkey M?><?primarykey missed signals?><primary><emphasis role="strong">missed signals</emphasis></primary><seealso> <link linkend="iddle3497" preference="0"><emphasis role="strong">performance</emphasis>, liveness</link>.</seealso></indexterm><indexterm id="iddle3214" significance="normal"><?indexkey M?><?primarykey missed signals?><primary><emphasis role="strong">missed signals</emphasis></primary></indexterm><indexterm id="iddle4436" significance="normal"><?indexkey S?><?primarykey stateDependentMethod example?><primary><emphasis role="strong">stateDependentMethod example</emphasis></primary></indexterm><indexterm id="iddle5135" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey CONDITION?><?tertiarykey CANONICAL FORM?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>condition</secondary><tertiary>canonical form</tertiary></indexterm>When using condition waits (<literal>Object.wait</literal> or <literal>Condition.await</literal>):</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Always have a condition predicate—some test of object state that must hold before proceeding;</para></listitem>
<listitem><para>Always test the condition predicate before calling <literal>wait</literal>, and again after returning from <literal>wait</literal>;</para></listitem>
<listitem><para>Always call <literal>wait</literal> in a loop;</para></listitem>
<listitem><para>Ensure that the state variables making up the condition predicate are guarded by the lock associated with the condition queue;</para></listitem>
<listitem><para>Hold the lock associated with the the condition queue when calling <literal>wait</literal>, <literal>notify</literal>, or <literal>notifyAll</literal>; and</para></listitem>
<listitem><para>Do not release the lock after checking the condition predicate but before acting on it.</para></listitem>
</itemizedlist>
</sidebar>
</section>
<section id="ch14lev2sec6" label="14.2.3" xreflabel="14.2.3">
<title id="ch14lev2sec6__title">Missed Signals</title>
<para><link linkend="ch10" preference="0">Chapter 10</link> discussed liveness failures such as deadlock and livelock. Another form of liveness failure is <emphasis>missed signals</emphasis>. A missed signal occurs when a thread must wait for a specific condition that is already true, but fails to check the condition predicate before waiting. Now the thread is waiting to be notified of an event that has already occurred. This is like starting the toast, going out to get the newspaper, having the bell go off while you are outside, and then sitting down at the kitchen table waiting for the toast bell. You could wait a long time—potentially forever.<footnote id="ch14fn10" label="10"><para>In order to emerge from this wait, someone else would have to make toast, but this will just make matters worse; when the bell rings, you will then have a disagreement about toast ownership.</para></footnote> Unlike the marmalade for your toast, notification is not “sticky”—if thread <emphasis>A</emphasis> notifies on a condition queue and thread <emphasis>B</emphasis> subsequently waits on that same condition queue, <emphasis>B</emphasis> does <emphasis>not</emphasis> immediately wake up—another notification is required to wake <emphasis>B</emphasis>. Missed signals are the result of coding errors like those warned against in the list above, such as failing to test the condition predicate before calling <literal>wait</literal>. If you structure your condition waits as in <link linkend="ch14list07" preference="0">Listing 14.7</link>, you will not have problems with missed signals.</para>
</section>
<section id="ch14lev2sec7" condition="302" label="14.2.4" xreflabel="14.2.4">
<?docpage num="302"?><?docpage num="303"?>
<title id="ch14lev2sec7__title">Notification</title>
<para><indexterm id="iddle3215" significance="normal"><?indexkey M?><?primarykey missed signals?><?secondarykey AS SINGLE NOTIFICATION RISK?><primary><emphasis role="strong">missed signals</emphasis></primary><secondary>as single notification risk</secondary></indexterm><indexterm id="iddle3310" significance="normal"><?indexkey N?><?primarykey notification?><primary><emphasis role="strong">notification</emphasis></primary><seealso> <link linkend="iddle3750" preference="0"><emphasis role="strong">queue(s)</emphasis>, blocking</link>.</seealso></indexterm><indexterm id="iddle3311" significance="normal"><?indexkey N?><?primarykey notification?><primary><emphasis role="strong">notification</emphasis></primary><seealso> <link linkend="iddle15051" preference="0"><emphasis role="strong">condition</emphasis></link>.</seealso></indexterm><indexterm id="iddle3312" significance="normal"><?indexkey N?><?primarykey notification?><primary><emphasis role="strong">notification</emphasis></primary><seealso> <link linkend="iddle2059" preference="0"><emphasis role="strong">event(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle3313" significance="normal"><?indexkey N?><?primarykey notification?><primary><emphasis role="strong">notification</emphasis></primary><seealso> <link linkend="iddle4520" preference="0"><emphasis role="strong">Swing</emphasis>, listeners</link>.</seealso></indexterm><indexterm id="iddle3314" significance="normal"><?indexkey N?><?primarykey notification?><primary><emphasis role="strong">notification</emphasis></primary><seealso> <link linkend="iddle3328" preference="0"><emphasis role="strong"><literal>notify</literal></emphasis></link>.</seealso></indexterm><indexterm id="iddle3315" significance="normal"><?indexkey N?><?primarykey notification?><primary><emphasis role="strong">notification</emphasis></primary><seealso> <link linkend="iddle3336" preference="0"><emphasis role="strong"><literal>notifyAll</literal></emphasis></link>.</seealso></indexterm><indexterm id="iddle3316" significance="normal"><?indexkey N?><?primarykey notification?><primary><emphasis role="strong">notification</emphasis></primary><seealso> <link linkend="iddle4320" preference="0"><emphasis role="strong">sleeping</emphasis></link>.</seealso></indexterm><indexterm id="iddle3317" significance="normal"><?indexkey N?><?primarykey notification?><primary><emphasis role="strong">notification</emphasis></primary><seealso> <link linkend="iddle1234" preference="0"><emphasis role="strong">block(ing)</emphasis>, waits</link>.</seealso></indexterm><indexterm id="iddle3318" significance="normal"><?indexkey N?><?primarykey notification?><primary><emphasis role="strong">notification</emphasis></primary><seealso> <link linkend="iddle5146" preference="0"><emphasis role="strong">waking up</emphasis></link>.</seealso></indexterm><indexterm id="iddle3331" significance="normal"><?indexkey N?><?primarykey notify?><?secondarykey MISSED SIGNAL RISK?><primary><emphasis role="strong"><literal>notify</literal></emphasis></primary><secondary>missed signal risk</secondary></indexterm><indexterm id="iddle3332" significance="normal"><?indexkey N?><?primarykey notify?><?secondarykey NOTIFYALL VS?><primary><emphasis role="strong"><literal>notify</literal></emphasis></primary><secondary><literal>notifyAll</literal> vs</secondary></indexterm><indexterm id="iddle3336" significance="normal"><?indexkey N?><?primarykey notifyAll?><primary><emphasis role="strong"><literal>notifyAll</literal></emphasis></primary></indexterm><indexterm id="iddle3337" significance="normal"><?indexkey N?><?primarykey notifyAll?><?secondarykey NOTIFY VS?><primary><emphasis role="strong">notifyAll</emphasis></primary><secondary><literal>notify</literal> vs</secondary></indexterm>So far, we’ve described half of what goes on in a condition wait: waiting. The other half is notification. In a bounded buffer, <literal>take</literal> blocks if called when the buffer is empty. In order for <literal>take</literal> to <emphasis>unblock</emphasis> when the buffer becomes nonempty, we must ensure that <emphasis>every</emphasis> code path in which the buffer could become nonempty performs a notification. In <literal>BoundedBuffer</literal>, there is only one such place—after a <literal>put</literal>. So <literal>put</literal> calls <literal>notifyAll</literal> after successfully adding an object to the buffer. Similarly, <literal>take</literal> calls <literal>notifyAll</literal> after removing an element to indicate that the buffer may no longer be full, in case any threads are waiting on the “not full” condition.</para>
<sidebar float="1" id="ch14sb04" condition="302"><title/>
<para>Whenever you wait on a condition, make sure that someone will perform a notification whenever the condition predicate becomes true.</para>
</sidebar>
<para>There are two notification methods in the condition queue API—<literal>notify</literal> and <literal>notifyAll</literal>. To call either, you must hold the lock associated with the condition queue object. Calling <literal>notify</literal> causes the JVM to select one thread waiting on that condition queue to wake up; calling <literal>notifyAll</literal> wakes up <emphasis>all</emphasis> the threads waiting on that condition queue. Because you must hold the lock on the condition queue object when calling <literal>notify</literal> or <literal>notifyAll</literal>, and waiting threads cannot return from <literal>wait</literal> without reacquiring the lock, the notifying thread should release the lock quickly to ensure that the waiting threads are unblocked as soon as possible.</para>
<para>Because multiple threads could be waiting on the same condition queue for different condition predicates, using <literal>notify</literal> instead of <literal>notifyAll</literal> can be dangerous, primarily because single notification is prone to a problem akin to missed signals.</para>
<para><literal>BoundedBuffer</literal> provides a good illustration of why <literal>notifyAll</literal> should be preferred to single <literal>notify</literal> in most cases. The condition queue is used for two different condition predicates: “not full” and “not empty”. Suppose thread <emphasis>A</emphasis> waits on a condition queue for predicate <emphasis>PA</emphasis>, while thread <emphasis>B</emphasis> waits on the same condition queue for predicate <emphasis>PB</emphasis>. Now, suppose <emphasis>PB</emphasis> becomes true and thread <emphasis>C</emphasis> performs a single <literal>notify</literal>: the JVM will wake up one thread of its own choosing. If <emphasis>A</emphasis> is chosen, it will wake up, see that <emphasis>PA</emphasis> is not yet true, and go back to waiting. Meanwhile, <emphasis>B</emphasis>, which could now make progress, does not wake up. This is not exactly a missed signal—it’s more of a “hijacked signal”—but the problem is the same: a thread is waiting for a signal that has (or should have) already occurred.</para>
<sidebar float="1" id="ch14sb05" condition="302"><title/>
<para><?docpage num="303"?><indexterm id="iddle1519" significance="normal"><?indexkey C?><?primarykey conditional?><?secondarykey NOTIFICATION?><primary><emphasis role="strong">conditional</emphasis></primary><secondary>notification</secondary></indexterm><indexterm id="iddle1520" significance="normal"><?indexkey C?><?primarykey conditional?><?secondarykey NOTIFICATION?><?tertiarykey AS OPTIMIZATION?><primary><emphasis role="strong">conditional</emphasis></primary><secondary>notification</secondary><tertiary>as optimization</tertiary></indexterm><indexterm id="iddle2555" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey NOTIFICATION?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>notification</secondary></indexterm><indexterm id="iddle3321" significance="normal"><?indexkey N?><?primarykey notification?><?secondarykey CONDITIONAL?><primary><emphasis role="strong">notification</emphasis></primary><secondary>conditional</secondary></indexterm><indexterm id="iddle3322" significance="normal"><?indexkey N?><?primarykey notification?><?secondarykey CONDITIONAL?><?tertiarykey AS OPTIMIZATION?><primary><emphasis role="strong">notification</emphasis></primary><secondary>conditional</secondary><tertiary>as optimization</tertiary></indexterm><indexterm id="iddle3328" significance="normal"><?indexkey N?><?primarykey notify?><primary><emphasis role="strong"><literal>notify</literal></emphasis></primary></indexterm><indexterm id="iddle3329" significance="normal"><?indexkey N?><?primarykey notify?><?secondarykey AS OPTIMIZATION?><primary><emphasis role="strong"><literal>notify</literal></emphasis></primary><secondary>as optimization</secondary></indexterm><indexterm id="iddle3335" significance="normal"><?indexkey N?><?primarykey notify?><?secondarykey USAGE GUIDELINES?><primary><emphasis role="strong"><literal>notify</literal></emphasis></primary><secondary>usage guidelines</secondary></indexterm><indexterm id="iddle3397" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey TECHNIQUES?><?tertiarykey CONDITIONAL NOTIFICATION?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>techniques</secondary><tertiary>conditional notification</tertiary></indexterm><indexterm id="iddle3510" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey NOTIFYALL IMPACT ON?><primary><emphasis role="strong">performance</emphasis></primary><secondary><literal>notifyAll</literal> impact on</secondary></indexterm><indexterm id="iddle4290" significance="normal"><?indexkey S?><?primarykey single notification?><primary><emphasis role="strong">single notification</emphasis></primary><see> <link linkend="iddle3328" preference="0"><emphasis role="strong"><literal>notify</literal></emphasis></link>.</see></indexterm><indexterm id="iddle4291" significance="normal"><?indexkey S?><?primarykey single notification?><primary><emphasis role="strong">single notification</emphasis></primary><see> <link linkend="iddle4278" preference="0"><emphasis role="strong">signal</emphasis></link>.</see></indexterm>Single <literal>notify</literal> can be used instead of <literal>notifyAll</literal> only when both of the following conditions hold:</para>
<itemizedlist mark="none" spacing="normal">
<listitem><formalpara><title><emphasis role="strong"><?design?>Uniform waiters.</emphasis></title><para>Only one condition predicate is associated with the condition queue, and each thread executes the same logic upon returning from <literal>wait</literal>; and</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>One-in, one-out.</emphasis></title><para>A notification on the condition variable enables at most one thread to proceed.</para></formalpara></listitem>
</itemizedlist>
</sidebar>
<para role="continued"><literal>BoundedBuffer</literal> meets the one-in, one-out requirement, but does not meet the uniform waiters requirement because waiting threads might be waiting for either the “not full” and “not empty” condition. A “starting gate” latch like that used in <literal>TestHarness</literal> on page <link linkend="ch05list11" preference="0" role="pageref">96</link>, in which a single event releases a set of threads, does not meet the one-in, one-out requirement because opening the starting gate lets multiple threads proceed.</para>
<para>Most classes don’t meet these requirements, so the prevailing wisdom is to use <literal>notifyAll</literal> in preference to single <literal>notify</literal>. While this may be inefficient, it is much easier to ensure that your classes behave correctly when using <literal>notifyAll</literal> instead of <literal>notify</literal>.</para>
<para>This “prevailing wisdom” makes some people uncomfortable, and for good reason. Using <literal>notifyAll</literal> when only one thread can make progress is inefficient—sometimes a little, sometimes grossly so. If ten threads are waiting on a condition queue, calling <literal>notifyAll</literal> causes each of them to wake up and contend for the lock; then most or all of them will go right back to sleep. This means a lot of context switches and a lot of contended lock acquisitions for each event that enables (maybe) a single thread to make progress. (In the worst case, using <literal>notify-All</literal> results in <emphasis>O</emphasis>(<emphasis>n</emphasis><superscript>2</superscript>) wakeups where <emphasis>n</emphasis> would suffice.) This is another situation where performance concerns support one approach and safety concerns support the other.</para>
<para>The notification done by <literal>put</literal> and <literal>take</literal> in <literal>BoundedBuffer</literal> is conservative: a notification is performed every time an object is put into or removed from the buffer. This could be optimized by observing that a thread can be released from a wait only if the buffer goes from empty to not empty or from full to not full, and notifying only if a <literal>put</literal> or <literal>take</literal> effected one of these state transitions. This is called <emphasis>conditional notification.</emphasis> While conditional notification can improve performance, it is tricky to get right (and also complicates the implementation of subclasses) and so should be used carefully. <link linkend="ch14list08" preference="0">Listing 14.8</link> illustrates using conditional notification in <literal>BoundedBuffer</literal>.<literal>put</literal>.</para>
<para>Single notification and conditional notification are optimizations. As always, follow the principle “First make it right, and then make it fast—<emphasis>if</emphasis> it is not already fast enough” when using these optimizations; it is easy to introduce strange liveness failures by applying them incorrectly.</para>

<para><?docpage num="304"?></para><example id="ch14list08" label="14.8" role="Listing" xreflabel="14.8" condition="304">

<title id="ch14list08__title">Using Conditional Notification in <literal>BoundedBuffer.put</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public synchronized void put(V v) throws InterruptedException {
    while (isFull())
        wait();
    <emphasis role="strong">boolean wasEmpty = isEmpty();</emphasis>
    doPut(v);
    <emphasis role="strong">if (wasEmpty)</emphasis>
        <emphasis role="strong">notifyAll();</emphasis>
}
</programlisting>
</example>
</section>
<section id="ch14lev2sec8" label="14.2.5" xreflabel="14.2.5">
<title id="ch14lev2sec8__title">Example: A Gate Class</title>
<para><indexterm id="iddle1202" significance="normal"><?indexkey B?><?primarykey binary latch?><primary><emphasis role="strong">binary latch</emphasis></primary></indexterm><indexterm id="iddle1450" significance="normal"><?indexkey C?><?primarykey Concurrent Programming in Java?><primary><emphasis role="strong"><emphasis>Concurrent Programming in Java</emphasis></emphasis></primary></indexterm><indexterm id="iddle1521" significance="normal"><?indexkey C?><?primarykey conditional?><?secondarykey NOTIFICATION?><?tertiarykey SUBCLASSING SAFETY ISSUES?><primary><emphasis role="strong">conditional</emphasis></primary><secondary>notification</secondary><tertiary>subclassing safety issues</tertiary></indexterm><indexterm id="iddle1522" significance="normal"><?indexkey C?><?primarykey conditional?><?secondarykey NOTIFICATION?><?tertiarykey USE?><primary><emphasis role="strong">conditional</emphasis></primary><secondary>notification</secondary><tertiary>use</tertiary></indexterm><indexterm id="iddle1962" significance="normal"><?indexkey D?><?primarykey documentation?><?secondarykey CRITICAL IMPORTANCE FOR CONDITIONAL NOTIFICATION USE?><primary><emphasis role="strong">documentation</emphasis></primary><secondary>critical importance for conditional notification use</secondary></indexterm><indexterm id="iddle2397" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey ISSUES AND CAUSES?><?tertiarykey STATE-DEPENDENT CLASSES?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>issues and causes</secondary><tertiary>state-dependent classes</tertiary></indexterm><indexterm id="iddle2447" significance="normal"><?indexkey G?><?primarykey gate?><?secondarykey THREADGATE EXAMPLE?><primary><emphasis role="strong">gate</emphasis></primary><secondary><literal>ThreadGate</literal> example</secondary></indexterm><indexterm id="iddle2938" significance="normal"><?indexkey L?><?primarykey latch(es)?><?secondarykey BINARY?><primary><emphasis role="strong">latch(es)</emphasis></primary><secondary>binary</secondary></indexterm><indexterm id="iddle2942" significance="normal"><?indexkey L?><?primarykey latch(es)?><?secondarykey THREADGATE EXAMPLE?><primary><emphasis role="strong">latch(es)</emphasis></primary><secondary><literal>ThreadGate</literal> example</secondary></indexterm><indexterm id="iddle3323" significance="normal"><?indexkey N?><?primarykey notification?><?secondarykey CONDITIONAL?><?tertiarykey USE?><primary><emphasis role="strong">notification</emphasis></primary><secondary>conditional</secondary><tertiary>use</tertiary></indexterm><indexterm id="iddle3333" significance="normal"><?indexkey N?><?primarykey notify?><?secondarykey SUBCLASSING SAFETY ISSUES?><primary><emphasis role="strong"><literal>notify</literal></emphasis></primary><secondary>subclassing safety issues</secondary></indexterm><indexterm id="iddle3334" significance="normal"><?indexkey N?><?primarykey notify?><?secondarykey SUBCLASSING SAFETY ISSUES?><?tertiarykey DOCUMENTATION IMPORTANCE?><primary><emphasis role="strong"><literal>notify</literal></emphasis></primary><secondary>subclassing safety issues</secondary><tertiary>documentation importance</tertiary></indexterm><indexterm id="iddle3799" significance="normal"><?indexkey R?><?primarykey reclosable thread gate?><primary><emphasis role="strong">reclosable thread gate</emphasis></primary></indexterm><indexterm id="iddle4045" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey SUBCLASSING ISSUES?><primary><emphasis role="strong">safety</emphasis></primary><secondary>subclassing issues</secondary></indexterm><indexterm id="iddle4506" significance="normal"><?indexkey S?><?primarykey subclassing?><primary><emphasis role="strong">subclassing</emphasis></primary></indexterm><indexterm id="iddle4507" significance="normal"><?indexkey S?><?primarykey subclassing?><?secondarykey SAFETY ISSUES?><primary><emphasis role="strong">subclassing</emphasis></primary><secondary>safety issues</secondary></indexterm>The starting gate latch in <literal>TestHarness</literal> on page <link linkend="ch05list11" preference="0" role="pageref">96</link> was constructed with an initial count of one, creating a <emphasis>binary latch</emphasis>: one with two states, the initial state and the terminal state. The latch prevents threads from passing the starting gate until it is opened, at which point all the threads can pass through. While this latching mechanism is often exactly what is needed, sometimes it is a drawback that a gate constructed in this manner cannot be reclosed once opened.</para>
<para>It is easy to develop a recloseable <literal>ThreadGate</literal> class using condition waits, as shown in <link linkend="ch14list09" preference="0">Listing 14.9</link>. <literal>ThreadGate</literal> lets the gate be opened and closed, providing an <literal>await</literal> method that blocks until the gate is opened. The <literal>open</literal> method uses <literal>notifyAll</literal> because the semantics of this class fail the “one-in, one-out” test for single notification.</para>
<para>The condition predicate used by <literal>await</literal> is more complicated than simply testing <literal>isOpen</literal>. This is needed because if <emphasis>N</emphasis> threads are waiting at the gate at the time it is opened, they should all be allowed to proceed. But, if the gate is opened and closed in rapid succession, all threads might not be released if <literal>await</literal> examines only <literal>isOpen</literal>: by the time all the threads receive the notification, reacquire the lock, and emerge from <literal>wait</literal>, the gate may have closed again. So <literal>ThreadGate</literal> uses a somewhat more complicated condition predicate: every time the gate is closed, a “generation” counter is incremented, and a thread may pass <literal>await</literal> if the gate is open now or if the gate has opened since this thread arrived at the gate.</para>
<para>Since <literal>ThreadGate</literal> only supports waiting for the gate to open, it performs notification only in <literal>open</literal>; to support both “wait for open” and “wait for close” operations, it would have to notify in both <literal>open</literal> and <literal>close</literal>. This illustrates why state-dependent classes can be fragile to maintain—the addition of a new statedependent operation may require modifying many code paths that modify the object state so that the appropriate notifications can be performed.</para>
</section>
<section id="ch14lev2sec9" label="14.2.6" xreflabel="14.2.6">
<title id="ch14lev2sec9__title">Subclass Safety Issues</title>
<para>Using conditional or single notification introduces constraints that can complicate subclassing [CPJ 3.3.3.3]. If you want to support subclassing at all, you must structure your class so subclasses can add the appropriate notification on behalf <?docpage num="305"?><indexterm id="iddle1988" significance="normal"><?indexkey E?><?primarykey Effective Java Programming Language Guide?><primary><emphasis role="strong"><emphasis>Effective Java Programming Language Guide</emphasis></emphasis></primary></indexterm><indexterm id="iddle2201" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey THREADGATE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ThreadGate</literal></secondary></indexterm>of the base class if it is subclassed in a way that violates one of the requirements for single or conditional notification.</para>
<example id="ch14list09" label="14.9" role="Listing" xreflabel="14.9" condition="305">
<title id="ch14list09__title">Recloseable Gate Using <literal>Wait</literal> and <literal>Notifyall</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ThreadGate {
    <emphasis>// CONDITION-PREDICATE: opened-since(n) (isOpen || generation&gt;n)</emphasis>
    @GuardedBy("this") private boolean isOpen;
    @GuardedBy("this") private int generation;

    public synchronized void close() {
        isOpen = false;
    }

    public synchronized void open() {
        ++generation;
        isOpen = true;
        notifyAll();
    }

    <emphasis>// BLOCKS-UNTIL: opened-since(generation on entry)</emphasis>
    public synchronized void await() throws InterruptedException {
        int arrivalGeneration = generation;
        while (!isOpen &amp;&amp; arrivalGeneration == generation)
            wait();
    }
}
</programlisting>
</example>
<para><emphasis>A state-dependent class should either fully expose (and document) its waiting and notification protocols to subclasses, or prevent subclasses from participating in them at all.</emphasis> (This is an extension of “design and document for inheritance, or else prohibit it” [EJ Item 15].) At the very least, designing a state-dependent class for inheritance requires exposing the condition queues and locks and documenting the condition predicates and synchronization policy; it may also require exposing the underlying state variables. (The worst thing a state-dependent class can do is expose its state to subclasses but <emphasis>not</emphasis> document its protocols for waiting and notification; this is like a class exposing its state variables but not documenting its invariants.)</para>
<para>One option for doing this is to effectively prohibit subclassing, either by making the class <literal>final</literal> or by hiding the condition queues, locks, and state variables from subclasses. Otherwise, if the subclass does something to undermine the way the base class uses <literal>notify</literal>, it needs to be able to repair the damage. Consider an unbounded blocking stack in which the pop operation blocks if the stack is empty but the push operation can always proceed. This meets the requirements for single notification. If this class uses single notification and a subclass adds a blocking “pop two consecutive elements” method, there are now two classes of <?docpage num="306"?><indexterm id="iddle1118" significance="normal"><?indexkey A?><?primarykey AQS (AbstractQueuedSynchronizer) framework?><?secondarykey EXIT PROTOCOL USE?><primary><emphasis role="strong">AQS (AbstractQueuedSynchronizer) framework</emphasis></primary><secondary>exit protocol use</secondary></indexterm><indexterm id="iddle1362" significance="normal"><?indexkey C?><?primarykey client-side locking?><?secondarykey AND CONDITION QUEUES?><primary><emphasis role="strong">client-side locking</emphasis></primary><secondary>and condition queues</secondary></indexterm><indexterm id="iddle1496" significance="normal"><?indexkey C?><?primarykey Condition?><?secondarykey EXPLICIT CONDITION OBJECT USE?><primary><emphasis role="strong">Condition</emphasis></primary><secondary>explicit condition object use</secondary></indexterm><indexterm id="iddle1506" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey QUEUES?><?tertiarykey EXPLICIT?><primary><emphasis role="strong">condition</emphasis></primary><secondary>queues</secondary><tertiary>explicit</tertiary></indexterm><indexterm id="iddle1508" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey QUEUES?><?tertiarykey INTRINSIC, DISADVANTAGES OF?><primary><emphasis role="strong">condition</emphasis></primary><secondary>queues</secondary><tertiary>intrinsic, disadvantages of</tertiary></indexterm><indexterm id="iddle1510" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey VARIABLES?><primary><emphasis role="strong">condition</emphasis></primary><secondary>variables</secondary></indexterm><indexterm id="iddle1511" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey VARIABLES?><?tertiarykey EXPLICIT?><primary><emphasis role="strong">condition</emphasis></primary><secondary>variables</secondary><tertiary>explicit</tertiary></indexterm><indexterm id="iddle1900" significance="normal"><?indexkey D?><?primarykey design?><?secondarykey CONDITION QUEUE ENCAPSULATION?><primary><emphasis role="strong">design</emphasis></primary><secondary>condition queue encapsulation</secondary></indexterm><indexterm id="iddle2017" significance="normal"><?indexkey E?><?primarykey encapsulation?><?secondarykey OF CONDITION QUEUES?><primary><emphasis role="strong">encapsulation</emphasis></primary><secondary>of condition queues</secondary></indexterm><indexterm id="iddle2037" significance="normal"><?indexkey E?><?primarykey entry protocols?><primary><emphasis role="strong">entry protocols</emphasis></primary></indexterm><indexterm id="iddle2038" significance="normal"><?indexkey E?><?primarykey entry protocols?><?secondarykey STATE-DEPENDENT OPERATIONS?><primary><emphasis role="strong">entry protocols</emphasis></primary><secondary>state-dependent operations</secondary></indexterm><indexterm id="iddle2279" significance="normal"><?indexkey E?><?primarykey exit protocols?><primary><emphasis role="strong">exit protocols</emphasis></primary></indexterm><indexterm id="iddle2280" significance="normal"><?indexkey E?><?primarykey exit protocols?><?secondarykey STATE-DEPENDENT OPERATIONS?><primary><emphasis role="strong">exit protocols</emphasis></primary><secondary>state-dependent operations</secondary></indexterm><indexterm id="iddle2825" significance="normal"><?indexkey I?><?primarykey intrinsic condition queues?><?secondarykey DISADVANTAGES OF?><primary><emphasis role="strong">intrinsic condition queues</emphasis></primary><secondary>disadvantages of</secondary></indexterm><indexterm id="iddle3068" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CLIENT-SIDE?><?tertiarykey CONDITION QUEUE ENCAPSULATION IMPACT ON?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>client-side</secondary><tertiary>condition queue encapsulation impact on</tertiary></indexterm><indexterm id="iddle3346" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey CONDITION?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>condition</secondary></indexterm><indexterm id="iddle3347" significance="normal"><?indexkey O?><?primarykey object(s)?><?secondarykey CONDITION?><?tertiarykey EXPLICIT?><primary><emphasis role="strong">object(s)</emphasis></primary><secondary>condition</secondary><tertiary>explicit</tertiary></indexterm><indexterm id="iddle3706" significance="normal"><?indexkey P?><?primarykey protocol(s)?><?secondarykey ENTRY AND EXIT?><primary><emphasis role="strong">protocol(s)</emphasis></primary><secondary>entry and exit</secondary></indexterm><indexterm id="iddle3707" significance="normal"><?indexkey P?><?primarykey protocol(s)?><?secondarykey ENTRY AND EXIT?><?tertiarykey STATE-DEPENDENT OPERATIONS?><primary><emphasis role="strong">protocol(s)</emphasis></primary><secondary>entry and exit</secondary><tertiary>state-dependent operations</tertiary></indexterm><indexterm id="iddle3760" significance="normal"><?indexkey Q?><?primarykey queue(s)?><?secondarykey CONDITION?><?tertiarykey INTRINSIC, DISADVANTAGES OF?><primary><emphasis role="strong">queue(s)</emphasis></primary><secondary>condition</secondary><tertiary>intrinsic, disadvantages of</tertiary></indexterm><indexterm id="iddle5048" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey CONDITION?><primary><emphasis role="strong">variables</emphasis></primary><secondary>condition</secondary></indexterm><indexterm id="iddle5049" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey CONDITION?><?tertiarykey EXPLICIT?><primary><emphasis role="strong">variables</emphasis></primary><secondary>condition</secondary><tertiary>explicit</tertiary></indexterm><indexterm id="iddle5100" significance="normal"><?indexkey V?><?primarykey visibility?><?secondarykey CONDITION QUEUE?><primary><emphasis role="strong">visibility</emphasis></primary><secondary>condition queue</secondary></indexterm><indexterm id="iddle5101" significance="normal"><?indexkey V?><?primarykey visibility?><?secondarykey CONDITION QUEUE?><?tertiarykey CONTROL, EXPLICIT CONDITION AND LOCK USE?><primary><emphasis role="strong">visibility</emphasis></primary><secondary>condition queue</secondary><tertiary>control, explicit Condition and Lock use</tertiary></indexterm>waiters: those waiting to pop one element and those waiting to pop two. But if the base class exposes the condition queue and documents its protocols for using it, the subclass can override the push method to perform a <literal>notifyAll</literal>, restoring safety.</para>
</section>
<section id="ch14lev2sec10" label="14.2.7" xreflabel="14.2.7">
<title id="ch14lev2sec10__title">Encapsulating Condition Queues</title>
<para>It is generally best to encapsulate the condition queue so that it is not accessible outside the class hierarchy in which it is used. Otherwise, callers might be tempted to think they understand your protocols for waiting and notification and use them in a manner inconsistent with your design. (It is impossible to enforce the uniform waiters requirement for single notification unless the condition queue object is inaccessible to code you do not control; if alien code mistakenly waits on your condition queue, this could subvert your notification protocol and cause a hijacked signal.)</para>
<para>Unfortunately, this advice—to encapsulate objects used as condition queues—is not consistent with the most common design pattern for thread-safe classes, in which an object’s intrinsic lock is used to guard its state. <literal>BoundedBuffer</literal> illustrates this common idiom, where the buffer object itself is the lock and condition queue. However, <literal>BoundedBuffer</literal> could be easily restructured to use a private lock object and condition queue; the only difference would be that it would no longer support any form of client-side locking.</para>
</section>
<section id="ch14lev2sec11" label="14.2.8" xreflabel="14.2.8">
<title id="ch14lev2sec11__title">Entry and Exit Protocols</title>
<para>Wellings (<link linkend="biblio01_032" preference="0">Wellings, 2004</link>) characterizes the proper use of <literal>wait</literal> and <literal>notify</literal> in terms of <emphasis>entry</emphasis> and <emphasis>exit protocols</emphasis>. For each state-dependent operation and for each operation that modifies state on which another operation has a state dependency, you should define and document an entry and exit protocol. The entry protocol is the operation’s condition predicate; the exit protocol involves examining any state variables that have been changed by the operation to see if they might have caused some other condition predicate to become true, and if so, notifying on the associated condition queue.</para>
<para><literal>AbstractQueuedSynchronizer</literal>, upon which most of the state-dependent classes in <literal>java.util.concurrent</literal> are built (see <link linkend="ch14lev1sec4" preference="0">Section 14.4</link>), exploits the concept of exit protocol. Rather than letting synchronizer classes perform their own notification, it instead requires synchronizer methods to return a value indicating whether its action might have unblocked one or more waiting threads. This explicit API requirement makes it harder to “forget” to notify on some state transitions.</para>
</section>
</section>
<section id="ch14lev1sec3" condition="306" label="14.3" xreflabel="14.3"><?docpage num="306"?>
<title id="ch14lev1sec3__title">Explicit Condition Objects</title>
<para>As we saw in <link linkend="ch13" preference="0">Chapter 13</link>, explicit <literal>Lock</literal>s can be useful in some situations where intrinsic locks are too inflexible. Just as <literal>Lock</literal> is a generalization of intrinsic locks, <literal>Condition</literal> (see <link linkend="ch14list10" preference="0">Listing 14.10</link>) is a generalization of intrinsic condition queues.</para>
<para><?docpage num="307"?><indexterm id="iddle1495" significance="normal"><?indexkey C?><?primarykey Condition?><primary><emphasis role="strong">Condition</emphasis></primary></indexterm><indexterm id="iddle1515" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey WAITS?><?tertiarykey INTERRUPTIBLE, AS FEATURE OF CONDITION?><primary><emphasis role="strong">condition</emphasis></primary><secondary>waits</secondary><tertiary>interruptible, as feature of <literal>Condition</literal></tertiary></indexterm><indexterm id="iddle1516" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey WAITS?><?tertiarykey UNINTERRUPTABLE, AS FEATURE OF CONDITION?><primary><emphasis role="strong">condition</emphasis></primary><secondary>waits</secondary><tertiary>uninterruptable, as feature of <literal>Condition</literal></tertiary></indexterm><indexterm id="iddle1789" significance="normal"><?indexkey D?><?primarykey deadline-based waits?><primary><emphasis role="strong">deadline-based waits</emphasis></primary></indexterm><indexterm id="iddle1790" significance="normal"><?indexkey D?><?primarykey deadline-based waits?><?secondarykey AS FEATURE OF CONDITION?><primary><emphasis role="strong">deadline-based waits</emphasis></primary><secondary>as feature of <literal>Condition</literal></secondary></indexterm><indexterm id="iddle2506" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey CONDITION METHODS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary><literal>Condition</literal> methods</secondary></indexterm><indexterm id="iddle2507" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey CONDITION METHODS?><?tertiarykey POTENTIAL CONFUSIONS?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary><literal>Condition</literal> methods</secondary><tertiary>potential confusions</tertiary></indexterm><indexterm id="iddle2798" significance="normal"><?indexkey I?><?primarykey interruption(s)?><?secondarykey AND CONDITION WAITS?><primary><emphasis role="strong">interruption(s)</emphasis></primary><secondary>and condition waits</secondary></indexterm><indexterm id="iddle3041" significance="normal"><?indexkey L?><?primarykey Lock?><?secondarykey AND CONDITION?><primary><emphasis role="strong">Lock</emphasis></primary><secondary>and <literal>Condition</literal></secondary></indexterm><indexterm id="iddle4895" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey DEADLINE-BASED WAITS?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>deadline-based waits</secondary></indexterm><indexterm id="iddle4896" significance="normal"><?indexkey T?><?primarykey time/timing?><?secondarykey DEADLINE-BASED WAITS?><?tertiarykey AS FEATURE OF CONDITION?><primary><emphasis role="strong">time/timing</emphasis></primary><secondary>deadline-based waits</secondary><tertiary>as feature of <literal>Condition</literal></tertiary></indexterm><indexterm id="iddle5137" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey CONDITION?><?tertiarykey INTERRUPTIBLE, AS FEATURE OF CONDITION?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>condition</secondary><tertiary>interruptible, as feature of <literal>Condition</literal></tertiary></indexterm><indexterm id="iddle5138" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey CONDITION?><?tertiarykey UNINTERRUPTABLE, AS FEATURE OF CONDITION?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>condition</secondary><tertiary>uninterruptable, as feature of <literal>Condition</literal></tertiary></indexterm><indexterm id="iddle5141" significance="normal"><?indexkey W?><?primarykey wait(s)?><?secondarykey SETS?><?tertiarykey MULTIPLE, AS FEATURE OF CONDITION?><primary><emphasis role="strong">wait(s)</emphasis></primary><secondary>sets</secondary><tertiary>multiple, as feature of <literal>Condition</literal></tertiary></indexterm>Intrinsic condition queues have several drawbacks. Each intrinsic lock can have only one associated condition queue, which means that in classes like <literal>BoundedBuffer</literal> multiple threads might wait on the same condition queue for different condition predicates, and the most common pattern for locking involves exposing the condition queue object. Both of these factors make it impossible to enforce the uniform waiter requirement for using <literal>notify</literal>. If you want to write a concurrent object with multiple condition predicates, or you want to exercise more control over the visibility of the condition queue, the explicit <literal>Lock</literal> and <literal>Condition</literal> classes offer a more flexible alternative to intrinsic locks and condition queues.</para>
<para>A <literal>Condition</literal> is associated with a single <literal>Lock</literal>, just as a condition queue is associated with a single intrinsic lock; to create a <literal>Condition</literal>, call <literal>Lock.newCondition</literal> on the associated lock. And just as <literal>Lock</literal> offers a richer feature set than intrinsic locking, <literal>Condition</literal> offers a richer feature set than intrinsic condition queues: multiple wait sets per lock, interruptible and uninterruptible condition waits, deadline-based waiting, and a choice of fair or nonfair queueing.</para>
<example id="ch14list10" label="14.10" role="Listing" xreflabel="14.10" condition="307">
<title id="ch14list10__title"><literal>Condition</literal> Interface.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public interface Condition {
    void await() throws InterruptedException;
    boolean await(long time, TimeUnit unit)
            throws InterruptedException;
    long awaitNanos(long nanosTimeout) throws InterruptedException;
    void awaitUninterruptibly();
    boolean awaitUntil(Date deadline) throws InterruptedException;

    void signal();
    void signalAll();
}
</programlisting>
</example>
<para>Unlike intrinsic condition queues, you can have as many <literal>Condition</literal> objects per <literal>Lock</literal> as you want. <literal>Condition</literal> objects inherit the fairness setting of their associated <literal>Lock</literal>; for fair locks, threads are released from <literal>Condition.await</literal> in FIFO order.</para>
<sidebar float="1" id="ch14sb06" condition="307"><title/>
<formalpara><title>Hazard warning:</title><para>The equivalents of <literal>wait</literal>, <literal>notify</literal>, and <literal>notifyAll</literal> for <literal>Condition</literal> objects are <literal>await</literal>, <literal>signal</literal>, and <literal>signalAll</literal>. However, <literal>Condition</literal> extends <literal>Object</literal>, which means that it also has <literal>wait</literal> and <literal>notify</literal> methods. Be sure to use the proper versions—<literal>await</literal> and <literal>signal</literal>—instead!</para></formalpara>
</sidebar>
<para><link linkend="ch14list11" preference="0">Listing 14.11</link> shows yet another bounded buffer implementation, this time using two <literal>Condition</literal>s, <literal>notFull</literal> and <literal>notEmpty</literal>, to represent explicitly the “not full” and “not empty” condition predicates. When <literal>take</literal> blocks because the buffer is empty, it waits on <literal>notEmpty</literal>, and <literal>put</literal> unblocks any threads blocked in <literal>take</literal> by signaling on <literal>notEmpty</literal>.</para>
<para><?docpage num="308"?><indexterm id="iddle2102" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CONDITIONBOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ConditionBoundedBuffer</literal></secondary></indexterm><indexterm id="iddle1016" significance="normal"><?indexkey A?><?primarykey AbstractQueuedSynchronizer?><primary><emphasis role="strong">AbstractQueuedSynchronizer</emphasis></primary><see> AQS framework.</see></indexterm><indexterm id="iddle1104" significance="normal"><?indexkey A?><?primarykey application(s)?><primary><emphasis role="strong">application(s)</emphasis></primary><seealso> frameworks(s).</seealso></indexterm><indexterm id="iddle1105" significance="normal"><?indexkey A?><?primarykey application(s)?><primary><emphasis role="strong">application(s)</emphasis></primary><seealso> <link linkend="iddle4192" preference="0"><emphasis role="strong">service(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle1106" significance="normal"><?indexkey A?><?primarykey application(s)?><primary><emphasis role="strong">application(s)</emphasis></primary><seealso> <link linkend="iddle3254" preference="0"><emphasis role="strong">monitoring</emphasis>, tools</link>.</seealso></indexterm><indexterm id="iddle1116" significance="normal"><?indexkey A?><?primarykey AQS (AbstractQueuedSynchronizer) framework?><primary><emphasis role="strong">AQS (AbstractQueuedSynchronizer) framework</emphasis></primary></indexterm><indexterm id="iddle1497" significance="normal"><?indexkey C?><?primarykey Condition?><?secondarykey INTRINSIC CONDITION QUEUES VS?><primary><emphasis role="strong">Condition</emphasis></primary><secondary>intrinsic condition queues vs</secondary></indexterm><indexterm id="iddle1498" significance="normal"><?indexkey C?><?primarykey Condition?><?secondarykey INTRINSIC CONDITION QUEUES VS?><?tertiarykey PERFORMANCE CONSIDERATIONS?><primary><emphasis role="strong">Condition</emphasis></primary><secondary>intrinsic condition queues vs</secondary><tertiary>performance considerations</tertiary></indexterm><indexterm id="iddle1502" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey PREDICATE?><?tertiarykey LOCK AND CONDITION VARIABLE RELATIONSHIP?><primary><emphasis role="strong">condition</emphasis></primary><secondary>predicate</secondary><tertiary>lock and condition variable relationship</tertiary></indexterm><indexterm id="iddle1595" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey LOCK?><?tertiarykey SIGNAL METHOD REDUCTION IN?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>lock</secondary><tertiary><literal>signal</literal> method reduction in</tertiary></indexterm><indexterm id="iddle1619" significance="normal"><?indexkey C?><?primarykey context switching?><?secondarykey SIGNAL METHOD REDUCTION IN?><primary><emphasis role="strong">context switching</emphasis></primary><secondary><literal>signal</literal> method reduction in</secondary></indexterm><indexterm id="iddle2101" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CONDITIONBOUNDEDBUFFER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ConditionBoundedBuffer</literal></secondary></indexterm><indexterm id="iddle2403" significance="normal"><?indexkey F?><?primarykey frameworks?><primary><emphasis role="strong">frameworks</emphasis></primary><seealso> AQS framework.</seealso></indexterm><indexterm id="iddle2404" significance="normal"><?indexkey F?><?primarykey frameworks?><primary><emphasis role="strong">frameworks</emphasis></primary><seealso> <link linkend="iddle4229" preference="0"><emphasis role="strong">shared/sharing</emphasis>, data structures</link>.</seealso></indexterm><indexterm id="iddle2405" significance="normal"><?indexkey F?><?primarykey frameworks?><primary><emphasis role="strong">frameworks</emphasis></primary><seealso> <link linkend="iddle2238" preference="0"><emphasis role="strong">Exchanger</emphasis></link>.</seealso></indexterm><indexterm id="iddle2406" significance="normal"><?indexkey F?><?primarykey frameworks?><primary><emphasis role="strong">frameworks</emphasis></primary><seealso> RMI framework.</seealso></indexterm><indexterm id="iddle2407" significance="normal"><?indexkey F?><?primarykey frameworks?><primary><emphasis role="strong">frameworks</emphasis></primary><seealso> Servlets framework.</seealso></indexterm><indexterm id="iddle3077" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey CONDITION VARIABLE AND CONDITION PREDICATE RELATIONSHIP?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>condition variable and condition predicate relationship</secondary></indexterm><indexterm id="iddle3817" significance="normal"><?indexkey R?><?primarykey ReentrantLock?><?secondarykey SEMAPHORE RELATIONSHIP WITH?><primary><emphasis role="strong">ReentrantLock</emphasis></primary><secondary><literal>Semaphore</literal> relationship with</secondary></indexterm><indexterm id="iddle4143" significance="normal"><?indexkey S?><?primarykey Semaphore?><?secondarykey SIMILARITIES TO REENTRANTLOCK?><primary><emphasis role="strong">Semaphore</emphasis></primary><secondary>similarities to <literal>ReentrantLock</literal></secondary></indexterm><indexterm id="iddle4192" significance="normal"><?indexkey S?><?primarykey service(s)?><primary><emphasis role="strong">service(s)</emphasis></primary><seealso> <link linkend="iddle2486" preference="0"><emphasis role="strong">GUI (Graphical User Interface)</emphasis>, applications</link>.</seealso></indexterm><indexterm id="iddle4193" significance="normal"><?indexkey S?><?primarykey service(s)?><primary><emphasis role="strong">service(s)</emphasis></primary><seealso> <link linkend="iddle2488" preference="0"><emphasis role="strong">GUI (Graphical User Interface)</emphasis>, frameworks</link>.</seealso></indexterm><indexterm id="iddle4278" significance="normal"><?indexkey S?><?primarykey signal?><primary><emphasis role="strong">signal</emphasis></primary></indexterm><indexterm id="iddle4279" significance="normal"><?indexkey S?><?primarykey signal?><?secondarykey CONDITIONBOUNDEDBUFFER EXAMPLE?><primary><emphasis role="strong">signal</emphasis></primary><secondary><literal>ConditionBoundedBuffer</literal> example</secondary></indexterm><indexterm id="iddle4591" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><?secondarykey BEHAVIOR AND INTERFACE?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary><secondary>behavior and interface</secondary></indexterm>The behavior of <literal>ConditionBoundedBuffer</literal> is the same as <literal>BoundedBuffer</literal>, but its use of condition queues is more readable—it is easier to analyze a class that uses multiple <literal>Condition</literal>s than one that uses a single intrinsic condition queue with multiple condition predicates. By separating the two condition predicates into separate wait sets, <literal>Condition</literal> makes it easier to meet the requirements for single notification. Using the more efficient <literal>signal</literal> instead of <literal>signalAll</literal> reduces the number of context switches and lock acquisitions triggered by each buffer operation.</para>
<para>Just as with built-in locks and condition queues, the three-way relationship among the lock, the condition predicate, and the condition variable must also hold when using explicit <literal>Lock</literal>s and <literal>Condition</literal>s. The variables involved in the condition predicate must be guarded by the <literal>Lock</literal>, and the <literal>Lock</literal> must be held when testing the condition predicate and when calling <literal>await</literal> and <literal>signal</literal>.<footnote id="ch14fn11" label="11"><para><literal>ReentrantLock</literal> requires that the <literal>Lock</literal> be held when calling <literal>signal</literal> or <literal>signalAll</literal>, but <literal>Lock</literal> implementations are permitted to construct <literal>Condition</literal>s that do not have this requirement.</para></footnote></para>
<para>Choose between using explicit <literal>Condition</literal>s and intrinsic condition queues in the same way as you would choose between <literal>ReentrantLock</literal> and <literal>synchronized</literal>: use <literal>Condition</literal> if you need its advanced features such as fair queueing or multiple wait sets per lock, and otherwise prefer intrinsic condition queues. (If you already use <literal>ReentrantLock</literal> because you need its advanced features, the choice is already made.)</para>
</section>
<section id="ch14lev1sec4" condition="308" label="14.4" xreflabel="14.4"><?docpage num="308"?>
<title id="ch14lev1sec4__title">Anatomy of a Synchronizer</title>
<para>The interfaces of <literal>ReentrantLock</literal> and <literal>Semaphore</literal> have a lot in common. Both classes act as a “gate”, allowing only a limited number of threads to pass at a time; threads arrive at the gate and are allowed through (<literal>lock</literal> or <literal>acquire</literal> returns successfully), are made to wait (<literal>lock</literal> or <literal>acquire</literal> blocks), or are turned away (<literal>tryLock</literal> or <literal>tryAcquire</literal> returns false, indicating that the lock or permit did not become available in the time allowed). Further, both allow interruptible, uninterruptible, and timed acquisition attempts, and both allow a choice of fair or nonfair queueing of waiting threads.</para>
<para>Given this commonality, you might think that <literal>Semaphore</literal> was implemented on top of <literal>ReentrantLock</literal>, or perhaps <literal>ReentrantLock</literal> was implemented as a <literal>Semaphore</literal> with one permit. This would be entirely practical; it is a common exercise to prove that a counting semaphore can be implemented using a lock (as in <literal>SemaphoreOnLock</literal> in <link linkend="ch14list12" preference="0">Listing 14.12</link>) and that a lock can be implemented using a counting semaphore.</para>
<para>In actuality, they are both implemented using a common base class, <literal>Abstract-QueuedSynchronizer</literal> (AQS)—as are many other synchronizers. AQS is a framework for building locks and synchronizers, and a surprisingly broad range of synchronizers can be built easily and efficiently using it. Not only are <literal>ReentrantLock</literal> and <literal>Semaphore</literal> built using AQS, but so are <literal>CountDownLatch</literal>, <literal>ReentrantReadWriteLock</literal>, <literal>SynchronousQueue</literal>,<footnote id="ch14fn12" label="12"><para>Java6 replaces the AQS-based <literal>SynchronousQueue</literal> with a (more scalable) nonblocking version.</para></footnote> and <literal>FutureTask</literal>.</para>

<para><?docpage num="309"?></para><example id="ch14list11" label="14.11" role="Listing" xreflabel="14.11" condition="309">

<title id="ch14list11__title">Bounded Buffer Using Explicit Condition Variables.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ConditionBoundedBuffer&lt;T&gt; {
    protected final Lock lock = new ReentrantLock();
    <emphasis>// CONDITION PREDICATE: <emphasis role="strong">notFull</emphasis> (count &lt; items.length)</emphasis>
    private final Condition notFull    = lock.newCondition();
    <emphasis>// CONDITION PREDICATE: notEmpty (count &gt; 0)</emphasis>
    private final Condition <emphasis role="strong">notEmpty</emphasis>  = lock.newCondition();
    @GuardedBy("lock")
    private final T[] items = (T[]) new Object[BUFFER_SIZE];
    @GuardedBy("lock") private int tail, head, count;

    <emphasis>// BLOCKS-UNTIL: notFull</emphasis>
    public void put(T x) throws InterruptedException {
        lock.lock();
        try {
            while (count == items.length)
                <emphasis role="strong">notFull.await();</emphasis>
            items[tail] = x;
            if (++tail == items.length)
                tail = 0;
            ++count;
            <emphasis role="strong">notEmpty.signal();</emphasis>
        } finally {
            lock.unlock();
        }
    }

    <emphasis>// BLOCKS-UNTIL: notEmpty</emphasis>
    public T take() throws InterruptedException {
        lock.lock();
        try {
            while (count == 0)
                <emphasis role="strong">notEmpty.await();</emphasis>
            T x = items[head];
            items[head] = null;
            if (++head == items.length)
                head = 0;
            --count;
            <emphasis role="strong">notFull.signal();</emphasis>
            return x;
        } finally {
            lock.unlock();
        }
    }
}
</programlisting>
</example>

<para><?docpage num="310"?></para><example id="ch14list12" label="14.12" role="Listing" xreflabel="14.12" condition="310">

<title id="ch14list12__title">Counting Semaphore Implemented Using <literal>Lock</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered"><emphasis>// Not really how java.util.concurrent.Semaphore is implemented</emphasis>
@ThreadSafe
public class SemaphoreOnLock {
    private final Lock lock = new ReentrantLock();
    <emphasis>// CONDITION PREDICATE: permitsAvailable (permits &gt; 0)</emphasis>
    private final Condition permitsAvailable = lock.newCondition();
    @GuardedBy("lock") private int permits;

    SemaphoreOnLock(int initialPermits) {
        lock.lock();
        try {
            permits = initialPermits;
        } finally {
            lock.unlock();
        }
    }

    <emphasis>// BLOCKS-UNTIL: permitsAvailable</emphasis>
    public void acquire() throws InterruptedException {
        lock.lock();
        try {
            while (permits &lt;= 0)
                permitsAvailable.await();
            --permits;
        } finally {
            lock.unlock();
        }
    }

    public void release() {
        lock.lock();
        try {
            ++permits;
            permitsAvailable.signal();
        } finally {
            lock.unlock();
        }
    }
}
</programlisting>
</example>
<para><?docpage num="311"?><indexterm id="iddle1703" significance="normal"><?indexkey C?><?primarykey counting semaphores?><?secondarykey SEMAPHOREONLOCK EXAMPLE?><primary><emphasis role="strong">counting semaphores</emphasis></primary><secondary><literal>SemaphoreOnLock</literal> example</secondary></indexterm><indexterm id="iddle2174" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SEMAPHOREONLOCK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SemaphoreOnLock</literal></secondary></indexterm><indexterm id="iddle4152" significance="normal"><?indexkey S?><?primarykey semaphores?><?secondarykey COUNTING?><?tertiarykey SEMAPHOREONLOCK EXAMPLE?><primary><emphasis role="strong">semaphores</emphasis></primary><secondary>counting</secondary><tertiary><literal>SemaphoreOnLock</literal> example</tertiary></indexterm><indexterm id="iddle1117" significance="normal"><?indexkey A?><?primarykey AQS (AbstractQueuedSynchronizer) framework?><primary><emphasis role="strong">AQS (AbstractQueuedSynchronizer) framework</emphasis></primary></indexterm><indexterm id="iddle1600" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey SCALABILITY UNDER?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>scalability under</secondary></indexterm><indexterm id="iddle1601" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey SCALABILITY UNDER?><?tertiarykey AS AQS ADVANTAGE?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>scalability under</secondary><tertiary>as AQS advantage</tertiary></indexterm><indexterm id="iddle3049" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary></indexterm><indexterm id="iddle3050" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ACQUISITION?><?tertiarykey AQS-BASED SYNCHRONIZER OPERATIONS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>acquisition</secondary><tertiary>AQS-based synchronizer operations</tertiary></indexterm><indexterm id="iddle3063" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey BUILDING?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>building</secondary></indexterm><indexterm id="iddle3064" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey BUILDING?><?tertiarykey AQS USE?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>building</secondary><tertiary>AQS use</tertiary></indexterm><indexterm id="iddle3834" significance="normal"><?indexkey R?><?primarykey release?><primary><emphasis role="strong">release</emphasis></primary></indexterm><indexterm id="iddle3835" significance="normal"><?indexkey R?><?primarykey release?><?secondarykey AQS SYNCHRONIZER OPERATION?><primary><emphasis role="strong">release</emphasis></primary><secondary>AQS synchronizer operation</secondary></indexterm><indexterm id="iddle4088" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey UNDER CONTENTION?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>under contention</secondary></indexterm><indexterm id="iddle4089" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey UNDER CONTENTION?><?tertiarykey AS AQS ADVANTAGE?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>under contention</secondary><tertiary>as AQS advantage</tertiary></indexterm><indexterm id="iddle4404" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey MANAGEMENT?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>management</secondary></indexterm><indexterm id="iddle4405" significance="normal"><?indexkey S?><?primarykey state(s)?><?secondarykey MANAGEMENT?><?tertiarykey AQS-BASED SYNCHRONIZER OPERATIONS?><primary><emphasis role="strong">state(s)</emphasis></primary><secondary>management</secondary><tertiary>AQS-based synchronizer operations</tertiary></indexterm><indexterm id="iddle4592" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><?secondarykey BUILDING?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary><secondary>building</secondary></indexterm><indexterm id="iddle4593" significance="normal"><?indexkey S?><?primarykey synchronizer(s)?><?secondarykey BUILDING?><?tertiarykey WITH AQS?><primary><emphasis role="strong">synchronizer(s)</emphasis></primary><secondary>building</secondary><tertiary>with AQS</tertiary></indexterm>AQS handles many of the details of implementing a synchronizer, such as FIFO queuing of waiting threads. Individual synchronizers can define flexible criteria for whether a thread should be allowed to pass or be required to wait.</para>
<para>Using AQS to build synchronizers offers several benefits. Not only does it substantially reduce the implementation effort, but you also needn’t pay for multiple points of contention, as you would when constructing one synchronizer on top of another. In <literal>SemaphoreOnLock</literal>, acquiring a permit has two places where it might block—once at the lock guarding the semaphore state, and then again if a permit is not available. Synchronizers built with AQS have only one point where they might block, reducing context-switch overhead and improving throughput. AQS was designed for scalability, and all the synchronizers in <literal>java.util.concurrent</literal> that are built with AQS benefit from this.</para>
</section>
<section id="ch14lev1sec5" condition="311" label="14.5" xreflabel="14.5"><?docpage num="311"?>
<title id="ch14lev1sec5__title">AbstractQueuedSynchronizer</title>
<para>Most developers will probably never use AQS directly; the standard set of synchronizers covers a fairly wide range of situations. But seeing how the standard synchronizers are implemented can help clarify how they work.</para>
<para>The basic operations that an AQS-based synchronizer performs are some variants of <emphasis>acquire</emphasis> and <emphasis>release</emphasis>. Acquisition is the state-dependent operation and can always block. With a lock or semaphore, the meaning of acquire is straightforward—acquire the lock or a permit—and the caller may have to wait until the synchronizer is in a state where that can happen. With <literal>CountDownLatch</literal>, acquire means “wait until the latch has reached its terminal state”, and with <literal>FutureTask</literal>, it means “wait until the task has completed”. Release is not a blocking operation; a release may allow threads blocked in acquire to proceed.</para>
<para>For a class to be state-dependent, it must have some state. AQS takes on the task of managing some of the state for the synchronizer class: it manages a single integer of state information that can be manipulated through the protected <literal>getState</literal>, <literal>setState</literal>, and <literal>compareAndSetState</literal> methods. This can be used to represent arbitrary state; for example, <literal>ReentrantLock</literal> uses it to represent the count of times the owning thread has acquired the lock, <literal>Semaphore</literal> uses it to represent the number of permits remaining, and <literal>FutureTask</literal> uses it to represent the state of the task (not yet started, running, completed, cancelled). Synchronizers can also manage additional state variables themselves; for example, <literal>ReentrantLock</literal> keeps track of the current lock owner so it can distinguish between reentrant and contended lock-acquisition requests.</para>
<para>Acquisition and release in AQS take the forms shown in <link linkend="ch14list13" preference="0">Listing 14.13</link>. Depending on the synchronizer, acquisition might be <emphasis>exclusive</emphasis>, as with <literal>Reentrant-Lock</literal>, or <emphasis>nonexclusive</emphasis>, as with <literal>Semaphore</literal> and <literal>CountDownLatch</literal>. An acquire operation has two parts. First, the synchronizer decides whether the current state permits acquisition; if so, the thread is allowed to proceed, and if not, the acquire blocks or fails. This decision is determined by the synchronizer semantics; for example, acquiring a lock can succeed if the lock is unheld, and acquiring a latch can succeed if the latch is in its terminal state.</para>
<para><?docpage num="312"?><indexterm id="iddle1504" significance="normal"><?indexkey C?><?primarykey condition?><?secondarykey QUEUES?><?tertiarykey AQS SUPPORT FOR?><primary><emphasis role="strong">condition</emphasis></primary><secondary>queues</secondary><tertiary>AQS support for</tertiary></indexterm>The second part involves possibly updating the synchronizer state; one thread acquiring the synchronizer can affect whether other threads can acquire it. For example, acquiring a lock changes the lock state from “unheld” to “held”, and acquiring a permit from a <literal>Semaphore</literal> reduces the number of permits left. On the other hand, the acquisition of a latch by one thread does not affect whether other threads can acquire it, so acquiring a latch does not change its state.</para>
<example id="ch14list13" label="14.13" role="Listing" xreflabel="14.13" condition="312">
<title id="ch14list13__title">Canonical Forms for Acquisition and Release in AQS.</title>
<programlisting format="linespecific" linenumbering="unnumbered">boolean acquire() throws InterruptedException {
    while (state does not permit acquire) {
        if (blocking acquisition requested) {
            enqueue current thread if not already queued
            block current thread
        }
        else
            return failure
    }
    possibly update synchronization state
    dequeue thread if it was queued
    return success
}

void release() {
    update synchronization state
    if (new state may permit a blocked thread to acquire)
        unblock one or more queued threads
}
</programlisting>
</example>
<para>A synchronizer supporting exclusive acquisition should implement the protected methods <literal>tryAcquire</literal>, <literal>tryRelease</literal>, and <literal>isHeldExclusively</literal>, and those supporting shared acquisition should implement <literal>tryAcquireShared</literal> and <literal>tryReleaseShared</literal>. The <literal>acquire</literal>, <literal>acquireShared</literal>, <literal>release</literal>, and <literal>releaseShared</literal> methods in AQS call the <literal>try</literal> forms of these methods in the synchronizer subclass to determine if the operation can proceed. The synchronizer subclass can use <literal>getState</literal>, <literal>setState</literal>, and <literal>compareAndSetState</literal> to examine and update the state according to its acquire and release semantics, and informs the base class through the return status whether the attempt to acquire or release the synchronizer was successful. For example, returning a negative value from <literal>tryAcquireShared</literal> indicates acquisition failure; returning zero indicates the synchronizer was acquired exclusively; and returning a positive value indicates the synchronizer was acquired nonexclusively. The <literal>tryRelease</literal> and <literal>tryReleaseShared</literal> methods should return <literal>true</literal> if the release may have unblocked threads attempting to acquire the synchronizer.</para>
<para>To simplify implementation of locks that support condition queues (like <literal>ReentrantLock</literal>), AQS also provides machinery for constructing condition variables <?docpage num="313"?><indexterm id="iddle1203" significance="normal"><?indexkey B?><?primarykey binary latch?><?secondarykey AQS-BASED?><primary><emphasis role="strong">binary latch</emphasis></primary><secondary>AQS-based</secondary></indexterm><indexterm id="iddle2148" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey ONESHOTLATCH?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>OneShotLatch</literal></secondary></indexterm><indexterm id="iddle2939" significance="normal"><?indexkey L?><?primarykey latch(es)?><?secondarykey BINARY?><?tertiarykey AQS-BASED?><primary><emphasis role="strong">latch(es)</emphasis></primary><secondary>binary</secondary><tertiary>AQS-based</tertiary></indexterm>associated with synchronizers.</para>
<section id="ch14lev2sec12" label="14.5.1" xreflabel="14.5.1">
<title id="ch14lev2sec12__title">A Simple Latch</title>
<para><literal>OneShotLatch</literal> in <link linkend="ch14list14" preference="0">Listing 14.14</link> is a binary latch implemented using AQS. It has two public methods, <literal>await</literal> and <literal>signal</literal>, that correspond to acquisition and release. Initially, the latch is closed; any thread calling <literal>await</literal> blocks until the latch is opened. Once the latch is opened by a call to <literal>signal</literal>, waiting threads are released and threads that subsequently arrive at the latch will be allowed to proceed.</para>
<example id="ch14list14" label="14.14" role="Listing" xreflabel="14.14" condition="313">
<title id="ch14list14__title">Binary Latch Using <literal>AbstractQueuedSynchronizer</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class OneShotLatch {
    private final Sync sync = new Sync();

    public void signal() { sync.releaseShared(0); }

    public void await() throws InterruptedException {
        sync.acquireSharedInterruptibly(0);
    }

    private class Sync extends AbstractQueuedSynchronizer {
        protected int tryAcquireShared(int ignored) {
            <emphasis>// Succeed if latch is open (state == 1), else fail</emphasis>
            return (getState() == 1) ? 1 : -1;
        }

        protected boolean tryReleaseShared(int ignored) {
            setState(1);  <emphasis>// Latch is now open</emphasis>
            return true;  <emphasis>// Other threads may now be able to acquire</emphasis>

        }
    }
}
</programlisting>
</example>
<para>In <literal>OneShotLatch</literal>, the AQS state holds the latch state—closed (zero) or open (one). The <literal>await</literal> method calls <literal>acquireSharedInterruptibly</literal> in AQS, which in turn consults the <literal>tryAcquireShared</literal> method in <literal>OneShotLatch</literal>. The <literal>tryAcquire-Shared</literal> implementation must return a value indicating whether or not acquisition can proceed. If the latch has been previously opened, <literal>tryAcquireShared</literal> returns success, allowing the thread to pass; otherwise it returns a value indicating that the acquisition attempt failed. The <literal>acquireSharedInterruptibly</literal> method interprets failure to mean that the thread should be placed on the queue of waiting threads. Similarly, <literal>signal</literal> calls <literal>releaseShared</literal>, which causes <literal>tryReleaseShared</literal> to be consulted. The <literal>tryReleaseShared</literal> implementation unconditionally sets the latch state to open and indicates (through its return value) that the synchronizer <?docpage num="314"?><indexterm id="iddle1858" significance="normal"><?indexkey D?><?primarykey delegation?><?secondarykey ADVANTAGES?><primary><emphasis role="strong">delegation</emphasis></primary><secondary>advantages</secondary></indexterm><indexterm id="iddle1859" significance="normal"><?indexkey D?><?primarykey delegation?><?secondarykey ADVANTAGES?><?tertiarykey CLASS EXTENSION VS?><primary><emphasis role="strong">delegation</emphasis></primary><secondary>advantages</secondary><tertiary>class extension vs</tertiary></indexterm><indexterm id="iddle1989" significance="normal"><?indexkey E?><?primarykey Effective Java Programming Language Guide?><primary><emphasis role="strong"><emphasis>Effective Java Programming Language Guide</emphasis></emphasis></primary></indexterm><indexterm id="iddle3811" significance="normal"><?indexkey R?><?primarykey ReentrantLock?><primary><emphasis role="strong">ReentrantLock</emphasis></primary></indexterm><indexterm id="iddle3812" significance="normal"><?indexkey R?><?primarykey ReentrantLock?><?secondarykey AQS USE?><primary><emphasis role="strong">ReentrantLock</emphasis></primary><secondary>AQS use</secondary></indexterm>is in a fully released state. This causes AQS to let all waiting threads attempt to reacquire the synchronizer, and acquisition will now succeed because <literal>tryAcquireShared</literal> returns success.</para>
<para><literal>OneShotLatch</literal> is a fully functional, usable, performant synchronizer, implemented in only twenty or so lines of code. Of course, it is missing some useful features—such as timed acquisition or the ability to inspect the latch state—but these are easy to implement as well, since AQS provides timed versions of the acquisition methods and utility methods for common inspection operations.</para>
<para><literal>OneShotLatch</literal> could have been implemented by extending AQS rather than delegating to it, but this is undesirable for several reasons [EJ Item 14]. Doing so would undermine the simple (two-method) interface of <literal>OneShotLatch</literal>, and while the public methods of AQS won’t allow callers to corrupt the latch state, callers could easily use them incorrectly. None of the synchronizers in <literal>java.util.concurrent</literal> extends AQS directly—they all delegate to private inner subclasses of AQS instead.</para>
</section>
</section>
<section id="ch14lev1sec6" condition="314" label="14.6" xreflabel="14.6"><?docpage num="314"?>
<title id="ch14lev1sec6__title">AQS in Java.util.concurrent Synchronizer Classes</title>
<para>Many of the blocking classes in <literal>java.util.concurrent</literal>, such as <literal>ReentrantLock</literal>, <literal>Semaphore</literal>, <literal>ReentrantReadWriteLock</literal>, <literal>CountDownLatch</literal>, <literal>SynchronousQueue</literal>, and <literal>FutureTask</literal>, are built using AQS. Without getting too deeply into the details (the source code is part of the JDK download<footnote id="ch14fn13" label="13"><para>Or with fewer licensing restrictions at <literal><ulink url="http://gee.cs.oswego.edu/dl/concurrency-interest">http://gee.cs.oswego.edu/dl/concurrency-interest</ulink></literal>.</para></footnote>), let’s take a quick look at how each of these classes uses AQS.</para>
<section id="ch14lev2sec13" label="14.6.1" xreflabel="14.6.1">
<title id="ch14lev2sec13__title">ReentrantLock</title>
<para><literal>ReentrantLock</literal> supports only exclusive acquisition, so it implements <literal>tryAcquire</literal>, <literal>tryRelease</literal>, and <literal>isHeldExclusively</literal>; <literal>tryAcquire</literal> for the nonfair version is shown in <link linkend="ch14list15" preference="0">Listing 14.15</link>. <literal>ReentrantLock</literal> uses the synchronization state to hold the lock acquisition count, and maintains an <literal>owner</literal> variable holding the identity of the owning thread that is modified only when the current thread has just acquired the lock or is just about to release it.<footnote id="ch14fn14" label="14"><para>Because the protected state-manipulation methods have the memory semantics of a volatile read or write and <literal>ReentrantLock</literal> is careful to read the <literal>owner</literal> field only after calling <literal>getState</literal> and write it only before calling <literal>setState</literal>, <literal>ReentrantLock</literal> can piggyback on the memory semantics of the synchronization state, and thus avoid further synchronization—see <link linkend="ch16lev2sec4" preference="0">Section 16.1.4</link>.</para></footnote> In <literal>tryRelease</literal>, it checks the <literal>owner</literal> field to ensure that the current thread owns the lock before allowing an <literal>unlock</literal> to proceed; in <literal>tryAcquire</literal>, it uses this field to differentiate between a reentrant acquisition and a contended acquisition attempt.</para>
<para>When a thread attempts to acquire a lock, <literal>tryAcquire</literal> first consults the lock state. If it is unheld, it tries to update the lock state to indicate that it is held. Because the state could have changed since it was first inspected a few instructions ago, <literal>tryAcquire</literal> uses <literal>compareAndSetState</literal> to attempt to atomically update the state to indicate that the lock is now held and confirm that the state has not changed since last observed. (See the description of <literal>compareAndSet</literal> in <link linkend="ch15lev1sec3" preference="0">Section 15.3</link>.) If the lock state indicates that it is already held, if the current thread is the <?docpage num="315"?><indexterm id="iddle1698" significance="normal"><?indexkey C?><?primarykey CountDownLatch?><?secondarykey AQS USE?><primary><emphasis role="strong">CountDownLatch</emphasis></primary><secondary>AQS use</secondary></indexterm><indexterm id="iddle4137" significance="normal"><?indexkey S?><?primarykey Semaphore?><?secondarykey AQS USE?><primary><emphasis role="strong">Semaphore</emphasis></primary><secondary>AQS use</secondary></indexterm>owner of the lock, the acquisition count is incremented; if the current thread is not the owner of the lock, the acquisition attempt fails.</para>
<example id="ch14list15" label="14.15" role="Listing" xreflabel="14.15" condition="315">
<title id="ch14list15__title"><literal>Tryacquire</literal> Implementation From Nonfair <literal>ReentrantLock</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">protected boolean tryAcquire(int ignored) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (compareAndSetState(0, 1)) {
            owner = current;
            return true;
        }
    } else if (current == owner) {
        setState(c+1);
        return true;
    }
    return false;
}
</programlisting>
</example>
<para><literal>ReentrantLock</literal> also takes advantage of AQS’s built-in support for multiple condition variables and wait sets. <literal>Lock.newCondition</literal> returns a new instance of <literal>ConditionObject</literal>, an inner class of AQS.</para>
</section>
<section id="ch14lev2sec14" label="14.6.2" xreflabel="14.6.2">
<title id="ch14lev2sec14__title">Semaphore and CountDownLatch</title>
<para><literal>Semaphore</literal> uses the AQS synchronization state to hold the count of permits currently available. The <literal>tryAcquireShared</literal> method (see <link linkend="ch14list16" preference="0">Listing 14.16</link>) first computes the number of permits remaining, and if there are not enough, returns a value indicating that the acquire failed. If sufficient permits appear to be left, it attempts to atomically reduce the permit count using <literal>compareAndSetState</literal>. If that succeeds (meaning that the permit count had not changed since it last looked), it returns a value indicating that the acquire succeeded. The return value also encodes whether <emphasis>other</emphasis> shared acquisition attempts might succeed, in which case other waiting threads will also be unblocked.</para>
<para>The <literal>while</literal> loop terminates either when there are not enough permits or when <literal>tryAcquireShared</literal> can atomically update the permit count to reflect acquisition. While any given call to <literal>compareAndSetState</literal> may fail due to contention with another thread (see <link linkend="ch15lev1sec3" preference="0">Section 15.3</link>), causing it to retry, one of these two termination criteria will become true within a reasonable number of retries. Similarly, <literal>tryReleaseShared</literal> increases the permit count, potentially unblocking waiting threads, and retries until the update succeeds. The return value of <literal>tryReleaseShared</literal> indicates whether other threads might have been unblocked by the release.</para>
<para><literal>CountDownLatch</literal> uses AQS in a similar manner to <literal>Semaphore</literal>: the synchronization state holds the current count. The <literal>countDown</literal> method calls <literal>release</literal>, which causes the counter to be decremented and unblocks waiting threads if the counter <?docpage num="316"?><indexterm id="iddle2431" significance="normal"><?indexkey F?><?primarykey FutureTask?><?secondarykey AQS USE?><primary><emphasis role="strong">FutureTask</emphasis></primary><secondary>AQS use</secondary></indexterm><indexterm id="iddle3818" significance="normal"><?indexkey R?><?primarykey ReentrantReadWriteLock?><primary><emphasis role="strong">ReentrantReadWriteLock</emphasis></primary></indexterm><indexterm id="iddle3819" significance="normal"><?indexkey R?><?primarykey ReentrantReadWriteLock?><?secondarykey AQS USE?><primary><emphasis role="strong">ReentrantReadWriteLock</emphasis></primary><secondary>AQS use</secondary></indexterm>has reached zero; <literal>await</literal> calls <literal>acquire</literal>, which returns immediately if the counter has reached zero and otherwise blocks.</para>
<example id="ch14list16" label="14.16" role="Listing" xreflabel="14.16" condition="316">
<title id="ch14list16__title"><literal>Tryacquireshared</literal> and <literal>Tryreleaseshared</literal> from <literal>Semaphore</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">protected int tryAcquireShared(int acquires) {
    while (true) {
        int available = getState();
        int remaining = available - acquires;
        if (remaining &lt; 0
                || compareAndSetState(available, remaining))
            return remaining;
    }
}

protected boolean tryReleaseShared(int releases) {
    while (true) {
        int p = getState();
        if (compareAndSetState(p, p + releases))
            return true;
    }
}
</programlisting>
</example>
</section>
<section id="ch14lev2sec15" label="14.6.3" xreflabel="14.6.3">
<title id="ch14lev2sec15__title">FutureTask</title>
<para>At first glance, <literal>FutureTask</literal> doesn’t even look like a synchronizer. But <literal>Future.get</literal> has semantics that are very similar to that of a latch—if some event (the completion or cancellation of the task represented by the <literal>FutureTask</literal>) has occurred, then threads can proceed, otherwise they are queued until that event occurs.</para>
<para><literal>FutureTask</literal> uses the AQS synchronization state to hold the task status—running, completed, or cancelled. It also maintains additional state variables to hold the result of the computation or the exception it threw. It further maintains a reference to the thread that is running the computation (if it is currently in the running state), so that it can be interrupted if the task is cancelled.</para>
</section>
<section id="ch14lev2sec16" label="14.6.4" xreflabel="14.6.4">
<title id="ch14lev2sec16__title">ReentrantReadWriteLock</title>
<para>The interface for <literal>ReadWriteLock</literal> suggests there are two locks—a reader lock and a writer lock—but in the AQS-based implementation of <literal>ReentrantReadWriteLock</literal>, a single AQS subclass manages both read and write locking. <literal>ReentrantRead-WriteLock</literal> uses 16 bits of the state for the write-lock count, and the other 16 bits for the read-lock count. Operations on the read lock use the shared acquire and release methods; operations on the write lock use the exclusive acquire and release methods.</para>
<para>Internally, AQS maintains a queue of waiting threads, keeping track of whether a thread has requested exclusive or shared access. In <literal>ReentrantRead-WriteLock</literal>, <?docpage num="317"?><indexterm id="iddle3400" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey ACQUISITION, IN REENTRANTREAD-WRITELOCK?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>acquisition, in <literal>ReentrantRead-WriteLock</literal></secondary></indexterm>when the lock becomes available, if the thread at the head of the queue was looking for write access it will get it, and if the thread at the head of the queue was looking for read access, all queued threads up to the first writer will get it.<footnote id="ch14fn15" label="15"><para>This mechanism does not permit the choice of a reader-preference or writer-preference policy, as some read-write lock implementations do. For that, either the AQS wait queue would need to be something other than a FIFO queue, or two queues would be needed. However, such a strict ordering policy is rarely needed in practice; if the nonfair version of <literal>ReentrantReadWriteLock</literal> does not offer acceptable liveness, the fair version usually provides satisfactory ordering and guarantees nonstarvation of readers and writers.</para></footnote></para>
</section>
</section>



<section id="ch14lev1sec7" condition="317" label="" xreflabel=""><?docpage num="317"?><?docpage num="318"?>
<title id="ch14lev1sec7__title">Summary</title>
<para>If you need to implement a state-dependent class—one whose methods must block if a state-based precondition does not hold—the best strategy is usually to build upon an existing library class such as <literal>Semaphore</literal>, <literal>BlockingQueue</literal>, or <literal>CountDownLatch</literal>, as in <literal>ValueLatch</literal> on page <link linkend="ch08list15" preference="0" role="pageref">187</link>. However, sometimes existing library classes do not provide a sufficient foundation; in these cases, you can build your own synchronizers using intrinsic condition queues, explicit <literal>Condition</literal> objects, or <literal>AbstractQueuedSynchronizer</literal>. Intrinsic condition queues are tightly bound to intrinsic locking, since the mechanism for managing state dependence is necessarily tied to the mechanism for ensuring state consistency. Similarly, explicit <literal>Condition</literal>s are tightly bound to explicit <literal>Lock</literal>s, and offer an extended feature set compared to intrinsic condition queues, including multiple wait sets per lock, interruptible or uninterruptible condition waits, fair or nonfair queuing, and deadline-based waiting.</para>
</section>

</chapter>

<chapter id="ch15" label="15" xreflabel="15" condition="319">
<?docpage num="319"?>
<title id="ch15__title">Atomic Variables and Nonblocking Synchronization</title>


<para><indexterm id="iddle1022" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey INTEGRITY?><primary><emphasis role="strong">access</emphasis></primary><secondary>integrity</secondary></indexterm><indexterm id="iddle1023" significance="normal"><?indexkey A?><?primarykey access?><?secondarykey INTEGRITY?><?tertiarykey NONBLOCKING ALGORITHM USE?><primary><emphasis role="strong">access</emphasis></primary><secondary>integrity</secondary><tertiary>nonblocking algorithm use</tertiary></indexterm><indexterm id="iddle1054" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey NONBLOCKING?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>nonblocking</secondary></indexterm><indexterm id="iddle1058" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey NONBLOCKING?><?tertiarykey SYNCHRONIZATION?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>nonblocking</secondary><tertiary>synchronization</tertiary></indexterm><indexterm id="iddle1137" significance="normal"><?indexkey A?><?primarykey atomic variables?><primary><emphasis role="strong">atomic variables</emphasis></primary></indexterm><indexterm id="iddle1170" significance="normal"><?indexkey A?><?primarykey AtomicInteger?><?secondarykey NONBLOCKING ALGORITHM USE?><primary><emphasis role="strong">AtomicInteger</emphasis></primary><secondary>nonblocking algorithm use</secondary></indexterm><indexterm id="iddle1174" significance="normal"><?indexkey A?><?primarykey AtomicReference?><?secondarykey NONBLOCKING ALGORITHM USE?><primary><emphasis role="strong">AtomicReference</emphasis></primary><secondary>nonblocking algorithm use</secondary></indexterm><indexterm id="iddle1324" significance="normal"><?indexkey C?><?primarykey CAS (compare-and-swap) instructions?><?secondarykey NONBLOCKING ALGORITHM USE?><primary><emphasis role="strong">CAS (compare-and-swap) instructions</emphasis></primary><secondary>nonblocking algorithm use</secondary></indexterm><indexterm id="iddle1484" significance="normal"><?indexkey C?><?primarykey ConcurrentLinkedQueue?><?secondarykey ALGORITHM?><primary><emphasis role="strong">ConcurrentLinkedQueue</emphasis></primary><secondary>algorithm</secondary></indexterm><indexterm id="iddle1755" significance="normal"><?indexkey D?><?primarykey data?><?secondarykey SHARING?><?tertiarykey ACCESS COORDINATION?><primary><emphasis role="strong">data</emphasis></primary><secondary>sharing</secondary><tertiary>access coordination</tertiary></indexterm><indexterm id="iddle1800" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey AVOIDANCE?><?tertiarykey NONBLOCKING ALGORITHM ADVANTAGES?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>avoidance</secondary><tertiary>nonblocking algorithm advantages</tertiary></indexterm><indexterm id="iddle2470" significance="normal"><?indexkey G?><?primarykey granularity?><?secondarykey NONBLOCKING ALGORITHM ADVANTAGES?><primary><emphasis role="strong">granularity</emphasis></primary><secondary>nonblocking algorithm advantages</secondary></indexterm><indexterm id="iddle2918" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey NONBLOCKING ALGORITHM USE?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>nonblocking algorithm use</secondary></indexterm><indexterm id="iddle3024" significance="normal"><?indexkey L?><?primarykey liveness?><?secondarykey NONBLOCKING ALGORITHM ADVANTAGES?><primary><emphasis role="strong">liveness</emphasis></primary><secondary>nonblocking algorithm advantages</secondary></indexterm><indexterm id="iddle3087" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey DISADVANTAGES OF?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>disadvantages of</secondary></indexterm><indexterm id="iddle3121" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey NONBLOCKING ALGORITHMS VS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>nonblocking algorithms vs</secondary></indexterm><indexterm id="iddle3301" significance="normal"><?indexkey N?><?primarykey nonblocking algorithms?><primary><emphasis role="strong">nonblocking algorithms</emphasis></primary></indexterm><indexterm id="iddle3305" significance="normal"><?indexkey N?><?primarykey nonblocking algorithms?><?secondarykey SYNCHRONIZATION?><primary><emphasis role="strong">nonblocking algorithms</emphasis></primary><secondary>synchronization</secondary></indexterm><indexterm id="iddle3377" significance="normal"><?indexkey O?><?primarykey optimistic concurrency management?><primary><emphasis role="strong">optimistic concurrency management</emphasis></primary><see> <link linkend="iddle3487" preference="0"><emphasis role="strong">performance</emphasis>, atomic variables</link>.</see></indexterm><indexterm id="iddle3378" significance="normal"><?indexkey O?><?primarykey optimistic concurrency management?><primary><emphasis role="strong">optimistic concurrency management</emphasis></primary><see> <link linkend="iddle1321" preference="0"><emphasis role="strong">CAS (compare-and-swap) instructions</emphasis></link>.</see></indexterm><indexterm id="iddle3379" significance="normal"><?indexkey O?><?primarykey optimistic concurrency management?><primary><emphasis role="strong">optimistic concurrency management</emphasis></primary><see> <link linkend="iddle3535" preference="0"><emphasis role="strong">performance</emphasis>, techniques for improving, nonblocking algorithms</link>.</see></indexterm><indexterm id="iddle3394" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey TECHNIQUES?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>techniques</secondary><seealso> atomic variabless.</seealso></indexterm><indexterm id="iddle3395" significance="normal"><?indexkey O?><?primarykey optimization?><?secondarykey TECHNIQUES?><primary><emphasis role="strong">optimization</emphasis></primary><secondary>techniques</secondary><seealso> nonblocking synchronization.</seealso></indexterm><indexterm id="iddle3427" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey REDUCTION?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>reduction</secondary><see> <link linkend="iddle3535" preference="0"><emphasis role="strong">performance</emphasis>, techniques for improving, nonblocking algorithms</link>.</see></indexterm><indexterm id="iddle3428" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey REDUCTION?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>reduction</secondary><see> <link linkend="iddle1714" preference="0"><emphasis role="strong">CPU utilization</emphasis>, optimization</link>.</see></indexterm><indexterm id="iddle3429" significance="normal"><?indexkey O?><?primarykey overhead?><?secondarykey REDUCTION?><primary><emphasis role="strong">overhead</emphasis></primary><secondary>reduction</secondary><see> <link linkend="iddle4741" preference="0"><emphasis role="strong">thread(s)</emphasis></link>.</see></indexterm><indexterm id="iddle3533" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TECHNIQUES FOR IMPROVING?><primary><emphasis role="strong">performance</emphasis></primary><secondary>techniques for improving</secondary></indexterm><indexterm id="iddle3534" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TECHNIQUES FOR IMPROVING?><?tertiarykey ATOMIC VARIABLES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>techniques for improving</secondary><tertiary>atomic variables</tertiary></indexterm><indexterm id="iddle3535" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey TECHNIQUES FOR IMPROVING?><?tertiarykey NONBLOCKING ALGORITHMS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>techniques for improving</secondary><tertiary>nonblocking algorithms</tertiary></indexterm><indexterm id="iddle4083" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey TECHNIQUES FOR IMPROVING?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>techniques for improving</secondary></indexterm><indexterm id="iddle4084" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey TECHNIQUES FOR IMPROVING?><?tertiarykey ATOMIC VARIABLES?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>techniques for improving</secondary><tertiary>atomic variables</tertiary></indexterm><indexterm id="iddle4085" significance="normal"><?indexkey S?><?primarykey scalability?><?secondarykey TECHNIQUES FOR IMPROVING?><?tertiarykey NONBLOCKING ALGORITHMS?><primary><emphasis role="strong">scalability</emphasis></primary><secondary>techniques for improving</secondary><tertiary>nonblocking algorithms</tertiary></indexterm><indexterm id="iddle5045" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey ATOMIC?><?tertiarykey NONBLOCKING ALGORITHMS AND?><primary><emphasis role="strong">variables</emphasis></primary><secondary>atomic</secondary><tertiary>nonblocking algorithms and</tertiary></indexterm><indexterm id="iddle5065" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey VOLATILE?><?tertiarykey ATOMIC VARIABLE CLASS USE?><primary><emphasis role="strong">variables</emphasis></primary><secondary>volatile</secondary><tertiary>atomic variable class use</tertiary></indexterm><indexterm id="iddle5123" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey VARIABLES?><?tertiarykey ATOMIC VARIABLE CLASS USE?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>variables</secondary><tertiary>atomic variable class use</tertiary></indexterm>Many of the classes in <literal>java.util.concurrent</literal>, such as <literal>Semaphore</literal> and <literal>ConcurrentLinkedQueue</literal>, provide better performance and scalability than alternatives using <literal>synchronized</literal>. In this chapter, we take a look at the primary source of this performance boost: atomic variables and nonblocking synchronization.</para>
<para>Much of the recent research on concurrent algorithms has focused on <emphasis>nonblocking algorithms</emphasis>, which use low-level atomic machine instructions such as <emphasis>compare-and-swap</emphasis> instead of locks to ensure data integrity under concurrent access. Nonblocking algorithms are used extensively in operating systems and JVMs for thread and process scheduling, garbage collection, and to implement locks and other concurrent data structures.</para>
<para>Nonblocking algorithms are considerably more complicated to design and implement than lock-based alternatives, but they can offer significant scalability and liveness advantages. They coordinate at a finer level of granularity and can greatly reduce scheduling overhead because they don’t block when multiple threads contend for the same data. Further, they are immune to deadlock and other liveness problems. In lock-based algorithms, other threads cannot make progress if a thread goes to sleep or spins while holding a lock, whereas nonblocking algorithms are impervious to individual thread failures. As of Java 5.0, it is possible to build efficient nonblocking algorithms in Java using the <emphasis>atomic variable classes</emphasis> such as <literal>AtomicInteger</literal> and <literal>AtomicReference</literal>.</para>
<para>Atomic variables can also be used as “better volatile variables” even if you are not developing nonblocking algorithms. Atomic variables offer the same memory semantics as volatile variables, but with additional support for atomic updates—making them ideal for counters, sequence generators, and statistics gathering while offering better scalability than lock-based alternatives.</para>



<section id="ch15lev1sec1" condition="319" label="15.1" xreflabel="15.1"><?docpage num="319"?>
<title id="ch15lev1sec1__title">Disadvantages of Locking</title>
<para>Coordinating access to shared state using a consistent locking protocol ensures that whichever thread holds the lock guarding a set of variables has exclusive <?docpage num="320"?><indexterm id="iddle1589" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey LOCK?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>lock</secondary></indexterm><indexterm id="iddle1590" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey LOCK?><?tertiarykey COSTS OF?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>lock</secondary><tertiary>costs of</tertiary></indexterm><indexterm id="iddle2917" significance="normal"><?indexkey J?><?primarykey JVM (Java Virtual Machine)?><?secondarykey LOCK CONTENTION HANDLING?><primary><emphasis role="strong">JVM (Java Virtual Machine)</emphasis></primary><secondary>lock contention handling</secondary></indexterm><indexterm id="iddle3657" significance="normal"><?indexkey P?><?primarykey priority(s)?><primary><emphasis role="strong">priority(s)</emphasis></primary></indexterm><indexterm id="iddle3658" significance="normal"><?indexkey P?><?primarykey priority(s)?><?secondarykey INVERSION?><primary><emphasis role="strong">priority(s)</emphasis></primary><secondary>inversion</secondary></indexterm><indexterm id="iddle3691" significance="normal"><?indexkey P?><?primarykey profiling?><?secondarykey JVM USE?><primary><emphasis role="strong">profiling</emphasis></primary><secondary>JVM use</secondary></indexterm><indexterm id="iddle4512" significance="normal"><?indexkey S?><?primarykey suspension, thread?><?secondarykey COSTS OF?><primary><emphasis role="strong">suspension, thread</emphasis></primary><secondary>costs of</secondary></indexterm><indexterm id="iddle4827" significance="normal"><?indexkey T?><?primarykey thread(s)?><?secondarykey SUSPENSION?><?tertiarykey COSTS OF?><primary><emphasis role="strong">thread(s)</emphasis></primary><secondary>suspension</secondary><tertiary>costs of</tertiary></indexterm><indexterm id="iddle5126" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey VARIABLES?><?tertiarykey ATOMICITY DISADVANTAGES?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>variables</secondary><tertiary>atomicity disadvantages</tertiary></indexterm>access to those variables, and that any changes made to those variables are visible to other threads that subsequently acquire the lock.</para>
<para>Modern JVMs can optimize uncontended lock acquisition and release fairly effectively, but if multiple threads request the lock at the same time the JVM enlists the help of the operating system. If it gets to this point, some unfortunate thread will be suspended and have to be resumed later.<footnote id="ch15fn01" label="1"><para>A smart JVM need not necessarily suspend a thread if it contends for a lock; it could use profiling data to decide adaptively between suspension and spin locking based on how long the lock has been held during previous acquisitions.</para></footnote> When that thread is resumed, it may have to wait for other threads to finish their scheduling quanta before it is actually scheduled. Suspending and resuming a thread has a lot of overhead and generally entails a lengthy interruption. For lock-based classes with fine-grained operations (such as the synchronized collections classes, where most methods contain only a few operations), the ratio of scheduling overhead to useful work can be quite high <emphasis>when the lock is frequently contended</emphasis>.</para>
<para>Volatile variables are a lighter-weight synchronization mechanism than locking because they do not involve context switches or thread scheduling. However, volatile variables have some limitations compared to locking: while they provide similar visibility guarantees, they cannot be used to construct atomic compound actions. This means that volatile variables cannot be used when one variable depends on another, or when the new value of a variable depends on its old value. This limits when volatile variables are appropriate, since they cannot be used to reliably implement common tools such as counters or mutexes.<footnote id="ch15fn02" label="2"><para>It is theoretically possible, though wholly impractical, to use the semantics of <literal>volatile</literal> to construct mutexes and other synchronizers; see (<link linkend="biblio01_029" preference="0">Raynal, 1986</link>).</para></footnote></para>
<para>For example, while the increment operation (<literal>++i</literal>) may <emphasis>look</emphasis> like an atomic operation, it is actually three distinct operations—fetch the current value of the variable, add one to it, and then write the updated value back. In order to not lose an update, the entire read-modify-write operation must be atomic. So far, the only way we’ve seen to do this is with locking, as in <literal>Counter</literal> on page <link linkend="ch04list01" preference="0" role="pageref">56</link>.</para>
<para><literal>Counter</literal> is thread-safe, and in the presence of little or no contention performs just fine. But under contention, performance suffers because of context-switch overhead and scheduling delays. When locks are held so briefly, being put to sleep is a harsh penalty for asking for the lock at the wrong time.</para>
<para>Locking has a few other disadvantages. When a thread is waiting for a lock, it cannot do anything else. If a thread holding a lock is delayed (due to a page fault, scheduling delay, or the like), then no thread that needs that lock can make progress. This can be a serious problem if the blocked thread is a high-priority thread but the thread holding the lock is a lower-priority thread—a performance hazard known as <emphasis>priority inversion</emphasis>. Even though the higher-priority thread should have precedence, it must wait until the lock is released, and this effectively downgrades its priority to that of the lower-priority thread. If a thread holding a lock is permanently blocked (due to an infinite loop, deadlock, livelock, or other liveness failure), any threads waiting for that lock can never make progress.</para>
<para>Even ignoring these hazards, locking is simply a heavyweight mechanism for fine-grained operations such as incrementing a counter. It would be nice to have a finer-grained technique for managing contention between threads—something <?docpage num="321"?><indexterm id="iddle1321" significance="normal"><?indexkey C?><?primarykey CAS (compare-and-swap) instructions?><primary><emphasis role="strong">CAS (compare-and-swap) instructions</emphasis></primary><seealso> <link linkend="iddle1144" preference="0"><emphasis role="strong">atomic/atomicity</emphasis></link>, ; <link linkend="iddle5040" preference="0"><emphasis role="strong">variables</emphasis></link>.</seealso></indexterm><indexterm id="iddle1389" significance="normal"><?indexkey C?><?primarykey compare-and-swap (CAS) instructions?><primary><emphasis role="strong">compare-and-swap (CAS) instructions</emphasis></primary><see> <link linkend="iddle1321" preference="0"><emphasis role="strong">CAS (compare-and-swap) instructions</emphasis></link>.</see></indexterm><indexterm id="iddle1605" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey THREAD?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>thread</secondary></indexterm><indexterm id="iddle1606" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey THREAD?><?tertiarykey COLLISION DETECTION HELP WITH?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>thread</secondary><tertiary>collision detection help with</tertiary></indexterm><indexterm id="iddle2617" significance="normal"><?indexkey H?><?primarykey hardware?><?secondarykey CONCURRENCY SUPPORT?><primary><emphasis role="strong">hardware</emphasis></primary><secondary>concurrency support</secondary></indexterm><indexterm id="iddle3096" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey EXCLUSIVE?><?tertiarykey ALTERNATIVES TO?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>exclusive</secondary><tertiary>alternatives to</tertiary></indexterm><indexterm id="iddle4513" significance="normal"><?indexkey S?><?primarykey suspension, thread?><?secondarykey ELIMINATION BY CAS-BASED CONCURRENCY MECHANISMS?><primary><emphasis role="strong">suspension, thread</emphasis></primary><secondary>elimination by CAS-based concurrency mechanisms</secondary></indexterm>like volatile variables, but offering the possibility of atomic updates as well. Happily, modern processors offer us precisely such a mechanism.</para>
</section>
<section id="ch15lev1sec2" condition="321" label="15.2" xreflabel="15.2"><?docpage num="321"?>
<title id="ch15lev1sec2__title">Hardware Support for Concurrency</title>
<para>Exclusive locking is a <emphasis>pessimistic</emphasis> technique—it assumes the worst (if you don’t lock your door, gremlins will come in and rearrange your stuff) and doesn’t proceed until you can guarantee, by acquiring the appropriate locks, that other threads will not interfere.</para>
<para>For fine-grained operations, there is an alternate approach that is often more efficient—the <emphasis>optimistic</emphasis> approach, whereby you proceed with an update, hopeful that you can complete it without interference. This approach relies on <emphasis>collision detection</emphasis> to determine if there has been interference from other parties during the update, in which case the operation fails and can be retried (or not). The optimistic approach is like the old saying, “It is easier to obtain forgiveness than permission”, where “easier” here means “more efficient”.</para>
<para>Processors designed for multiprocessor operation provide special instructions for managing concurrent access to shared variables. Early processors had atomic <emphasis>test-and-set</emphasis>, <emphasis>fetch-and-increment</emphasis>, or <emphasis>swap</emphasis> instructions sufficient for implementing mutexes that could in turn be used to implement more sophisticated concurrent objects. Today, nearly every modern processor has some form of atomic read-modify-write instruction, such as <emphasis>compare-and-swap</emphasis> or <emphasis>load-linked/store-conditional</emphasis>. Operating systems and JVMs use these instructions to implement locks and concurrent data structures, but until Java 5.0 they had not been available directly to Java classes.</para>
<section id="ch15lev2sec1" label="15.2.1" xreflabel="15.2.1">
<title id="ch15lev2sec1__title">Compare and Swap</title>
<para>The approach taken by most processor architectures, including IA32 and Sparc, is to implement a <emphasis>compare-and-swap</emphasis> (CAS) instruction. (Other processors, such as PowerPC, implement the same functionality with a pair of instructions: <emphasis>loadlinked</emphasis> and <emphasis>store-conditional</emphasis>.) CAS has three operands—a memory location <emphasis>V</emphasis> on which to operate, the expected old value <emphasis>A</emphasis>, and the newvalue <emphasis>B</emphasis>. CAS atomically updates <emphasis>V</emphasis> to the new value <emphasis>B</emphasis>, but only if the value in <emphasis>V</emphasis> matches the expected old value <emphasis>A</emphasis>; otherwise it does nothing. In either case, it returns the value currently in <emphasis>V</emphasis>. (The variant called compare-and-set instead returns whether the operation succeeded.) CAS means “I think <emphasis>V</emphasis> should have the value <emphasis>A</emphasis>; if it does, put <emphasis>B</emphasis> there, otherwise don’t change it but tell me I was wrong.” CAS is an optimistic technique—it proceeds with the update in the hope of success, and can detect failure if another thread has updated the variable since it was last examined. <literal>SimulatedCAS</literal> in <link linkend="ch15list01" preference="0">Listing 15.1</link> illustrates the semantics (but not the implementation or performance) of CAS.</para>
<para>When multiple threads attempt to update the same variable simultaneously using CAS, one wins and updates the variable’s value, and the rest lose. But the losers are not punished by suspension, as they could be if they failed to acquire a lock; instead, they are told that they didn’t win the race this time but <?docpage num="322"?><indexterm id="iddle2178" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SIMULATEDCAS?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SimulatedCAS</literal></secondary></indexterm><indexterm id="iddle2377" significance="normal"><?indexkey F?><?primarykey flexibility?><?secondarykey IN CAS-BASED ALGORITHMS?><primary><emphasis role="strong">flexibility</emphasis></primary><secondary>in CAS-based algorithms</secondary></indexterm><indexterm id="iddle3307" significance="normal"><?indexkey N?><?primarykey nonblocking algorithms?><?secondarykey THREAD-SAFE COUNTER USE?><primary><emphasis role="strong">nonblocking algorithms</emphasis></primary><secondary>thread-safe counter use</secondary></indexterm>can try again. Because a thread that loses a CAS is not blocked, it can decide whether it wants to try again, take some other recovery action, or do nothing.<footnote id="ch15fn03" label="3"><para>Doing nothing may be a perfectly sensible response to a failed CAS; in some nonblocking algorithms, such as the linked queue algorithm in <link linkend="ch15lev2sec7" preference="0">Section 15.4.2</link>, a failed CAS means that someone else already did the work you were planning to do.</para></footnote> This flexibility eliminates many of the liveness hazards associated with locking (though in unusual cases can introduce the risk of <emphasis>livelock</emphasis>—see <link linkend="ch10lev2sec10" preference="0">Section 10.3.3</link>).</para>
<example id="ch15list01" label="15.1" role="Listing" xreflabel="15.1" condition="322">
<title id="ch15list01__title">Simulated CAS Operation.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class SimulatedCAS {
    @GuardedBy("this") private int value;

    public synchronized int get() { return value; }

    public synchronized int compareAndSwap(int expectedValue,
                                           int newValue) {
        int oldValue = value;
        if (oldValue == expectedValue)
            value = newValue;
        return oldValue;
    }

    public synchronized boolean compareAndSet(int expectedValue,
                                              int newValue) {
        return (expectedValue
                == compareAndSwap(expectedValue, newValue));
    }
}
</programlisting>
</example>
<para>The typical pattern for using CAS is first to read the value <emphasis>A</emphasis> from <emphasis>V</emphasis>, derive the new value <emphasis>B</emphasis> from <emphasis>A</emphasis>, and then use CAS to atomically change <emphasis>V</emphasis> from <emphasis>A</emphasis> to <emphasis>B</emphasis> so long as no other thread has changed <emphasis>V</emphasis> to another value in the meantime. CAS addresses the problem of implementing atomic read-modify-write sequences without locking, because it can detect interference from other threads.</para>
</section>
<section id="ch15lev2sec2" label="15.2.2" xreflabel="15.2.2">
<title id="ch15lev2sec2__title">A Nonblocking Counter</title>
<para><literal>CasCounter</literal> in <link linkend="ch15list02" preference="0">Listing 15.2</link> implements a thread-safe counter using CAS. The increment operation follows the canonical form—fetch the old value, transform it to the new value (adding one), and use CAS to set the new value. If the CAS fails, the operation is immediately retried. Retrying repeatedly is usually a reasonable strategy, although in cases of extreme contention it might be desirable to wait or back off before retrying to avoid livelock.</para>
<para><?docpage num="323"?><indexterm id="iddle2095" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CASCOUNTER?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>CasCounter</literal></secondary></indexterm><indexterm id="iddle3515" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey OPTIMIZATION?><?tertiarykey CAS-BASED OPERATIONS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>optimization</secondary><tertiary>CAS-based operations</tertiary></indexterm><literal>CasCounter</literal> does not block, though it may have to retry several<footnote id="ch15fn04" label="4"><para>Theoretically, it could have to retry arbitrarily many times if other threads keep winning the CAS race; in practice, this sort of starvation rarely happens.</para></footnote> times if other threads are updating the counter at the same time. (In practice, if all you need is a counter or sequence generator, just use <literal>AtomicInteger</literal> or <literal>AtomicLong</literal>, which provide atomic increment and other arithmetic methods.)</para>
<example id="ch15list02" label="15.2" role="Listing" xreflabel="15.2" condition="323">
<title id="ch15list02__title">Nonblocking Counter Using CAS.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class CasCounter {
    private SimulatedCAS value;

    public int getValue() {
        return value.get();
    }

    public int increment() {
        int v;
        do {
            v = value.get();
        }
        while (v != value.compareAndSwap(v, v + 1));
        return v + 1;
    }
}
</programlisting>
</example>
<para>At first glance, the CAS-based counter looks as if it should perform worse than a lock-based counter; it has more operations and a more complicated control flow, and depends on the seemingly complicated CAS operation. But in reality, CAS-based counters significantly outperform lock-based counters if there is even a small amount of contention, and often even if there is no contention. The fast path for uncontended lock acquisition typically requires at least one CAS plus other lock-related housekeeping, so more work is going on in the best case for a lock-based counter than in the normal case for the CAS-based counter. Since the CAS succeeds most of the time (assuming low to moderate contention), the hardware will correctly predict the branch implicit in the <literal>while</literal> loop, minimizing the overhead of the more complicated control logic.</para>
<para>The language syntax for locking may be compact, but the work done by the JVM and OS to manage locks is not. Locking entails traversing a relatively complicated code path in the JVM and may entail OS-level locking, thread suspension, and context switches. In the best case, locking requires at least one CAS, so using locks moves the CAS out of sight but doesn’t save any actual execution cost. On the other hand, executing a CAS from within the program involves no JVM code, system calls, or scheduling activity. What looks like a longer code path at the application level is in fact a much shorter code path when JVM and OS activity are <?docpage num="324"?><indexterm id="iddle1139" significance="normal"><?indexkey A?><?primarykey atomic variables?><?secondarykey CLASSES?><primary><emphasis role="strong">atomic variables</emphasis></primary><secondary>classes</secondary></indexterm><indexterm id="iddle1143" significance="normal"><?indexkey A?><?primarykey atomic variables?><?secondarykey VOLATILE VARIABLES VS?><primary><emphasis role="strong">atomic variables</emphasis></primary><secondary>volatile variables vs</secondary></indexterm><indexterm id="iddle1169" significance="normal"><?indexkey A?><?primarykey AtomicInteger?><primary><emphasis role="strong">AtomicInteger</emphasis></primary></indexterm><indexterm id="iddle1322" significance="normal"><?indexkey C?><?primarykey CAS (compare-and-swap) instructions?><?secondarykey JAVA CLASS SUPPORT IN JAVA 5.0?><primary><emphasis role="strong">CAS (compare-and-swap) instructions</emphasis></primary><secondary>Java class support in Java 5.0</secondary></indexterm><indexterm id="iddle1602" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey SCOPE?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>scope</secondary></indexterm><indexterm id="iddle1603" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey SCOPE?><?tertiarykey ATOMIC VARIABLE LIMITATION OF?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>scope</secondary><tertiary>atomic variable limitation of</tertiary></indexterm><indexterm id="iddle2332" significance="normal"><?indexkey F?><?primarykey fast path?><primary sortas="fast path"><emphasis role="strong">’fast path’ synchronization</emphasis></primary></indexterm><indexterm id="iddle2333" significance="normal"><?indexkey F?><?primarykey fast path?><?secondarykey CAS-BASED OPERATIONS VS?><primary sortas="fast path"><emphasis role="strong">’fast path’ synchronization</emphasis></primary><secondary>CAS-based operations vs</secondary></indexterm><indexterm id="iddle4105" significance="normal"><?indexkey S?><?primarykey scope/scoped?><?secondarykey CONTENTION?><primary><emphasis role="strong">scope/scoped</emphasis></primary><secondary>contention</secondary></indexterm><indexterm id="iddle4106" significance="normal"><?indexkey S?><?primarykey scope/scoped?><?secondarykey CONTENTION?><?tertiarykey ATOMIC VARIABLE LIMITATION OF?><primary><emphasis role="strong">scope/scoped</emphasis></primary><secondary>contention</secondary><tertiary>atomic variable limitation of</tertiary></indexterm><indexterm id="iddle4552" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey %?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>’fast path’</secondary></indexterm><indexterm id="iddle4553" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey %?><?tertiarykey CAS-BASED OPERATIONS VS?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>’fast path’</secondary><tertiary>CAS-based operations vs</tertiary></indexterm><indexterm id="iddle5042" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey ATOMIC?><primary><emphasis role="strong">variables</emphasis></primary><secondary>atomic</secondary></indexterm><indexterm id="iddle5043" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey ATOMIC?><?tertiarykey CLASSES?><primary><emphasis role="strong">variables</emphasis></primary><secondary>atomic</secondary><tertiary>classes</tertiary></indexterm>taken into account. The primary disadvantage of CAS is that it forces the caller to deal with contention (by retrying, backing off, or giving up), whereas locks deal with contention automatically by blocking until the lock is available.<footnote id="ch15fn05" label="5"><para>Actually, the biggest disadvantage of CAS is the difficulty of constructing the surrounding algorithms correctly.</para></footnote></para>
<para>CAS performance varies widely across processors. On a single-CPU system, a CAS typically takes on the order of a handful of clock cycles, since no synchronization across processors is necessary. As of this writing, the cost of an uncontended CAS on multiple CPU systems ranges from about ten to about 150 cycles; CAS performance is a rapidly moving target and varies not only across architectures but even across versions of the same processor. Competitive forces will likely result in continued CAS performance improvement over the next several years. A good rule of thumb is that the cost of the “fast path” for <emphasis>uncontended</emphasis> lock acquisition and release on most processors is approximately twice the cost of a CAS.</para>
</section>
<section id="ch15lev2sec3" label="15.2.3" xreflabel="15.2.3">
<title id="ch15lev2sec3__title">CAS Support in the JVM</title>
<para>So, how does Java code convince the processor to execute a CAS on its behalf? Prior to Java 5.0, there was no way to do this short of writing native code. In Java 5.0, low-level support was added to expose CAS operations on <literal>int</literal>, <literal>long</literal>, and object references, and the JVM compiles these into the most efficient means provided by the underlying hardware. On platforms supporting CAS, the runtime inlines them into the appropriate machine instruction(s); in the worst case, if a CAS-like instruction is not available the JVM uses a spin lock. This low-level JVMsupport is used by the atomic variable classes (<literal>AtomicXxx</literal> in <literal>java.util.concurrent. atomic</literal>) to provide an efficient CAS operation on numeric and reference types; these atomic variable classes are used, directly or indirectly, to implement most of the classes in <literal>java.util.concurrent</literal>.</para>
</section>
</section>
<section id="ch15lev1sec3" condition="324" label="15.3" xreflabel="15.3"><?docpage num="324"?>
<title id="ch15lev1sec3__title">Atomic Variable Classes</title>
<para>Atomic variables are finer-grained and lighter-weight than locks, and are critical for implementing high-performance concurrent code on multiprocessor systems. Atomic variables limit the scope of contention to a single variable; this is as finegrained as you can get (assuming your algorithm can even be implemented using such fine granularity). The fast (uncontended) path for updating an atomic variable is no slower than the fast path for acquiring a lock, and usually faster; the slow path is definitely faster than the slow path for locks because it does not involve suspending and rescheduling threads. With algorithms based on atomic variables instead of locks, threads are more likely to be able to proceed without delay and have an easier time recovering if they do experience contention.</para>
<para>The atomic variable classes provide a generalization of volatile variables to support atomic conditional read-modify-write operations. <literal>AtomicInteger</literal> represents an <literal>int</literal> value, and provides <literal>get</literal> and <literal>set</literal> methods with the same memory <?docpage num="325"?><indexterm id="iddle1127" significance="normal"><?indexkey A?><?primarykey arrays?><?secondarykey ATOMIC VARIABLE?><primary><emphasis role="strong">arrays</emphasis></primary><secondary>atomic variable</secondary></indexterm><indexterm id="iddle1168" significance="normal"><?indexkey A?><?primarykey AtomicBoolean?><primary><emphasis role="strong">AtomicBoolean</emphasis></primary></indexterm><indexterm id="iddle1172" significance="normal"><?indexkey A?><?primarykey AtomicLong?><primary><emphasis role="strong">AtomicLong</emphasis></primary></indexterm><indexterm id="iddle1173" significance="normal"><?indexkey A?><?primarykey AtomicReference?><primary><emphasis role="strong">AtomicReference</emphasis></primary></indexterm><indexterm id="iddle1332" significance="normal"><?indexkey C?><?primarykey check-then-act operation?><?secondarykey ATOMIC VARIABLE HANDLING?><primary><emphasis role="strong">check-then-act operation</emphasis></primary><secondary>atomic variable handling</secondary></indexterm><indexterm id="iddle1523" significance="normal"><?indexkey C?><?primarykey conditional?><?secondarykey READ-MODIFY-WRITER OPERATIONS?><primary><emphasis role="strong">conditional</emphasis></primary><secondary>read-modify-writer operations</secondary></indexterm><indexterm id="iddle1524" significance="normal"><?indexkey C?><?primarykey conditional?><?secondarykey READ-MODIFY-WRITER OPERATIONS?><?tertiarykey ATOMIC VARIABLE SUPPORT FOR?><primary><emphasis role="strong">conditional</emphasis></primary><secondary>read-modify-writer operations</secondary><tertiary>atomic variable support for</tertiary></indexterm><indexterm id="iddle2853" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey MULTIVARIABLE?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>multivariable</secondary></indexterm><indexterm id="iddle2854" significance="normal"><?indexkey I?><?primarykey invariant(s)?><?secondarykey MULTIVARIABLE?><?tertiarykey AND ATOMIC VARIABLES?><primary><emphasis role="strong">invariant(s)</emphasis></primary><secondary>multivariable</secondary><tertiary>and atomic variables</tertiary></indexterm><indexterm id="iddle3271" significance="normal"><?indexkey M?><?primarykey multivariable invariants?><primary><emphasis role="strong">multivariable invariants</emphasis></primary></indexterm><indexterm id="iddle3272" significance="normal"><?indexkey M?><?primarykey multivariable invariants?><?secondarykey AND ATOMIC VARIABLES?><primary><emphasis role="strong">multivariable invariants</emphasis></primary><secondary>and atomic variables</secondary></indexterm><indexterm id="iddle3655" significance="normal"><?indexkey P?><?primarykey primitive?><?secondarykey WRAPPER CLASSES?><primary><emphasis role="strong">primitive</emphasis></primary><secondary>wrapper classes</secondary></indexterm><indexterm id="iddle3656" significance="normal"><?indexkey P?><?primarykey primitive?><?secondarykey WRAPPER CLASSES?><?tertiarykey ATOMIC SCALAR CLASSES VS?><primary><emphasis role="strong">primitive</emphasis></primary><secondary>wrapper classes</secondary><tertiary>atomic scalar classes vs</tertiary></indexterm><indexterm id="iddle4122" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey ATOMIC ARRAYS?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>atomic arrays</secondary></indexterm><indexterm id="iddle5047" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey ATOMIC?><?tertiarykey VOLATILE VARIABLES VS?><primary><emphasis role="strong">variables</emphasis></primary><secondary>atomic</secondary><tertiary>volatile variables vs</tertiary></indexterm><indexterm id="iddle5067" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey VOLATILE?><?tertiarykey ATOMIC VARIABLE VS?><primary><emphasis role="strong">variables</emphasis></primary><secondary>volatile</secondary><tertiary>atomic variable vs</tertiary></indexterm><indexterm id="iddle5125" significance="normal"><?indexkey V?><?primarykey volatile?><?secondarykey VARIABLES?><?tertiarykey ATOMIC VARIABLE VS?><primary><emphasis role="strong">volatile</emphasis></primary><secondary>variables</secondary><tertiary>atomic variable vs</tertiary></indexterm>semantics as reads and writes to a volatile <literal>int</literal>. It also provides an atomic <literal>compareAndSet</literal> method (which if successful has the memory effects of both reading and writing a volatile variable) and, for convenience, atomic add, increment, and decrement methods. <literal>AtomicInteger</literal> bears a superficial resemblance to an extended <literal>Counter</literal> class, but offers far greater scalability under contention because it can directly exploit underlying hardware support for concurrency.</para>
<para>There are twelve atomic variable classes, divided into four groups: scalars, field updaters, arrays, and compound variables. The most commonly used atomic variables are the scalars: <literal>AtomicInteger</literal>, <literal>AtomicLong</literal>, <literal>AtomicBoolean</literal>, and <literal>AtomicReference</literal>. All support CAS; the <literal>Integer</literal> and <literal>Long</literal> versions support arithmetic as well. (To simulate atomic variables of other primitive types, you can cast <literal>short</literal> or <literal>byte</literal> values to and from <literal>int</literal>, and use <literal>floatToIntBits</literal> or <literal>doubleToLongBits</literal> for floating-point numbers.)</para>
<para>The atomic array classes (available in <literal>Integer</literal>, <literal>Long</literal>, and <literal>Reference</literal> versions) are arrays whose elements can be updated atomically. The atomic array classes provide volatile access semantics to the elements of the array, a feature not available for ordinary arrays—a <literal>volatile</literal> array has <literal>volatile</literal> semantics only for the array reference, not for its elements. (The other types of atomic variables are discussed in <link linkend="ch15lev2sec8" preference="0">Sections 15.4.3</link> and <link linkend="ch15lev2sec9" preference="0">15.4.4</link>.)</para>
<para>While the atomic scalar classes extend <literal>Number</literal>, they do not extend the primitive wrapper classes such as <literal>Integer</literal> or <literal>Long</literal>. In fact, they cannot: the primitive wrapper classes are immutable whereas the atomic variable classes are mutable. The atomic variable classes also do not redefine <literal>hashCode</literal> or <literal>equals</literal>; each instance is distinct. Like most mutable objects, they are not good candidates for keys in hash-based collections.</para>
<section id="ch15lev2sec4" label="15.3.1" xreflabel="15.3.1">
<title id="ch15lev2sec4__title">Atomics as “Better Volatiles”</title>
<para>In <link linkend="ch03lev2sec10" preference="0">Section 3.4.2</link>, we used a <literal>volatile</literal> reference to an immutable object to update multiple state variables atomically. That example relied on check-then-act, but in that particular case the race was harmless because we did not care if we occasionally lost an update. In most other situations, such a check-then-act would not be harmless and could compromise data integrity. For example, <literal>NumberRange</literal> on page <link linkend="ch04list10" preference="0" role="pageref">67</link> could not be implemented safely with a <literal>volatile</literal> reference to an immutable holder object for the upper and lower bounds, nor with using atomic integers to store the bounds. Because an invariant constrains the two numbers and they cannot be updated simultaneously while preserving the invariant, a number range class using <literal>volatile</literal> references or multiple atomic integers will have unsafe check-then-act sequences.</para>
<para>We can combine the technique from <literal>OneValueCache</literal> with atomic references to close the race condition by <emphasis>atomically</emphasis> updating the reference to an immutable object holding the lower and upper bounds. <literal>CasNumberRange</literal> in <link linkend="ch15list03" preference="0">Listing 15.3</link> uses an <literal>AtomicReference</literal> to an <literal>IntPair</literal> to hold the state; by using <literal>compareAndSet</literal> it can update the upper or lower bound without the race conditions of <literal>NumberRange</literal>.</para>

<para><?docpage num="326"?><?docpage num="327"?></para><example id="ch15list03" label="15.3" role="Listing" xreflabel="15.3" condition="326">

<title id="ch15list03__title">Preserving Multivariable Invariants Using CAS.</title>
<programlisting format="linespecific" linenumbering="unnumbered">public class CasNumberRange {
    @Immutable
    private static class IntPair {
        final int lower;  // Invariant: lower &lt;= upper
        final int upper;
        ...
    }
    private final AtomicReference&lt;IntPair&gt; values =
        new AtomicReference&lt;IntPair&gt;(new IntPair(0, 0));

    public int getLower() { return values.get().lower; }
    public int getUpper() { return values.get().upper; }

    public void setLower(int i) {
        while (true) {
            IntPair oldv = values.get();
            if (i &gt; oldv.upper)
                throw new IllegalArgumentException(
                   "Can't set lower to " + i + " &gt; upper");
            IntPair newv = new IntPair(i, oldv.upper);
            if (values.compareAndSet(oldv, newv))
                return;
        }
    }
    // <emphasis>similarly for setUpper</emphasis>
}
</programlisting>
</example>
</section>
<section id="ch15lev2sec5" label="15.3.2" xreflabel="15.3.2">
<title id="ch15lev2sec5__title">Performance Comparison: Locks Versus Atomic Variables</title>
<para><indexterm id="iddle1140" significance="normal"><?indexkey A?><?primarykey atomic variables?><?secondarykey LOCKING VS?><primary><emphasis role="strong">atomic variables</emphasis></primary><secondary>locking vs</secondary></indexterm><indexterm id="iddle2096" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CASNUMBERRANGE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>CasNumberRange</literal></secondary></indexterm><indexterm id="iddle3060" significance="normal"><?indexkey L?><?primarykey lock(ing)?><?secondarykey ATOMIC VARIABLES VS?><primary><emphasis role="strong">lock(ing)</emphasis></primary><secondary>atomic variables vs</secondary></indexterm><indexterm id="iddle3487" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey ATOMIC VARIABLES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>atomic variables</secondary></indexterm><indexterm id="iddle3488" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey ATOMIC VARIABLES?><?tertiarykey LOCKING VS?><primary><emphasis role="strong">performance</emphasis></primary><secondary>atomic variables</secondary><tertiary>locking vs</tertiary></indexterm><indexterm id="iddle3507" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey MEASUREMENT OF?><?tertiarykey LOCKS VS. ATOMIC VARIABLES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>measurement of</secondary><tertiary>locks vs. atomic variables</tertiary></indexterm><indexterm id="iddle3788" significance="normal"><?indexkey R?><?primarykey random(ness)?><?secondarykey PSEUDORANDOM NUMBER GENERATION?><primary><emphasis role="strong">random(ness)</emphasis></primary><secondary>pseudorandom number generation</secondary></indexterm><indexterm id="iddle3789" significance="normal"><?indexkey R?><?primarykey random(ness)?><?secondarykey PSEUDORANDOM NUMBER GENERATION?><?tertiarykey SCALABILITY?><primary><emphasis role="strong">random(ness)</emphasis></primary><secondary>pseudorandom number generation</secondary><tertiary>scalability</tertiary></indexterm><indexterm id="iddle5044" significance="normal"><?indexkey V?><?primarykey variables?><?secondarykey ATOMIC?><?tertiarykey LOCKING VS?><primary><emphasis role="strong">variables</emphasis></primary><secondary>atomic</secondary><tertiary>locking vs</tertiary></indexterm>To demonstrate the differences in scalability between locks and atomic variables, we constructed a benchmark comparing several implementations of a pseudorandom number generator (PRNG). In a PRNG, the next “random” number is a deterministic function of the previous number, so a PRNG must remember the previous number as part of its state.</para>
<para><link linkend="ch15list04" preference="0">Listings 15.4</link> and <link linkend="ch15list05" preference="0">15.5</link> show two implementations of a thread-safe PRNG, one using <literal>ReentrantLock</literal> and the other using <literal>AtomicInteger</literal>. The test driver invokes each repeatedly; each iteration generates a random number (which fetches and modifies the shared <literal>seed</literal> state) and also performs a number of “busy-work” iterations that operate strictly on thread-local data. This simulates typical operations that include some portion of operating on shared state and some portion of operating on thread-local state.</para>
<para><link linkend="ch15fig01" preference="1">Figures 15.1</link> and <link linkend="ch15fig02" preference="1">15.2</link> show throughput with low and moderate levels of simulated work in each iteration. With a low level of thread-local computation, <?docpage num="328"?><indexterm id="iddle1171" significance="normal"><?indexkey A?><?primarykey AtomicInteger?><?secondarykey RANDOM NUMBER GENERATOR USING?><primary><emphasis role="strong">AtomicInteger</emphasis></primary><secondary>random number generator using</secondary></indexterm><indexterm id="iddle2076" significance="normal"><?indexkey E?><?primarykey example classes?><primary><emphasis role="strong">example classes</emphasis></primary></indexterm><indexterm id="iddle2077" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey ATOMICPSEUDORANDOM?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>AtomicPseudoRandom</literal></secondary></indexterm><indexterm id="iddle2168" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey REENTRANTLOCKPSEUDORANDOM?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ReentrantLockPseudoRandom</literal></secondary></indexterm><indexterm id="iddle3816" significance="normal"><?indexkey R?><?primarykey ReentrantLock?><?secondarykey RANDOM NUMBER GENERATOR USING?><primary><emphasis role="strong">ReentrantLock</emphasis></primary><secondary>random number generator using</secondary></indexterm><indexterm id="iddle1596" significance="normal"><?indexkey C?><?primarykey contention/contended?><?secondarykey LOCKING VS. ATOMIC VARIABLES?><primary><emphasis role="strong">contention/contended</emphasis></primary><secondary>locking vs. atomic variables</secondary></indexterm><indexterm id="iddle4869" significance="normal"><?indexkey T?><?primarykey throughput?><?secondarykey LOCKING VS. ATOMIC VARIABLES?><primary><emphasis role="strong">throughput</emphasis></primary><secondary>locking vs. atomic variables</secondary></indexterm>the lock or atomic variable experiences heavy contention; with more thread-local computation, the lock or atomic variable experiences less contention since it is accessed less often by each thread.</para>
<figure float="1" id="ch15fig01" label="15.1" xreflabel="15.1" condition="328">

<title id="ch15fig01__title"><literal>Lock</literal> and <literal>AtomicInteger</literal> Performance Under High Contention.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/15fig01_alt.gif"?><imagedata depth="274" fileref="graphics/15fig01.gif" format="GIF" role="stdwidth" width="500"/></imageobject></mediaobject>
</figure>
<figure float="1" id="ch15fig02" label="15.2" xreflabel="15.2" condition="329">
<?docpage num="329"?>
<title id="ch15fig02__title"><literal>Lock</literal> and <literal>AtomicInteger</literal> Performance Under Moderate Contention.</title>
<mediaobject float="0"><imageobject><?piTableAlternative default="graphics/15fig02_alt.gif"?><imagedata depth="274" fileref="graphics/15fig02.gif" format="GIF" role="stdwidth" width="500"/></imageobject></mediaobject>
</figure>
<example id="ch15list04" label="15.4" role="Listing" xreflabel="15.4" condition="327">
<?docpage num="327"?>
<title id="ch15list04__title">Random Number Generator Using <literal>ReentrantLock</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ReentrantLockPseudoRandom extends PseudoRandom {
    private final Lock lock = new ReentrantLock(false);
    private int seed;

    ReentrantLockPseudoRandom(int seed) {
        this.seed = seed;
    }

    public int nextInt(int n) {
        lock.lock();
        try {
            int s = seed;
            seed = calculateNext(s);
            int remainder = s % n;
            return remainder &gt; 0 ? remainder : remainder + n;
        } finally {
            lock.unlock();
        }
    }
}
</programlisting>
</example>
<example id="ch15list05" label="15.5" role="Listing" xreflabel="15.5" condition="327">
<?docpage num="327"?>
<title id="ch15list05__title">Random Number Generator Using <literal>AtomicInteger</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class AtomicPseudoRandom extends PseudoRandom {
    private AtomicInteger seed;

    AtomicPseudoRandom(int seed) {
        this.seed = new AtomicInteger(seed);
    }

    public int nextInt(int n) {
        while (true) {
            int s = seed.get();
            int nextSeed = calculateNext(s);
            if (seed.compareAndSet(s, nextSeed)) {
                int remainder = s % n;
                return remainder &gt; 0 ? remainder : remainder + n;
            }
        }
    }
}
</programlisting>
</example>
<para><indexterm id="iddle1052" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey LOCK-FREE?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>lock-free</secondary></indexterm><indexterm id="iddle1055" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey NONBLOCKING?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>nonblocking</secondary></indexterm><indexterm id="iddle1056" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey NONBLOCKING?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>nonblocking</secondary></indexterm><indexterm id="iddle1323" significance="normal"><?indexkey C?><?primarykey CAS (compare-and-swap) instructions?><?secondarykey LOCK-FREE ALGORITHM USE?><primary><emphasis role="strong">CAS (compare-and-swap) instructions</emphasis></primary><secondary>lock-free algorithm use</secondary></indexterm><indexterm id="iddle1325" significance="normal"><?indexkey C?><?primarykey CAS (compare-and-swap) instructions?><?secondarykey NONBLOCKING ALGORITHM USE?><primary><emphasis role="strong">CAS (compare-and-swap) instructions</emphasis></primary><secondary>nonblocking algorithm use</secondary></indexterm><indexterm id="iddle1801" significance="normal"><?indexkey D?><?primarykey deadlock(s)?><?secondarykey AVOIDANCE?><?tertiarykey NONBLOCKING ALGORITHM ADVANTAGES?><primary><emphasis role="strong">deadlock(s)</emphasis></primary><secondary>avoidance</secondary><tertiary>nonblocking algorithm advantages</tertiary></indexterm><indexterm id="iddle3165" significance="normal"><?indexkey L?><?primarykey lock-free algorithms?><primary><emphasis role="strong">lock-free algorithms</emphasis></primary></indexterm><indexterm id="iddle3302" significance="normal"><?indexkey N?><?primarykey nonblocking algorithms?><primary><emphasis role="strong">nonblocking algorithms</emphasis></primary></indexterm><indexterm id="iddle3303" significance="normal"><?indexkey N?><?primarykey nonblocking algorithms?><primary><emphasis role="strong">nonblocking algorithms</emphasis></primary></indexterm><indexterm id="iddle3508" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey MEASUREMENT OF?><?tertiarykey LOCKS VS. ATOMIC VARIABLES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>measurement of</secondary><tertiary>locks vs. atomic variables</tertiary></indexterm><indexterm id="iddle3659" significance="normal"><?indexkey P?><?primarykey priority(s)?><?secondarykey INVERSION?><?tertiarykey AVOIDANCE, NONBLOCKING ALGORITHM ADVANTAGES?><primary><emphasis role="strong">priority(s)</emphasis></primary><secondary>inversion</secondary><tertiary>avoidance, nonblocking algorithm advantages</tertiary></indexterm>As these graphs show, at high contention levels locking tends to outperform atomic variables, but at more realistic contention levels atomic variables outperform locks.<footnote id="ch15fn06" label="6"><para>The same holds true in other domains: traffic lights provide better throughput for high traffic but rotaries provide better throughput for low traffic; the contention scheme used by ethernet networks performs better at low traffic levels, but the token-passing scheme used by token ring networks does better with heavy traffic.</para></footnote> This is because a lock reacts to contention by suspending threads, reducing CPU usage and synchronization traffic on the shared memory bus. (This is similar to how blocking producers in a producer-consumer design reduces the load on consumers and thereby lets them catch up.) On the other hand, with atomic variables, contention management is pushed back to the calling class. Like most CAS-based algorithms, <literal>AtomicPseudoRandom</literal> reacts to contention by trying again immediately, which is usually the right approach but in a high-contention environment just creates more contention.</para>
<para>Before we condemn <literal>AtomicPseudoRandom</literal> as poorly written or atomic variables as a poor choice compared to locks, we should realize that the level of contention in <link linkend="ch15fig01" preference="1">Figure 15.1</link> is unrealistically high: no real program does nothing but contend for a lock or atomic variable. In practice, atomics tend to scale better than locks because atomics deal more effectively with typical contention levels.</para>
<para>The performance reversal between locks and atomics at differing levels of contention illustrates the strengths and weaknesses of each. With low to moderate contention, atomics offer better scalability; with high contention, locks offer better contention avoidance. (CAS-based algorithms also outperform lock-based ones on single-CPU systems, since a CAS always succeeds on a single-CPU system <?docpage num="329"?>except in the unlikely case that a thread is preempted in the middle of the read-modify-write operation.)</para>
<para><link linkend="ch15fig01" preference="1">Figures 15.1</link> and <link linkend="ch15fig02" preference="1">15.2</link> include a third curve; an implementation of <literal>PseudoRandom</literal> that uses a <literal>ThreadLocal</literal> for the PRNG state. This implementation approach changes the behavior of the class—each thread sees its own private sequence of pseudorandom numbers, instead of all threads sharing one sequence—but illustrates that it is often cheaper to not share state at all if it can be avoided. We can improve scalability by dealing more effectively with contention, but true scalability is achieved only by eliminating contention entirely.</para>
</section>
</section>
<section id="ch15lev1sec4" condition="329" label="15.4" xreflabel="15.4"><?docpage num="329"?>
<title id="ch15lev1sec4__title">Nonblocking Algorithms</title>
<para>Lock-based algorithms are at risk for a number of liveness failures. If a thread holding a lock is delayed due to blocking I/O, page fault, or other delay, it is possible that no thread will make progress. An algorithm is called <emphasis>nonblocking</emphasis> if failure or suspension of any thread cannot cause failure or suspension of another thread; an algorithm is called <emphasis>lock-free</emphasis> if, at each step, <emphasis>some</emphasis> thread can make progress. Algorithms that use CAS exclusively for coordination between threads can, if constructed correctly, be both nonblocking and lock-free. An uncontended CAS always succeeds, and if multiple threads contend for a CAS, one always wins and therefore makes progress. Nonblocking algorithms are also immune to deadlock or priority inversion (though they can exhibit starvation or livelock because they can involve repeated retries). We’ve seen one nonblocking algorithm so far: <literal>CasCounter</literal>. Good nonblocking algorithms are known for many common data structures, including stacks, queues, priority queues, and hash tables—though <?docpage num="330"?><?docpage num="331"?><indexterm id="iddle2992" significance="normal"><?indexkey L?><?primarykey linked lists?><?secondarykey NONBLOCKING?><primary><emphasis role="strong">linked lists</emphasis></primary><secondary>nonblocking</secondary></indexterm><indexterm id="iddle4359" significance="normal"><?indexkey S?><?primarykey stack(s)?><?secondarykey NONBLOCKING?><primary><emphasis role="strong">stack(s)</emphasis></primary><secondary>nonblocking</secondary></indexterm>designing new ones is a task best left to experts.</para>
<section id="ch15lev2sec6" label="15.4.1" xreflabel="15.4.1">
<title id="ch15lev2sec6__title">A Nonblocking Stack</title>
<para>Nonblocking algorithms are considerably more complicated than their lock-based equivalents. The key to creating nonblocking algorithms is figuring out how to limit the scope of atomic changes to a <emphasis>single</emphasis> variable while maintaining data consistency. In linked collection classes such as queues, you can sometimes get away with expressing state transformations as changes to individual links and using an <literal>AtomicReference</literal> to represent each link that must be updated atomically.</para>
<para>Stacks are the simplest linked data structure: each element refers to only one other element and each element is referred to by only one object reference. <literal>ConcurrentStack</literal> in <link linkend="ch15list06" preference="0">Listing 15.6</link> shows how to construct a stack using atomic references. The stack is a linked list of <literal>Node</literal> elements, rooted at <literal>top</literal>, each of which contains a value and a link to the next element. The <literal>push</literal> method prepares a new link node whose <literal>next</literal> field refers to the current top of the stack, and then uses CAS to try to install it on the top of the stack. If the same node is still on the top of the stack as when we started, the CAS succeeds; if the top node has changed (because another thread has added or removed elements since we started), the CAS fails and <literal>push</literal> updates the new node based on the current stack state and tries again. In either case, the stack is still in a consistent state after the CAS.</para>
<para><literal>CasCounter</literal> and <literal>ConcurrentStack</literal> illustrate characteristics of all nonblocking algorithms: some work is done speculatively and may have to be redone. In <literal>ConcurrentStack</literal>, when we construct the <literal>Node</literal> representing the new element, we are hoping that the value of the <literal>next</literal> reference will still be correct by the time it is installed on the stack, but are prepared to retry in the event of contention.</para>
<para>Nonblocking algorithms like <literal>ConcurrentStack</literal> derive their thread safety from the fact that, like locking, <literal>compareAndSet</literal> provides both atomicity and visibility guarantees. When a thread changes the state of the stack, it does so with a <literal>compareAndSet</literal>, which has the memory effects of a volatile write. When a thread examines the stack, it does so by calling <literal>get</literal> on the same <literal>AtomicReference</literal>, which has the memory effects of a volatile read. So any changes made by one thread are safely published to any other thread that examines the state of the list. And the list is modified with a <literal>compareAndSet</literal> that atomically either updates the <literal>top</literal> reference or fails if it detects interference from another thread.</para>
</section>
<section id="ch15lev2sec7" label="15.4.2" xreflabel="15.4.2">
<title id="ch15lev2sec7__title">A Nonblocking Linked List</title>
<para>The two nonblocking algorithms we’ve seen so far, the counter and the stack, illustrate the basic pattern of using CAS to update a value speculatively, retrying if the update fails. The trick to building nonblocking algorithms is to limit the scope of atomic changes to a single variable. With counters this is trivial, and with a stack it is straightforward enough, but for more complicated data structures such as queues, hash tables, or trees, it can get a lot trickier.</para>
<para>A linked queue is more complicated than a stack because it must support fast access to both the head and the tail. To do this, it maintains separate head and tail pointers. Two pointers refer to the node at the tail: the <literal>next</literal> pointer of the current <?docpage num="332"?><indexterm id="iddle1064" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey TREIBER&rsquo;S?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>Treiber’s</secondary></indexterm><indexterm id="iddle1065" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey TREIBER&rsquo;S?><?tertiarykey NONBLOCKING STACK?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>Treiber’s</secondary><tertiary>nonblocking stack</tertiary></indexterm><indexterm id="iddle2100" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey CONCURRENTSTACK?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>ConcurrentStack</literal></secondary></indexterm><indexterm id="iddle4973" significance="normal"><?indexkey T?><?primarykey Treiber&rsquo;s nonblocking stack algorithm?><primary><emphasis role="strong">Treiber’s nonblocking stack algorithm</emphasis></primary></indexterm><indexterm id="iddle1053" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><?secondarykey MICHAEL-SCOTT NONBLOCKING QUEUE?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><secondary>Michael-Scott nonblocking queue</secondary></indexterm><indexterm id="iddle2991" significance="normal"><?indexkey L?><?primarykey linked lists?><?secondarykey MICHAEL-SCOTT NONBLOCKING QUEUE?><primary><emphasis role="strong">linked lists</emphasis></primary><secondary>Michael-Scott nonblocking queue</secondary></indexterm><indexterm id="iddle3212" significance="normal"><?indexkey M?><?primarykey Michael-Scott nonblocking queue?><primary><emphasis role="strong">Michael-Scott nonblocking queue</emphasis></primary></indexterm>last element, and the tail pointer. To insert a new element successfully, both of these pointers must be updated—atomically. At first glance, this cannot be done with atomic variables; separate CAS operations are required to update the two pointers, and if the first succeeds but the second one fails the queue is left in an inconsistent state. And, even if both operations succeed, another thread could try to access the queue between the first and the second. Building a nonblocking algorithm for a linked queue requires a plan for both these situations.</para>
<example id="ch15list06" label="15.6" role="Listing" xreflabel="15.6" condition="331">
<?docpage num="331"?>
<title id="ch15list06__title">Nonblocking Stack Using Treiber’s Algorithm (<link linkend="biblio01_031" preference="0">Treiber, 1986</link>).</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ConcurrentStack &lt;E&gt; {
    AtomicReference&lt;Node&lt;E&gt;&gt; top = new AtomicReference&lt;Node&lt;E&gt;&gt;();

    public void push(E item) {
        Node&lt;E&gt; newHead = new Node&lt;E&gt;(item);
        Node&lt;E&gt; oldHead;
        do {
            oldHead = top.get();
            newHead.next = oldHead;
        } while (!top.compareAndSet(oldHead, newHead));
    }

    public E pop() {
        Node&lt;E&gt; oldHead;
        Node&lt;E&gt; newHead;
        do {
            oldHead = top.get();
            if (oldHead == null)
                return null;
            newHead = oldHead.next;
        } while (!top.compareAndSet(oldHead, newHead));
        return oldHead.item;
    }

    private static class Node &lt;E&gt; {
        public final E item;
        public Node&lt;E&gt; next;

        public Node(E item) {
            this.item = item;
        }
    }
}
</programlisting>
</example>
<para>We need several tricks to develop this plan. The first is to ensure that the data structure is always in a consistent state, even in the middle of an multi-step update. That way, if thread <emphasis>A</emphasis> is in the middle of a update when thread <emphasis>B</emphasis> arrives on the scene, <emphasis>B</emphasis> can tell that an operation has been partially completed and knows not to try immediately to apply its own update. Then <emphasis>B</emphasis> can wait (by repeatedly examining the queue state) until <emphasis>A</emphasis> finishes, so that the two don’t get in each other’s way.</para>
<para>While this trick by itself would suffice to let threads “take turns” accessing the data structure without corrupting it, if one thread failed in the middle of an update, no thread would be able to access the queue at all. To make the algorithm nonblocking, we must ensure that the failure of a thread does not prevent other threads from making progress. Thus, the second trick is to make sure that if <emphasis>B</emphasis> arrives to find the data structure in the middle of an update by <emphasis>A</emphasis>, enough information is already embodied in the data structure for <emphasis>B</emphasis> to <emphasis>finish the update for A</emphasis>. If <emphasis>B</emphasis> “helps” <emphasis>A</emphasis> by finishing <emphasis>A</emphasis>’s operation, <emphasis>B</emphasis> can proceed with its own operation without waiting for <emphasis>A</emphasis>. When <emphasis>A</emphasis> gets around to finishing its operation, it will find that <emphasis>B</emphasis> already did the job for it.</para>
<para><literal>LinkedQueue</literal> in <link linkend="ch15list07" preference="0">Listing 15.7</link> shows the insertion portion of the Michael-Scott nonblocking linked-queue algorithm (<link linkend="biblio01_026" preference="0">Michael and Scott, 1996</link>), which is used by <literal>ConcurrentLinkedQueue</literal>. As in many queue algorithms, an empty queue consists of a “sentinel” or “dummy” node, and the head and tail pointers are initialized to refer to the sentinel. The tail pointer always refers to the sentinel (if the queue is empty), the last element in the queue, or (in the case that an operation is in mid-update) the second-to-last element. <link linkend="ch15fig03" preference="1">Figure 15.3</link> illustrates a queue with two elements in the normal, or <emphasis>quiescent</emphasis>, state.</para>
<figure float="1" id="ch15fig03" label="15.3" xreflabel="15.3" condition="331">
<?docpage num="331"?>
<title id="ch15fig03__title">Queue with Two Elements in Quiescent State.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="140" fileref="graphics/15fig03.gif" format="GIF" width="400"/></imageobject>

</mediaobject>
</figure>
<para>Inserting a new element involves updating two pointers. The first links the new node to the end of the list by updating the <literal>next</literal> pointer of the current last element; the second swings the tail pointer around to point to the new last element. <?docpage num="333"?><?docpage num="334"?>Between these two operations, the queue is in the <emphasis>intermediate</emphasis> state, shown in <link linkend="ch15fig04" preference="1">Figure 15.4</link>. After the second update, the queue is again in the quiescent state, shown in <link linkend="ch15fig05" preference="1">Figure 15.5</link>.</para>
<figure float="1" id="ch15fig04" label="15.4" xreflabel="15.4" condition="333">

<title id="ch15fig04__title">Queue in Intermediate State During Insertion.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="134" fileref="graphics/15fig04.gif" format="GIF" width="497"/></imageobject>

</mediaobject>
</figure>
<figure float="1" id="ch15fig05" label="15.5" xreflabel="15.5" condition="333">

<title id="ch15fig05__title">Queue Again in Quiescent State After Insertion is Complete.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="131" fileref="graphics/15fig05.gif" format="GIF" width="487"/></imageobject>

</mediaobject>
</figure>
<para>The key observation that enables both of the required tricks is that if the queue is in the quiescent state, the <literal>next</literal> field of the link node pointed to by <literal>tail</literal> is null, and if it is in the intermediate state, <literal>tail.next</literal> is non-null. So any thread can immediately tell the state of the queue by examining <literal>tail.next</literal>. Further, if the queue is in the intermediate state, it can be restored to the quiescent state by advancing the tail pointer forward one node, finishing the operation for whichever thread is in the middle of inserting an element.<footnote id="ch15fn07" label="7"><para>For a full account of the correctness of this algorithm, see (<link linkend="biblio01_026" preference="0">Michael and Scott, 1996</link>) or (<link linkend="biblio01_017" preference="0">Herlihy and Shavit, 2006</link>).</para></footnote></para>
<para><literal>LinkedQueue.put</literal> first checks to see if the queue is in the intermediate state before attempting to insert a new element (step <emphasis>A</emphasis>). If it is, then some other thread is already in the process of inserting an element (between its steps <emphasis>C</emphasis> and <emphasis>D</emphasis>). Rather than wait for that thread to finish, the current thread helps it by finishing the operation for it, advancing the tail pointer (step <emphasis>B</emphasis>). It then repeats this check in case another thread has started inserting a new element, advancing the tail pointer until it finds the queue in the quiescent state so it can begin its own insertion.</para>
<para>The CAS at step <emphasis>C</emphasis>, which links the new node at the tail of the queue, could fail if two threads try to insert an element at the same time. In that case, no harm is done: no changes have been made, and the current thread can just reload the tail pointer and try again. Once <emphasis>C</emphasis> succeeds, the insertion is considered to have <?docpage num="335"?><indexterm id="iddle2129" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey LINKEDQUEUE?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>LinkedQueue</literal></secondary></indexterm><indexterm id="iddle1157" significance="normal"><?indexkey A?><?primarykey atomic/atomicity?><?secondarykey FIELD UPDATERS?><primary><emphasis role="strong">atomic/atomicity</emphasis></primary><secondary>field updaters</secondary></indexterm><indexterm id="iddle1176" significance="normal"><?indexkey A?><?primarykey AtomicReferenceFieldUpdater?><primary><emphasis role="strong">AtomicReferenceFieldUpdater</emphasis></primary></indexterm><indexterm id="iddle1485" significance="normal"><?indexkey C?><?primarykey ConcurrentLinkedQueue?><?secondarykey REFLECTION USE?><primary><emphasis role="strong">ConcurrentLinkedQueue</emphasis></primary><secondary>reflection use</secondary></indexterm><indexterm id="iddle2338" significance="normal"><?indexkey F?><?primarykey fields?><primary><emphasis role="strong">fields</emphasis></primary></indexterm><indexterm id="iddle2339" significance="normal"><?indexkey F?><?primarykey fields?><?secondarykey ATOMIC UPDATERS?><primary><emphasis role="strong">fields</emphasis></primary><secondary>atomic updaters</secondary></indexterm><indexterm id="iddle3823" significance="normal"><?indexkey R?><?primarykey reflection?><primary><emphasis role="strong">reflection</emphasis></primary></indexterm><indexterm id="iddle3824" significance="normal"><?indexkey R?><?primarykey reflection?><?secondarykey ATOMIC FIELD UPDATER USE?><primary><emphasis role="strong">reflection</emphasis></primary><secondary>atomic field updater use</secondary></indexterm><indexterm id="iddle5015" significance="normal"><?indexkey U?><?primarykey updating?><?secondarykey ATOMIC FIELDS?><primary><emphasis role="strong">updating</emphasis></primary><secondary>atomic fields</secondary></indexterm><indexterm id="iddle5090" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey REFLECTION-BASED?><primary><emphasis role="strong">views</emphasis></primary><secondary>reflection-based</secondary></indexterm><indexterm id="iddle5091" significance="normal"><?indexkey V?><?primarykey views?><?secondarykey REFLECTION-BASED?><?tertiarykey BY ATOMIC FIELD UPDATERS?><primary><emphasis role="strong">views</emphasis></primary><secondary>reflection-based</secondary><tertiary>by atomic field updaters</tertiary></indexterm>taken effect; the second CAS (step <emphasis>D</emphasis>) is considered “cleanup”, since it can be performed either by the inserting thread or by any other thread. If <emphasis>D</emphasis> fails, the inserting thread returns anyway rather than retrying the CAS, because no retry is needed—another thread has already finished the job in its step <emphasis>B</emphasis>! This works because before any thread tries to link a new node into the queue, it first checks to see if the queue needs cleaning up by checking if <literal>tail.next</literal> is non-null. If it is, it advances the tail pointer first (perhaps multiple times) until the queue is in the quiescent state.</para>
<example id="ch15list07" label="15.7" role="Listing" xreflabel="15.7" condition="334">
<?docpage num="334"?>
<title id="ch15list07__title">Insertion in the Michael-Scott Nonblocking Queue Algorithm (<link linkend="biblio01_026" preference="0">Michael and Scott, 1996</link>).</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class LinkedQueue &lt;E&gt; {
    private static class Node &lt;E&gt; {
        final E item;
        final AtomicReference&lt;Node&lt;E&gt;&gt; next;

        public Node(E item, Node&lt;E&gt; next) {
            this.item = item;
            this.next = new AtomicReference&lt;Node&lt;E&gt;&gt;(next);
        }
    }

    private final Node&lt;E&gt; dummy = new Node&lt;E&gt;(null, null);
    private final AtomicReference&lt;Node&lt;E&gt;&gt; head
            = new AtomicReference&lt;Node&lt;E&gt;&gt;(dummy);
    private final AtomicReference&lt;Node&lt;E&gt;&gt; tail
            = new AtomicReference&lt;Node&lt;E&gt;&gt;(dummy);

    public boolean put(E item) {
        Node&lt;E&gt; newNode = new Node&lt;E&gt;(item, null);
        while (true) {
            Node&lt;E&gt; curTail = tail.get();
            Node&lt;E&gt; tailNext = curTail.next.get();
            if (curTail == tail.get()) {
                if (tailNext != null) {                     <inlinemediaobject><imageobject><imagedata depth="25" fileref="graphics/a.gif" format="GIF" width="25"/></imageobject></inlinemediaobject>
                    // <emphasis>Queue in intermediate state, advance tail</emphasis>
                    tail.compareAndSet(curTail, tailNext);   <inlinemediaobject><imageobject><imagedata depth="25" fileref="graphics/b.gif" format="GIF" width="25"/></imageobject></inlinemediaobject>
                } else {
                    // <emphasis>In quiescent state, try inserting new node</emphasis>
                    if (curTail.next.compareAndSet(null, newNode)) { <inlinemediaobject><imageobject><imagedata depth="23" fileref="graphics/c.gif" format="GIF" width="25"/></imageobject></inlinemediaobject>
                        // <emphasis>Insertion succeeded, try advancing tail</emphasis>
                        tail.compareAndSet(curTail, newNode);        <inlinemediaobject><imageobject><imagedata depth="23" fileref="graphics/d.gif" format="GIF" width="25"/></imageobject></inlinemediaobject>
                        return true;
                   }
                }
            }
        }
    }
}
</programlisting>
</example>
</section>
<section id="ch15lev2sec8" label="15.4.3" xreflabel="15.4.3">
<title id="ch15lev2sec8__title">Atomic Field Updaters</title>
<para><link linkend="ch15list07" preference="0">Listing 15.7</link> illustrates the algorithm used by <literal>ConcurrentLinkedQueue</literal>, but the actual implementation is a bit different. Instead of representing each <literal>Node</literal> with an atomic reference, <literal>ConcurrentLinkedQueue</literal> uses an ordinary volatile reference and updates it through the reflection-based <literal>AtomicReferenceFieldUpdater</literal>, as shown in <link linkend="ch15list08" preference="0">Listing 15.8</link>.</para>
<example id="ch15list08" label="15.8" role="Listing" xreflabel="15.8" condition="335">
<title id="ch15list08__title">Using Atomic Field Updaters in <literal>ConcurrentLinkedQueue</literal>.</title>
<programlisting format="linespecific" linenumbering="unnumbered">private class Node&lt;E&gt; {
    private final E item;
    private volatile Node&lt;E&gt; next;

    public Node(E item) {
        this.item = item;
    }
}

private static AtomicReferenceFieldUpdater&lt;Node, Node&gt; nextUpdater
        = AtomicReferenceFieldUpdater.newUpdater(
                Node.class, Node.class, "next");
</programlisting>
</example>
<para>The atomic field updater classes (available in <literal>Integer</literal>, <literal>Long</literal>, and <literal>Reference</literal> versions) represent a reflection-based “view” of an existing volatile field so that CAS can be used on existing volatile fields. The updater classes have no constructors; to create one, you call the <literal>newUpdater</literal> factory method, specifying the class and field name. The field updater classes are not tied to a specific instance; one can be used to update the target field for any instance of the target class. The atomicity guarantees for the updater classes are weaker than for the regular atomic classes because you cannot guarantee that the underlying fields will not be modified directly—the <literal>compareAndSet</literal> and arithmetic methods guarantee atomicity only with respect to other threads using the atomic field updater methods.</para>
<para>In <literal>ConcurrentLinkedQueue</literal>, updates to the <literal>next</literal> field of a <literal>Node</literal> are applied using the <literal>compareAndSet</literal> method of <literal>nextUpdater</literal>. This somewhat circuitous approach is used entirely for performance reasons. For frequently allocated, short-lived objects like queue link nodes, eliminating the creation of an <literal>AtomicReference</literal> for each <literal>Node</literal> is significant enough to reduce the cost of insertion operations. <?docpage num="336"?><indexterm id="iddle1003" significance="normal"><?indexkey A?><?primarykey ABA problem?><primary><emphasis role="strong">ABA problem</emphasis></primary></indexterm>However, in nearly all situations, ordinary atomic variables perform just fine—in only a few cases will the atomic field updaters be needed. (The atomic field updaters are also useful when you want to perform atomic updates while preserving the serialized form of an existing class.)</para>
</section>
<section id="ch15lev2sec9" label="15.4.4" xreflabel="15.4.4">
<title id="ch15lev2sec9__title">The ABA Problem</title>
<para>The <emphasis>ABA problem</emphasis> is an anomaly that can arise from the naive use of compare-and-swap in algorithms where nodes can be recycled (primarily in environments without garbage collection). A CAS effectively asks “Is the value of <emphasis>V</emphasis> still <emphasis>A</emphasis>?”, and proceeds with the update if so. In most situations, including the examples presented in this chapter, this is entirely sufficient. However, sometimes we really want to ask “Has the value of <emphasis>V</emphasis> changed since I last observed it to be <emphasis>A</emphasis>?” For some algorithms, changing <emphasis>V</emphasis> from <emphasis>A</emphasis> to <emphasis>B</emphasis> and then back to <emphasis>A</emphasis> still counts as a change that requires us to retry some algorithmic step.</para>
<para>This <emphasis>ABA problem</emphasis> can arise in algorithms that do their own memory management for link node objects. In this case, that the head of a list still refers to a previously observed node is not enough to imply that the contents of the list have not changed. If you cannot avoid the ABA problem by letting the garbage collector manage link nodes for you, there is still a relatively simple solution: instead of updating the value of a reference, update a <emphasis>pair</emphasis> of values, a reference and a version number. Even if the value changes from <emphasis>A</emphasis> to <emphasis>B</emphasis> and back to <emphasis>A</emphasis>, the version numbers will be different. <literal>AtomicStampedReference</literal> (and its cousin <literal>AtomicMarkableReference</literal>) provide atomic conditional update on a pair of variables. <literal>AtomicStampedReference</literal> updates an object reference-integer pair, allowing “versioned” references that are immune<footnote id="ch15fn08" label="8"><para>In practice, anyway; theoretically the counter could wrap.</para></footnote> to the ABA problem. Similarly, <literal>AtomicMarkableReference</literal> updates an object reference-boolean pair that is used by some algorithms to let a node remain in a list while being marked as deleted.<footnote id="ch15fn09" label="9"><para>Many processors provide a double-wide CAS (CAS2 or CASX) operation that can operate on a pointer-integer pair, which would make this operation reasonably efficient. As of Java 6, <literal>Atomic-StampedReference</literal> does not use double-wide CAS even on platforms that support it. (Double-wide CAS differs from DCAS, which operates on two unrelated memory locations; as of this writing, no current processor implements DCAS.)</para></footnote></para>
</section>
</section>



<section id="ch15lev1sec5" condition="336" label="" xreflabel=""><?docpage num="336"?>
<title id="ch15lev1sec5__title">Summary</title>
<para>Nonblocking algorithms maintain thread safety by using low-level concurrency primitives such as compare-and-swap instead of locks. These low-level primitives are exposed through the atomic variable classes, which can also be used as “better volatile variables” providing atomic update operations for integers and object references.</para>
<para>Nonblocking algorithms are difficult to design and implement, but can offer better scalability under typical conditions and greater resistance to liveness failures. Many of the advances in concurrent performance from one JVM version to the next come from the use of nonblocking algorithms, both within the JVM and in the platform libraries.</para>
</section>

</chapter>

<chapter id="ch16" label="16" xreflabel="16" condition="337">
<?docpage num="337"?>
<title id="ch16__title">The Java Memory Model</title>


<para><indexterm id="iddle1014" significance="normal"><?indexkey A?><?primarykey abstractions?><primary><emphasis role="strong">abstractions</emphasis></primary><see> <link linkend="iddle3219" preference="0"><emphasis role="strong">model(s)/modeling</emphasis></link>.</see></indexterm><indexterm id="iddle1015" significance="normal"><?indexkey A?><?primarykey abstractions?><primary><emphasis role="strong">abstractions</emphasis></primary><see> <link linkend="iddle4645" preference="0"><emphasis role="strong">task(s)</emphasis>, representation</link>.</see></indexterm><indexterm id="iddle2892" significance="normal"><?indexkey J?><?primarykey Java Memory Model (JMM)?><primary><emphasis role="strong">Java Memory Model (JMM)</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle2893" significance="normal"><?indexkey J?><?primarykey Java Memory Model (JMM)?><primary><emphasis role="strong">Java Memory Model (JMM)</emphasis></primary><seealso> <link linkend="iddle2571" preference="0"><emphasis role="strong">guidelines</emphasis>, safety</link>.</seealso></indexterm><indexterm id="iddle2894" significance="normal"><?indexkey J?><?primarykey Java Memory Model (JMM)?><primary><emphasis role="strong">Java Memory Model (JMM)</emphasis></primary><seealso> <link linkend="iddle1604" preference="0"><emphasis role="strong">contention/contended</emphasis>, synchronization</link>.</seealso></indexterm><indexterm id="iddle2895" significance="normal"><?indexkey J?><?primarykey Java Memory Model (JMM)?><primary><emphasis role="strong">Java Memory Model (JMM)</emphasis></primary><seealso> <link linkend="iddle3209" preference="0"><emphasis role="strong">memory</emphasis>, visibility</link>.</seealso></indexterm><indexterm id="iddle2908" significance="normal"><?indexkey J?><?primarykey JMM (Java Memory Model)?><primary><emphasis role="strong">JMM (Java Memory Model)</emphasis></primary><see> <link linkend="iddle2892" preference="0"><emphasis role="strong">Java Memory Model (JMM)</emphasis></link>.</see></indexterm><indexterm id="iddle3202" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey MODELS?><?tertiarykey JMM?><primary><emphasis role="strong">memory</emphasis></primary><secondary>models</secondary><tertiary>JMM</tertiary></indexterm><indexterm id="iddle3216" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><seealso> <link linkend="iddle2892" preference="0"><emphasis role="strong">Java Memory Model (JMM)</emphasis></link>.</seealso></indexterm><indexterm id="iddle3217" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><seealso> <link linkend="iddle3287" preference="0"><emphasis role="strong">MVC (model-view-controller) pattern</emphasis></link>.</seealso></indexterm><indexterm id="iddle3218" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><seealso> <link linkend="iddle4645" preference="0"><emphasis role="strong">task(s)</emphasis>, representation</link>.</seealso></indexterm><indexterm id="iddle3219" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><seealso> <link linkend="iddle5017" preference="0"><emphasis role="strong">updating</emphasis>, views</link>.</seealso></indexterm><indexterm id="iddle3224" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey MEMORY?><?tertiarykey JMM?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>memory</secondary><tertiary>JMM</tertiary></indexterm><indexterm id="iddle3230" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey SHARED DATA?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>shared data</secondary><seealso> <link linkend="iddle3444" preference="0"><emphasis role="strong">page renderer examples</emphasis></link>.</seealso></indexterm><indexterm id="iddle3444" significance="normal"><?indexkey P?><?primarykey page renderer examples?><primary><emphasis role="strong">page renderer examples</emphasis></primary><seealso> <link linkend="iddle3216" preference="0"><emphasis role="strong">model(s)/modeling</emphasis></link>, shared data.</seealso></indexterm><indexterm id="iddle4135" significance="normal"><?indexkey S?><?primarykey semantics?><?secondarykey WITHIN-THREAD-AS-IF-SERIAL?><primary><emphasis role="strong">semantics</emphasis></primary><secondary>within-thread-as-if-serial</secondary></indexterm><indexterm id="iddle4224" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey DATA?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>data</secondary><seealso> <link linkend="iddle3444" preference="0"><emphasis role="strong">page renderer examples</emphasis></link>.</seealso></indexterm><indexterm id="iddle5155" significance="normal"><?indexkey W?><?primarykey within-thread-as-if-serial semantics?><primary><emphasis role="strong">within-thread-as-if-serial semantics</emphasis></primary></indexterm>Throughout this book, we’ve mostly avoided the low-level details of the Java Memory Model (JMM) and instead focused on higher-level design issues such as safe publication, specification of, and adherence to synchronization policies. These derive their safety from the JMM, and you may find it easier to use these mechanisms effectively when you understand <emphasis>why</emphasis> they work. This chapter pulls back the curtain to reveal the low-level requirements and guarantees of the Java Memory Model and the reasoning behind some of the higher-level design rules offered in this book.</para>



<section id="ch16lev1sec1" condition="337" label="16.1" xreflabel="16.1"><?docpage num="337"?>
<title id="ch16lev1sec1__title">What is a Memory Model, and Why would I Want One?</title>
<para>Suppose one thread assigns a value to <literal>aVariable</literal>:</para>
<informalexample>
<programlisting format="linespecific" linenumbering="unnumbered">aVariable = 3;</programlisting>
</informalexample>
<para role="continued">A memory model addresses the question “Under what conditions does a thread that reads <literal>aVariable</literal> see the value 3?” This may sound like a dumb question, but in the absence of synchronization, there are a number of reasons a threadmight not immediately—or ever—see the results of an operation in another thread. Compilers may generate instructions in a different order than the “obvious” one suggested by the source code, or store variables in registers instead of in memory; processors may execute instructions in parallel or out of order; caches may vary the order in which writes to variables are committed to main memory; and values stored in processor-local caches may not be visible to other processors. These factors can prevent a thread from seeing the most up-to-date value for a variable and can cause memory actions in other threads to appear to happen out of order—if you don’t use adequate synchronization.</para>
<para>In a single-threaded environment, all these tricks played on our program by the environment are hidden from us and have no effect other than to speed up execution. The Java Language Specification requires the JVM to maintain <emphasis>withinthread as-if-serial semantics</emphasis>: as long as the program has the same result as if it were executed in program order in a strictly sequential environment, all these games are permissible. And that’s a good thing, too, because these rearrangements are responsible for much of the improvement in computing performance <?docpage num="338"?><indexterm id="iddle1196" significance="normal"><?indexkey B?><?primarykey barrier(s)?><?secondarykey MEMORY?><primary><emphasis role="strong">barrier(s)</emphasis></primary><secondary>memory</secondary></indexterm><indexterm id="iddle2620" significance="normal"><?indexkey H?><?primarykey hardware?><?secondarykey PLATFORM MEMORY MODELS?><primary><emphasis role="strong">hardware</emphasis></primary><secondary>platform memory models</secondary></indexterm><indexterm id="iddle3195" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey BARRIERS?><primary><emphasis role="strong">memory</emphasis></primary><secondary>barriers</secondary></indexterm><indexterm id="iddle3200" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey MODELS?><primary><emphasis role="strong">memory</emphasis></primary><secondary>models</secondary></indexterm><indexterm id="iddle3201" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey MODELS?><?tertiarykey HARDWARE ARCHITECTURE?><primary><emphasis role="strong">memory</emphasis></primary><secondary>models</secondary><tertiary>hardware architecture</tertiary></indexterm><indexterm id="iddle3205" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey SHARED MEMORY MULTIPROCESSORS?><primary><emphasis role="strong">memory</emphasis></primary><secondary>shared memory multiprocessors</secondary></indexterm><indexterm id="iddle3222" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey MEMORY?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>memory</secondary></indexterm><indexterm id="iddle3223" significance="normal"><?indexkey M?><?primarykey model(s)/modeling?><?secondarykey MEMORY?><?tertiarykey HARDWARE ARCHITECTURE?><primary><emphasis role="strong">model(s)/modeling</emphasis></primary><secondary>memory</secondary><tertiary>hardware architecture</tertiary></indexterm><indexterm id="iddle3263" significance="normal"><?indexkey M?><?primarykey multiprocessor systems?><?secondarykey SHARED MEMORY?><primary><emphasis role="strong">multiprocessor systems</emphasis></primary><secondary>shared memory</secondary></indexterm><indexterm id="iddle3264" significance="normal"><?indexkey M?><?primarykey multiprocessor systems?><?secondarykey SHARED MEMORY?><?tertiarykey MEMORY MODELS?><primary><emphasis role="strong">multiprocessor systems</emphasis></primary><secondary>shared memory</secondary><tertiary>memory models</tertiary></indexterm><indexterm id="iddle4160" significance="normal"><?indexkey S?><?primarykey sequential/sequentiality?><?secondarykey CONSISTENCY?><primary><emphasis role="strong">sequential/sequentiality</emphasis></primary><secondary>consistency</secondary></indexterm><indexterm id="iddle4233" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey MEMORY MULTIPROCESSORS?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>memory multiprocessors</secondary></indexterm><indexterm id="iddle4234" significance="normal"><?indexkey S?><?primarykey shared/sharing?><?secondarykey MEMORY MULTIPROCESSORS?><?tertiarykey MEMORY MODELS?><primary><emphasis role="strong">shared/sharing</emphasis></primary><secondary>memory multiprocessors</secondary><tertiary>memory models</tertiary></indexterm><indexterm id="iddle5102" significance="normal"><?indexkey V?><?primarykey visibility?><?secondarykey GUARANTEES?><primary><emphasis role="strong">visibility</emphasis></primary><secondary>guarantees</secondary></indexterm><indexterm id="iddle5103" significance="normal"><?indexkey V?><?primarykey visibility?><?secondarykey GUARANTEES?><?tertiarykey JMM SPECIFICATION OF?><primary><emphasis role="strong">visibility</emphasis></primary><secondary>guarantees</secondary><tertiary>JMM specification of</tertiary></indexterm>in recent years. Certainly higher clock rates have contributed to improved performance, but so has increased parallelism—pipelined superscalar execution units, dynamic instruction scheduling, speculative execution, and sophisticated multilevel memory caches. As processors have become more sophisticated, so too have compilers, rearranging instructions to facilitate optimal execution and using sophisticated global register-allocation algorithms. And as processor manufacturers transition to multicore processors, largely because clock rates are getting harder to increase economically, hardware parallelism will only increase.</para>
<para>In a multithreaded environment, the illusion of sequentiality cannot be maintained without significant performance cost. Sincemost of the time threads within a concurrent application are each “doing their own thing”, excessive inter-thread coordination would only slow down the application to no real benefit. It is only when multiple threads share data that it is necessary to coordinate their activities, and the JVM relies on the program to identify when this is happening by using synchronization.</para>
<para>The JMM specifies the minimal guarantees the JVM must make about when writes to variables become visible to other threads. It was designed to balance the need for predictability and ease of program development with the realities of implementing high-performance JVMs on a wide range of popular processor architectures. Some aspects of the JMM may be disturbing at first if you are not familiar with the tricks used by modern processors and compilers to squeeze extra performance out of your program.</para>
<section id="ch16lev2sec1" label="16.1.1" xreflabel="16.1.1">
<title id="ch16lev2sec1__title">Platform Memory Models</title>
<para>In a shared-memory multiprocessor architecture, each processor has its own cache that is periodically reconciled with main memory. Processor architectures provide varying degrees of <emphasis>cache coherence</emphasis>; some provide minimal guarantees that allow different processors to see different values for the same memory location at virtually any time. The operating system, compiler, and runtime (and sometimes, the program, too) must make up the difference between what the hardware provides and what thread safety requires.</para>
<para>Ensuring that every processor knows what every other processor is doing at all times is expensive. Most of the time this information is not needed, so processors relax their memory-coherency guarantees to improve performance. An architecture’s <emphasis>memory model</emphasis> tells programs what guarantees they can expect from the memory system, and specifies the special instructions required (called <emphasis>memory barriers</emphasis> or <emphasis>fences</emphasis>) to get the additional memory coordination guarantees required when sharing data. In order to shield the Java developer from the differences between memory models across architectures, Java provides its own memory model, and the JVMdeals with the differences between the JMMand the underlying platform’s memory model by inserting memory barriers at the appropriate places.</para>
<para>One convenient mental model for program execution is to imagine that there is a single order in which the operations happen in a program, regardless of what processor they execute on, and that each read of a variable will see the last write in the execution order to that variable by any processor. This happy, if unrealistic, model is called <emphasis>sequential consistency</emphasis>. Software developers often <?docpage num="339"?><indexterm id="iddle1040" significance="normal"><?indexkey A?><?primarykey action(s)?><?secondarykey JMM SPECIFICATION?><primary><emphasis role="strong">action(s)</emphasis></primary><secondary>JMM specification</secondary></indexterm><indexterm id="iddle2775" significance="normal"><?indexkey I?><?primarykey interleaving?><?secondarykey ORDERING IMPACT?><primary><emphasis role="strong">interleaving</emphasis></primary><secondary>ordering impact</secondary></indexterm><indexterm id="iddle3203" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey REORDERING?><primary><emphasis role="strong">memory</emphasis></primary><secondary>reordering</secondary></indexterm><indexterm id="iddle3204" significance="normal"><?indexkey M?><?primarykey memory?><?secondarykey REORDERING?><?tertiarykey OPERATIONS?><primary><emphasis role="strong">memory</emphasis></primary><secondary>reordering</secondary><tertiary>operations</tertiary></indexterm><indexterm id="iddle3856" significance="normal"><?indexkey R?><?primarykey reordering?><?secondarykey MEMORY?><?tertiarykey OPERATIONS?><primary><emphasis role="strong">reordering</emphasis></primary><secondary>memory</secondary><tertiary>operations</tertiary></indexterm>mistakenly assume sequential consistency, but no modern multiprocessor offers sequential consistency and the JMM does not either. The classic sequential computing model, the von Neumann model, is only a vague approximation of how modern multiprocessors behave.</para>
<para>The bottom line is that modern shared-memory multiprocessors (and compilers) can do some surprising things when data is shared across threads, unless you’ve told them not to through the use of memory barriers. Fortunately, Java programs need not specify the placement of memory barriers; they need only identify when shared state is being accessed, through the proper use of synchronization.</para>
</section>
<section id="ch16lev2sec2" label="16.1.2" xreflabel="16.1.2">
<title id="ch16lev2sec2__title">Reordering</title>
<para>In describing race conditions and atomicity failures in <link linkend="ch02" preference="0">Chapter 2</link>, we used interaction diagrams depicting “unlucky timing” where the scheduler interleaved operations so as to cause incorrect results in insufficiently synchronized programs. To make matters worse, the JMM can permit actions to appear to execute in different orders from the perspective of different threads, making reasoning about ordering in the absence of synchronization even more complicated. The various reasons why operations might be delayed or appear to execute out of order can all be grouped into the general category of <emphasis>reordering</emphasis>.</para>
<para><literal>PossibleReordering</literal> in <link linkend="ch16list01" preference="0">Listing 16.1</link> illustrates how difficult it is to reason about the behavior of even the simplest concurrent programs unless they are correctly synchronized. It is fairly easy to imagine how <literal>PossibleReordering</literal> could print (1, 0), or (0, 1), or (1, 1): thread <emphasis>A</emphasis> could run to completion before <emphasis>B</emphasis> starts, <emphasis>B</emphasis> could run to completion before <emphasis>A</emphasis> starts, or their actions could be interleaved. But, strangely, <literal>PossibleReordering</literal> can also print (0, 0)! The actions in each thread have no dataflow dependence on each other, and accordingly can be executed out of order. (Even if they are executed in order, the timing by which caches are flushed to main memory can make it appear, from the perspective of <emphasis>B</emphasis>, that the assignments in <emphasis>A</emphasis> occurred in the opposite order.) <link linkend="ch16fig01" preference="1">Figure 16.1</link> shows a possible interleaving with reordering that results in printing (0, 0).</para>
<figure float="1" id="ch16fig01" label="16.1" xreflabel="16.1" condition="340">
<?docpage num="340"?>
<title id="ch16fig01__title">Interleaving Showing Reordering in <literal>PossibleReordering</literal>.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="119" fileref="graphics/16fig01.gif" format="GIF" width="396"/></imageobject>

</mediaobject>
</figure>
<para><indexterm id="iddle2155" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey POSSIBLEREORDERING?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>PossibleReordering</literal></secondary></indexterm><indexterm id="iddle2612" significance="normal"><?indexkey H?><?primarykey happens-before?><primary><emphasis role="strong">happens-before</emphasis></primary></indexterm><indexterm id="iddle2613" significance="normal"><?indexkey H?><?primarykey happens-before?><?secondarykey JMM DEFINITION?><primary><emphasis role="strong">happens-before</emphasis></primary><secondary>JMM definition</secondary></indexterm><indexterm id="iddle3411" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey PARTIAL?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>partial</secondary></indexterm><indexterm id="iddle3412" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey PARTIAL?><?tertiarykey HAPPENS-BEFORE, JMM DEFINITION?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>partial</secondary><tertiary>happens-before, JMM definition</tertiary></indexterm><indexterm id="iddle3460" significance="normal"><?indexkey P?><?primarykey partial ordering?><primary><emphasis role="strong">partial ordering</emphasis></primary></indexterm><indexterm id="iddle3463" significance="normal"><?indexkey P?><?primarykey partial ordering?><?secondarykey HAPPENS-BEFORE?><?tertiarykey JMM DEFINITION?><primary><emphasis role="strong">partial ordering</emphasis></primary><secondary>happens-before</secondary><tertiary>JMM definition</tertiary></indexterm><literal>PossibleReordering</literal> is a trivial program, and it is still surprisingly tricky to enumerate its possible results. Reordering at the memory level can make programs behave unexpectedly. It is prohibitively difficult to reason about ordering in the absence of synchronization; it is much easier to ensure that your program uses synchronization appropriately. Synchronization inhibits the compiler, runtime, and hardware from reordering memory operations in ways that would violate the visibility guarantees provided by the JMM.<footnote id="ch16fn01" label="1"><para>On most popular processor architectures, the memory model is strong enough that the performance cost of a volatile read is in line with that of a nonvolatile read.</para></footnote></para>
</section>
<section id="ch16lev2sec3" label="16.1.3" xreflabel="16.1.3">
<title id="ch16lev2sec3__title">The Java Memory Model in 500 Words or Less</title>
<para>The Java Memory Model is specified in terms of <emphasis>actions</emphasis>, which include reads and writes to variables, locks and unlocks of monitors, and starting and joining with <?docpage num="340"?>threads. The JMM defines a partial ordering <footnote id="ch16fn02" label="2"><para>A partial ordering <inlinemediaobject><imageobject><imagedata depth="11" fileref="graphics/gamma.jpg" format="JPG" width="12"/></imageobject></inlinemediaobject> is a relation on a set that is antisymmetric, reflexive, and transitive, but for any two elements <emphasis>x</emphasis> and <emphasis>y</emphasis>, it need not be the case that <emphasis>x</emphasis> <inlinemediaobject><imageobject><imagedata depth="11" fileref="graphics/gamma.jpg" format="JPG" width="12"/></imageobject></inlinemediaobject> <emphasis>y</emphasis> or <emphasis>y</emphasis> <inlinemediaobject><imageobject><imagedata depth="11" fileref="graphics/gamma.jpg" format="JPG" width="12"/></imageobject></inlinemediaobject> <emphasis>x</emphasis>. We use partial orderings every day to express preferences; we may prefer sushi to cheeseburgers and Mozart to Mahler, but we don’t necessarily have a clear preference between cheeseburgers and Mozart.</para></footnote> called <emphasis>happens-before</emphasis> on all actions within the program. To guarantee that the thread executing action <emphasis>B</emphasis> can see the results of action <emphasis>A</emphasis> (whether or not <emphasis>A</emphasis> and <emphasis>B</emphasis> occur in different threads), there must be a <emphasis>happens-before</emphasis> relationship between <emphasis>A</emphasis> and <emphasis>B</emphasis>. In the absence of a <emphasis>happens-before</emphasis> ordering between two operations, the JVM is free to reorder them as it pleases.</para>
<example id="ch16list01" label="16.1" role="Listing" xreflabel="16.1" condition="340">
<title id="ch16list01__title">Insufficiently Synchronized Program that can have Surprising Results. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">public class PossibleReordering {
    static int x = 0, y = 0;
    static int a = 0, b = 0;

    public static void main(String[] args)
            throws InterruptedException {
        Thread one = new Thread(new Runnable() {
            public void run() {
                a = 1;
                x = b;
            }
        });
        Thread other = new Thread(new Runnable() {
            public void run() {
                b = 1;
                y = a;
            }
        });
        one.start(); other.start();
        one.join();   other.join();
        System.out.println("( "+ x + "," + y + ")");
    }
}
</programlisting>
</example>
<para><?docpage num="341"?><indexterm id="iddle1675" significance="normal"><?indexkey C?><?primarykey correctly synchronized program?><primary><emphasis role="strong">correctly synchronized program</emphasis></primary></indexterm><indexterm id="iddle1763" significance="normal"><?indexkey D?><?primarykey data race?><primary><emphasis role="strong">data race</emphasis></primary></indexterm><indexterm id="iddle3417" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey TOTAL?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>total</secondary></indexterm><indexterm id="iddle3418" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey TOTAL?><?tertiarykey SYNCHRONIZATION ACTIONS?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>total</secondary><tertiary>synchronization actions</tertiary></indexterm><indexterm id="iddle4013" significance="normal"><?indexkey R?><?primarykey rules?><?secondarykey HAPPENS-BEFORE?><primary><emphasis role="strong">rules</emphasis></primary><secondary>happens-before</secondary></indexterm><indexterm id="iddle4547" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey CORRECTLY SYNCHRONIZED PROGRAM?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>correctly synchronized program</secondary></indexterm>A <emphasis>data race</emphasis> occurs when a variable is read by more than one thread, and written by at least one thread, but the reads and writes are not ordered by <emphasis>happens-before</emphasis>. A <emphasis>correctly synchronized program</emphasis> is one with no data races; correctly synchronized programs exhibit sequential consistency, meaning that all actions within the program appear to happen in a fixed, global order.</para>
<sidebar float="1" id="ch16sb01" condition="341"><title/>
<para>The rules for <emphasis>happens-before</emphasis> are:</para>
<itemizedlist mark="none" spacing="normal">
<listitem><formalpara><title><emphasis role="strong"><?design?>Program order rule.</emphasis></title><para>Each action in a thread <emphasis>happens-before</emphasis> every action in that thread that comes later in the program order.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Monitor lock rule.</emphasis></title><para>An unlock on a monitor lock <emphasis>happens-before</emphasis> every subsequent lock on that same monitor lock.<footnote id="ch16fn03" label="3"><para>Locks and unlocks on explicit <literal>Lock</literal> objects have the same memory semantics as intrinsic locks.</para></footnote></para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Volatile variable rule.</emphasis></title><para>A write to a volatile field <emphasis>happens-before</emphasis> every subsequent read of that same field.<footnote id="ch16fn04" label="4"><para>Reads and writes of atomic variables have the same memory semantics as volatile variables.</para></footnote></para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Thread start rule.</emphasis></title><para>A call to <literal>Thread.start</literal> on a thread <emphasis>happens-before</emphasis> every action in the started thread.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Thread termination rule.</emphasis></title><para>Any action in a thread <emphasis>happens-before</emphasis> any other thread detects that thread has terminated, either by successfully return from <literal>Thread.join</literal> or by <literal>Thread.isAlive</literal> returning <literal>false</literal>.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Interruption rule.</emphasis></title><para>A thread calling <literal>interrupt</literal> on another thread <emphasis>happens-before</emphasis> the interrupted thread detects the interrupt (either by having <literal>InterruptedException</literal> thrown, or invoking <literal>isInterrupted</literal> or <literal>interrupted</literal>).</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Finalizer rule.</emphasis></title><para>The end of a constructor for an object <emphasis>happens-before</emphasis> the start of the finalizer for that object.</para></formalpara></listitem>
<listitem><formalpara><title><emphasis role="strong"><?design?>Transitivity.</emphasis></title><para>If <emphasis>A happens-before B</emphasis>, and <emphasis>B happens-before C</emphasis>, then <emphasis>A happens-before C</emphasis>.</para></formalpara></listitem>
</itemizedlist>
</sidebar>
<para role="continued">Even though actions are only partially ordered, synchronization actions—lock acquisition and release, and reads and writes of <literal>volatile</literal> variables—are totally ordered. This makes it sensible to describe <emphasis>happens-before</emphasis> in terms of “subsequent” lock acquisitions and reads of <literal>volatile</literal> variables.</para>
<para><link linkend="ch16fig02" preference="1">Figure 16.2</link> illustrates the <emphasis>happens-before</emphasis> relation when two threads synchronize using a common lock. All the actions within thread <emphasis>A</emphasis> are ordered by the program <?docpage num="342"?><indexterm id="iddle1119" significance="normal"><?indexkey A?><?primarykey AQS (AbstractQueuedSynchronizer) framework?><?secondarykey FUTURETASK IMPLEMENTATION?><primary><emphasis role="strong">AQS (AbstractQueuedSynchronizer) framework</emphasis></primary><secondary><literal>FutureTask</literal> implementation</secondary></indexterm><indexterm id="iddle1120" significance="normal"><?indexkey A?><?primarykey AQS (AbstractQueuedSynchronizer) framework?><?secondarykey FUTURETASK IMPLEMENTATION?><?tertiarykey PIGGYBACKING USE?><primary><emphasis role="strong">AQS (AbstractQueuedSynchronizer) framework</emphasis></primary><secondary><literal>FutureTask</literal> implementation</secondary><tertiary>piggybacking use</tertiary></indexterm><indexterm id="iddle2396" significance="normal"><?indexkey F?><?primarykey fragility?><?secondarykey ISSUES AND CAUSES?><?tertiarykey PIGGYBACKING?><primary><emphasis role="strong">fragility</emphasis></primary><secondary>issues and causes</secondary><tertiary>piggybacking</tertiary></indexterm><indexterm id="iddle2614" significance="normal"><?indexkey H?><?primarykey happens-before?><?secondarykey PIGGYBACKING?><primary><emphasis role="strong">happens-before</emphasis></primary><secondary>piggybacking</secondary></indexterm><indexterm id="iddle3413" significance="normal"><?indexkey O?><?primarykey order(ing)?><?secondarykey PARTIAL?><?tertiarykey HAPPENS-BEFORE, PIGGYBACKING?><primary><emphasis role="strong">order(ing)</emphasis></primary><secondary>partial</secondary><tertiary>happens-before, piggybacking</tertiary></indexterm><indexterm id="iddle3464" significance="normal"><?indexkey P?><?primarykey partial ordering?><?secondarykey HAPPENS-BEFORE?><?tertiarykey PIGGYBACKING?><primary><emphasis role="strong">partial ordering</emphasis></primary><secondary>happens-before</secondary><tertiary>piggybacking</tertiary></indexterm><indexterm id="iddle3554" significance="normal"><?indexkey P?><?primarykey piggybacking?><?secondarykey ON SYNCHRONIZATION?><primary><emphasis role="strong">piggybacking</emphasis></primary><secondary>on synchronization</secondary></indexterm><indexterm id="iddle4562" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey PIGGYBACKING?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>piggybacking</secondary></indexterm>order rule, as are the actions within thread <emphasis>B</emphasis>. Because <emphasis>A</emphasis> releases lock <emphasis>M</emphasis> and <emphasis>B</emphasis> subsequently acquires <emphasis>M</emphasis>, all the actions in <emphasis>A</emphasis> before releasing the lock are therefore ordered before the actions in <emphasis>B</emphasis> after acquiring the lock. When two threads synchronize on <emphasis>different</emphasis> locks, we can’t say anything about the ordering of actions between them—there is no <emphasis>happens-before</emphasis> relation between the actions in the two threads.</para>
<figure float="1" id="ch16fig02" label="16.2" xreflabel="16.2" condition="342">

<title id="ch16fig02__title">Illustration of <emphasis>Happens-before</emphasis> in the Java Memory Model.</title>
<mediaobject float="0">
<imageobject>
<imagedata depth="390" fileref="graphics/16fig02.gif" format="GIF" width="500"/></imageobject>

</mediaobject>
</figure>
</section>
<section id="ch16lev2sec4" label="16.1.4" xreflabel="16.1.4">
<title id="ch16lev2sec4__title">Piggybacking on Synchronization</title>
<para>Because of the strength of the <emphasis>happens-before</emphasis> ordering, you can sometimes piggyback on the visibility properties of an existing synchronization. This entails combining the program order rule for <emphasis>happens-before</emphasis> with one of the other ordering rules (usually the monitor lock or volatile variable rule) to order accesses to a variable not otherwise guarded by a lock. This technique is very sensitive to the order in which statements occur and is therefore quite fragile; it is an advanced technique that should be reserved for squeezing the last drop of performance out of the most performance-critical classes like <literal>ReentrantLock</literal>.</para>
<para>The implementation of the protected <literal>AbstractQueuedSynchronizer</literal> methods in <literal>FutureTask</literal> illustrates piggybacking. AQS maintains an integer of synchronizer state that <literal>FutureTask</literal> uses to store the task state: running, completed, or <?docpage num="343"?><indexterm id="iddle2190" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SYNC?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>Sync</literal></secondary></indexterm>cancelled. But <literal>FutureTask</literal> also maintains additional variables, such as the result of the computation. When one thread calls <literal>set</literal> to save the result and another thread calls <literal>get</literal> to retrieve it, the two had better be ordered by <emphasis>happens-before</emphasis>. This could be done by making the reference to the result <literal>volatile</literal>, but it is possible to exploit existing synchronization to achieve the same result at lower cost.</para>
<para><literal>FutureTask</literal> is carefully crafted to ensure that a successful call to <literal>tryReleaseShared</literal> always <emphasis>happens-before</emphasis> a subsequent call to <literal>tryAcquireShared</literal>; <literal>try-ReleaseShared</literal> always writes to a volatile variable that is read by <literal>tryAcquire-Shared</literal>. <link linkend="ch16list02" preference="0">Listing 16.2</link> shows the <literal>innerSet</literal> and <literal>innerGet</literal> methods that are called when the result is saved or retrieved; since <literal>innerSet</literal> writes <literal>result</literal> before calling <literal>releaseShared</literal> (which calls <literal>tryReleaseShared</literal>) and <literal>innerGet</literal> reads <literal>result</literal> after calling <literal>acquireShared</literal> (which calls <literal>tryAcquireShared</literal>), the program order rule combines with the volatile variable rule to ensure that the write of <literal>result</literal> in <literal>innerGet</literal> <emphasis>happens-before</emphasis> the read of <literal>result</literal> in <literal>innerGet</literal>.</para>
<example id="ch16list02" label="16.2" role="Listing" xreflabel="16.2" condition="343">
<title id="ch16list02__title">Inner Class of <literal>FutureTask</literal> Illustrating Synchronization Piggybacking.</title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="45" fileref="graphics/face1.jpg" format="JPG" width="45"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered"><emphasis>// Inner class of FutureTask</emphasis>
private final class Sync extends AbstractQueuedSynchronizer {
    private static final int RUNNING = 1, RAN = 2, CANCELLED = 4;
    private V result;
    private Exception exception;

    void innerSet(V v) {
        while (true) {
            int s = getState();
            if (ranOrCancelled(s))
                return;
            if (compareAndSetState(s, RAN))
                break;
        }
        result = v;
        releaseShared(0);
        done();
    }

    V innerGet() throws InterruptedException, ExecutionException {
        acquireSharedInterruptibly(0);
        if (getState() == CANCELLED)
            throw new CancellationException();
        if (exception != null)
            throw new ExecutionException(exception);
        return result;
    }
}
</programlisting>
</example>
<para><?docpage num="344"?><indexterm id="iddle3553" significance="normal"><?indexkey P?><?primarykey piggybacking?><primary><emphasis role="strong">piggybacking</emphasis></primary></indexterm><indexterm id="iddle3735" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey UNSAFE?><primary><emphasis role="strong">publication</emphasis></primary><secondary>unsafe</secondary></indexterm>We call this technique “piggybacking” because it uses an existing <emphasis>happensbefore</emphasis> ordering that was created for some other reason to ensure the visibility of object <emphasis>X</emphasis>, rather than creating a <emphasis>happens-before</emphasis> ordering specifically for publishing <emphasis>X</emphasis>.</para>
<para>Piggybacking of the sort employed by <literal>FutureTask</literal> is quite fragile and should not be undertaken casually. However, in some cases piggybacking is perfectly reasonable, such as when a class commits to a <emphasis>happens-before</emphasis> ordering between methods as part of its specification. For example, safe publication using a <literal>BlockingQueue</literal> is a form of piggybacking. One thread putting an object on a queue and another thread subsequently retrieving it constitutes safe publication because there is guaranteed to be sufficient internal synchronization in a <literal>BlockingQueue</literal> implementation to ensure that the enqueue <emphasis>happens-before</emphasis> the dequeue.</para>
<para>Other <emphasis>happens-before</emphasis> orderings guaranteed by the class library include:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para>Placing an item in a thread-safe collection <emphasis>happens-before</emphasis> another thread retrieves that item from the collection;</para></listitem>
<listitem><para>Counting down on a <literal>CountDownLatch</literal> <emphasis>happens-before</emphasis> a thread returns from <literal>await</literal> on that latch;</para></listitem>
<listitem><para>Releasing a permit to a <literal>Semaphore</literal> <emphasis>happens-before</emphasis> acquiring a permit from that same <literal>Semaphore</literal>;</para></listitem>
<listitem><para>Actions taken by the task represented by a <literal>Future</literal> <emphasis>happens-before</emphasis> another thread successfully returns from <literal>Future.get</literal>;</para></listitem>
<listitem><para>Submitting a <literal>Runnable</literal> or <literal>Callable</literal> to an <literal>Executor</literal> <emphasis>happens-before</emphasis> the task begins execution; and</para></listitem>
<listitem><para>A thread arriving at a <literal>CyclicBarrier</literal> or <literal>Exchanger</literal> <emphasis>happens-before</emphasis> the other threads are released from that same barrier or exchange point. If <literal>CyclicBarrier</literal> uses a barrier action, arriving at the barrier <emphasis>happens-before</emphasis> the barrier action, which in turn <emphasis>happens-before</emphasis> threads are released from the barrier.</para></listitem>
</itemizedlist>
</section>
</section>
<section id="ch16lev1sec2" condition="344" label="16.2" xreflabel="16.2"><?docpage num="344"?>
<title id="ch16lev1sec2__title">Publication</title>
<para><link linkend="ch03" preference="0">Chapter 3</link> explored how an object could be safely or improperly published. The safe publication techniques described there derive their safety from guarantees provided by the JMM; the risks of improper publication are consequences of the absence of a <emphasis>happens-before</emphasis> ordering between publishing a shared object and accessing it from another thread.</para>
<section id="ch16lev2sec5" label="16.2.1" xreflabel="16.2.1">
<title id="ch16lev2sec5__title">Unsafe Publication</title>
<para>The possibility of reordering in the absence of a <emphasis>happens-before</emphasis> relationship explains why publishing an object without adequate synchronization can allow another thread to see a <emphasis>partially constructed object</emphasis> (see <link linkend="ch03lev1sec5" preference="0">Section 3.5</link>). Initializing a new object involves writing to variables—the new object’s fields. Similarly, publishing a reference involves writing to another variable—the reference to the new object. <?docpage num="345"?><?docpage num="346"?><indexterm id="iddle2211" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey UNSAFELAZYINITIALIZATION?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>UnsafeLazyInitialization</literal></secondary></indexterm><indexterm id="iddle2739" significance="normal"><?indexkey I?><?primarykey initialization?><?secondarykey LAZY?><?tertiarykey UNSAFE PUBLICATION RISKS?><primary><emphasis role="strong">initialization</emphasis></primary><secondary>lazy</secondary><tertiary>unsafe publication risks</tertiary></indexterm><indexterm id="iddle2949" significance="normal"><?indexkey L?><?primarykey lazy initialization?><?secondarykey UNSAFE PUBLICATION RISKS?><primary><emphasis role="strong">lazy initialization</emphasis></primary><secondary>unsafe publication risks</secondary></indexterm>If you do not ensure that publishing the shared reference <emphasis>happens-before</emphasis> another thread loads that shared reference, then the write of the reference to the new object can be reordered (from the perspective of the thread consuming the object) with the writes to its fields. In that case, another thread could see an up-to-date value for the object reference but <emphasis>out-of-date values for some or all of that object’s state</emphasis>—a partially constructed object.</para>
<para>Unsafe publication can happen as a result of an incorrect lazy initialization, as shown in Figure 16.3. At first glance, the only problem here seems to be the race condition described in <link linkend="ch02lev2sec3" preference="0">Section 2.2.2</link>. Under certain circumstances, such as when all instances of the <literal>Resource</literal> are identical, you might be willing to overlook these (along with the inefficiency of possibly creating the <literal>Resource</literal> more than once). Unfortunately, even if these defects are overlooked, <literal>UnsafeLazyInitialization</literal> is still not safe, because another thread could observe a reference to a partially constructed <literal>Resource</literal>.</para>
<example id="ch16list03" label="16.3" role="Listing" xreflabel="16.3" condition="345">
<title id="ch16list03__title">Unsafe Lazy Initialization. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@NotThreadSafe
public class UnsafeLazyInitialization {
    private static Resource resource;

    public static Resource getInstance() {
        if (resource == null)
            resource = new Resource();  // unsafe publication
        return resource;
    }
}
</programlisting>
</example>
<para>Suppose thread <emphasis>A</emphasis> is the first to invoke <literal>getInstance</literal>. It sees that <literal>resource</literal> is <literal>null</literal>, instantiates a new <literal>Resource</literal>, and sets <literal>resource</literal> to reference it. When thread <emphasis>B</emphasis> later calls <literal>getInstance</literal>, it might see that <literal>resource</literal> already has a non-null value and just use the already constructed <literal>Resource</literal>. This might look harmless at first, but <emphasis>there is no happens-before ordering between the writing of resource in A and the reading of resource in B</emphasis>. A data race has been used to publish the object, and therefore <emphasis>B</emphasis> is not guaranteed to see the correct state of the <literal>Resource</literal>.</para>
<para>The <literal>Resource</literal> constructor changes the fields of the freshly allocated <literal>Resource</literal> from their default values (written by the <literal>Object</literal> constructor) to their initial values. Since neither thread used synchronization, <emphasis>B</emphasis> could possibly see <emphasis>A</emphasis>’s actions in a different order than <emphasis>A</emphasis> performed them. So even though <emphasis>A</emphasis> initialized the <literal>Resource</literal> before setting <literal>resource</literal> to reference it, <emphasis>B</emphasis> could see the write to <literal>resource</literal> as occurring <emphasis>before</emphasis> the writes to the fields of the <literal>Resource</literal>. <emphasis>B</emphasis> could thus see a partially constructed <literal>Resource</literal> that may well be in an invalid state—and whose state may unexpectedly change later.</para>
<sidebar float="1" id="ch16sb02" condition="345"><title/>
<para><?docpage num="346"?><indexterm id="iddle2529" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey HAPPENS-BEFORE USE?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>happens-before use</secondary></indexterm><indexterm id="iddle2699" significance="normal"><?indexkey I?><?primarykey idioms?><?secondarykey SAFE INITIALIZATION?><primary><emphasis role="strong">idioms</emphasis></primary><secondary>safe initialization</secondary></indexterm><indexterm id="iddle2743" significance="normal"><?indexkey I?><?primarykey initialization?><?secondarykey SAFETY?><?tertiarykey IDIOMS FOR?><primary><emphasis role="strong">initialization</emphasis></primary><secondary>safety</secondary><tertiary>idioms for</tertiary></indexterm><indexterm id="iddle2901" significance="normal"><?indexkey J?><?primarykey Java Programming Language, The?><primary><emphasis role="strong"><emphasis>Java Programming Language, The</emphasis></emphasis></primary></indexterm><indexterm id="iddle3727" significance="normal"><?indexkey P?><?primarykey publication?><?secondarykey SAFE?><primary><emphasis role="strong">publication</emphasis></primary><secondary>safe</secondary></indexterm><indexterm id="iddle4035" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey INITIALIZATION?><?tertiarykey IDIOMS FOR?><primary><emphasis role="strong">safety</emphasis></primary><secondary>initialization</secondary><tertiary>idioms for</tertiary></indexterm>With the exception of immutable objects, it is not safe to use an object that has been initialized by another thread unless the publication <emphasis>happensbefore</emphasis> the consuming thread uses it.</para>
</sidebar>
</section>
<section id="ch16lev2sec6" label="16.2.2" xreflabel="16.2.2">
<title id="ch16lev2sec6__title">Safe Publication</title>
<para>The safe-publication idioms described in <link linkend="ch03" preference="0">Chapter 3</link> ensure that the published object is visible to other threads because they ensure the publication <emphasis>happens-before</emphasis> the consuming thread loads a reference to the published object. If thread <emphasis>A</emphasis> places <emphasis>X</emphasis> on a <literal>BlockingQueue</literal> (and no thread subsequently modifies it) and thread <emphasis>B</emphasis> retrieves it from the queue, <emphasis>B</emphasis> is guaranteed to see <emphasis>X</emphasis> as <emphasis>A</emphasis> left it. This is because the <literal>BlockingQueue</literal> implementations have sufficient internal synchronization to ensure that the <literal>put</literal> <emphasis>happens-before</emphasis> the <literal>take</literal>. Similarly, using a shared variable guarded by a lock or a shared volatile variable ensures that reads and writes of that variable are ordered by <emphasis>happens-before</emphasis>.</para>
<para>This <emphasis>happens-before</emphasis> guarantee is actually a stronger promise of visibility and ordering than made by safe publication. When <emphasis>X</emphasis> is safely published from <emphasis>A</emphasis> to <emphasis>B</emphasis>, the safe publication guarantees visibility of the state of <emphasis>X</emphasis>, but not of the state of other variables <emphasis>A</emphasis> may have touched. But if <emphasis>A</emphasis> putting <emphasis>X</emphasis> on a queue <emphasis>happens-before B</emphasis> fetches <emphasis>X</emphasis> from that queue, not only does <emphasis>B</emphasis> see <emphasis>X</emphasis> in the state that <emphasis>A</emphasis> left it (assuming that <emphasis>X</emphasis> has not been subsequently modified by <emphasis>A</emphasis> or anyone else), but <emphasis>B</emphasis> sees <emphasis>everything A</emphasis> did before the handoff (again, subject to the same caveat).<footnote id="ch16fn05" label="5"><para>The JMMguarantees that <emphasis>B</emphasis> sees a value at least as up-to-date as the value that <emphasis>A</emphasis> wrote; subsequent writes may or may not be visible.</para></footnote></para>
<para>Why did we focus so heavily on <literal>@GuardedBy</literal> and safe publication, when the JMM already provides us with the more powerful <emphasis>happens-before</emphasis>? Thinking in terms of handing off object ownership and publication fits better into most program designs than thinking in terms of visibility of individual memory writes. The <emphasis>happens-before</emphasis> ordering operates at the level of individual memory accesses—it is a sort of “concurrency assembly language”. Safe publication operates at a level closer to that of your program’s design.</para>
</section>
<section id="ch16lev2sec7" label="16.2.3" xreflabel="16.2.3">
<title id="ch16lev2sec7__title">Safe Initialization Idioms</title>
<para>It sometimes makes sense to defer initialization of objects that are expensive to initialize until they are actually needed, but we have seen how the misuse of lazy initialization can lead to trouble. <literal>UnsafeLazyInitialization</literal> can be fixed by making the <literal>getResource</literal> method <literal>synchronized</literal>, as shown in <link linkend="ch16list04" preference="0">Listing 16.4</link>. Because the code path through <literal>getInstance</literal> is fairly short (a test and a predicted branch), if <literal>getInstance</literal> is not called frequently by many threads, there is little enough contention for the <literal>SafeLazyInitialization</literal> lock that this approach offers adequate performance.</para>
<para>The treatment of static fields with initializers (or fields whose value is initialized in a static initialization block [JPL 2.2.1 and 2.5.3]) is somewhat special and <?docpage num="347"?><indexterm id="iddle1990" significance="normal"><?indexkey E?><?primarykey Effective Java Programming Language Guide?><primary><emphasis role="strong"><emphasis>Effective Java Programming Language Guide</emphasis></emphasis></primary></indexterm><indexterm id="iddle2696" significance="normal"><?indexkey I?><?primarykey idioms?><?secondarykey LAZY INITIALIZATION HOLDER CLASS?><primary><emphasis role="strong">idioms</emphasis></primary><secondary>lazy initialization holder class</secondary></indexterm><indexterm id="iddle4440" significance="normal"><?indexkey S?><?primarykey static?><?secondarykey INITIALIZER?><?tertiarykey SAFE PUBLICATION MECHANISM?><primary><emphasis role="strong">static</emphasis></primary><secondary>initializer</secondary><tertiary>safe publication mechanism</tertiary></indexterm>offers additional thread-safety guarantees. Static initializers are run by the JVM at class initialization time, after class loading but before the class is used by any thread. Because the JVM acquires a lock during initialization [JLS 12.4.2] and this lock is acquired by each thread at least once to ensure that the class has been loaded, memory writes made during static initialization are automatically visible to all threads. Thus statically initialized objects require no explicit synchronization either during construction or when being referenced. However, this applies only to the <emphasis>as-constructed</emphasis> state—if the object is mutable, synchronization is still required by both readers and writers to make subsequent modifications visible and to avoid data corruption.</para>
<example id="ch16list04" label="16.4" role="Listing" xreflabel="16.4" condition="347">
<title id="ch16list04__title">Thread-safe Lazy Initialization.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class SafeLazyInitialization {
    private static Resource resource;

    public  <emphasis role="strong">synchronized</emphasis>  static Resource getInstance() {
        if (resource == null)
            resource = new Resource();
        return resource;
    }
}
</programlisting>
</example>
<example id="ch16list05" label="16.5" role="Listing" xreflabel="16.5" condition="347">
<title id="ch16list05__title">Eager Initialization.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class EagerInitialization {
    private static Resource resource  = <emphasis role="strong">new Resource();</emphasis>

    public static Resource getResource() { return resource; }
}
</programlisting>
</example>
<para>Using eager initialization, shown in <link linkend="ch16list05" preference="0">Listing 16.5</link>, eliminates the synchronization cost incurred on each call to <literal>getInstance</literal> in <literal>SafeLazyInitialization</literal>. This technique can be combined with the JVM’s lazy class loading to create a lazy initialization technique that does not require synchronization on the common code path. The <emphasis>lazy initialization holder class</emphasis> idiom [EJ Item 48] in <link linkend="ch16list06" preference="0">Listing 16.6</link> uses a class whose only purpose is to initialize the <literal>Resource</literal>. The JVM defers initializing the <literal>ResourceHolder</literal> class until it is actually used [JLS 12.4.1], and because the <literal>Resource</literal> is initialized with a static initializer, no additional synchronization is needed. The first call to <literal>getResource</literal> by any thread causes <literal>ResourceHolder</literal> to be loaded and initialized, at which time the initialization of the <literal>Resource</literal> happens through the static initializer.</para>

<para><?docpage num="348"?></para><example id="ch16list06" label="16.6" role="Listing" xreflabel="16.6" condition="348">

<title id="ch16list06__title">Lazy Initialization Holder Class Idiom.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class ResourceFactory {
     private static class <emphasis role="strong">ResourceHolder {</emphasis>
         public static Resource resource = new Resource();
     }

     public static Resource getResource() {
         return  <emphasis role="strong">ResourceHolder.resource ;</emphasis>
     }
}
</programlisting>
</example>
</section>
<section id="ch16lev2sec8" label="16.2.4" xreflabel="16.2.4">
<title id="ch16lev2sec8__title">Double-checked Locking</title>
<para><indexterm id="iddle1047" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><seealso> <link linkend="iddle1943" preference="0"><emphasis role="strong">design patterns</emphasis></link>.</seealso></indexterm><indexterm id="iddle1048" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><seealso> <link linkend="iddle2687" preference="0"><emphasis role="strong">idioms</emphasis></link>.</seealso></indexterm><indexterm id="iddle1049" significance="normal"><?indexkey A?><?primarykey algorithm(s)?><primary><emphasis role="strong">algorithm(s)</emphasis></primary><seealso> <link linkend="iddle4645" preference="0"><emphasis role="strong">task(s)</emphasis>, representation</link>.</seealso></indexterm><indexterm id="iddle1943" significance="normal"><?indexkey D?><?primarykey design patterns?><primary><emphasis role="strong">design patterns</emphasis></primary></indexterm><indexterm id="iddle1944" significance="normal"><?indexkey D?><?primarykey design patterns?><?secondarykey ANTIPATTERN EXAMPLE?><primary><emphasis role="strong">design patterns</emphasis></primary><secondary>antipattern example</secondary></indexterm><indexterm id="iddle1945" significance="normal"><?indexkey D?><?primarykey design patterns?><?secondarykey ANTIPATTERN EXAMPLE?><?tertiarykey DOUBLE-CHECKED LOCKING?><primary><emphasis role="strong">design patterns</emphasis></primary><secondary>antipattern example</secondary><tertiary>double-checked locking</tertiary></indexterm><indexterm id="iddle1968" significance="normal"><?indexkey D?><?primarykey double-checked locking (DCL)?><primary><emphasis role="strong">double-checked locking (DCL)</emphasis></primary></indexterm><indexterm id="iddle2687" significance="normal"><?indexkey I?><?primarykey idioms?><primary><emphasis role="strong">idioms</emphasis></primary><seealso> <link linkend="iddle1047" preference="0"><emphasis role="strong">algorithm(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2688" significance="normal"><?indexkey I?><?primarykey idioms?><primary><emphasis role="strong">idioms</emphasis></primary><seealso> <link linkend="iddle1635" preference="0"><emphasis role="strong">conventions</emphasis></link>.</seealso></indexterm><indexterm id="iddle2689" significance="normal"><?indexkey I?><?primarykey idioms?><primary><emphasis role="strong">idioms</emphasis></primary><seealso> <link linkend="iddle1943" preference="0"><emphasis role="strong">design patterns</emphasis></link>.</seealso></indexterm><indexterm id="iddle2690" significance="normal"><?indexkey I?><?primarykey idioms?><primary><emphasis role="strong">idioms</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle2691" significance="normal"><?indexkey I?><?primarykey idioms?><primary><emphasis role="strong">idioms</emphasis></primary><seealso> <link linkend="iddle3567" preference="0"><emphasis role="strong">policy(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle2692" significance="normal"><?indexkey I?><?primarykey idioms?><primary><emphasis role="strong">idioms</emphasis></primary><seealso> <link linkend="iddle3130" preference="0"><emphasis role="strong">lock(ing)</emphasis>, protocols</link>.</seealso></indexterm><indexterm id="iddle2693" significance="normal"><?indexkey I?><?primarykey idioms?><primary><emphasis role="strong">idioms</emphasis></primary><seealso> <link linkend="iddle1929" preference="0"><emphasis role="strong">design</emphasis>, strategies</link>.</seealso></indexterm><indexterm id="iddle2694" significance="normal"><?indexkey I?><?primarykey idioms?><?secondarykey DOUBLE-CHECKED LOCKING (DCL)?><primary><emphasis role="strong">idioms</emphasis></primary><secondary>double-checked locking (DCL)</secondary></indexterm><indexterm id="iddle2695" significance="normal"><?indexkey I?><?primarykey idioms?><?secondarykey DOUBLE-CHECKED LOCKING (DCL)?><?tertiarykey AS BAD PRACTICE?><primary><emphasis role="strong">idioms</emphasis></primary><secondary>double-checked locking (DCL)</secondary><tertiary>as bad practice</tertiary></indexterm><indexterm id="iddle2697" significance="normal"><?indexkey I?><?primarykey idioms?><?secondarykey LAZY INITIALIZATION HOLDER CLASS?><primary><emphasis role="strong">idioms</emphasis></primary><secondary>lazy initialization holder class</secondary></indexterm><indexterm id="iddle2738" significance="normal"><?indexkey I?><?primarykey initialization?><?secondarykey LAZY?><?tertiarykey SAFE IDIOM FOR?><primary><emphasis role="strong">initialization</emphasis></primary><secondary>lazy</secondary><tertiary>safe idiom for</tertiary></indexterm><indexterm id="iddle2948" significance="normal"><?indexkey L?><?primarykey lazy initialization?><?secondarykey SAFE IDIOM FOR?><primary><emphasis role="strong">lazy initialization</emphasis></primary><secondary>safe idiom for</secondary></indexterm><indexterm id="iddle3514" significance="normal"><?indexkey P?><?primarykey performance?><?secondarykey OPTIMIZATION?><?tertiarykey BAD PRACTICES?><primary><emphasis role="strong">performance</emphasis></primary><secondary>optimization</secondary><tertiary>bad practices</tertiary></indexterm><indexterm id="iddle3860" significance="normal"><?indexkey R?><?primarykey representation?><primary><emphasis role="strong">representation</emphasis></primary><seealso> <link linkend="iddle1047" preference="0"><emphasis role="strong">algorithm(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle3861" significance="normal"><?indexkey R?><?primarykey representation?><primary><emphasis role="strong">representation</emphasis></primary><seealso> <link linkend="iddle4463" preference="0"><emphasis role="strong">strategies</emphasis>, design</link>.</seealso></indexterm><indexterm id="iddle3862" significance="normal"><?indexkey R?><?primarykey representation?><primary><emphasis role="strong">representation</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle3863" significance="normal"><?indexkey R?><?primarykey representation?><primary><emphasis role="strong">representation</emphasis></primary><seealso> <link linkend="iddle4377" preference="0"><emphasis role="strong">state(s)</emphasis></link>.</seealso></indexterm><indexterm id="iddle4537" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey BAD PRACTICES?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>bad practices</secondary></indexterm><indexterm id="iddle4538" significance="normal"><?indexkey S?><?primarykey synchronization/synchronized?><?secondarykey BAD PRACTICES?><?tertiarykey DOUBLE-CHECKED LOCKING?><primary><emphasis role="strong">synchronization/<literal>synchronized</literal></emphasis></primary><secondary>bad practices</secondary><tertiary>double-checked locking</tertiary></indexterm>No book on concurrency would be complete without a discussion of the infamous double-checked locking (DCL) antipattern, shown in <link linkend="ch16list07" preference="0">Listing 16.7</link>. In very early JVMs, synchronization, even uncontended synchronization, had a significant performance cost. As a result, many clever (or at least clever-looking) tricks were invented to reduce the impact of synchronization—some good, some bad, and some ugly. DCL falls into the “ugly” category.</para>
<para>Again, because the performance of early JVMs left something to be desired, lazy initialization was often used to avoid potentially unnecessary expensive operations or reduce application startup time. A properly written lazy initialization method requires synchronization. But at the time, synchronization was slow and, more importantly, not completely understood: the exclusion aspects were well enough understood, but the visibility aspects were not.</para>
<para>DCL purported to offer the best of both worlds—lazy initialization without paying the synchronization penalty on the common code path. The way it worked was first to check whether initialization was needed without synchronizing, and if the <literal>resource</literal> reference was not <literal>null</literal>, use it. Otherwise, synchronize and check again if the <literal>Resource</literal> is initialized, ensuring that only one thread actually initializes the shared <literal>Resource</literal>. The common code path—fetching a reference to an already constructed <literal>Resource</literal>—doesn’t use synchronization. And that’s where the problem is: as described in <link linkend="ch16lev2sec5" preference="0">Section 16.2.1</link>, it is possible for a thread to see a partially constructed <literal>Resource</literal>.</para>
<para>The real problem with DCL is the assumption that the worst thing that can happen when reading a shared object reference without synchronization is to erroneously see a stale value (in this case, <literal>null</literal>); in that case the DCL idiom compensates for this risk by trying again with the lock held. But the worst case is actually considerably worse—it is possible to see a current value of the reference but stale values for the object’s state, meaning that the object could be seen to be in an invalid or incorrect state.</para>
<para>Subsequent changes in the JMM (Java 5.0 and later) have enabled DCL to work <emphasis>if</emphasis> <literal>resource</literal> is made <literal>volatile</literal>, and the performance impact of this is small since volatile reads are usually only slightly more expensive than nonvolatile reads. <?docpage num="349"?><indexterm id="iddle1969" significance="normal"><?indexkey D?><?primarykey double-checked locking (DCL)?><primary><emphasis role="strong">double-checked locking (DCL)</emphasis></primary></indexterm><indexterm id="iddle2112" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey DOUBLECHECKEDLOCKING?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>DoubleCheckedLocking</literal></secondary></indexterm><indexterm id="iddle2535" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INITIALIZATION SAFETY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>initialization safety</secondary></indexterm><indexterm id="iddle2744" significance="normal"><?indexkey I?><?primarykey initialization?><?secondarykey SAFETY?><?tertiarykey JMM SUPPORT?><primary><emphasis role="strong">initialization</emphasis></primary><secondary>safety</secondary><tertiary>JMM support</tertiary></indexterm><indexterm id="iddle4036" significance="normal"><?indexkey S?><?primarykey safety?><?secondarykey INITIALIZATION?><?tertiarykey JMM SUPPORT?><primary><emphasis role="strong">safety</emphasis></primary><secondary>initialization</secondary><tertiary>JMM support</tertiary></indexterm>However, this is an idiom whose utility has largely passed—the forces that motivated it (slow uncontended synchronization, slow JVM startup) are no longer in play, making it less effective as an optimization. The lazy initialization holder idiom offers the same benefits and is easier to understand.</para>
<example id="ch16list07" label="16.7" role="Listing" xreflabel="16.7" condition="349">
<title id="ch16list07__title">Double-checked-locking Antipattern. <emphasis>Don’t Do this.</emphasis></title>
<mediaobject float="0" role="titleicon"><imageobject><imagedata depth="52" fileref="graphics/face.jpg" format="JPG" width="52"/></imageobject></mediaobject>
<programlisting format="linespecific" linenumbering="unnumbered">@NotThreadSafe
public class DoubleCheckedLocking {
    private static Resource resource;

    public static Resource getInstance() {
        if (resource == null) {
            synchronized (DoubleCheckedLocking.class) {
                if (resource == null)
                    resource = new Resource();
            }
        }
        return resource;
    }
}
</programlisting>
</example>
</section>
</section>
<section id="ch16lev1sec3" condition="349" label="16.3" xreflabel="16.3"><?docpage num="349"?>
<title id="ch16lev1sec3__title">Initialization Safety</title>
<para>The guarantee of <emphasis>initialization safety</emphasis> allows properly constructed <emphasis>immutable</emphasis> objects to be safely shared across threads without synchronization, regardless of how they are published—even if published using a data race. (This means that <literal>UnsafeLazyInitialization</literal> is actually safe <emphasis>if</emphasis> <literal>Resource</literal> is immutable.)</para>
<para>Without initialization safety, supposedly immutable objects like <literal>String</literal> can appear to change their value if synchronization is not used by both the publishing and consuming threads. The security architecture relies on the immutability of <literal>String</literal>; the lack of initialization safety could create security vulnerabilities that allow malicious code to bypass security checks.</para>
<sidebar float="1" id="ch16sb03" condition="349"><title/>
<para>Initialization safety guarantees that for <emphasis>properly constructed</emphasis> objects, all threads will see the correct values of final fields that were set by the constructor, regardless of how the object is published. Further, any variables that can be <emphasis>reached</emphasis> through a final field of a properly constructed object (such as the elements of a final array or the contents of a <literal>HashMap</literal> referenced by a final field) are also guaranteed to be visible to other threads. <footnote id="ch16fn06" label="6"><para>This applies only to objects that are reachable <emphasis>only</emphasis> through <literal>final</literal> fields of the object under construction.</para></footnote></para>
</sidebar>
<para><?docpage num="350"?><indexterm id="iddle2172" significance="normal"><?indexkey E?><?primarykey example classes?><?secondarykey SAFESTATES?><primary><emphasis role="strong">example classes</emphasis></primary><secondary><literal>SafeStates</literal></secondary></indexterm><indexterm id="iddle2536" significance="normal"><?indexkey G?><?primarykey guidelines?><?secondarykey INITIALIZATION SAFETY?><primary><emphasis role="strong">guidelines</emphasis></primary><secondary>initialization safety</secondary></indexterm><indexterm id="iddle2710" significance="normal"><?indexkey I?><?primarykey immutable/immutability?><?secondarykey INITIALIZATION SAFETY LIMITATION?><primary><emphasis role="strong">immutable/immutability</emphasis></primary><secondary>initialization safety limitation</secondary></indexterm><indexterm id="iddle3853" significance="normal"><?indexkey R?><?primarykey reordering?><?secondarykey INITIALIZATION SAFETY LIMITATION?><primary><emphasis role="strong">reordering</emphasis></primary><secondary>initialization safety limitation</secondary></indexterm>For objects with final fields, initialization safety prohibits reordering any part of construction with the initial load of a reference to that object. All writes to final fields made by the constructor, as well as to any variables reachable through those fields, become “frozen” when the constructor completes, and any thread that obtains a reference to that object is guaranteed to see a value that is at least as up to date as the frozen value. Writes that initialize variables reachable through final fields are not reordered with operations following the post-construction freeze.</para>
<para>Initialization safety means that <literal>SafeStates</literal> in <link linkend="ch16list08" preference="0">Listing 16.8</link> could be safely published even through unsafe lazy initialization or stashing a reference to a <literal>SafeStates</literal> in a public static field with no synchronization, even though it uses no synchronization and relies on the non-thread-safe <literal>HashSet</literal>.</para>
<example id="ch16list08" label="16.8" role="Listing" xreflabel="16.8" condition="350">
<title id="ch16list08__title">Initialization Safety for Immutable Objects.</title>
<programlisting format="linespecific" linenumbering="unnumbered">@ThreadSafe
public class SafeStates {
    private  <emphasis role="strong">final</emphasis>  Map&lt;String, String&gt; states;

    public SafeStates() {
        states = new HashMap&lt;String, String&gt;();
        states.put("alaska", "AK");
        states.put("alabama", "AL");
        ...
        states.put("wyoming", "WY");
    }

    public String getAbbreviation(String s) {
        return states.get(s);
    }
}
</programlisting>
</example>
<para>However, a number of small changes to <literal>SafeStates</literal> would take away its thread safety. If <literal>states</literal> were not final, or if any method other than the constructor modified its contents, initialization safety would not be strong enough to safely access <literal>SafeStates</literal> without synchronization. If <literal>SafeStates</literal> had other nonfinal fields, other threads might still see incorrect values of those fields. And allowing the object to escape during construction invalidates the initialization-safety guarantee.</para>
<sidebar float="1" id="ch16sb04" condition="350"><title/>
<para>Initialization safety makes visibility guarantees only for the values that are reachable through final fields as of the time the constructor finishes. For values reachable through nonfinal fields, or values that may change after construction, you must use synchronization to ensure visibility.</para>
</sidebar>
</section>



<section id="ch16lev1sec4" condition="351" label="" xreflabel="">
<?docpage num="351"?><?docpage num="352"?>
<title id="ch16lev1sec4__title">Summary</title>
<para>The Java Memory Model specifies when the actions of one thread on memory are guaranteed to be visible to another. The specifics involve ensuring that operations are ordered by a partial ordering called <emphasis>happens-before</emphasis>, which is specified at the level of individual memory and synchronization operations. In the absence of sufficient synchronization, some very strange things can happen when threads access shared data. However, the higher-level rules offered in <link linkend="ch02" preference="0">Chapters 2</link> and <link linkend="ch03" preference="0">3</link>, such as <literal>@GuardedBy</literal> and safe publication, can be used to ensure thread safety without resorting to the low-level details of <emphasis>happens-before</emphasis>.</para>
</section>

</chapter>

<appendix id="app01" xreflabel="A" condition="353" label="A"><?docpage num="353"?><title id="app01__title">Annotations for Concurrency</title>




<para><indexterm id="iddle1093" significance="normal"><?indexkey A?><?primarykey annotations?><primary><emphasis role="strong">annotations</emphasis></primary><seealso> <link linkend="iddle2518" preference="0"><emphasis role="strong">guidelines</emphasis>, documentation</link>.</seealso></indexterm><indexterm id="iddle1098" significance="normal"><?indexkey A?><?primarykey annotations?><?secondarykey %?><primary><emphasis role="strong">annotations</emphasis></primary><secondary><literal>@Immutable</literal></secondary></indexterm><indexterm id="iddle1099" significance="normal"><?indexkey A?><?primarykey annotations?><?secondarykey %?><primary><emphasis role="strong">annotations</emphasis></primary><secondary><literal>@NotThreadSafe</literal></secondary></indexterm><indexterm id="iddle1100" significance="normal"><?indexkey A?><?primarykey annotations?><?secondarykey %?><primary><emphasis role="strong">annotations</emphasis></primary><secondary><literal>@ThreadSafe</literal></secondary></indexterm><indexterm id="iddle1456" significance="normal"><?indexkey C?><?primarykey concurrent/concurrency?><?secondarykey ANNOTATIONS?><primary><emphasis role="strong">concurrent/concurrency</emphasis></primary><secondary>annotations</secondary></indexterm><indexterm id="iddle1828" significance="normal"><?indexkey D?><?primarykey debugging?><?secondarykey ANNOTATION USE?><primary><emphasis role="strong">debugging</emphasis></primary><secondary>annotation use</secondary></indexterm><indexterm id="iddle1960" significance="normal"><?indexkey D?><?primarykey documentation?><?secondarykey ANNOTATION USE?><primary><emphasis role="strong">documentation</emphasis></primary><secondary>annotation use</secondary></indexterm><indexterm id="iddle2480" significance="normal"><?indexkey G?><?primarykey GuardedBy?><primary sortas="GuardedBy"><emphasis role="strong">@GuardedBy</emphasis></primary></indexterm><indexterm id="iddle2704" significance="normal"><?indexkey I?><?primarykey Immutable?><primary sortas="Immutable"><emphasis role="strong">@Immutable</emphasis></primary></indexterm><indexterm id="iddle3339" significance="normal"><?indexkey N?><?primarykey NotThreadSafe?><primary sortas="NotThreadSafe"><emphasis role="strong">@NotThreadSafe</emphasis></primary></indexterm><indexterm id="iddle4861" significance="normal"><?indexkey T?><?primarykey ThreadSafe?><primary sortas="ThreadSafe"><emphasis role="strong">@ThreadSafe</emphasis></primary></indexterm><indexterm id="iddle4939" significance="normal"><?indexkey T?><?primarykey tools?><?secondarykey ANNOTATION USE?><primary><emphasis role="strong">tools</emphasis></primary><secondary>annotation use</secondary></indexterm>We’ve used annotations such as <literal>@GuardedBy</literal> and <literal>@ThreadSafe</literal> to show how thread-safety promises and synchronization policies can be documented. This appendix documents these annotations; their source code can be downloaded from this book’s website. (There are, of course, additional thread-safety promises and implementation details that should be documented but that are not captured by this minimal set of annotations.)</para>



<section id="app01lev1sec1" condition="353" label="A.1" xreflabel="A.1"><?docpage num="353"?>
<title id="app01lev1sec1__title">Class Annotations</title>
<para>We use three class-level annotations to describe a class’s <emphasis>intended</emphasis> thread-safety promises: <literal>@Immutable</literal>, <literal>@ThreadSafe</literal>, and <literal>@NotThreadSafe</literal>. <literal>@Immutable</literal> means, of course, that the class is immutable, and implies <literal>@ThreadSafe</literal>. <literal>@NotThreadSafe</literal> is optional—if a class is not annotated as thread-safe, it should be presumed not to be thread-safe, but if you want to make it extra clear, use <literal>@NotThreadSafe</literal>.</para>
<para>These annotations are relatively unintrusive and are beneficial to both users and maintainers. Users can see immediately whether a class is thread-safe, and maintainers can see immediately whether thread-safety guarantees must be preserved. Annotations are also useful to a third constituency: tools. Static codeanalysis tools may be able to verify that the code complies with the contract indicated by the annotation, such as verifying that a class annotated with <literal>@Immutable</literal> actually is immutable.</para>
</section>
<section id="app01lev1sec2" condition="353" label="A.2" xreflabel="A.2"><?docpage num="353"?>
<title id="app01lev1sec2__title">Field and Method Annotations</title>
<para>The class-level annotations above are part of the public documentation for the class. Other aspects of a class’s thread-safety strategy are entirely for maintainers and are not part of its public documentation.</para>
<para>Classes that use locking should document which state variables are guarded with which locks, and which locks are used to guard those variables. A common source of inadvertent non-thread-safety is when a thread-safe class consistently uses locking to guard its state, but is later modified to add either new state variables that are not adequately guarded by locking, or new methods that do not <?docpage num="354"?><indexterm id="iddle1096" significance="normal"><?indexkey A?><?primarykey annotations?><?secondarykey %?><primary><emphasis role="strong">annotations</emphasis></primary><secondary><literal>@GuardedBy</literal></secondary></indexterm>use locking properly to guard the existing state variables. Documenting which variables are guarded by which locks can help prevent both types of omissions.</para>
<para><literal>@GuardedBy(lock)</literal> documents that a field or method should be accessed only with a specific lock held. The <literal>lock</literal> argument identifies the lock that should be held when accessing the annotated field or method. The possible values for <literal>lock</literal> are:</para>
<itemizedlist mark="bullet" spacing="normal">
<listitem><para><literal>@GuardedBy("this")</literal>, meaning the intrinsic lock on the containing object (the object of which the method or field is a member);</para></listitem>
<listitem><para><literal>@GuardedBy("</literal><emphasis><literal>fieldName</literal></emphasis><literal>")</literal>, meaning the lock associated with the object referenced by the named field, either an intrinsic lock (for fields that do not refer to a <literal>Lock</literal>) or an explicit <literal>Lock</literal> (for fields that refer to a <literal>Lock</literal>);</para></listitem>
<listitem><para><literal>@GuardedBy("</literal><emphasis><literal>ClassName.fieldName</literal></emphasis><literal>")</literal>, like <literal>@GuardedBy("fieldName")</literal>, but referencing a lock object held in a static field of another class;</para></listitem>
<listitem><para><literal>@GuardedBy("</literal><emphasis><literal>methodName</literal></emphasis><literal>()")</literal>, meaning the lock object that is returned by calling the named method;</para></listitem>
<listitem><para><literal>@GuardedBy("</literal><emphasis><literal>ClassName</literal></emphasis><literal>.class")</literal>, meaning the class literal object for the named class.</para></listitem>
</itemizedlist>
<para role="continued">Using <literal>@GuardedBy</literal> to identify each state variable that needs locking and which lock guards it can assist in maintenance and code reviews, and can help automated analysis tools spot potential thread-safety errors.</para>
</section>

</appendix>

<bibliography id="bib01" condition="355">
<?docpage num="355"?>
<title id="bib01__title">Bibliography</title><para><indexterm id="iddle1201" significance="normal"><?indexkey B?><?primarykey bibliography?><primary><emphasis role="strong">bibliography</emphasis></primary></indexterm></para>
<bibliomixed id="biblio01_001"><author><firstname>Ken</firstname> <surname>Arnold,</surname></author> <author><firstname>James</firstname> <surname>Gosling,</surname></author> and <author><firstname>David</firstname> <surname>Holmes.</surname></author> <citetitle pubwork="book" role="italic">The Java Programming Language</citetitle>, <edition>Fourth Edition</edition>. <publishername>Addison–Wesley</publishername>, <copyright><year>2005</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_002"><author><firstname>David</firstname> <othername role="mi">F.</othername> <surname>Bacon,</surname></author> <author><firstname>Ravi</firstname> <othername role="mi">B.</othername> <surname>Konuru,</surname></author> <author><firstname>Chet</firstname> <surname>Murthy,</surname></author> and <author><firstname>Mauricio</firstname> <othername role="mi">J.</othername> <surname>Serrano.</surname></author> <title>Thin Locks: Featherweight Synchronization for Java</title>. <bibliomisc>In <emphasis>SIGPLAN Conference on Programming Language Design and Implementation</emphasis></bibliomisc>, <pagenums>pages 258</pagenums>–<pagenums>268</pagenums>, <pagenums>1998</pagenums>. <address format="linespecific">URL <otheraddr><ulink url="http://citeseer.ist.psu.edu/bacon98thin.html">http://citeseer.ist.psu.edu/bacon98thin.html</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_003"><author><firstname>Joshua</firstname> <surname>Bloch.</surname></author> <citetitle pubwork="book" role="italic">Effective Java Programming Language Guide</citetitle>. <publishername>Addison–Wesley</publishername>, <copyright><year>2001</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_004"><author><firstname>Joshua</firstname> <surname>Bloch</surname></author> and <author><firstname>Neal</firstname> <surname>Gafter.</surname></author> <citetitle pubwork="book" role="italic">Java Puzzlers</citetitle>. <publishername>Addison–Wesley</publishername>, <copyright><year>2005</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_005"><author><firstname>Hans</firstname> <surname>Boehm.</surname></author> <author><firstname>Destructors,</firstname></author> <author><firstname>Finalizers,</firstname></author> and <author><firstname>Synchronization.</firstname></author> <bibliomisc>In <emphasis>POPL ’03: Proceedings of the 30th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages</emphasis></bibliomisc>, <pagenums>pages 262</pagenums>–<pagenums>272</pagenums>. <publishername>ACM Press</publishername>, <copyright><year>2003</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://doi.acm.org/10.1145/604131.604153">http://doi.acm.org/10.1145/604131.604153</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_006"><author><firstname>Hans</firstname> <surname>Boehm.</surname></author> <author><firstname>Finalization,</firstname></author> <author><firstname>Threads,</firstname></author> and <bibliomisc>the Java Memory Model</bibliomisc>. <title>JavaOne presentation</title>, <copyright><year>2005</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://developers.sun.com/learning/javaoneonline/2005/coreplatform/TS-3281.pdf">http://developers.sun.com/learning/javaoneonline/2005/coreplatform/TS-3281.pdf</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_007"><author><firstname>Joseph</firstname> <surname>Bowbeer.</surname></author> <title>The Last Word in Swing Threads</title>, <copyright><year>2005</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://java.sun.com/products/jfc/tsc/articles/threads/threads3.html">http://java.sun.com/products/jfc/tsc/articles/threads/threads3.html</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_008"><author><firstname>Cliff</firstname> <surname>Click.</surname></author> <title>Performance Myths Exposed. JavaOne presentation</title>, <copyright><year>2003</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_009"><author><firstname>Cliff</firstname> <surname>Click.</surname></author> <title>Performance Myths Revisited. JavaOne presentation</title>, <copyright><year>2005</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://developers.sun.com/learning/javaoneonline/2005/coreplatform/TS-3268.pdf">http://developers.sun.com/learning/javaoneonline/2005/coreplatform/TS-3268.pdf</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_010"><author><firstname>Martin</firstname> <surname>Fowler.</surname></author> <title>Presentation Model</title>, <copyright><year>2005</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://www.martinfowler.com/eaaDev/PresentationModel.html">http://www.martinfowler.com/eaaDev/PresentationModel.html</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_011"><author><firstname>Erich</firstname> <surname>Gamma,</surname></author> <author><firstname>Richard</firstname> <surname>Helm,</surname></author> <author><firstname>Ralph</firstname> <surname>Johnson,</surname></author> and <author><firstname>John</firstname> <surname>Vlissides.</surname></author> <citetitle pubwork="book" role="italic">Design Patterns</citetitle>. <publishername>Addison–Wesley</publishername>, <copyright><year>1995</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_012"><author><firstname>Martin</firstname> <surname>Gardner.</surname></author> <title>The fantastic combinations of John Conway’s new solitaire game ’Life’</title>. <citetitle pubwork="journal" role="italic">Scientific American</citetitle>, <pubdate>October 1970</pubdate>.</bibliomixed>
<bibliomixed id="biblio01_013"><author><firstname>James</firstname> <surname>Gosling,</surname></author> <author><firstname>Bill</firstname> <surname>Joy,</surname></author> <author><firstname>Guy</firstname> <surname>Steele,</surname></author> and <author><firstname>Gilad</firstname> <surname>Bracha.</surname></author> <citetitle pubwork="book" role="italic">The Java Language Specification</citetitle>, <edition>Third Edition</edition>. <publishername>Addison–Wesley</publishername>, <copyright><year>2005</year></copyright>.</bibliomixed>
<?docpage num="356"?>
<bibliomixed id="biblio01_014"><author><firstname>Tim</firstname> <surname>Harris</surname></author> and <author><firstname>Keir</firstname> <surname>Fraser.</surname></author> <title>Language Support for Lightweight Transactions</title>. <bibliomisc>In <emphasis>OOPSLA ’03: Proceedings of the 18th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications</emphasis></bibliomisc>, <pagenums>pages 388</pagenums>–<pagenums>402</pagenums>. <publishername>ACM Press</publishername>, <copyright><year>2003</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://doi.acm.org/10.1145/949305.949340">http://doi.acm.org/10.1145/949305.949340</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_015"><author><firstname>Tim</firstname> <surname>Harris,</surname></author> <author><firstname>Simon</firstname> <surname>Marlow,</surname></author> <author><firstname>Simon</firstname> <surname>Peyton-Jones,</surname></author> and <author><firstname>Maurice</firstname> <surname>Herlihy.</surname></author> <title>Composable Memory Transactions</title>. <bibliomisc>In <emphasis>PPoPP ’05: Proceedings of the Tenth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming</emphasis></bibliomisc>, <pagenums>pages 48</pagenums>–<pagenums>60</pagenums>. <publishername>ACM Press</publishername>, <copyright><year>2005</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://doi.acm.org/10.1145/1065944.1065952">http://doi.acm.org/10.1145/1065944.1065952</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_016"><author><firstname>Maurice</firstname> <surname>Herlihy.</surname></author> <title>Wait-Free Synchronization</title>. <citetitle pubwork="book" role="italic">ACM Transactions on Programming Languages and Systems</citetitle>, <volumenum>13</volumenum>(<issuenum>1</issuenum>):<pagenums>124</pagenums>–<pagenums>149</pagenums>, <copyright><year>1991</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://doi.acm.org/10.1145/114005.102808">http://doi.acm.org/10.1145/114005.102808</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_017"><author><firstname>Maurice</firstname> <surname>Herlihy</surname></author> and <author><firstname>Nir</firstname> <surname>Shavit.</surname></author> <citetitle pubwork="book" role="italic">Multiprocessor Synchronization and Concurrent Data Structures</citetitle>. <publishername>Morgan-Kaufman</publishername>, <copyright><year>2006</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_018"><author><firstname>C. A.</firstname> <othername role="mi">R.</othername> <surname>Hoare.</surname></author> <title>Monitors: An Operating System Structuring Concept</title>. <citetitle pubwork="book" role="italic">Communications of the ACM</citetitle>, <volumenum>17</volumenum>(<issuenum>10</issuenum>):<pagenums>549</pagenums>–<pagenums>557</pagenums>, <copyright><year>1974</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://doi.acm.org/10.1145/355620.361161">http://doi.acm.org/10.1145/355620.361161</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_019"><author><firstname>David</firstname> <surname>Hovemeyer</surname></author> and <author><firstname>William</firstname> <surname>Pugh.</surname></author> <title>Finding Bugs is Easy</title>. <citetitle pubwork="book" role="italic">SIGPLAN Notices</citetitle>, <volumenum>39</volumenum> (<issuenum>12</issuenum>):<pagenums>92</pagenums>–<pagenums>106</pagenums>, <copyright><year>2004</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://doi.acm.org/10.1145/1052883.1052895">http://doi.acm.org/10.1145/1052883.1052895</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_020"><author><firstname>Ramnivas</firstname> <surname>Laddad.</surname></author> <citetitle pubwork="book" role="italic">AspectJ in Action</citetitle>. <publishername>Manning</publishername>, <copyright><year>2003</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_021"><author><firstname>Doug</firstname> <surname>Lea.</surname></author> <citetitle pubwork="book" role="italic">Concurrent Programming in Java</citetitle>, <edition>Second Edition</edition>. <publishername>Addison–Wesley</publishername>, <copyright><year>2000</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_022"><author><firstname>Doug</firstname> <surname>Lea.</surname></author> <title>JSR-133 Cookbook for Compiler Writers</title>. <address format="linespecific">URL <otheraddr><ulink url="http://gee.cs.oswego.edu/dl/jmm/cookbook.html">http://gee.cs.oswego.edu/dl/jmm/cookbook.html</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_023"><author><firstname>J. D.</firstname> <othername role="mi">C.</othername> <surname>Little.</surname></author> <title>A proof of the Queueing Formula <emphasis>L</emphasis> = <emphasis>?W</emphasis>"</title>. <citetitle pubwork="book" role="italic">Operations Research</citetitle>, <volumenum>9</volumenum>: <pagenums>383</pagenums>–<pagenums>387</pagenums>, <copyright><year>1961</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_024"><author><firstname>Jeremy</firstname> <surname>Manson,</surname></author> <author><firstname>William</firstname> <surname>Pugh,</surname></author> and <author><firstname>Sarita</firstname> <othername role="mi">V.</othername> <surname>Adve.</surname></author> <title>The Java Memory Model</title>. <bibliomisc>In <emphasis>POPL ’05: Proceedings of the 32nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages</emphasis></bibliomisc>, <pagenums>pages 378</pagenums>–<pagenums>391</pagenums>. <publishername>ACM Press</publishername>, <copyright><year>2005</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://doi.acm.org/10.1145/1040305.1040336">http://doi.acm.org/10.1145/1040305.1040336</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_025"><author><firstname>George</firstname> <surname>Marsaglia.</surname></author> <title>XorShift RNGs</title>. <citetitle pubwork="book" role="italic">Journal of Statistical Software</citetitle>, <volumenum>8</volumenum>(<issuenum>13</issuenum>), <copyright><year>2003</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://www.jstatsoft.org/v08/i14">http://www.jstatsoft.org/v08/i14</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_026"><author><firstname>Maged</firstname> <othername role="mi">M.</othername> <surname>Michael</surname></author> and <author><firstname>Michael</firstname> <othername role="mi">L.</othername> <surname>Scott.</surname></author> <author><firstname>Simple,</firstname></author> <author><firstname>Fast,</firstname></author> and <author><firstname>Practical</firstname> <surname>Non-Blocking</surname></author> and <author><firstname>Blocking</firstname> <surname>Concurrent</surname></author> <author><firstname>Queue</firstname> <surname>Algorithms.</surname></author> <bibliomisc>In <emphasis>Symposium on Principles of Distributed Computing</emphasis></bibliomisc>, <pagenums>pages 267</pagenums>–<pagenums>275</pagenums>, <copyright><year>1996</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://citeseer.ist.psu.edu/michael96simple.html">http://citeseer.ist.psu.edu/michael96simple.html</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_027"><author><firstname>Mark</firstname> <surname>Moir</surname></author> and <author><firstname>Nir</firstname> <surname>Shavit.</surname></author> <citetitle pubwork="book" role="italic">Concurrent Data Structures</citetitle>, <bibliomisc>In <emphasis>Handbook of Data Structures and Applications</emphasis>, chapter 47</bibliomisc>. <publishername>CRC Press</publishername>, <copyright><year>2004</year></copyright>.</bibliomixed>
<?docpage num="357"?>
<bibliomixed id="biblio01_028"><author><firstname>William</firstname> <surname>Pugh</surname></author> and <author><firstname>Jeremy</firstname> <surname>Manson.</surname></author> <title><indexterm id="iddle2891" significance="normal"><?indexkey J?><?primarykey Java Language Specification, The?><primary><emphasis role="strong"><emphasis>Java Language Specification, The</emphasis></emphasis></primary></indexterm>Java Memory Model and Thread Specification</title>, <copyright><year>2004</year></copyright>. <address format="linespecific">URL <otheraddr><ulink url="http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf">http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf</ulink></otheraddr></address>.</bibliomixed>
<bibliomixed id="biblio01_029"><author><firstname>M.</firstname> <surname>Raynal.</surname></author> <citetitle pubwork="book" role="italic">Algorithms for Mutual Exclusion</citetitle>. <publishername>MIT Press</publishername>, <copyright><year>1986</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_030"><author><firstname>William</firstname> <othername role="mi">N.</othername> <surname>Scherer,</surname></author> <author><firstname>Doug</firstname> <surname>Lea,</surname></author> and <author><firstname>Michael</firstname> <othername role="mi">L.</othername> <surname>Scott.</surname></author> <title>Scalable Synchronous Queues</title>. <bibliomisc>In <emphasis>11th ACM SIGPLAN Symposium on Principles and Practices of Parallel Programming (PPoPP)</emphasis></bibliomisc>, <copyright><year>2006</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_031"><author><firstname>R.</firstname> <othername role="mi">K.</othername> <surname>Treiber.</surname></author> <title>Systems Programming: Coping with Parallelism. Technical Report RJ 5118</title>, <publishername>IBM Almaden Research Center</publishername>, <copyright><year>April 1986</year></copyright>.</bibliomixed>
<bibliomixed id="biblio01_032"><author><firstname>Andrew</firstname> <surname>Wellings.</surname></author> <citetitle pubwork="book" role="italic">Concurrent and Real-Time Programming in Java</citetitle>. <publishername>John Wiley &amp; Sons</publishername>, <copyright><year>2004</year></copyright>.</bibliomixed>
</bibliography>

</part>


<info><cover><mediaobject><imageobject><imagedata fileref="graphics/0321349601_large.jpg"></imagedata></imageobject></mediaobject></cover></info><index/></book>